<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Bryan Travis Smith, Ph.D</title><link href="http://www.bryantravissmith.com/" rel="alternate"></link><link href="http://www.bryantravissmith.com/feeds/galvanize.atom.xml" rel="self"></link><id>http://www.bryantravissmith.com/</id><updated>2015-08-03T10:30:00-07:00</updated><entry><title>Galvanize - Week 06 - Day 5</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-06-05/" rel="alternate"></link><updated>2015-07-10T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-07-10:galvanize/galvanize-data-science-06-05/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 6 - Day 5&lt;/h2&gt;
&lt;p&gt;Since today was friday our quiz was our weekly survey about how we feel about our progress in the program.   Its been pretty static for me.   Instructors are good, I am learning a lot and ready to learn more, and I get the most out of working on the projects.   &lt;/p&gt;
&lt;p&gt;Today was a lecture on time-series models.  In my opinion, it is too much to cover in a single lesson.  The presentations were to0 basic, then jump to a point that anyone who did not have time-series experience couldn't follow because they wouldn't have context.   Being able to abstractly follow a lesson is not the same as walking away with an intuition for the material.   It was one of the few days where we universally walked away without any intuition.  &lt;/p&gt;
&lt;h2&gt;Time Series&lt;/h2&gt;
&lt;p&gt;One of my faviorite aspects of our morning sprint was learning how to use the Pandas datetime (and string) functionality in a way that perserves its underlying use of C.   There were times where I would try to do something in a very hacky sort of way, and it would take a long time.   What I have since learned is that all these tasks can be done using Pandas functionality, but you need to know how to use it in the correct way.   Read the documentation.  Serioursy!&lt;/p&gt;
&lt;h2&gt;Exploring Monthly Birth Data&lt;/h2&gt;
&lt;p&gt;We would given monthly birth data from 1980 to 2010.   Our goal was to try to develop a very basic model and use the timeseries functionality in pandas.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;

&lt;span class="n"&gt;birth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data/birth.txt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;birth&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;shape&lt;/span&gt;
&lt;span class="n"&gt;birth&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;372&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;num_births&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;295&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;286&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;300&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;278&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;272&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;dates = pd.date_range(start=&amp;#39;Jan 1980&amp;#39;,end=&amp;#39;Jan 2011&amp;#39;,freq=&amp;#39;M&amp;#39;)
dates




&amp;lt;class &amp;#39;pandas.tseries.index.DatetimeIndex&amp;#39;&amp;gt;
[1980-01-31, ..., 2010-12-31]
Length: 372, Freq: M, Timezone: None
&lt;/pre&gt;&lt;/div&gt;


&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create a &lt;code&gt;time&lt;/code&gt; variable (range: 1-372) to be used later in the regressions 
and both a &lt;code&gt;month&lt;/code&gt; and &lt;code&gt;year&lt;/code&gt; variable (use &lt;code&gt;pd.DatetimeIndex&lt;/code&gt; to strip these 
values from your dates).&lt;/p&gt;
&lt;p&gt;birth['time_step'] = range(1,373)
birth.head()&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;num_births&lt;/th&gt;
      &lt;th&gt;time_step&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;295&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;286&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;300&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;278&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;272&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;dt_index = pd.DatetimeIndex(dates)
birth[&amp;#39;year&amp;#39;] = dt_index.year
birth[&amp;#39;month&amp;#39;] = dt_index.month
birth[&amp;#39;datetime&amp;#39;] = dt_index
birth.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;num_births&lt;/th&gt;
      &lt;th&gt;time_step&lt;/th&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;month&lt;/th&gt;
      &lt;th&gt;datetime&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;295&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1980-01-31&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;286&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1980-02-29&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;300&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;1980-03-31&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;278&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;1980-04-30&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;272&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;1980-05-31&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;birth = birth.set_index(&amp;#39;datetime&amp;#39;)
birth.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;num_births&lt;/th&gt;
      &lt;th&gt;time_step&lt;/th&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;month&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;datetime&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1980-01-31&lt;/th&gt;
      &lt;td&gt;295&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1980-02-29&lt;/th&gt;
      &lt;td&gt;286&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1980-03-31&lt;/th&gt;
      &lt;td&gt;300&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1980-04-30&lt;/th&gt;
      &lt;td&gt;278&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1980-05-31&lt;/th&gt;
      &lt;td&gt;272&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure(figsize=(14,8))
birth.num_births.plot()
plt.xlabel(&amp;#39;Time&amp;#39;)
plt.ylabel(&amp;quot;Number of Births per Month&amp;quot;)
plt.title(&amp;quot;Number of Births per Month from Jan 1980 to Dec 2010&amp;quot;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_7_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;Now that we have our data in the correct form, we can look at different components of the behavior.  We learned that we can break time series into 4 components:  Trend, Seasonal, Cyclic, and Irreducible Error.   That will be the goal for the rest of our morning sprint.&lt;/p&gt;
&lt;h2&gt;Trend&lt;/h2&gt;
&lt;p&gt;We are first going to look at the trend in the data.  we want to fit this as best we can with a simple model.    &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure(figsize=(14,8))
birth.resample(&amp;#39;AS&amp;#39;,how=&amp;#39;sum&amp;#39;).num_births[1:].plot()
plt.xlabel(&amp;#39;Time&amp;#39;)
plt.ylabel(&amp;quot;Number of Births per Year&amp;quot;)
plt.title(&amp;quot;Number of Births per Year from Jan 1980 to Dec 2010&amp;quot;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_9_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def polyFit(x,y,deg=2):
    coef = np.polyfit(x,y,deg=deg)
    pred = coef[deg]*np.ones(x.shape)
    for i in range(deg-1,-1,-1):
        pred += coef[i]*x**(deg-i)
    return pred

plt.figure(figsize=(14,8))
plt.plot(birth.index,birth.num_births,alpha=0.3,label=&amp;#39;Data&amp;#39;)
for i in range(2,8):
    plt.plot(birth.index,
             polyFit(birth.time_step.values,birth.num_births.values,deg=i),
             label=&amp;#39;Ply Deg: {}&amp;#39;.format(i),
             lw=3)
plt.legend()
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_10_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;trend = polyFit(birth.time_step.values,birth.num_births.values,deg=5)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Our naive approach is to fit the trend with a poly nomial.  I decided to cycle through a number of polynomial fits to the 30 years of data to find a model that most smoothly matches the trend without unreal havior at the end points.   A degree 7 polynomial follows the trend well, but we can see that it projects a dramatic increase in births.   The degree 3 polynomial says that historically, births were very low.   The balance is the degree 5 (purple).&lt;/p&gt;
&lt;p&gt;We are going to subtrack the trend out of our data and examine the seasonal component.   &lt;/p&gt;
&lt;h2&gt;Seasonal Component&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure(figsize=(14,8))
plt.plot(birth.index,(birth.num_births-trend))
plt.xlabel(&amp;quot;Time&amp;quot;)
plt.ylabel(&amp;quot;Number of Birth - Trend&amp;quot;)




&amp;lt;matplotlib.text.Text at 0x10d4c9650&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_13_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;With the exceptional of 2000-2004, our model captures the trend.  The average deviation does look to be centered around zero, and we see a seasonal component with an amplitude of about 20 births.  Lets see what this data looks like if we aggregate.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure(figsize=(14,8))
birth[&amp;#39;num_birth_minus_trend&amp;#39;] = birth.num_births-trend
birth.groupby(&amp;#39;month&amp;#39;).num_birth_minus_trend.mean().plot(label=&amp;quot;Average Seasonal Component&amp;quot;)
plt.plot(range(1,13),20*np.sin(6.28*(np.arange(1,13))/12+3.14159),label=&amp;quot;Sin Function&amp;quot;)
plt.ylabel(&amp;quot;Number of Births&amp;quot;)
plt.xlabel(&amp;quot;Month&amp;quot;)
plt.legend()




&amp;lt;matplotlib.legend.Legend at 0x10e64e610&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_15_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;The sine function is a good approximation of the seasonal/cyclic component.   Another way we could have done this was to break up into quarterly and montly componentents, make dummy variables, and do a linear fit.  I will do this later to compare the results.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;birth[&amp;#39;trend&amp;#39;] = trend
birth[&amp;#39;seasonal&amp;#39;] = 20*np.sin(6.28*(birth.month)/12+3.14159)
birth[&amp;#39;num_birth_minus_trend_minus_seasonal&amp;#39;] = birth.num_birth_minus_trend - birth.seasonal
birth[&amp;#39;trend_plus_seasonal&amp;#39;] = birth.trend + birth.seasonal
birth.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;num_births&lt;/th&gt;
      &lt;th&gt;time_step&lt;/th&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;month&lt;/th&gt;
      &lt;th&gt;num_birth_minus_trend&lt;/th&gt;
      &lt;th&gt;seasonal&lt;/th&gt;
      &lt;th&gt;trend&lt;/th&gt;
      &lt;th&gt;num_birth_minus_trend_minus_seasonal&lt;/th&gt;
      &lt;th&gt;trend_plus_seasonal&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;datetime&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1980-01-31&lt;/th&gt;
      &lt;td&gt;295&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;4.517789&lt;/td&gt;
      &lt;td&gt;-9.995356&lt;/td&gt;
      &lt;td&gt;290.482211&lt;/td&gt;
      &lt;td&gt;14.513145&lt;/td&gt;
      &lt;td&gt;280.486855&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1980-02-29&lt;/th&gt;
      &lt;td&gt;286&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;-4.540754&lt;/td&gt;
      &lt;td&gt;-17.315170&lt;/td&gt;
      &lt;td&gt;290.540754&lt;/td&gt;
      &lt;td&gt;12.774416&lt;/td&gt;
      &lt;td&gt;273.225584&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1980-03-31&lt;/th&gt;
      &lt;td&gt;300&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;9.372178&lt;/td&gt;
      &lt;td&gt;-19.999994&lt;/td&gt;
      &lt;td&gt;290.627822&lt;/td&gt;
      &lt;td&gt;29.372171&lt;/td&gt;
      &lt;td&gt;270.627829&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1980-04-30&lt;/th&gt;
      &lt;td&gt;278&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;-12.742668&lt;/td&gt;
      &lt;td&gt;-17.331142&lt;/td&gt;
      &lt;td&gt;290.742668&lt;/td&gt;
      &lt;td&gt;4.588474&lt;/td&gt;
      &lt;td&gt;273.411526&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1980-05-31&lt;/th&gt;
      &lt;td&gt;272&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;-18.884553&lt;/td&gt;
      &lt;td&gt;-10.023025&lt;/td&gt;
      &lt;td&gt;290.884553&lt;/td&gt;
      &lt;td&gt;-8.861528&lt;/td&gt;
      &lt;td&gt;280.861528&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure(figsize=(14,8))
birth.trend_plus_seasonal.plot(label=&amp;quot;Trend+Seasonal&amp;quot;)
birth.num_births.plot(label=&amp;quot;Data&amp;quot;)
plt.xlabel(&amp;#39;Time&amp;#39;)
plt.ylabel(&amp;quot;Number of Births per Month&amp;quot;)
plt.title(&amp;quot;Number of Births per Month from Jan 1980 to Dec 2010&amp;quot;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_18_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure(figsize=(14,5))
plt.subplot(1,2,1)
birth.num_birth_minus_trend_minus_seasonal.plot()
plt.xlabel(&amp;quot;Time&amp;quot;)
plt.ylabel(&amp;quot;Error of Fit&amp;quot;)
plt.subplot(1,2,2)
birth.num_birth_minus_trend_minus_seasonal.plot(kind=&amp;#39;hist&amp;#39;)
plt.ylabel(&amp;quot;Count&amp;quot;)
plt.xlabel(&amp;quot;Error of Fit&amp;quot;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_19_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We see that our model does not capture all of the features displayed in the birth data, but the errors are starting to look like gaussian noise.   It is at this point that we will stop, because in the afternoon we are going to be covering better models for approaching these types of problems.&lt;/p&gt;
&lt;h2&gt;Pandas&lt;/h2&gt;
&lt;p&gt;This blog is more of a collection of notes for me to review about datascience than anything else.  In that spirit I am going to put some plots and code in here to remember for the future.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure(figsize=(14,8))
ax = plt.gca()
birth.num_births.plot(ax=ax, label=&amp;quot;Monthly&amp;quot;,color=&amp;#39;indianred&amp;#39;,lw=3,alpha=0.3)
birth.resample(&amp;#39;Q-NOV&amp;#39;).num_births.plot(ax=ax,label=&amp;#39;Quarterly&amp;#39;,color=&amp;#39;steelblue&amp;#39;,lw=3,alpha=0.5)
birth.resample(&amp;#39;AS&amp;#39;).num_births.plot(ax=ax,label=&amp;#39;Yearly&amp;#39;,color=&amp;#39;forestgreen&amp;#39;,lw=3,alpha=0.8)
plt.legend()
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_21_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;Using the series and time functionality&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;nums = pd.Series(birth.num_births)
plt.figure(figsize=(14,6))
plt.subplot(1,2,1)
nums.plot()
plt.subplot(1,2,2)
nums[&amp;#39;2006&amp;#39;:&amp;#39;2010&amp;#39;].plot()




&amp;lt;matplotlib.axes._subplots.AxesSubplot at 0x1139495d0&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_23_1.png" /&gt;&lt;/p&gt;
&lt;h2&gt;Statsmodel Package&lt;/h2&gt;
&lt;p&gt;We were encorage to do this process using the stats model package because it has a more evolved way of doing time-series analysis.  Though we were also told that R is the best way to do this kind of analysis because all the methods have been developed for years.  The statsmodel package for python are
6. Turn the &lt;code&gt;num_births&lt;/code&gt; into a time series using &lt;code&gt;pd.Series()&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;birth[&amp;#39;time_step2&amp;#39;] = birth.time_step.values**2
birth[&amp;#39;time_step3&amp;#39;] = birth.time_step.values**3
birth[&amp;#39;time_step4&amp;#39;] = birth.time_step.values**4
birth[&amp;#39;time_step5&amp;#39;] = birth.time_step.values**5
birth.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;num_births&lt;/th&gt;
      &lt;th&gt;time_step&lt;/th&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;month&lt;/th&gt;
      &lt;th&gt;num_birth_minus_trend&lt;/th&gt;
      &lt;th&gt;seasonal&lt;/th&gt;
      &lt;th&gt;trend&lt;/th&gt;
      &lt;th&gt;num_birth_minus_trend_minus_seasonal&lt;/th&gt;
      &lt;th&gt;trend_plus_seasonal&lt;/th&gt;
      &lt;th&gt;time_step2&lt;/th&gt;
      &lt;th&gt;time_step3&lt;/th&gt;
      &lt;th&gt;time_step4&lt;/th&gt;
      &lt;th&gt;time_step5&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;datetime&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1980-01-31&lt;/th&gt;
      &lt;td&gt;295&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;4.517789&lt;/td&gt;
      &lt;td&gt;-9.995356&lt;/td&gt;
      &lt;td&gt;290.482211&lt;/td&gt;
      &lt;td&gt;14.513145&lt;/td&gt;
      &lt;td&gt;280.486855&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1980-02-29&lt;/th&gt;
      &lt;td&gt;286&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;-4.540754&lt;/td&gt;
      &lt;td&gt;-17.315170&lt;/td&gt;
      &lt;td&gt;290.540754&lt;/td&gt;
      &lt;td&gt;12.774416&lt;/td&gt;
      &lt;td&gt;273.225584&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1980-03-31&lt;/th&gt;
      &lt;td&gt;300&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;9.372178&lt;/td&gt;
      &lt;td&gt;-19.999994&lt;/td&gt;
      &lt;td&gt;290.627822&lt;/td&gt;
      &lt;td&gt;29.372171&lt;/td&gt;
      &lt;td&gt;270.627829&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;81&lt;/td&gt;
      &lt;td&gt;243&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1980-04-30&lt;/th&gt;
      &lt;td&gt;278&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;-12.742668&lt;/td&gt;
      &lt;td&gt;-17.331142&lt;/td&gt;
      &lt;td&gt;290.742668&lt;/td&gt;
      &lt;td&gt;4.588474&lt;/td&gt;
      &lt;td&gt;273.411526&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;64&lt;/td&gt;
      &lt;td&gt;256&lt;/td&gt;
      &lt;td&gt;1024&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1980-05-31&lt;/th&gt;
      &lt;td&gt;272&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;-18.884553&lt;/td&gt;
      &lt;td&gt;-10.023025&lt;/td&gt;
      &lt;td&gt;290.884553&lt;/td&gt;
      &lt;td&gt;-8.861528&lt;/td&gt;
      &lt;td&gt;280.861528&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;125&lt;/td&gt;
      &lt;td&gt;625&lt;/td&gt;
      &lt;td&gt;3125&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;statsmodels.api&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sm&lt;/span&gt;
&lt;span class="n"&gt;model1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OLS&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;birth&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_births&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;sm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;birth&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_step&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]))&lt;/span&gt;
&lt;span class="n"&gt;results1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;model2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OLS&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;birth&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_births&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;sm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;birth&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_step&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_step2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]))&lt;/span&gt;
&lt;span class="n"&gt;results2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;model3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OLS&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;birth&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_births&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;sm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;birth&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_step&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_step2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_step3&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]))&lt;/span&gt;
&lt;span class="n"&gt;results3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;model4&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OLS&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;birth&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_births&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;sm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;birth&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_step&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_step2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_step3&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_step4&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]))&lt;/span&gt;
&lt;span class="n"&gt;results4&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model4&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;model5&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OLS&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;birth&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_births&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;sm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;birth&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_step&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_step2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_step3&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_step4&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_step5&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]))&lt;/span&gt;
&lt;span class="n"&gt;results5&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model5&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;results1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;results2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;results3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;results4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;results5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;birth&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;birth&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_births&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;AIC: &lt;/span&gt;&lt;span class="si"&gt;%4.1f&lt;/span&gt;&lt;span class="s"&gt;, BIC: &lt;/span&gt;&lt;span class="si"&gt;%4.1f&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;aic&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bic&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;birth&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fittedvalues&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Ploy Deg: {}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Time&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Number of Births Per Month&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;AIC&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;3593.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;BIC&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;3600.8&lt;/span&gt;
&lt;span class="n"&gt;AIC&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;3400.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;BIC&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;3411.8&lt;/span&gt;
&lt;span class="n"&gt;AIC&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;3262.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;BIC&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;3277.7&lt;/span&gt;
&lt;span class="n"&gt;AIC&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;3231.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;BIC&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;3250.9&lt;/span&gt;
&lt;span class="n"&gt;AIC&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;3225.6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;BIC&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;3249.1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_26_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;The nice thing about statsmodel over numpy poly fit is that it gives a number of statistics about how well the data is being fitted.  The AIC/BIC can be used to decide which model is a better model.  In this case the biggest increase happened going to a degree 3 polynomial, after that the models are not significantly better for fitting the data.   They are, however, better and extrapolating outside of the data.&lt;/p&gt;
&lt;p&gt;Using statsmodel, we can create categorical variables for the season, and try to fit a seasonal component that way&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;birth[&amp;#39;Wi&amp;#39;] = np.where(birth.month.isin([12,1,2]),1,0)
birth[&amp;#39;Sp&amp;#39;] = np.where(birth.month.isin([3,4,5]),1,0)
birth[&amp;#39;Su&amp;#39;] = np.where(birth.month.isin([6,7,8]),1,0)
birth[&amp;#39;Fa&amp;#39;] = np.where(birth.month.isin([9,10,11]),1,0)


birth.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;num_births&lt;/th&gt;
      &lt;th&gt;time_step&lt;/th&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;month&lt;/th&gt;
      &lt;th&gt;num_birth_minus_trend&lt;/th&gt;
      &lt;th&gt;seasonal&lt;/th&gt;
      &lt;th&gt;trend&lt;/th&gt;
      &lt;th&gt;num_birth_minus_trend_minus_seasonal&lt;/th&gt;
      &lt;th&gt;trend_plus_seasonal&lt;/th&gt;
      &lt;th&gt;time_step2&lt;/th&gt;
      &lt;th&gt;time_step3&lt;/th&gt;
      &lt;th&gt;time_step4&lt;/th&gt;
      &lt;th&gt;time_step5&lt;/th&gt;
      &lt;th&gt;Wi&lt;/th&gt;
      &lt;th&gt;Sp&lt;/th&gt;
      &lt;th&gt;Su&lt;/th&gt;
      &lt;th&gt;Fa&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;datetime&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1980-01-31&lt;/th&gt;
      &lt;td&gt;295&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;4.517789&lt;/td&gt;
      &lt;td&gt;-9.995356&lt;/td&gt;
      &lt;td&gt;290.482211&lt;/td&gt;
      &lt;td&gt;14.513145&lt;/td&gt;
      &lt;td&gt;280.486855&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1980-02-29&lt;/th&gt;
      &lt;td&gt;286&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;-4.540754&lt;/td&gt;
      &lt;td&gt;-17.315170&lt;/td&gt;
      &lt;td&gt;290.540754&lt;/td&gt;
      &lt;td&gt;12.774416&lt;/td&gt;
      &lt;td&gt;273.225584&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1980-03-31&lt;/th&gt;
      &lt;td&gt;300&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;9.372178&lt;/td&gt;
      &lt;td&gt;-19.999994&lt;/td&gt;
      &lt;td&gt;290.627822&lt;/td&gt;
      &lt;td&gt;29.372171&lt;/td&gt;
      &lt;td&gt;270.627829&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;81&lt;/td&gt;
      &lt;td&gt;243&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1980-04-30&lt;/th&gt;
      &lt;td&gt;278&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;-12.742668&lt;/td&gt;
      &lt;td&gt;-17.331142&lt;/td&gt;
      &lt;td&gt;290.742668&lt;/td&gt;
      &lt;td&gt;4.588474&lt;/td&gt;
      &lt;td&gt;273.411526&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;64&lt;/td&gt;
      &lt;td&gt;256&lt;/td&gt;
      &lt;td&gt;1024&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1980-05-31&lt;/th&gt;
      &lt;td&gt;272&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;1980&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;-18.884553&lt;/td&gt;
      &lt;td&gt;-10.023025&lt;/td&gt;
      &lt;td&gt;290.884553&lt;/td&gt;
      &lt;td&gt;-8.861528&lt;/td&gt;
      &lt;td&gt;280.861528&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;125&lt;/td&gt;
      &lt;td&gt;625&lt;/td&gt;
      &lt;td&gt;3125&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;model6 = sm.OLS(birth.num_births,sm.add_constant(birth[[&amp;#39;time_step&amp;#39;,&amp;#39;time_step2&amp;#39;,&amp;#39;time_step3&amp;#39;,&amp;#39;time_step4&amp;#39;,&amp;#39;time_step5&amp;#39;,&amp;#39;Wi&amp;#39;,&amp;#39;Sp&amp;#39;,&amp;#39;Su&amp;#39;,&amp;#39;Fa&amp;#39;]]))
results6 = model6.fit()
plt.figure(figsize=(14,8))
plt.plot(birth.index,birth.num_births,alpha=0.3)
plt.plot(birth.index,results6.fittedvalues)
plt.xlabel(&amp;quot;Time&amp;quot;)
plt.ylabel(&amp;quot;Number of Births per Month&amp;quot;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_30_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure(figsize=(14,4))
plt.subplot(1,2,1)
plt.plot(birth.index,results6.resid,&amp;#39;bo&amp;#39;)
plt.subplot(1,2,2)
plt.hist(birth.num_births-results6.fittedvalues)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_31_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;Using the seasonal fit gave similar results as the sine fit, but it did not assume an underlying model.&lt;/p&gt;
&lt;h2&gt;Exponential Smooth&lt;/h2&gt;
&lt;p&gt;When fitting time series data it is sometime important to weight the most recent information as more important the older information.  This leads to a class of models that lead to time varying coefficients.  They do not explicitly depend on time, but they are fitted in a weighted way that depends on the most recent information.  For instance, a linear fit has an intercept and slope, and this model will have time varying intercept and slopes because at each point in time, the model fits in a way that biases the most recent information.   &lt;/p&gt;
&lt;p&gt;We were introduced to a Holt Method, which is what I just described, and a Holt-Winter method that including a seasonal component to the the fit.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="s-Atom"&gt;class&lt;/span&gt; &lt;span class="nv"&gt;Holt&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;

    &lt;span class="s-Atom"&gt;def&lt;/span&gt; &lt;span class="k"&gt;__&lt;/span&gt;&lt;span class="nf"&gt;init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
        &lt;span class="s-Atom"&gt;pass&lt;/span&gt;

    &lt;span class="s-Atom"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;x&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;y&lt;/span&gt; 
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;l&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="s-Atom"&gt;int_fit_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;size&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="s-Atom"&gt;fit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;polyfit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;:int_fit_size&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="s-Atom"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;:int_fit_size&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="s-Atom"&gt;deg&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;l&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;b&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="s-Atom"&gt;alphas&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;dim&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="s-Atom"&gt;gammas&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;dim&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;SE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="s-Atom"&gt;dim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;dim&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;alpha&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="nf"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;alphas&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
            &lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;gamma&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="nf"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;gammas&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
                &lt;span class="s-Atom"&gt;pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                &lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;i&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nf"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
                    &lt;span class="s-Atom"&gt;#print&lt;/span&gt; &lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;gamma&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                    &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;l&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="s-Atom"&gt;+&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s-Atom"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;l&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;b&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
                    &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;b&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;gamma*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;l&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;l&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="s-Atom"&gt;+&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s-Atom"&gt;gamma&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;b&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                    &lt;span class="s-Atom"&gt;pred&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;l&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;b&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;SE&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;power&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s-Atom"&gt;pred&lt;/span&gt;&lt;span class="p"&gt;[:-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

        &lt;span class="s-Atom"&gt;row&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argmin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;SE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="s-Atom"&gt;dim&lt;/span&gt;
        &lt;span class="s-Atom"&gt;col&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argmin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;SE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s-Atom"&gt;row&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="s-Atom"&gt;dim&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;alphas&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;row&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;gamma&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;gammas&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;col&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="s-Atom"&gt;pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;i&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nf"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
            &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;l&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="s-Atom"&gt;+&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;l&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;b&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;b&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;gamma*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;l&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;l&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="s-Atom"&gt;+&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;gamma&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;b&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;l&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;b&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;power&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;[:-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="s-Atom"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="s-Atom"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;time&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;z&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1.96&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
        &lt;span class="s-Atom"&gt;se&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;i&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;time&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
            &lt;span class="s-Atom"&gt;se&lt;/span&gt; &lt;span class="s-Atom"&gt;+=&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;alpha**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="s-Atom"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;gamma&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
        &lt;span class="s-Atom"&gt;se&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;z&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;s&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;se&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="s-Atom"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;l&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;b&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="s-Atom"&gt;time&lt;/span&gt;
        &lt;span class="s-Atom"&gt;high&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;predictions&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s-Atom"&gt;se&lt;/span&gt;
        &lt;span class="s-Atom"&gt;low&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;predictions&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s-Atom"&gt;se&lt;/span&gt;
        &lt;span class="s-Atom"&gt;return&lt;/span&gt; &lt;span class="s-Atom"&gt;low&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;high&lt;/span&gt;

    &lt;span class="s-Atom"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;forcast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;time&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;z&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1.96&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
        &lt;span class="s-Atom"&gt;high_forcast&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="s-Atom"&gt;low_forcast&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="s-Atom"&gt;forcast&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;i&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;time&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
            &lt;span class="s-Atom"&gt;se&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;j&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
                &lt;span class="s-Atom"&gt;se&lt;/span&gt; &lt;span class="s-Atom"&gt;+=&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;alpha**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="s-Atom"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s-Atom"&gt;j&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;gamma&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
            &lt;span class="s-Atom"&gt;se&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;s&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;se&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="s-Atom"&gt;mean&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;l&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;b&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="s-Atom"&gt;forcast&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="s-Atom"&gt;high_forcast&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;mean&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s-Atom"&gt;z&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="s-Atom"&gt;se&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="s-Atom"&gt;low_forcast&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;mean&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s-Atom"&gt;z&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="s-Atom"&gt;se&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="s-Atom"&gt;return&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;forcast&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;high_forcast&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;low_forcast&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="s-Atom"&gt;holt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;Holt&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="s-Atom"&gt;holt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;birth&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;time_step&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;birth&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;num_births&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;



&lt;span class="s-Atom"&gt;low&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;high&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;holt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;time&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s-Atom"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;figsize=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="s-Atom"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;fill_between&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;birth&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;low&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;high&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;alpha=.&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s-Atom"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;birth&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;birth&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;num_births&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,)&lt;/span&gt;
&lt;span class="s-Atom"&gt;birth&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;num_births&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;alpha=.&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s-Atom"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Time&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s-Atom"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Number of Births Per Month&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s-Atom"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_34_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;What is real interesting about this model is that it is strait forward to estimate the errors on the predictions.  The fit matches the actual values (interpolation) perfectly.   We can use this model to predict what will hapen in the future.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;forcast,high,low = holt.forcast(time=12)
plt.figure(figsize=(14,8))
plt.fill_between(range(1,13),low,high,alpha=.2)
plt.plot(range(1,13),forcast,alpha=1,)
plt.xlim([1,12])
plt.xlabel(&amp;quot;Months in the Future&amp;quot;)
plt.ylabel(&amp;quot;Number of Births Per Month&amp;quot;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_36_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;Despite fiting the data very well (because it weights the most recent information), it does not forcast seasonal variation.  At the end of the day, it is a linear model that will only extrapolate linearly into the future.  This model will not work well for this data more than a month or two in the future.  To do this we would need to use a Holt-Winter method.   That will come later&lt;/p&gt;
&lt;h2&gt;Afternoon - SARMA&lt;/h2&gt;
&lt;p&gt;SARMIA stands fro Seasonal AutoRegression Moving Averaging Models that including the fact that past errors can contribute to current results, and that past values can be predictive of today's results.   Our focus in the afternoon was using the statsmodel package's implementaton of these models.  Our data was a series of logins to a site over a two month period.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;logins = pd.read_json(&amp;quot;data/logins.json&amp;quot;)
logins.loc[:,0] = pd.to_datetime(logins.loc[:,0])
logins.columns = [&amp;#39;datetime&amp;#39;]
logins[&amp;#39;count&amp;#39;] = np.ones(logins.shape[0])
logins.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;datetime&lt;/th&gt;
      &lt;th&gt;count&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;2012-03-01 00:05:55&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2012-03-01 00:06:23&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;2012-03-01 00:06:52&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;2012-03-01 00:11:23&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;2012-03-01 00:12:47&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;We are using the 1 count so that when we resample to different time periods, say by hour, we can sum all the counts in every hour to get the logins per hour.  We can also do this per day, or per week.  Next we are going to make a pandas timeseries object.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;ts = pd.Series(np.ones(logins.shape[0]),index=logins.datetime)
plt.figure(figsize=(14,8))
ts.resample(&amp;#39;1D&amp;#39;,how=&amp;#39;sum&amp;#39;).plot()
plt.xlabel(&amp;quot;Time&amp;quot;)
plt.ylabel(&amp;quot;Login Counts&amp;quot;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_40_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We see here that the logins have a weekly behavior where users are loggin in on the weekends, and not using the site very much on the weekdays.  We can also see that the number of logins seems to be increasing slightly as the weeks progress.   Lets use SARMA to investigate&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;statsmodels.api&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sm&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;acf_pacf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ts&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lag&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;fig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;ax1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;211&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;fig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;graphics&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tsa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot_acf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ts&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;lag&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;212&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;fig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;graphics&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tsa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot_pacf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ts&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;lag&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;ts1day&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;resample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;1D&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;how&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sum&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;acf_pacf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ts1day&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_42_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;The autocorrelation and partial autocorrelation show moving and seasonal variaton.   The first feature we are conserned with the the first node being out side of the statistically insignificant (purple) region.   That suggest that we need to adda  difference component.   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;ts1day.diff(1).plot()




&amp;lt;matplotlib.axes._subplots.AxesSubplot at 0x1195ea0d0&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_44_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;By ploting the difference between one day at the next, we see the average is no longer moving.  The next component is the 7 day components.   That we will do with our model fit.  We are going to use stats model to fit the data.  The (0,1,0) term is the differece we saw to deal with the moving average.  The (1,1,0,7) is the auto correclation, the difference, and finaly the seasonality of 7 days.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;model=sm.tsa.SARIMAX(ts1day, order=(0,1,0), seasonal_order=(1,1,0,7)).fit()
model.summary()
&lt;/pre&gt;&lt;/div&gt;


&lt;table class="simpletable"&gt;
&lt;caption&gt;Statespace Model Results&lt;/caption&gt;
&lt;tr&gt;
  &lt;th&gt;Dep. Variable:&lt;/th&gt;                 &lt;td&gt;y&lt;/td&gt;               &lt;th&gt;  No. Observations:  &lt;/th&gt;    &lt;td&gt;61&lt;/td&gt;   
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Model:&lt;/th&gt;           &lt;td&gt;SARIMAX(0, 1, 0)x(1, 1, 0, 7)&lt;/td&gt; &lt;th&gt;  Log Likelihood     &lt;/th&gt; &lt;td&gt;-287.751&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Date:&lt;/th&gt;                  &lt;td&gt;Sun, 12 Jul 2015&lt;/td&gt;        &lt;th&gt;  AIC                &lt;/th&gt;  &lt;td&gt;579.503&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Time:&lt;/th&gt;                      &lt;td&gt;14:33:39&lt;/td&gt;            &lt;th&gt;  BIC                &lt;/th&gt;  &lt;td&gt;583.725&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Sample:&lt;/th&gt;                   &lt;td&gt;03-01-2012&lt;/td&gt;           &lt;th&gt;  HQIC               &lt;/th&gt;  &lt;td&gt;581.157&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;&lt;/th&gt;                         &lt;td&gt;- 04-30-2012&lt;/td&gt;          &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;   
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Covariance Type:&lt;/th&gt;              &lt;td&gt;opg&lt;/td&gt;              &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;   
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
     &lt;td&gt;&lt;/td&gt;        &lt;th&gt;coef&lt;/th&gt;     &lt;th&gt;std err&lt;/th&gt;      &lt;th&gt;z&lt;/th&gt;      &lt;th&gt;P&gt;|z|&lt;/th&gt; &lt;th&gt;[95.0% Conf. Int.]&lt;/th&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;ar.S.L7&lt;/th&gt; &lt;td&gt;   -0.2059&lt;/td&gt; &lt;td&gt;    0.135&lt;/td&gt; &lt;td&gt;   -1.524&lt;/td&gt; &lt;td&gt; 0.127&lt;/td&gt; &lt;td&gt;   -0.471     0.059&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;sigma2&lt;/th&gt;  &lt;td&gt; 3025.7975&lt;/td&gt; &lt;td&gt;  578.692&lt;/td&gt; &lt;td&gt;    5.229&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt; 1891.582  4160.013&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;plt.plot(ts1day.index[1:],model.predict(0)[0,1:])
plt.plot(ts1day.index[1:],ts1day.values[1:])





[&amp;lt;matplotlib.lines.Line2D at 0x119d6b550&amp;gt;]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_47_1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;tsmodel = pd.Series(model.predict(0)[0,1:]-ts1day.values[1:],index=ts1day.index[1:])
acf_pacf(tsmodel, 28)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_48_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We see that this time-series model does well on matching the historical data and removes the autocorrelation and partial correlations that appread in the previous fits.  We could try to further address the poitns at n=2.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;model=sm.tsa.SARIMAX(ts1day, order=(2,1,0), seasonal_order=(1,1,0,7)).fit()
model.summary()
&lt;/pre&gt;&lt;/div&gt;


&lt;table class="simpletable"&gt;
&lt;caption&gt;Statespace Model Results&lt;/caption&gt;
&lt;tr&gt;
  &lt;th&gt;Dep. Variable:&lt;/th&gt;                 &lt;td&gt;y&lt;/td&gt;               &lt;th&gt;  No. Observations:  &lt;/th&gt;    &lt;td&gt;61&lt;/td&gt;   
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Model:&lt;/th&gt;           &lt;td&gt;SARIMAX(2, 1, 0)x(1, 1, 0, 7)&lt;/td&gt; &lt;th&gt;  Log Likelihood     &lt;/th&gt; &lt;td&gt;-285.344&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Date:&lt;/th&gt;                  &lt;td&gt;Sun, 12 Jul 2015&lt;/td&gt;        &lt;th&gt;  AIC                &lt;/th&gt;  &lt;td&gt;578.688&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Time:&lt;/th&gt;                      &lt;td&gt;14:43:19&lt;/td&gt;            &lt;th&gt;  BIC                &lt;/th&gt;  &lt;td&gt;587.131&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Sample:&lt;/th&gt;                   &lt;td&gt;03-01-2012&lt;/td&gt;           &lt;th&gt;  HQIC               &lt;/th&gt;  &lt;td&gt;581.997&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;&lt;/th&gt;                         &lt;td&gt;- 04-30-2012&lt;/td&gt;          &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;   
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Covariance Type:&lt;/th&gt;              &lt;td&gt;opg&lt;/td&gt;              &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;   
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
     &lt;td&gt;&lt;/td&gt;        &lt;th&gt;coef&lt;/th&gt;     &lt;th&gt;std err&lt;/th&gt;      &lt;th&gt;z&lt;/th&gt;      &lt;th&gt;P&gt;|z|&lt;/th&gt; &lt;th&gt;[95.0% Conf. Int.]&lt;/th&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;ar.L1&lt;/th&gt;   &lt;td&gt;   -0.2857&lt;/td&gt; &lt;td&gt;    0.115&lt;/td&gt; &lt;td&gt;   -2.479&lt;/td&gt; &lt;td&gt; 0.013&lt;/td&gt; &lt;td&gt;   -0.512    -0.060&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;ar.L2&lt;/th&gt;   &lt;td&gt;   -0.1796&lt;/td&gt; &lt;td&gt;    0.132&lt;/td&gt; &lt;td&gt;   -1.357&lt;/td&gt; &lt;td&gt; 0.175&lt;/td&gt; &lt;td&gt;   -0.439     0.080&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;ar.S.L7&lt;/th&gt; &lt;td&gt;   -0.2359&lt;/td&gt; &lt;td&gt;    0.158&lt;/td&gt; &lt;td&gt;   -1.489&lt;/td&gt; &lt;td&gt; 0.136&lt;/td&gt; &lt;td&gt;   -0.546     0.075&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;sigma2&lt;/th&gt;  &lt;td&gt; 2751.6619&lt;/td&gt; &lt;td&gt;  501.665&lt;/td&gt; &lt;td&gt;    5.485&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt; 1768.416  3734.907&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;plt.plot(ts1day.index[1:],model.predict(0)[0,1:])
plt.plot(ts1day.index[1:],ts1day.values[1:])




[&amp;lt;matplotlib.lines.Line2D at 0x11a1bc610&amp;gt;]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_51_1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;tsmodel = pd.Series(model.predict(0)[0,1:]-ts1day.values[1:],index=ts1day.index[1:])
acf_pacf(tsmodel, 28)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D5/output_52_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;This is a slightly better model than the previous model.  The AIC/BIC does show improvement, but not so much that I would confidently say one model is better than the other.  We are talking fractions of a percent improvment.   What is nice is that this is signficantly quicker than the methods of writing Holt and Holt-Winter classes from before.  &lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="time series"></category><category term="ARMA"></category><category term="SARMA"></category><category term="Holt"></category><category term="Holt-Winter"></category></entry><entry><title>Galvanize - Week 06 - Day 3</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-06-03/" rel="alternate"></link><updated>2015-08-03T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-07-08:galvanize/galvanize-data-science-06-03/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 6 - Day 3&lt;/h2&gt;
&lt;p&gt;I liked our quiz today.  It was more SQL, but we had to load data into a local PostgreSQL database and test the queries.  We were give two table discriptions:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;log
    userid
    tmstmp
    itemid
    event

items
    itemid
    name
    category
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Where the possible events are:
&lt;em&gt; &lt;code&gt;view&lt;/code&gt;: Viewing the details of an item
&lt;/em&gt; &lt;code&gt;add&lt;/code&gt;: Adding the item to shopping cart
* &lt;code&gt;buy&lt;/code&gt;: Buying an item&lt;/p&gt;
&lt;p&gt;We had to write two queries.  One that would select all the user, item pairs where a user has added an item to the cart but has not bought it.  If they bought that item, then added it to their cart again, that add should be counted.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;    SELECT a.userid, a.itemid FROM log a 
    JOIN (SELECT userid, 
                    itemid, 
                    MAX(tmstmp) as last_tmstmp 
        FROM log
        GROUP BY userid, itemid) b 
    ON a.userid = b.userid
    AND a.itemid = b.itemid
    AND a.event = &amp;#39;add&amp;#39;
    AND a.tmstmp = b.last_tmstamp
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The next query we had to write was to fetch the ratio of views to purchases for each category.   I decided to get the count for views and joins for each item, then group by category for the ratio.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;    SELECT i.category,
        SUM( a.buy_count ) / SUM( a.view_count ) 
            as ration
    FROM items i JOIN (
        SELECT itemid,
        SUM( CASE(event = &amp;#39;buy&amp;#39; THEN 1 ELSE 0) )
            as buy_count,
        SUM( CASE(event = &amp;#39;view&amp;#39; THEN 1 ELSE 0) )
            as view_count 
        FROM log 
        GROUP BY itemid) a
    ON i.itemid = a.itemid
    GROUP BY i.category
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Collaborative Filtering&lt;/h2&gt;
&lt;p&gt;Collaborative Filtering is a way to make recommendations based on using related data to make predictions.  There are item-item collaborative filtering techniques that take interest in one item to be a signal that you might be interested in a similar item.  User-user collaborative filtering takes users that are similar to you and recommends things these users have liked that you have not tried/bought/experienced.   &lt;/p&gt;
&lt;p&gt;Our morning sprint is making an item-item collaborative filtering enging for moviews in the data from 
You will be using the &lt;a href="http://grouplens.org/datasets/movielens/"&gt;MovieLens&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Our process for making recommendations will involved the following: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Calculated how similarly movies are related using cosine similarity  &lt;/li&gt;
&lt;li&gt;Construct a neighborhood for each movie of the N most similar movies  &lt;/li&gt;
&lt;li&gt;Take the weighted average of each user's previous ratings for each movie's neighborhood&lt;/li&gt;
&lt;li&gt;Return prediction&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Our ItemItemRecommender Class is below.  This class does not take advantage of scipy's sparse matrixes.  The reason is I found that for this dataset that it ran measurably slower compared to using numpy matrixes.   I am not sure if I am just unfarmiliar with the best practices of sparse matrixes, or if there is something characteristic of sparse matrixes.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;ItemItemRecommender&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;neighborhood_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Initializes the parameters of the model.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;neighborhood_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;neighborhood_size&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="kp"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Implements the model and fits it to the data passed as an&lt;/span&gt;
&lt;span class="sd"&gt;        argument.&lt;/span&gt;

&lt;span class="sd"&gt;        Stores objects for describing model fit as class attributes.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kp"&gt;matrix&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_set_neighborhoods&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_set_neighborhoods&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Gets the items most similar to each other item.&lt;/span&gt;

&lt;span class="sd"&gt;        Should set a class attribute with a matrix that is has&lt;/span&gt;
&lt;span class="sd"&gt;        number of rows equal to number of items and number of &lt;/span&gt;
&lt;span class="sd"&gt;        columns equal to neighborhood size. Entries of this matrix&lt;/span&gt;
&lt;span class="sd"&gt;        will be indexes of other items.&lt;/span&gt;

&lt;span class="sd"&gt;        You will call this in your fit method.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics.pairwise&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;cosine_similarity&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cosine_similarity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;neighborhoods&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sim&lt;/span&gt;&lt;span class="p"&gt;[:,:],&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)[:,&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;neighborhood_size&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;pred_one_user&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Accept user id as arg. Return the predictions for a single user.&lt;/span&gt;

&lt;span class="sd"&gt;        Optional argument to specify whether or not timing should be provided&lt;/span&gt;
&lt;span class="sd"&gt;        on this operation.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;scores&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,:]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;nonzero&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
            &lt;span class="n"&gt;relevant_items&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;intersect1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scores&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;neighborhoods&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;assume_unique&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="c"&gt;#if i in scores:&lt;/span&gt;
            &lt;span class="c"&gt;#    result = self.matrix[mask,:][0,i]&lt;/span&gt;
            &lt;span class="c"&gt;#else:&lt;/span&gt;
            &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;relevant_items&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sim&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;relevant_items&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sim&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;relevant_items&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;pred_all_users&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Repeated calls of pred_one_user, are combined into a single matrix.&lt;/span&gt;
&lt;span class="sd"&gt;        Return value is matrix of users (rows) items (columns) and predicted&lt;/span&gt;
&lt;span class="sd"&gt;        ratings (values).&lt;/span&gt;

&lt;span class="sd"&gt;        Optional argument to specify whether or not timing should be provided&lt;/span&gt;
&lt;span class="sd"&gt;        on this operation.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
            &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pred_one_user&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt;


    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;top_n_recs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Takes user_id argument and number argument.&lt;/span&gt;

&lt;span class="sd"&gt;        Returns that number of items with the highest predicted ratings,&lt;/span&gt;
&lt;span class="sd"&gt;        after removing items that user has already rated.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;scores&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,:]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;nonzero&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pred_one_user&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;scores&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;)[::&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][:&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We are ready to import our data&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;ItemRecommender&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ItemItemRecommender&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="n"&gt;ratings_contents&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_table&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;../data/u.data&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                     &lt;span class="n"&gt;names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;user&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;movie&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;rating&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;timestamp&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ratings_contents&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;drop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;timestamp&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_index&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;user&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;movie&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unstack&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;droplevel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fillna&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;movie&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;th&gt;8&lt;/th&gt;
      &lt;th&gt;9&lt;/th&gt;
      &lt;th&gt;10&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;1673&lt;/th&gt;
      &lt;th&gt;1674&lt;/th&gt;
      &lt;th&gt;1675&lt;/th&gt;
      &lt;th&gt;1676&lt;/th&gt;
      &lt;th&gt;1677&lt;/th&gt;
      &lt;th&gt;1678&lt;/th&gt;
      &lt;th&gt;1679&lt;/th&gt;
      &lt;th&gt;1680&lt;/th&gt;
      &lt;th&gt;1681&lt;/th&gt;
      &lt;th&gt;1682&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;user&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 1682 columns&lt;/p&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;
&lt;span class="n"&gt;IIR&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ItemItemRecommender&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;t1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;IIR&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Time to Fit: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;t1&lt;/span&gt;

&lt;span class="n"&gt;Time&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Fit&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.853658914566&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The item-item recommender is finding a cosine similarity matrix, which is relatively quick.  Predictions, however, will not that quick.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;t1=time()
print &amp;quot;Prediction: &amp;quot;, np.round(IIR.pred_one_user(0)[:10],0)
print &amp;quot;Actual:     &amp;quot;, df.values[0,:10]
print &amp;quot;Time to Predict 1 User: &amp;quot;, time()-t1

Prediction:  [ 4.  3.  4.  4.  3.  5.  4.  4.  4.  4.]
Actual:      [ 5.  3.  4.  3.  3.  5.  4.  1.  5.  3.]
Time to Predict 1 User:  0.0642509460449
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If we want to predict for all users.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;t1 = time()
predictions = IIR.pred_all_users()
print &amp;quot;Time to predict 943 Users:&amp;quot;, time()-t1

Time to predict 943 Users: 23.9097139835
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can also increase the size of the neighborhoods for similar movies.  We just did 20, lets change it to 75.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;
&lt;span class="n"&gt;IIR&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ItemItemRecommender&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;75&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;t1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;IIR&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Time to Fit: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;t1&lt;/span&gt;
&lt;span class="n"&gt;t1&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Prediction: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;round&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;IIR&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pred_one_user&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Actual:     &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Time to Predict 1 User: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;t1&lt;/span&gt;
&lt;span class="n"&gt;t1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;IIR&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pred_all_users&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Time to predict 943 Users:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;t1&lt;/span&gt;

&lt;span class="n"&gt;Time&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Fit&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.224536895752&lt;/span&gt;
&lt;span class="n"&gt;Prediction&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="mf"&gt;4.&lt;/span&gt;  &lt;span class="mf"&gt;4.&lt;/span&gt;  &lt;span class="mf"&gt;4.&lt;/span&gt;  &lt;span class="mf"&gt;4.&lt;/span&gt;  &lt;span class="mf"&gt;4.&lt;/span&gt;  &lt;span class="mf"&gt;5.&lt;/span&gt;  &lt;span class="mf"&gt;4.&lt;/span&gt;  &lt;span class="mf"&gt;4.&lt;/span&gt;  &lt;span class="mf"&gt;4.&lt;/span&gt;  &lt;span class="mf"&gt;4.&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;Actual&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;      &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="mf"&gt;5.&lt;/span&gt;  &lt;span class="mf"&gt;3.&lt;/span&gt;  &lt;span class="mf"&gt;4.&lt;/span&gt;  &lt;span class="mf"&gt;3.&lt;/span&gt;  &lt;span class="mf"&gt;3.&lt;/span&gt;  &lt;span class="mf"&gt;5.&lt;/span&gt;  &lt;span class="mf"&gt;4.&lt;/span&gt;  &lt;span class="mf"&gt;1.&lt;/span&gt;  &lt;span class="mf"&gt;5.&lt;/span&gt;  &lt;span class="mf"&gt;3.&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;Time&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Predict&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;User&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.0480990409851&lt;/span&gt;
&lt;span class="n"&gt;Time&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;predict&lt;/span&gt; &lt;span class="mi"&gt;943&lt;/span&gt; &lt;span class="n"&gt;Users&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;32.1997280121&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can see that the neighborhood size is going to change the results.  One thing I know is that there are many more action moviews then documentaries in the dataset.   This does not allow us to filter based on the different number of each.   &lt;/p&gt;
&lt;p&gt;The larger neighborhood also increases the computation size.  Papers have published results that it does reduce the mean square error.  For a production item-item recommender like the one we built, we would have to update our predictions at a regualar basis.  This would have to be off line because of how long it takes to fit.&lt;/p&gt;
&lt;h2&gt;Top Movies&lt;/h2&gt;
&lt;p&gt;We also have movie details for the data in our recommender.  I am going to import that data and see what movies are being recommended.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;idf = pd.read_table(&amp;quot;../data/u.item&amp;quot;,sep=&amp;quot;|&amp;quot;,header=None)
idf = idf.iloc[:,[1,2]]
idf.columns = [&amp;#39;Title&amp;#39;,&amp;#39;Date&amp;#39;]
idf.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Title&lt;/th&gt;
      &lt;th&gt;Date&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Toy Story (1995)&lt;/td&gt;
      &lt;td&gt;01-Jan-1995&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;GoldenEye (1995)&lt;/td&gt;
      &lt;td&gt;01-Jan-1995&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Four Rooms (1995)&lt;/td&gt;
      &lt;td&gt;01-Jan-1995&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Get Shorty (1995)&lt;/td&gt;
      &lt;td&gt;01-Jan-1995&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;Copycat (1995)&lt;/td&gt;
      &lt;td&gt;01-Jan-1995&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The first user rated the following movies:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;user1_rating_indexes = df.values[0,:].nonzero()[0]
user1 = idf.loc[user1_rating_indexes,:]
user1[&amp;#39;Ratings&amp;#39;] = df.values[0,user1_rating_indexes]
user1[user1.Ratings==5]
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Title&lt;/th&gt;
      &lt;th&gt;Date&lt;/th&gt;
      &lt;th&gt;Ratings&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Toy Story (1995)&lt;/td&gt;
      &lt;td&gt;01-Jan-1995&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;Shanghai Triad (Yao a yao yao dao waipo qiao) ...&lt;/td&gt;
      &lt;td&gt;01-Jan-1995&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;8&lt;/th&gt;
      &lt;td&gt;Dead Man Walking (1995)&lt;/td&gt;
      &lt;td&gt;01-Jan-1995&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;11&lt;/th&gt;
      &lt;td&gt;Usual Suspects, The (1995)&lt;/td&gt;
      &lt;td&gt;14-Aug-1995&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12&lt;/th&gt;
      &lt;td&gt;Mighty Aphrodite (1995)&lt;/td&gt;
      &lt;td&gt;30-Oct-1995&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;13&lt;/th&gt;
      &lt;td&gt;Postino, Il (1994)&lt;/td&gt;
      &lt;td&gt;01-Jan-1994&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;14&lt;/th&gt;
      &lt;td&gt;Mr. Holland's Opus (1995)&lt;/td&gt;
      &lt;td&gt;29-Jan-1996&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;15&lt;/th&gt;
      &lt;td&gt;French Twist (Gazon maudit) (1995)&lt;/td&gt;
      &lt;td&gt;01-Jan-1995&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;18&lt;/th&gt;
      &lt;td&gt;Antonia's Line (1995)&lt;/td&gt;
      &lt;td&gt;01-Jan-1995&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;31&lt;/th&gt;
      &lt;td&gt;Crumb (1994)&lt;/td&gt;
      &lt;td&gt;01-Jan-1994&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;41&lt;/th&gt;
      &lt;td&gt;Clerks (1994)&lt;/td&gt;
      &lt;td&gt;01-Jan-1994&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;43&lt;/th&gt;
      &lt;td&gt;Dolores Claiborne (1994)&lt;/td&gt;
      &lt;td&gt;01-Jan-1994&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;44&lt;/th&gt;
      &lt;td&gt;Eat Drink Man Woman (1994)&lt;/td&gt;
      &lt;td&gt;01-Jan-1994&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;47&lt;/th&gt;
      &lt;td&gt;Hoop Dreams (1994)&lt;/td&gt;
      &lt;td&gt;01-Jan-1994&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;49&lt;/th&gt;
      &lt;td&gt;Star Wars (1977)&lt;/td&gt;
      &lt;td&gt;01-Jan-1977&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;54&lt;/th&gt;
      &lt;td&gt;Professional, The (1994)&lt;/td&gt;
      &lt;td&gt;01-Jan-1994&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;56&lt;/th&gt;
      &lt;td&gt;Priest (1994)&lt;/td&gt;
      &lt;td&gt;01-Jan-1994&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;58&lt;/th&gt;
      &lt;td&gt;Three Colors: Red (1994)&lt;/td&gt;
      &lt;td&gt;01-Jan-1994&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;59&lt;/th&gt;
      &lt;td&gt;Three Colors: Blue (1993)&lt;/td&gt;
      &lt;td&gt;01-Jan-1993&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;63&lt;/th&gt;
      &lt;td&gt;Shawshank Redemption, The (1994)&lt;/td&gt;
      &lt;td&gt;01-Jan-1994&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;80&lt;/th&gt;
      &lt;td&gt;Hudsucker Proxy, The (1994)&lt;/td&gt;
      &lt;td&gt;01-Jan-1994&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;81&lt;/th&gt;
      &lt;td&gt;Jurassic Park (1993)&lt;/td&gt;
      &lt;td&gt;01-Jan-1993&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;85&lt;/th&gt;
      &lt;td&gt;Remains of the Day, The (1993)&lt;/td&gt;
      &lt;td&gt;01-Jan-1993&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;86&lt;/th&gt;
      &lt;td&gt;Searching for Bobby Fischer (1993)&lt;/td&gt;
      &lt;td&gt;01-Jan-1993&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;88&lt;/th&gt;
      &lt;td&gt;Blade Runner (1982)&lt;/td&gt;
      &lt;td&gt;01-Jan-1982&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;90&lt;/th&gt;
      &lt;td&gt;Nightmare Before Christmas, The (1993)&lt;/td&gt;
      &lt;td&gt;01-Jan-1993&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;92&lt;/th&gt;
      &lt;td&gt;Welcome to the Dollhouse (1995)&lt;/td&gt;
      &lt;td&gt;24-May-1996&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;95&lt;/th&gt;
      &lt;td&gt;Terminator 2: Judgment Day (1991)&lt;/td&gt;
      &lt;td&gt;01-Jan-1991&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;99&lt;/th&gt;
      &lt;td&gt;Fargo (1996)&lt;/td&gt;
      &lt;td&gt;14-Feb-1997&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;107&lt;/th&gt;
      &lt;td&gt;Kids in the Hall: Brain Candy (1996)&lt;/td&gt;
      &lt;td&gt;12-Apr-1996&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;173&lt;/th&gt;
      &lt;td&gt;Raiders of the Lost Ark (1981)&lt;/td&gt;
      &lt;td&gt;01-Jan-1981&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;174&lt;/th&gt;
      &lt;td&gt;Brazil (1985)&lt;/td&gt;
      &lt;td&gt;01-Jan-1985&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;175&lt;/th&gt;
      &lt;td&gt;Aliens (1986)&lt;/td&gt;
      &lt;td&gt;01-Jan-1986&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;176&lt;/th&gt;
      &lt;td&gt;Good, The Bad and The Ugly, The (1966)&lt;/td&gt;
      &lt;td&gt;01-Jan-1966&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;177&lt;/th&gt;
      &lt;td&gt;12 Angry Men (1957)&lt;/td&gt;
      &lt;td&gt;01-Jan-1957&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;180&lt;/th&gt;
      &lt;td&gt;Return of the Jedi (1983)&lt;/td&gt;
      &lt;td&gt;14-Mar-1997&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;182&lt;/th&gt;
      &lt;td&gt;Alien (1979)&lt;/td&gt;
      &lt;td&gt;01-Jan-1979&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;189&lt;/th&gt;
      &lt;td&gt;Henry V (1989)&lt;/td&gt;
      &lt;td&gt;01-Jan-1989&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;190&lt;/th&gt;
      &lt;td&gt;Amadeus (1984)&lt;/td&gt;
      &lt;td&gt;01-Jan-1984&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;194&lt;/th&gt;
      &lt;td&gt;Terminator, The (1984)&lt;/td&gt;
      &lt;td&gt;01-Jan-1984&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;195&lt;/th&gt;
      &lt;td&gt;Dead Poets Society (1989)&lt;/td&gt;
      &lt;td&gt;01-Jan-1989&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;196&lt;/th&gt;
      &lt;td&gt;Graduate, The (1967)&lt;/td&gt;
      &lt;td&gt;01-Jan-1967&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;197&lt;/th&gt;
      &lt;td&gt;Nikita (La Femme Nikita) (1990)&lt;/td&gt;
      &lt;td&gt;01-Jan-1990&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;201&lt;/th&gt;
      &lt;td&gt;Groundhog Day (1993)&lt;/td&gt;
      &lt;td&gt;01-Jan-1993&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;203&lt;/th&gt;
      &lt;td&gt;Back to the Future (1985)&lt;/td&gt;
      &lt;td&gt;01-Jan-1985&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;206&lt;/th&gt;
      &lt;td&gt;Cyrano de Bergerac (1990)&lt;/td&gt;
      &lt;td&gt;01-Jan-1990&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;207&lt;/th&gt;
      &lt;td&gt;Young Frankenstein (1974)&lt;/td&gt;
      &lt;td&gt;01-Jan-1974&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;215&lt;/th&gt;
      &lt;td&gt;When Harry Met Sally... (1989)&lt;/td&gt;
      &lt;td&gt;01-Jan-1989&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;220&lt;/th&gt;
      &lt;td&gt;Breaking the Waves (1996)&lt;/td&gt;
      &lt;td&gt;15-Nov-1996&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;222&lt;/th&gt;
      &lt;td&gt;Sling Blade (1996)&lt;/td&gt;
      &lt;td&gt;22-Nov-1996&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;223&lt;/th&gt;
      &lt;td&gt;Ridicule (1996)&lt;/td&gt;
      &lt;td&gt;27-Nov-1996&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;227&lt;/th&gt;
      &lt;td&gt;Star Trek: The Wrath of Khan (1982)&lt;/td&gt;
      &lt;td&gt;01-Jan-1982&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;234&lt;/th&gt;
      &lt;td&gt;Mars Attacks! (1996)&lt;/td&gt;
      &lt;td&gt;13-Dec-1996&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;241&lt;/th&gt;
      &lt;td&gt;Kolya (1996)&lt;/td&gt;
      &lt;td&gt;24-Jan-1997&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;245&lt;/th&gt;
      &lt;td&gt;Chasing Amy (1997)&lt;/td&gt;
      &lt;td&gt;01-Jan-1997&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;252&lt;/th&gt;
      &lt;td&gt;Pillow Book, The (1995)&lt;/td&gt;
      &lt;td&gt;13-Jun-1997&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;257&lt;/th&gt;
      &lt;td&gt;Contact (1997)&lt;/td&gt;
      &lt;td&gt;11-Jul-1997&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;267&lt;/th&gt;
      &lt;td&gt;Chasing Amy (1997)&lt;/td&gt;
      &lt;td&gt;01-Jan-1997&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;268&lt;/th&gt;
      &lt;td&gt;Full Monty, The (1997)&lt;/td&gt;
      &lt;td&gt;01-Jan-1997&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;269&lt;/th&gt;
      &lt;td&gt;Gattaca (1997)&lt;/td&gt;
      &lt;td&gt;01-Jan-1997&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;81 rows × 3 columns&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Based on this list, our recommener is making recommendations for movies that user has not watched.  The Top 10 Movies recommended to this user are:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;idf.loc[IIR.top_n_recs(0,10),:]
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Title&lt;/th&gt;
      &lt;th&gt;Date&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;810&lt;/th&gt;
      &lt;td&gt;Thirty-Two Short Films About Glenn Gould (1993)&lt;/td&gt;
      &lt;td&gt;01-Jan-1993&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1572&lt;/th&gt;
      &lt;td&gt;Spirits of the Dead (Tre passi nel delirio) (1...&lt;/td&gt;
      &lt;td&gt;01-Jan-1968&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1526&lt;/th&gt;
      &lt;td&gt;Senseless (1998)&lt;/td&gt;
      &lt;td&gt;09-Jan-1998&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1462&lt;/th&gt;
      &lt;td&gt;Boys, Les (1997)&lt;/td&gt;
      &lt;td&gt;01-Jan-1997&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;792&lt;/th&gt;
      &lt;td&gt;Crooklyn (1994)&lt;/td&gt;
      &lt;td&gt;01-Jan-1994&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1544&lt;/th&gt;
      &lt;td&gt;Frankie Starlight (1995)&lt;/td&gt;
      &lt;td&gt;01-Jan-1995&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1023&lt;/th&gt;
      &lt;td&gt;Mrs. Dalloway (1997)&lt;/td&gt;
      &lt;td&gt;01-Jan-1997&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;781&lt;/th&gt;
      &lt;td&gt;Little Odessa (1994)&lt;/td&gt;
      &lt;td&gt;01-Jan-1994&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1369&lt;/th&gt;
      &lt;td&gt;I Can't Sleep (J'ai pas sommeil) (1994)&lt;/td&gt;
      &lt;td&gt;01-Jan-1994&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1360&lt;/th&gt;
      &lt;td&gt;Search for One-eye Jimmy, The (1996)&lt;/td&gt;
      &lt;td&gt;01-Jan-1996&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Unfortunately we do not have a measure for how successful these recommnedations are.  We can not have the user watch them, and if we did we would need the user to follow up with a rating.  These are all predicted to be 5 star movies for this user.&lt;/p&gt;
&lt;p&gt;One of the shortcomings I see from looking up some of these titles on IMDB is the measure of similarity is only user ratings.   This metric does not deal with the property of the movies.  I, personally, like Kevin Spacey.   He has been in a wide variety of movies, and I have enjoyed movies that are out of my traditional preferences in part of his performances.   That is not weighted into our similarity.  Including it, however, will also increase the computational time for updates.  &lt;/p&gt;
&lt;h2&gt;Matrix Factorization Based Recommenders&lt;/h2&gt;
&lt;p&gt;Our afternoon paired sprint was implementing matrix factorization based recommenders.   These involved constructing two matrixes that multiply together to produce the rating matrix.  The idea is that through the user of latent variables, the matrix product will make predictions for movies that are not yet reviewed.  &lt;/p&gt;
&lt;p&gt;We were introduced to the &lt;a href="http://sifter.org/~simon/journal/20061211.html"&gt;Simon Funk&lt;/a&gt; matrix factorization using stocastic gradient decent.   There is a good &lt;a href="http://www2.research.att.com/~volinsky/papers/ieeecomputer.pdf"&gt;ATT Research Paper&lt;/a&gt; on this topics.  Our implmentation was to be contained in a class that match the 'API' from the morning sprint.   &lt;/p&gt;
&lt;p&gt;The idea is that we have a ratings matrix $R$, and are trying to break it into a users matrix $U$ and a movie matrix $M$ such that:&lt;/p&gt;
&lt;p&gt;$$R = U \ M$$&lt;/p&gt;
&lt;p&gt;Since we do not know $U$ and $M$, we must find it by finding the error, then iteratively changing the matrixes until we have the least error possible.&lt;/p&gt;
&lt;p&gt;$$ \mbox{squared error} =  \sum_{i,j} (r_{ij} - u_{ia} \ m_{aj})^2 $$&lt;/p&gt;
&lt;p&gt;The SGD method is to go through all the ratings and use the following update rules:&lt;/p&gt;
&lt;p&gt;$$ u_i \ = u_i + \ \gamma ( e_{ij} m_i - \lambda u_i ) $$&lt;/p&gt;
&lt;p&gt;$$ m_i  \ = m_i + \ \gamma ( e_{ij} u_j - \lambda m_i ) $$&lt;/p&gt;
&lt;p&gt;You can see our class below&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="s-Atom"&gt;class&lt;/span&gt; &lt;span class="nv"&gt;MatrixFactorizationRecommender&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;object&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;

    &lt;span class="s-Atom"&gt;def&lt;/span&gt; &lt;span class="k"&gt;__&lt;/span&gt;&lt;span class="nf"&gt;init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.001&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                 &lt;span class="s-Atom"&gt;regularization&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.02&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;optimizer_pct_improvement_criterion&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                 &lt;span class="s-Atom"&gt;verbose&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;

        &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;Initializes the parameters of the model.&lt;/span&gt;
&lt;span class="s2"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;n_features&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;n_features&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;learning_rate&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;regularization&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;regularization&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;optimizer_pct_improvement_criterion&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;optimizer_pct_improvement_criterion&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;verbose&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;verbose&lt;/span&gt;

    &lt;span class="s-Atom"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;Like the scikit learn fit methods, this method &lt;/span&gt;
&lt;span class="s2"&gt;        should take the ratings data as an input and should&lt;/span&gt;
&lt;span class="s2"&gt;        compute and store the matrix factorization. It should assign&lt;/span&gt;
&lt;span class="s2"&gt;        some class variables like n_users, which depend on the&lt;/span&gt;
&lt;span class="s2"&gt;        ratings_mat data.&lt;/span&gt;

&lt;span class="s2"&gt;        It can return nothing&lt;/span&gt;
&lt;span class="s2"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;matrix&lt;/span&gt;

        &lt;span class="s-Atom"&gt;n_users&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="s-Atom"&gt;n_movies&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="s-Atom"&gt;n_already_rated&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;nonzero&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="s-Atom"&gt;size&lt;/span&gt;
        &lt;span class="s-Atom"&gt;user_mat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="s-Atom"&gt;n_users&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;n_features&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nf"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s-Atom"&gt;n_users&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;n_features&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="s-Atom"&gt;movie_mat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="s-Atom"&gt;n_movies&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;n_features&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nf"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;n_features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;n_movies&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;


        &lt;span class="s-Atom"&gt;optimizer_iteration_count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="s-Atom"&gt;sse_accum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="s-Atom"&gt;if&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nn"&gt;verbose&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="nf"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Optimizaiton Statistics&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="nf"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Iterations | Mean Squared Error  |  Percent Improvement&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="nf"&gt;while&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;optimizer_iteration_count&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="nf"&gt;or&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;pct_improvement&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;optimizer_pct_improvement_criterion&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
            &lt;span class="s-Atom"&gt;old_sse&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;sse_accum&lt;/span&gt;
            &lt;span class="s-Atom"&gt;sse_accum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
            &lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;i&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;n_users&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
                &lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;j&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;n_movies&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
                    &lt;span class="s-Atom"&gt;if&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
                        &lt;span class="s-Atom"&gt;error&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="s-Atom"&gt;\&lt;/span&gt;
                            &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;user_mat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s-Atom"&gt;movie_mat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;j&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
                        &lt;span class="s-Atom"&gt;sse_accum&lt;/span&gt; &lt;span class="s-Atom"&gt;+=&lt;/span&gt; &lt;span class="s-Atom"&gt;error**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
                        &lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;k&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="nf"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;n_features&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
                            &lt;span class="s-Atom"&gt;user_mat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;k&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;user_mat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
                                &lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;k&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="s-Atom"&gt;error&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="s-Atom"&gt;movie_mat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;regularization&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="s-Atom"&gt;user_mat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;k&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
                            &lt;span class="s-Atom"&gt;movie_mat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;movie_mat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
                                &lt;span class="s-Atom"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="s-Atom"&gt;error&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="s-Atom"&gt;user_mat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;k&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;regularization&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="s-Atom"&gt;movie_mat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;j&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="s-Atom"&gt;pct_improvement&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;old_sse&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="s-Atom"&gt;sse_accum&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="s-Atom"&gt;old_sse&lt;/span&gt;
            &lt;span class="s-Atom"&gt;if&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nn"&gt;verbose&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="nf"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;%d \t\t %f \t\t %f&amp;quot;&lt;/span&gt; &lt;span class="c1"&gt;% (&lt;/span&gt;
                        &lt;span class="s-Atom"&gt;optimizer_iteration_count&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;sse_accum&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="s-Atom"&gt;n_already_rated&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;pct_improvement&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="s-Atom"&gt;old_sse&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;sse_accum&lt;/span&gt;
            &lt;span class="s-Atom"&gt;optimizer_iteration_count&lt;/span&gt; &lt;span class="s-Atom"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;user_mat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;user_mat&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;movie_mat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;movie_mat&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;recommendations&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;user_mat&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;movie_mat&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="s-Atom"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;pred_one_user&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;index&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;Returns the predicted rating for a single&lt;/span&gt;
&lt;span class="s2"&gt;        user.&lt;/span&gt;
&lt;span class="s2"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="s-Atom"&gt;return&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;recommendations&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="s-Atom"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;pred_all_users&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;Returns the predicted rating for all users/items.&lt;/span&gt;
&lt;span class="s2"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="s-Atom"&gt;return&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;recommendations&lt;/span&gt;

    &lt;span class="s-Atom"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;top_n_recs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;Takes user_id argument and number argument.&lt;/span&gt;

&lt;span class="s2"&gt;        Returns that number of items with the highest predicted ratings,&lt;/span&gt;
&lt;span class="s2"&gt;        after removing items that user has already rated.&lt;/span&gt;
&lt;span class="s2"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="s-Atom"&gt;scores&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="nf"&gt;nonzero&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="s-Atom"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;pred_one_user&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;index&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="s-Atom"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;scores&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="s-Atom"&gt;return&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="s-Atom"&gt;::-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s-Atom"&gt;:n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we can look at the relative performance and predictions from this morning!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;SVD&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;MatrixFactorizationRecommender&lt;/span&gt;
&lt;span class="n"&gt;NMF&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MatrixFactorizationRecommender&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;t1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;NMF&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Time to Fit: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;t1&lt;/span&gt;

&lt;span class="n"&gt;Time&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Fit&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;51.0261509418&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The fit time is signficantly longer than the Item-Item recommender.  What about predictions.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;t1=time()
print &amp;quot;Prediction: &amp;quot;, np.round(NMF.pred_one_user(0)[:10],0)
print &amp;quot;Actual:     &amp;quot;, df.values[0,:10]
print &amp;quot;Time to Predict 1 User: &amp;quot;, time()-t1
t1 = time()
predictions = NMF.pred_all_users()
print &amp;quot;Time to predict 943 Users:&amp;quot;, time()-t1

Prediction:  [ 4.  3.  3.  3.  3.  4.  4.  4.  4.  4.]
Actual:      [ 5.  3.  4.  3.  3.  5.  4.  1.  5.  3.]
Time to Predict 1 User:  0.00182199478149
Time to predict 943 Users: 0.00263500213623
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So in this case the predictions is just the matrix multiplication found in the fit.  It is significantly faster to make predictions.   In fact I cheated by saving the predictions in the class.  This is really just a lookup.&lt;/p&gt;
&lt;p&gt;It does seem the predictions are not as good as the Item-Item recommendor.   Lets look at the movie predictions.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;idf.loc[NMF.top_n_recs(0,10),:]
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Title&lt;/th&gt;
      &lt;th&gt;Date&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1632&lt;/th&gt;
      &lt;td&gt;� k�ldum klaka (Cold Fever) (1994)&lt;/td&gt;
      &lt;td&gt;08-Mar-1996&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1405&lt;/th&gt;
      &lt;td&gt;When Night Is Falling (1995)&lt;/td&gt;
      &lt;td&gt;01-Jan-1995&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1458&lt;/th&gt;
      &lt;td&gt;Madame Butterfly (1995)&lt;/td&gt;
      &lt;td&gt;20-Sep-1996&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1616&lt;/th&gt;
      &lt;td&gt;Hugo Pool (1997)&lt;/td&gt;
      &lt;td&gt;01-Jan-1997&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1463&lt;/th&gt;
      &lt;td&gt;Stars Fell on Henrietta, The (1995)&lt;/td&gt;
      &lt;td&gt;01-Jan-1995&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1648&lt;/th&gt;
      &lt;td&gt;Big One, The (1997)&lt;/td&gt;
      &lt;td&gt;27-Mar-1998&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1583&lt;/th&gt;
      &lt;td&gt;Symphonie pastorale, La (1946)&lt;/td&gt;
      &lt;td&gt;01-Jan-1946&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1340&lt;/th&gt;
      &lt;td&gt;Hedd Wyn (1992)&lt;/td&gt;
      &lt;td&gt;01-Jan-1992&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1481&lt;/th&gt;
      &lt;td&gt;Gate of Heavenly Peace, The (1995)&lt;/td&gt;
      &lt;td&gt;10-May-1996&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1599&lt;/th&gt;
      &lt;td&gt;Guantanamera (1994)&lt;/td&gt;
      &lt;td&gt;16-May-1997&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;These are wildly different predictions than this morning.  In order to get a feel for which better we need to come up with a way to validate our strategy. &lt;/p&gt;
&lt;h2&gt;Validations&lt;/h2&gt;
&lt;p&gt;If this was a uppervised problem, we would make a training and testing set, cross validate on the training set, then measure the error on the test set.  We can do that here by removing rating from the matrix, and checking if which recommendor is making a better predictions on the test set.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;validation_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;REC&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;frac_row&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;frac_col&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="kp"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;scoring_func&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
    &lt;span class="n"&gt;row_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;frac_row&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;col_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;frac_col&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;matrix_copy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kp"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;matrix_copy&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;row_test&lt;/span&gt;&lt;span class="p"&gt;,:][:,&lt;/span&gt;&lt;span class="n"&gt;col_test&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.&lt;/span&gt;
    &lt;span class="n"&gt;REC&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;matrix_copy&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;REC&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pred_all_users&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;scoring_func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;row_test&lt;/span&gt;&lt;span class="p"&gt;,:][:,&lt;/span&gt;&lt;span class="n"&gt;col_test&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;row_test&lt;/span&gt;&lt;span class="p"&gt;,:][:,&lt;/span&gt;&lt;span class="n"&gt;col_test&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;mse_recommendor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;truth_mat&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pred_mat&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;        Computes mean-squared-error between a sparse and a dense matrix.  Does not include the 0&amp;#39;s from&lt;/span&gt;
&lt;span class="sd"&gt;        the sparse matrix in computation (treats them as missing)&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="c"&gt;#get mask of non-zero, mean-square of those, divide by count of those&lt;/span&gt;
        &lt;span class="n"&gt;nonzero_idx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;truth_mat&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;nonzero&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;mse&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;truth_mat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;nonzero_idx&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;pred_mat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;nonzero_idx&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;mse&lt;/span&gt;


&lt;span class="n"&gt;IIR&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ItemItemRecommender&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;neighborhood_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;validation_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;IIR&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;mse_recommendor&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;




&lt;span class="mf"&gt;0.57135223474377161&lt;/span&gt;




&lt;span class="n"&gt;NMF&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MatrixFactorizationRecommender&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;validation_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;NMF&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;mse_recommendor&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;




&lt;span class="mf"&gt;0.88865196231368859&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Our mean error on the Item-Item is about half a rating, while the error on the Matrix-Factorization is almost a full rating.   In this case, I will probably go with the Item-Item&lt;/p&gt;
&lt;p&gt;The NMF, on the other hand, has a number of turning parameters.  I performed a gridsearch offline, and found parameters that improved the fit.   The way Item-Item is done, this is not possible.   Below is a fit that is much better.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;NMF = MatrixFactorizationRecommender(n_features=20,learning_rate=0.01,regularization=0.01)
validation_score(NMF,0.3,0.3,df.values,mse_recommendor)




0.47107202771056506




NMF = MatrixFactorizationRecommender(n_features=20,learning_rate=0.01,regularization=0.01)
NMF.fit(df.values)
idf.loc[NMF.top_n_recs(0,10),:]
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Title&lt;/th&gt;
      &lt;th&gt;Date&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;407&lt;/th&gt;
      &lt;td&gt;Close Shave, A (1995)&lt;/td&gt;
      &lt;td&gt;28-Apr-1996&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1367&lt;/th&gt;
      &lt;td&gt;Mina Tannenbaum (1994)&lt;/td&gt;
      &lt;td&gt;01-Jan-1994&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;510&lt;/th&gt;
      &lt;td&gt;Lawrence of Arabia (1962)&lt;/td&gt;
      &lt;td&gt;01-Jan-1962&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;660&lt;/th&gt;
      &lt;td&gt;High Noon (1952)&lt;/td&gt;
      &lt;td&gt;01-Jan-1952&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;646&lt;/th&gt;
      &lt;td&gt;Ran (1985)&lt;/td&gt;
      &lt;td&gt;01-Jan-1985&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;284&lt;/th&gt;
      &lt;td&gt;Secrets &amp;amp; Lies (1996)&lt;/td&gt;
      &lt;td&gt;04-Oct-1996&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;918&lt;/th&gt;
      &lt;td&gt;City of Lost Children, The (1995)&lt;/td&gt;
      &lt;td&gt;01-Jan-1995&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;477&lt;/th&gt;
      &lt;td&gt;Philadelphia Story, The (1940)&lt;/td&gt;
      &lt;td&gt;01-Jan-1940&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;428&lt;/th&gt;
      &lt;td&gt;Day the Earth Stood Still, The (1951)&lt;/td&gt;
      &lt;td&gt;01-Jan-1951&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1141&lt;/th&gt;
      &lt;td&gt;When We Were Kings (1996)&lt;/td&gt;
      &lt;td&gt;14-Feb-1997&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;We can see the movies recommended by the tuned recommendor are different from before.  They are also, at a glance, much more related to the moviews this user rated.  This improves the recommendor, but the search took over an hour to run, and I have no idea how much better we can make it.&lt;/p&gt;
&lt;p&gt;One final note is that we noticed with Matrix-Factorization based recomendors is that when the number of features are low, the highest rated and most rated movies dominate the suggestions.   You haven't seen 'Titatic'?  Watch it!  'Casablanca'?  Watch it!   It defaults to a popularity recommendor instead of a personalized recommendor.   &lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="nlp"></category><category term="collaboritive filtering"></category><category term="recommendation engines"></category></entry><entry><title>Galvanize - Week 06 - Day 2</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-06-02/" rel="alternate"></link><updated>2015-07-07T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-07-07:galvanize/galvanize-data-science-06-02/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 6 - Day 2&lt;/h2&gt;
&lt;p&gt;Today we had a weekly assessment.  It was on natural language processing, profit curves, dimentional reduction, and clustering.   We were given an hour, but it was more like a 40 minute assessment.   After that we broke out into groups to discuss capstone project ideas.  We each gave 5 rough ideas, and made suggesting for refining and improving them.  Right now I working with 3 personal projects, and 2 prospective projects for companies I have talked with.   &lt;/p&gt;
&lt;h2&gt;Non-Negative Matrix Facorization&lt;/h2&gt;
&lt;p&gt;Today we covered NMF methods for topic modeling.  I was shocked witht the results we found when we used this method on the NY Times dataset we have been playing with for the last week.   &lt;/p&gt;
&lt;p&gt;The ideas is that we break a matrix, like the TfIdf vectors relating articles to words for the New York Times.  This matrix can be decomposed into two matrixes.   One that relates Articles to Topics, and another non-negative matrix that relates Topics to words.  The first task we had was writing our own NMF algorithm class.  We use the method proposed by &lt;a href="http://papers.nips.cc/paper/1861-algorithms-for-non-negative-matrix-factorization.pdf"&gt;Daniel D. Lee and H. Sebastian Seung&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;We are going to first load in our NY Times data, show our class, then analysis the topics&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pickle&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="n"&gt;ny&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_pickle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data/articles.pkl&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ny&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;document_type&lt;/th&gt;
      &lt;th&gt;web_url&lt;/th&gt;
      &lt;th&gt;lead_paragraph&lt;/th&gt;
      &lt;th&gt;abstract&lt;/th&gt;
      &lt;th&gt;snippet&lt;/th&gt;
      &lt;th&gt;news_desk&lt;/th&gt;
      &lt;th&gt;word_count&lt;/th&gt;
      &lt;th&gt;source&lt;/th&gt;
      &lt;th&gt;section_name&lt;/th&gt;
      &lt;th&gt;subsection_name&lt;/th&gt;
      &lt;th&gt;_id&lt;/th&gt;
      &lt;th&gt;pub_date&lt;/th&gt;
      &lt;th&gt;print_page&lt;/th&gt;
      &lt;th&gt;headline&lt;/th&gt;
      &lt;th&gt;content&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;article&lt;/td&gt;
      &lt;td&gt;http://www.nytimes.com/2013/10/03/sports/footb...&lt;/td&gt;
      &lt;td&gt;You would think that in a symmetric zero-sum s...&lt;/td&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;You would think that in a symmetric zero-sum s...&lt;/td&gt;
      &lt;td&gt;Sports&lt;/td&gt;
      &lt;td&gt;347&lt;/td&gt;
      &lt;td&gt;The New York Times&lt;/td&gt;
      &lt;td&gt;Sports&lt;/td&gt;
      &lt;td&gt;Pro Football&lt;/td&gt;
      &lt;td&gt;524d4e3a38f0d8198974001f&lt;/td&gt;
      &lt;td&gt;2013-10-03T00:00:00Z&lt;/td&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;Week 5 Probabilities: Why Offense Is More Impo...&lt;/td&gt;
      &lt;td&gt;the original goal building model football fore...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;article&lt;/td&gt;
      &lt;td&gt;http://www.nytimes.com/2013/10/03/us/new-immig...&lt;/td&gt;
      &lt;td&gt;House Democrats on Wednesday unveiled an immig...&lt;/td&gt;
      &lt;td&gt;House Democrats unveil immigration bill that p...&lt;/td&gt;
      &lt;td&gt;House Democrats on Wednesday unveiled an immig...&lt;/td&gt;
      &lt;td&gt;National&lt;/td&gt;
      &lt;td&gt;83&lt;/td&gt;
      &lt;td&gt;The New York Times&lt;/td&gt;
      &lt;td&gt;U.S.&lt;/td&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;524cf71338f0d8198973ff7b&lt;/td&gt;
      &lt;td&gt;2013-10-03T00:00:00Z&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;New Immigration Bill Put Forward&lt;/td&gt;
      &lt;td&gt;house unveiled immigration bill provides path ...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;article&lt;/td&gt;
      &lt;td&gt;http://www.nytimes.com/2013/10/03/us/arizona-j...&lt;/td&gt;
      &lt;td&gt;A federal judge on Wednesday ordered the appoi...&lt;/td&gt;
      &lt;td&gt;Federal Judge Murray Snow orders the appointme...&lt;/td&gt;
      &lt;td&gt;A federal judge on Wednesday ordered the appoi...&lt;/td&gt;
      &lt;td&gt;National&lt;/td&gt;
      &lt;td&gt;160&lt;/td&gt;
      &lt;td&gt;The New York Times&lt;/td&gt;
      &lt;td&gt;U.S.&lt;/td&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;524cf50e38f0d8198973ff79&lt;/td&gt;
      &lt;td&gt;2013-10-03T00:00:00Z&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;Arizona: Judge Orders Monitor to Oversee Maric...&lt;/td&gt;
      &lt;td&gt;federal judge wednesday ordered appointment in...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;article&lt;/td&gt;
      &lt;td&gt;http://www.nytimes.com/2013/10/03/us/texas-sta...&lt;/td&gt;
      &lt;td&gt;Texas has turned to a compounding pharmacy to ...&lt;/td&gt;
      &lt;td&gt;Documents show that Texas, nation's most activ...&lt;/td&gt;
      &lt;td&gt;Texas has turned to a compounding pharmacy to ...&lt;/td&gt;
      &lt;td&gt;National&lt;/td&gt;
      &lt;td&gt;112&lt;/td&gt;
      &lt;td&gt;The New York Times&lt;/td&gt;
      &lt;td&gt;U.S.&lt;/td&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;524cf39a38f0d8198973ff78&lt;/td&gt;
      &lt;td&gt;2013-10-03T00:00:00Z&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;Texas: State Bought Execution Drugs From a Com...&lt;/td&gt;
      &lt;td&gt;texas nation’s active death-penalty state turn...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;article&lt;/td&gt;
      &lt;td&gt;http://www.nytimes.com/2013/10/03/sports/tenni...&lt;/td&gt;
      &lt;td&gt;Rafael Nadal, aiming to end Novak Djokovic’s r...&lt;/td&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;Rafael Nadal, aiming to end Novak Djokovic’s r...&lt;/td&gt;
      &lt;td&gt;Sports&lt;/td&gt;
      &lt;td&gt;49&lt;/td&gt;
      &lt;td&gt;The New York Times&lt;/td&gt;
      &lt;td&gt;Sports&lt;/td&gt;
      &lt;td&gt;Tennis&lt;/td&gt;
      &lt;td&gt;524cf28b38f0d8198973ff73&lt;/td&gt;
      &lt;td&gt;2013-10-03T00:00:00Z&lt;/td&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;Nadal on Track for No. 1 Spot&lt;/td&gt;
      &lt;td&gt;rafael nadal aiming end novak djokovic’s run 1...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.feature_extraction.text&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;CountVectorizer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;TfidfVectorizer&lt;/span&gt;

&lt;span class="n"&gt;tfidf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TfidfVectorizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;stop_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tfidf_articles&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ny&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;tfidf_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_articles&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;todense&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tfidf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_feature_names&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;tfidf_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
&lt;span class="n"&gt;tfidf_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1405&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;000&lt;/th&gt;
      &lt;th&gt;10&lt;/th&gt;
      &lt;th&gt;100&lt;/th&gt;
      &lt;th&gt;10th&lt;/th&gt;
      &lt;th&gt;11&lt;/th&gt;
      &lt;th&gt;11th&lt;/th&gt;
      &lt;th&gt;12&lt;/th&gt;
      &lt;th&gt;120&lt;/th&gt;
      &lt;th&gt;13&lt;/th&gt;
      &lt;th&gt;130&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;youtube&lt;/th&gt;
      &lt;th&gt;zarif&lt;/th&gt;
      &lt;th&gt;zealand&lt;/th&gt;
      &lt;th&gt;zen&lt;/th&gt;
      &lt;th&gt;zero&lt;/th&gt;
      &lt;th&gt;zhang&lt;/th&gt;
      &lt;th&gt;zhou&lt;/th&gt;
      &lt;th&gt;zone&lt;/th&gt;
      &lt;th&gt;zoo&lt;/th&gt;
      &lt;th&gt;zorn&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.063525&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.103347&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.243745&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 5000 columns&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;We have a matrix V, and our goal is to factor it into the product of two matrixes.&lt;/p&gt;
&lt;p&gt;$$V = W \ H$$&lt;/p&gt;
&lt;p&gt;The algorithm we implemented randomly initates W and H with positive, non-zero values.   It then solves for new W's an d H's using the least squared minimization.   We then continue this updateing until we have reached the desired tolerance or reached the max number of iterations.  For illustration purposed I have printed the iteration, cost, and change in cost as we fit.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="s-Atom"&gt;class&lt;/span&gt; &lt;span class="nv"&gt;NMF&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;

    &lt;span class="s-Atom"&gt;def&lt;/span&gt; &lt;span class="k"&gt;__&lt;/span&gt;&lt;span class="nf"&gt;init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nv"&gt;V&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;max_iter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;tol&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="s-Atom"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;data_frame&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;V&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;V&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;V&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;values&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;latent_topics&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;max_iter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;max_iter&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;W&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;size=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;V&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="s-Atom"&gt;k&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;100.&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;H&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;size=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nv"&gt;V&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;100.&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;tol&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;tol&lt;/span&gt;

    &lt;span class="s-Atom"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
        &lt;span class="s-Atom"&gt;dcost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;_&lt;/span&gt;&lt;span class="nf"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="s-Atom"&gt;cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;dcost&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="s-Atom"&gt;iter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="nf"&gt;while&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;dcost&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;tol&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nf"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;iter&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;max_iter&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
            &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;_&lt;/span&gt;&lt;span class="nf"&gt;update&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="s-Atom"&gt;temp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;_&lt;/span&gt;&lt;span class="nf"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="s-Atom"&gt;dcost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;temp&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s-Atom"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="s-Atom"&gt;cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;temp&lt;/span&gt;

            &lt;span class="s-Atom"&gt;iter&lt;/span&gt; &lt;span class="s-Atom"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s-Atom"&gt;iter&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;dcost&lt;/span&gt;
        &lt;span class="s-Atom"&gt;return&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;W&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;H&lt;/span&gt;


    &lt;span class="s-Atom"&gt;def&lt;/span&gt; &lt;span class="k"&gt;_&lt;/span&gt;&lt;span class="nf"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
        &lt;span class="s-Atom"&gt;return&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;power&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;V&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;W&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;H&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="s-Atom"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;mse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
        &lt;span class="s-Atom"&gt;return&lt;/span&gt; &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;_&lt;/span&gt;&lt;span class="nf"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="s-Atom"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;V&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;V&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="s-Atom"&gt;def&lt;/span&gt; &lt;span class="k"&gt;_&lt;/span&gt;&lt;span class="nf"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
        &lt;span class="nv"&gt;H&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;resid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;rank&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nv"&gt;S&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;linalg&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;lstsq&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;W&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;V&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="s-Atom"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;H&lt;/span&gt;&lt;span class="s-Atom"&gt;&amp;lt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="nv"&gt;H&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;b&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="s-Atom"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;H&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;H&lt;/span&gt;

        &lt;span class="nv"&gt;WT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;resid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;rank&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nv"&gt;S&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;linalg&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;lstsq&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;H&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;V&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="nv"&gt;W&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;WT&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;T&lt;/span&gt;
        &lt;span class="s-Atom"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;W&lt;/span&gt;&lt;span class="s-Atom"&gt;&amp;lt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="nv"&gt;W&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;b&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="s-Atom"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;
        &lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;W&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;W&lt;/span&gt;

    &lt;span class="s-Atom"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;top10headlines&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
        &lt;span class="s-Atom"&gt;top10_indexes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;W&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;:-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;indexes&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="nf"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;top10_indexes&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
            &lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;New Topic: {}&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;index&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="nn"&gt;indexes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s-Atom"&gt;ny&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;&amp;#39;headline&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class="s-Atom"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;top3topics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
        &lt;span class="s-Atom"&gt;return&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;H&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;T&lt;/span&gt;&lt;span class="p"&gt;))[&lt;/span&gt;&lt;span class="s-Atom"&gt;::-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="nf"&gt;tolist&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;


&lt;span class="s-Atom"&gt;nmf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;NMF&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;tfidf_df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;max_iter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s-Atom"&gt;nmf&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mf"&gt;1358.53775257&lt;/span&gt; &lt;span class="mf"&gt;183045559.295&lt;/span&gt;
&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mf"&gt;1300.48172616&lt;/span&gt; &lt;span class="mf"&gt;58.0560264073&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mf"&gt;1268.32077125&lt;/span&gt; &lt;span class="mf"&gt;32.1609549088&lt;/span&gt;
&lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="mf"&gt;1248.0232425&lt;/span&gt; &lt;span class="mf"&gt;20.2975287559&lt;/span&gt;
&lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="mf"&gt;1229.45407174&lt;/span&gt; &lt;span class="mf"&gt;18.5691707553&lt;/span&gt;
&lt;span class="mi"&gt;6&lt;/span&gt; &lt;span class="mf"&gt;1215.00022839&lt;/span&gt; &lt;span class="mf"&gt;14.4538433585&lt;/span&gt;
&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="mf"&gt;1204.01153417&lt;/span&gt; &lt;span class="mf"&gt;10.9886942162&lt;/span&gt;
&lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="mf"&gt;1196.65905672&lt;/span&gt; &lt;span class="mf"&gt;7.35247744427&lt;/span&gt;
&lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="mf"&gt;1192.26204639&lt;/span&gt; &lt;span class="mf"&gt;4.39701033659&lt;/span&gt;
&lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="mf"&gt;1189.20603662&lt;/span&gt; &lt;span class="mf"&gt;3.05600976726&lt;/span&gt;
&lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="mf"&gt;1186.97772507&lt;/span&gt; &lt;span class="mf"&gt;2.22831154859&lt;/span&gt;
&lt;span class="mi"&gt;12&lt;/span&gt; &lt;span class="mf"&gt;1185.18812772&lt;/span&gt; &lt;span class="mf"&gt;1.7895973489&lt;/span&gt;
&lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mf"&gt;1183.65092545&lt;/span&gt; &lt;span class="mf"&gt;1.53720227374&lt;/span&gt;
&lt;span class="mi"&gt;14&lt;/span&gt; &lt;span class="mf"&gt;1182.66629927&lt;/span&gt; &lt;span class="mf"&gt;0.984626175047&lt;/span&gt;
&lt;span class="mi"&gt;15&lt;/span&gt; &lt;span class="mf"&gt;1182.18979125&lt;/span&gt; &lt;span class="mf"&gt;0.47650802397&lt;/span&gt;
&lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="mf"&gt;1181.95567812&lt;/span&gt; &lt;span class="mf"&gt;0.234113130044&lt;/span&gt;
&lt;span class="mi"&gt;17&lt;/span&gt; &lt;span class="mf"&gt;1181.81545439&lt;/span&gt; &lt;span class="mf"&gt;0.140223734529&lt;/span&gt;
&lt;span class="mi"&gt;18&lt;/span&gt; &lt;span class="mf"&gt;1181.71161609&lt;/span&gt; &lt;span class="mf"&gt;0.103838298331&lt;/span&gt;
&lt;span class="mi"&gt;19&lt;/span&gt; &lt;span class="mf"&gt;1181.62183591&lt;/span&gt; &lt;span class="mf"&gt;0.0897801769704&lt;/span&gt;
&lt;span class="mi"&gt;20&lt;/span&gt; &lt;span class="mf"&gt;1181.53770034&lt;/span&gt; &lt;span class="mf"&gt;0.0841355706787&lt;/span&gt;
&lt;span class="mi"&gt;21&lt;/span&gt; &lt;span class="mf"&gt;1181.4564612&lt;/span&gt; &lt;span class="mf"&gt;0.0812391435775&lt;/span&gt;
&lt;span class="mi"&gt;22&lt;/span&gt; &lt;span class="mf"&gt;1181.38118262&lt;/span&gt; &lt;span class="mf"&gt;0.0752785771172&lt;/span&gt;
&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="mf"&gt;1181.31682066&lt;/span&gt; &lt;span class="mf"&gt;0.0643619614168&lt;/span&gt;
&lt;span class="mi"&gt;24&lt;/span&gt; &lt;span class="mf"&gt;1181.2649946&lt;/span&gt; &lt;span class="mf"&gt;0.0518260621986&lt;/span&gt;
&lt;span class="mi"&gt;25&lt;/span&gt; &lt;span class="mf"&gt;1181.22347343&lt;/span&gt; &lt;span class="mf"&gt;0.0415211619361&lt;/span&gt;
&lt;span class="mi"&gt;26&lt;/span&gt; &lt;span class="mf"&gt;1181.19324932&lt;/span&gt; &lt;span class="mf"&gt;0.0302241145484&lt;/span&gt;
&lt;span class="mi"&gt;27&lt;/span&gt; &lt;span class="mf"&gt;1181.17174525&lt;/span&gt; &lt;span class="mf"&gt;0.0215040704031&lt;/span&gt;
&lt;span class="mi"&gt;28&lt;/span&gt; &lt;span class="mf"&gt;1181.15728225&lt;/span&gt; &lt;span class="mf"&gt;0.0144629971055&lt;/span&gt;
&lt;span class="mi"&gt;29&lt;/span&gt; &lt;span class="mf"&gt;1181.14809469&lt;/span&gt; &lt;span class="mf"&gt;0.00918756042415&lt;/span&gt;
&lt;span class="mi"&gt;30&lt;/span&gt; &lt;span class="mf"&gt;1181.14236544&lt;/span&gt; &lt;span class="mf"&gt;0.00572925622464&lt;/span&gt;
&lt;span class="mi"&gt;31&lt;/span&gt; &lt;span class="mf"&gt;1181.13921747&lt;/span&gt; &lt;span class="mf"&gt;0.0031479679767&lt;/span&gt;
&lt;span class="mi"&gt;32&lt;/span&gt; &lt;span class="mf"&gt;1181.13736328&lt;/span&gt; &lt;span class="mf"&gt;0.00185418691763&lt;/span&gt;
&lt;span class="mi"&gt;33&lt;/span&gt; &lt;span class="mf"&gt;1181.13635232&lt;/span&gt; &lt;span class="mf"&gt;0.00101096086269&lt;/span&gt;
&lt;span class="mi"&gt;34&lt;/span&gt; &lt;span class="mf"&gt;1181.1358406&lt;/span&gt; &lt;span class="mf"&gt;0.000511715468292&lt;/span&gt;
&lt;span class="mi"&gt;35&lt;/span&gt; &lt;span class="mf"&gt;1181.13573402&lt;/span&gt; &lt;span class="mf"&gt;0.000106588699282&lt;/span&gt;
&lt;span class="mi"&gt;36&lt;/span&gt; &lt;span class="mf"&gt;1181.13608484&lt;/span&gt; &lt;span class="mf"&gt;0.000350827998545&lt;/span&gt;
&lt;span class="mi"&gt;37&lt;/span&gt; &lt;span class="mf"&gt;1181.13675405&lt;/span&gt; &lt;span class="mf"&gt;0.00066920801919&lt;/span&gt;
&lt;span class="mi"&gt;38&lt;/span&gt; &lt;span class="mf"&gt;1181.13754313&lt;/span&gt; &lt;span class="mf"&gt;0.000789074088061&lt;/span&gt;
&lt;span class="mi"&gt;39&lt;/span&gt; &lt;span class="mf"&gt;1181.1385491&lt;/span&gt; &lt;span class="mf"&gt;0.0010059775077&lt;/span&gt;
&lt;span class="mi"&gt;40&lt;/span&gt; &lt;span class="mf"&gt;1181.13956705&lt;/span&gt; &lt;span class="mf"&gt;0.00101795043247&lt;/span&gt;
&lt;span class="mi"&gt;41&lt;/span&gt; &lt;span class="mf"&gt;1181.14056188&lt;/span&gt; &lt;span class="mf"&gt;0.000994825212956&lt;/span&gt;
&lt;span class="mi"&gt;42&lt;/span&gt; &lt;span class="mf"&gt;1181.14148084&lt;/span&gt; &lt;span class="mf"&gt;0.000918961011848&lt;/span&gt;
&lt;span class="mi"&gt;43&lt;/span&gt; &lt;span class="mf"&gt;1181.14239117&lt;/span&gt; &lt;span class="mf"&gt;0.000910335122171&lt;/span&gt;
&lt;span class="mi"&gt;44&lt;/span&gt; &lt;span class="mf"&gt;1181.14328144&lt;/span&gt; &lt;span class="mf"&gt;0.000890265901035&lt;/span&gt;
&lt;span class="mi"&gt;45&lt;/span&gt; &lt;span class="mf"&gt;1181.14410508&lt;/span&gt; &lt;span class="mf"&gt;0.000823640306407&lt;/span&gt;
&lt;span class="mi"&gt;46&lt;/span&gt; &lt;span class="mf"&gt;1181.14485309&lt;/span&gt; &lt;span class="mf"&gt;0.000748005865034&lt;/span&gt;
&lt;span class="mi"&gt;47&lt;/span&gt; &lt;span class="mf"&gt;1181.14551725&lt;/span&gt; &lt;span class="mf"&gt;0.00066415951801&lt;/span&gt;
&lt;span class="mi"&gt;48&lt;/span&gt; &lt;span class="mf"&gt;1181.14612006&lt;/span&gt; &lt;span class="mf"&gt;0.000602811966701&lt;/span&gt;
&lt;span class="mi"&gt;49&lt;/span&gt; &lt;span class="mf"&gt;1181.14665547&lt;/span&gt; &lt;span class="mf"&gt;0.000535414914339&lt;/span&gt;
&lt;span class="mi"&gt;50&lt;/span&gt; &lt;span class="mf"&gt;1181.14714023&lt;/span&gt; &lt;span class="mf"&gt;0.000484758575794&lt;/span&gt;
&lt;span class="mi"&gt;51&lt;/span&gt; &lt;span class="mf"&gt;1181.14758135&lt;/span&gt; &lt;span class="mf"&gt;0.000441115262447&lt;/span&gt;
&lt;span class="mi"&gt;52&lt;/span&gt; &lt;span class="mf"&gt;1181.14797781&lt;/span&gt; &lt;span class="mf"&gt;0.000396463954758&lt;/span&gt;
&lt;span class="mi"&gt;53&lt;/span&gt; &lt;span class="mf"&gt;1181.14832584&lt;/span&gt; &lt;span class="mf"&gt;0.000348033931004&lt;/span&gt;
&lt;span class="mi"&gt;54&lt;/span&gt; &lt;span class="mf"&gt;1181.14864366&lt;/span&gt; &lt;span class="mf"&gt;0.000317815084145&lt;/span&gt;
&lt;span class="mi"&gt;55&lt;/span&gt; &lt;span class="mf"&gt;1181.14892223&lt;/span&gt; &lt;span class="mf"&gt;0.000278567937812&lt;/span&gt;
&lt;span class="mi"&gt;56&lt;/span&gt; &lt;span class="mf"&gt;1181.14917425&lt;/span&gt; &lt;span class="mf"&gt;0.000252021858387&lt;/span&gt;
&lt;span class="mi"&gt;57&lt;/span&gt; &lt;span class="mf"&gt;1181.14941041&lt;/span&gt; &lt;span class="mf"&gt;0.000236161348994&lt;/span&gt;
&lt;span class="mi"&gt;58&lt;/span&gt; &lt;span class="mf"&gt;1181.14962429&lt;/span&gt; &lt;span class="mf"&gt;0.000213882947492&lt;/span&gt;
&lt;span class="mi"&gt;59&lt;/span&gt; &lt;span class="mf"&gt;1181.14981494&lt;/span&gt; &lt;span class="mf"&gt;0.000190645713246&lt;/span&gt;
&lt;span class="mi"&gt;60&lt;/span&gt; &lt;span class="mf"&gt;1181.14999555&lt;/span&gt; &lt;span class="mf"&gt;0.000180610762527&lt;/span&gt;
&lt;span class="mi"&gt;61&lt;/span&gt; &lt;span class="mf"&gt;1181.15015622&lt;/span&gt; &lt;span class="mf"&gt;0.000160667058935&lt;/span&gt;
&lt;span class="mi"&gt;62&lt;/span&gt; &lt;span class="mf"&gt;1181.15029924&lt;/span&gt; &lt;span class="mf"&gt;0.000143026843944&lt;/span&gt;
&lt;span class="mi"&gt;63&lt;/span&gt; &lt;span class="mf"&gt;1181.15043527&lt;/span&gt; &lt;span class="mf"&gt;0.000136026186738&lt;/span&gt;
&lt;span class="mi"&gt;64&lt;/span&gt; &lt;span class="mf"&gt;1181.15055687&lt;/span&gt; &lt;span class="mf"&gt;0.000121601296541&lt;/span&gt;
&lt;span class="mi"&gt;65&lt;/span&gt; &lt;span class="mf"&gt;1181.15066677&lt;/span&gt; &lt;span class="mf"&gt;0.000109900271582&lt;/span&gt;
&lt;span class="mi"&gt;66&lt;/span&gt; &lt;span class="mf"&gt;1181.15076618&lt;/span&gt; &lt;span class="mf"&gt;9.94073752736e-05&lt;/span&gt;





&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;  &lt;span class="mf"&gt;1.00119406e-01&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;5.68400697e-01&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;...,&lt;/span&gt;
           &lt;span class="mf"&gt;1.64106596e+00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;5.05033775e-02&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;7.65333772e-04&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;  &lt;span class="mf"&gt;1.53327329e-01&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;6.22590411e-02&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;...,&lt;/span&gt;
           &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;  &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;...,&lt;/span&gt;
           &lt;span class="mf"&gt;3.75267776e-02&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;...,&lt;/span&gt; 
        &lt;span class="p"&gt;[&lt;/span&gt;  &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;...,&lt;/span&gt;
           &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.09754697e-01&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;  &lt;span class="mf"&gt;3.89527959e+00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.43767310e+00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;5.01533481e-01&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;...,&lt;/span&gt;
           &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.21685726e+00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;  &lt;span class="mf"&gt;3.68718629e+00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;2.72451285e-01&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;...,&lt;/span&gt;
           &lt;span class="mf"&gt;1.43511299e-01&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;4.36065874e-01&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;]]),&lt;/span&gt;
 &lt;span class="nf"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;  &lt;span class="mf"&gt;5.40116149e-04&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;8.76588753e-04&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.63700931e-04&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;...,&lt;/span&gt;
           &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;  &lt;span class="mf"&gt;2.03678399e-03&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;2.11042158e-03&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;2.47977461e-04&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;...,&lt;/span&gt;
           &lt;span class="mf"&gt;2.68599462e-03&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;4.31713278e-05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;  &lt;span class="mf"&gt;3.06087950e-03&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;2.04330832e-03&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;7.32513575e-04&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;...,&lt;/span&gt;
           &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;7.69852261e-04&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;2.37192788e-03&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;...,&lt;/span&gt; 
        &lt;span class="p"&gt;[&lt;/span&gt;  &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;4.41264815e-03&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;4.46157256e-04&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;...,&lt;/span&gt;
           &lt;span class="mf"&gt;1.77517615e-03&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;  &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.36233670e-03&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;...,&lt;/span&gt;
           &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;2.48418509e-04&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;2.45724743e-03&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;  &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;...,&lt;/span&gt;
           &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;1.00000000e-06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mf"&gt;6.87259348e-05&lt;/span&gt;&lt;span class="p"&gt;]]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For our NY Times example with 1405 articles, we see the fit took 66 iterations and a few seconds to complete.  We can estimate the mean squared error of our results from the matrix we were trying to fit.   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;nmf.mse()




0.00016813534038140441
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Which is close to the tolerance we were shooting for.  Our results do a solid approximation of the Tfidf matrix we were trying to approximate as a product of two matrixes.   Now that we have these matrixes, lets look at the results.&lt;/p&gt;
&lt;h2&gt;Words for Topics&lt;/h2&gt;
&lt;p&gt;We did an initial fit of 20 topics in our NY Times corpus.   For each topic, we can go through and find the top words associted with the topic.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;row&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="nf"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;tfidf_df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;nmf&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;H&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;:-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
    &lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Topic {}:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;row&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;tolist&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;college&lt;/span&gt; &lt;span class="s-Atom"&gt;life&lt;/span&gt; &lt;span class="s-Atom"&gt;poverty&lt;/span&gt; &lt;span class="s-Atom"&gt;people&lt;/span&gt; &lt;span class="s-Atom"&gt;writer&lt;/span&gt; &lt;span class="s-Atom"&gt;student&lt;/span&gt; &lt;span class="s-Atom"&gt;gun&lt;/span&gt; &lt;span class="s-Atom"&gt;york&lt;/span&gt; &lt;span class="s-Atom"&gt;teacher&lt;/span&gt; &lt;span class="s-Atom"&gt;new&lt;/span&gt; &lt;span class="s-Atom"&gt;child&lt;/span&gt; &lt;span class="s-Atom"&gt;school&lt;/span&gt; &lt;span class="mi"&gt;2013&lt;/span&gt; &lt;span class="s-Atom"&gt;editor&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;shutdown&lt;/span&gt; &lt;span class="s-Atom"&gt;economist&lt;/span&gt; &lt;span class="s-Atom"&gt;growth&lt;/span&gt; &lt;span class="s-Atom"&gt;price&lt;/span&gt; &lt;span class="s-Atom"&gt;stock&lt;/span&gt; &lt;span class="s-Atom"&gt;index&lt;/span&gt; &lt;span class="s-Atom"&gt;bond&lt;/span&gt; &lt;span class="s-Atom"&gt;investor&lt;/span&gt; &lt;span class="s-Atom"&gt;government&lt;/span&gt; &lt;span class="s-Atom"&gt;economy&lt;/span&gt; &lt;span class="s-Atom"&gt;debt&lt;/span&gt; &lt;span class="s-Atom"&gt;rate&lt;/span&gt; &lt;span class="s-Atom"&gt;market&lt;/span&gt; &lt;span class="s-Atom"&gt;bank&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;org&lt;/span&gt; &lt;span class="s-Atom"&gt;photograph&lt;/span&gt; &lt;span class="s-Atom"&gt;city&lt;/span&gt; &lt;span class="s-Atom"&gt;drawing&lt;/span&gt; &lt;span class="s-Atom"&gt;like&lt;/span&gt; &lt;span class="s-Atom"&gt;curator&lt;/span&gt; &lt;span class="s-Atom"&gt;street&lt;/span&gt; &lt;span class="s-Atom"&gt;collection&lt;/span&gt; &lt;span class="s-Atom"&gt;work&lt;/span&gt; &lt;span class="s-Atom"&gt;exhibition&lt;/span&gt; &lt;span class="s-Atom"&gt;artist&lt;/span&gt; &lt;span class="s-Atom"&gt;painting&lt;/span&gt; &lt;span class="s-Atom"&gt;gallery&lt;/span&gt; &lt;span class="s-Atom"&gt;museum&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;fan&lt;/span&gt; &lt;span class="s-Atom"&gt;stadium&lt;/span&gt; &lt;span class="s-Atom"&gt;baseball&lt;/span&gt; &lt;span class="s-Atom"&gt;cano&lt;/span&gt; &lt;span class="s-Atom"&gt;yankees&lt;/span&gt; &lt;span class="s-Atom"&gt;mariano&lt;/span&gt; &lt;span class="s-Atom"&gt;season&lt;/span&gt; &lt;span class="s-Atom"&gt;inning&lt;/span&gt; &lt;span class="s-Atom"&gt;rodriguez&lt;/span&gt; &lt;span class="s-Atom"&gt;game&lt;/span&gt; &lt;span class="s-Atom"&gt;jeter&lt;/span&gt; &lt;span class="s-Atom"&gt;girardi&lt;/span&gt; &lt;span class="s-Atom"&gt;pettitte&lt;/span&gt; &lt;span class="s-Atom"&gt;rivera&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;crime&lt;/span&gt; &lt;span class="s-Atom"&gt;sentence&lt;/span&gt; &lt;span class="s-Atom"&gt;prosecutor&lt;/span&gt; &lt;span class="s-Atom"&gt;trial&lt;/span&gt; &lt;span class="s-Atom"&gt;prison&lt;/span&gt; &lt;span class="s-Atom"&gt;law&lt;/span&gt; &lt;span class="s-Atom"&gt;federal&lt;/span&gt; &lt;span class="s-Atom"&gt;lawyer&lt;/span&gt; &lt;span class="s-Atom"&gt;justice&lt;/span&gt; &lt;span class="s-Atom"&gt;state&lt;/span&gt; &lt;span class="s-Atom"&gt;case&lt;/span&gt; &lt;span class="s-Atom"&gt;said&lt;/span&gt; &lt;span class="s-Atom"&gt;judge&lt;/span&gt; &lt;span class="s-Atom"&gt;court&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;berlin&lt;/span&gt; &lt;span class="s-Atom"&gt;vote&lt;/span&gt; &lt;span class="s-Atom"&gt;chancellor&lt;/span&gt; &lt;span class="s-Atom"&gt;coalition&lt;/span&gt; &lt;span class="s-Atom"&gt;election&lt;/span&gt; &lt;span class="s-Atom"&gt;social&lt;/span&gt; &lt;span class="s-Atom"&gt;democrat&lt;/span&gt; &lt;span class="s-Atom"&gt;euro&lt;/span&gt; &lt;span class="s-Atom"&gt;european&lt;/span&gt; &lt;span class="s-Atom"&gt;europe&lt;/span&gt; &lt;span class="s-Atom"&gt;german&lt;/span&gt; &lt;span class="s-Atom"&gt;party&lt;/span&gt; &lt;span class="s-Atom"&gt;ms&lt;/span&gt; &lt;span class="s-Atom"&gt;germany&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;medical&lt;/span&gt; &lt;span class="s-Atom"&gt;cost&lt;/span&gt; &lt;span class="s-Atom"&gt;pay&lt;/span&gt; &lt;span class="s-Atom"&gt;people&lt;/span&gt; &lt;span class="s-Atom"&gt;affordable&lt;/span&gt; &lt;span class="s-Atom"&gt;employee&lt;/span&gt; &lt;span class="s-Atom"&gt;coverage&lt;/span&gt; &lt;span class="s-Atom"&gt;plan&lt;/span&gt; &lt;span class="s-Atom"&gt;federal&lt;/span&gt; &lt;span class="s-Atom"&gt;law&lt;/span&gt; &lt;span class="s-Atom"&gt;company&lt;/span&gt; &lt;span class="s-Atom"&gt;exchange&lt;/span&gt; &lt;span class="s-Atom"&gt;care&lt;/span&gt; &lt;span class="s-Atom"&gt;insurance&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;red&lt;/span&gt; &lt;span class="s-Atom"&gt;indian&lt;/span&gt; &lt;span class="s-Atom"&gt;wright&lt;/span&gt; &lt;span class="s-Atom"&gt;league&lt;/span&gt; &lt;span class="s-Atom"&gt;homer&lt;/span&gt; &lt;span class="s-Atom"&gt;season&lt;/span&gt; &lt;span class="s-Atom"&gt;win&lt;/span&gt; &lt;span class="s-Atom"&gt;host&lt;/span&gt; &lt;span class="s-Atom"&gt;mets&lt;/span&gt; &lt;span class="s-Atom"&gt;card&lt;/span&gt; &lt;span class="s-Atom"&gt;wild&lt;/span&gt; &lt;span class="s-Atom"&gt;hit&lt;/span&gt; &lt;span class="s-Atom"&gt;game&lt;/span&gt; &lt;span class="s-Atom"&gt;run&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;care&lt;/span&gt; &lt;span class="s-Atom"&gt;debt&lt;/span&gt; &lt;span class="s-Atom"&gt;law&lt;/span&gt; &lt;span class="s-Atom"&gt;cruz&lt;/span&gt; &lt;span class="s-Atom"&gt;senator&lt;/span&gt; &lt;span class="s-Atom"&gt;vote&lt;/span&gt; &lt;span class="s-Atom"&gt;democrat&lt;/span&gt; &lt;span class="s-Atom"&gt;party&lt;/span&gt; &lt;span class="s-Atom"&gt;mr&lt;/span&gt; &lt;span class="s-Atom"&gt;obama&lt;/span&gt; &lt;span class="s-Atom"&gt;shutdown&lt;/span&gt; &lt;span class="s-Atom"&gt;government&lt;/span&gt; &lt;span class="s-Atom"&gt;senate&lt;/span&gt; &lt;span class="s-Atom"&gt;house&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;fan&lt;/span&gt; &lt;span class="s-Atom"&gt;played&lt;/span&gt; &lt;span class="s-Atom"&gt;sport&lt;/span&gt; &lt;span class="s-Atom"&gt;year&lt;/span&gt; &lt;span class="s-Atom"&gt;goal&lt;/span&gt; &lt;span class="s-Atom"&gt;football&lt;/span&gt; &lt;span class="s-Atom"&gt;giant&lt;/span&gt; &lt;span class="s-Atom"&gt;play&lt;/span&gt; &lt;span class="s-Atom"&gt;coach&lt;/span&gt; &lt;span class="s-Atom"&gt;league&lt;/span&gt; &lt;span class="s-Atom"&gt;said&lt;/span&gt; &lt;span class="s-Atom"&gt;player&lt;/span&gt; &lt;span class="s-Atom"&gt;season&lt;/span&gt; &lt;span class="s-Atom"&gt;game&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;comedy&lt;/span&gt; &lt;span class="s-Atom"&gt;breaking&lt;/span&gt; &lt;span class="s-Atom"&gt;hbo&lt;/span&gt; &lt;span class="s-Atom"&gt;million&lt;/span&gt; &lt;span class="s-Atom"&gt;television&lt;/span&gt; &lt;span class="s-Atom"&gt;fox&lt;/span&gt; &lt;span class="s-Atom"&gt;emmy&lt;/span&gt; &lt;span class="s-Atom"&gt;drama&lt;/span&gt; &lt;span class="s-Atom"&gt;series&lt;/span&gt; &lt;span class="s-Atom"&gt;network&lt;/span&gt; &lt;span class="s-Atom"&gt;abc&lt;/span&gt; &lt;span class="s-Atom"&gt;rating&lt;/span&gt; &lt;span class="s-Atom"&gt;cbs&lt;/span&gt; &lt;span class="s-Atom"&gt;nbc&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;war&lt;/span&gt; &lt;span class="s-Atom"&gt;al&lt;/span&gt; &lt;span class="s-Atom"&gt;international&lt;/span&gt; &lt;span class="s-Atom"&gt;rebel&lt;/span&gt; &lt;span class="s-Atom"&gt;security&lt;/span&gt; &lt;span class="s-Atom"&gt;russia&lt;/span&gt; &lt;span class="s-Atom"&gt;council&lt;/span&gt; &lt;span class="s-Atom"&gt;nation&lt;/span&gt; &lt;span class="s-Atom"&gt;assad&lt;/span&gt; &lt;span class="s-Atom"&gt;resolution&lt;/span&gt; &lt;span class="s-Atom"&gt;united&lt;/span&gt; &lt;span class="s-Atom"&gt;syrian&lt;/span&gt; &lt;span class="s-Atom"&gt;weapon&lt;/span&gt; &lt;span class="s-Atom"&gt;chemical&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;state&lt;/span&gt; &lt;span class="s-Atom"&gt;beijing&lt;/span&gt; &lt;span class="s-Atom"&gt;kong&lt;/span&gt; &lt;span class="s-Atom"&gt;hong&lt;/span&gt; &lt;span class="s-Atom"&gt;nuclear&lt;/span&gt; &lt;span class="s-Atom"&gt;energy&lt;/span&gt; &lt;span class="s-Atom"&gt;gas&lt;/span&gt; &lt;span class="s-Atom"&gt;said&lt;/span&gt; &lt;span class="s-Atom"&gt;korea&lt;/span&gt; &lt;span class="s-Atom"&gt;north&lt;/span&gt; &lt;span class="s-Atom"&gt;company&lt;/span&gt; &lt;span class="s-Atom"&gt;plant&lt;/span&gt; &lt;span class="s-Atom"&gt;chinese&lt;/span&gt; &lt;span class="s-Atom"&gt;oil&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;wind&lt;/span&gt; &lt;span class="s-Atom"&gt;yacht&lt;/span&gt; &lt;span class="s-Atom"&gt;club&lt;/span&gt; &lt;span class="s-Atom"&gt;regatta&lt;/span&gt; &lt;span class="s-Atom"&gt;francisco&lt;/span&gt; &lt;span class="s-Atom"&gt;san&lt;/span&gt; &lt;span class="s-Atom"&gt;racing&lt;/span&gt; &lt;span class="s-Atom"&gt;spithill&lt;/span&gt; &lt;span class="s-Atom"&gt;america&lt;/span&gt; &lt;span class="s-Atom"&gt;boat&lt;/span&gt; &lt;span class="s-Atom"&gt;zealand&lt;/span&gt; &lt;span class="s-Atom"&gt;team&lt;/span&gt; &lt;span class="s-Atom"&gt;oracle&lt;/span&gt; &lt;span class="s-Atom"&gt;race&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;killing&lt;/span&gt; &lt;span class="s-Atom"&gt;soldier&lt;/span&gt; &lt;span class="s-Atom"&gt;iraq&lt;/span&gt; &lt;span class="s-Atom"&gt;city&lt;/span&gt; &lt;span class="s-Atom"&gt;taliban&lt;/span&gt; &lt;span class="s-Atom"&gt;official&lt;/span&gt; &lt;span class="s-Atom"&gt;baghdad&lt;/span&gt; &lt;span class="s-Atom"&gt;bomb&lt;/span&gt; &lt;span class="s-Atom"&gt;afghan&lt;/span&gt; &lt;span class="s-Atom"&gt;pakistan&lt;/span&gt; &lt;span class="s-Atom"&gt;people&lt;/span&gt; &lt;span class="s-Atom"&gt;killed&lt;/span&gt; &lt;span class="s-Atom"&gt;police&lt;/span&gt; &lt;span class="s-Atom"&gt;attack&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;arrested&lt;/span&gt; &lt;span class="s-Atom"&gt;right&lt;/span&gt; &lt;span class="s-Atom"&gt;immigrant&lt;/span&gt; &lt;span class="s-Atom"&gt;athens&lt;/span&gt; &lt;span class="s-Atom"&gt;member&lt;/span&gt; &lt;span class="s-Atom"&gt;political&lt;/span&gt; &lt;span class="s-Atom"&gt;murder&lt;/span&gt; &lt;span class="s-Atom"&gt;parliament&lt;/span&gt; &lt;span class="s-Atom"&gt;greece&lt;/span&gt; &lt;span class="s-Atom"&gt;government&lt;/span&gt; &lt;span class="s-Atom"&gt;greek&lt;/span&gt; &lt;span class="s-Atom"&gt;police&lt;/span&gt; &lt;span class="s-Atom"&gt;golden&lt;/span&gt; &lt;span class="s-Atom"&gt;dawn&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;terrorist&lt;/span&gt; &lt;span class="s-Atom"&gt;group&lt;/span&gt; &lt;span class="s-Atom"&gt;attacker&lt;/span&gt; &lt;span class="s-Atom"&gt;westgate&lt;/span&gt; &lt;span class="s-Atom"&gt;american&lt;/span&gt; &lt;span class="s-Atom"&gt;official&lt;/span&gt; &lt;span class="s-Atom"&gt;militant&lt;/span&gt; &lt;span class="s-Atom"&gt;somali&lt;/span&gt; &lt;span class="s-Atom"&gt;attack&lt;/span&gt; &lt;span class="s-Atom"&gt;nairobi&lt;/span&gt; &lt;span class="s-Atom"&gt;somalia&lt;/span&gt; &lt;span class="s-Atom"&gt;kenyan&lt;/span&gt; &lt;span class="s-Atom"&gt;mall&lt;/span&gt; &lt;span class="s-Atom"&gt;shabab&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;pas&lt;/span&gt; &lt;span class="s-Atom"&gt;manning&lt;/span&gt; &lt;span class="s-Atom"&gt;tennessee&lt;/span&gt; &lt;span class="s-Atom"&gt;turnover&lt;/span&gt; &lt;span class="s-Atom"&gt;jet&lt;/span&gt; &lt;span class="s-Atom"&gt;giant&lt;/span&gt; &lt;span class="s-Atom"&gt;quarter&lt;/span&gt; &lt;span class="s-Atom"&gt;game&lt;/span&gt; &lt;span class="s-Atom"&gt;interception&lt;/span&gt; &lt;span class="s-Atom"&gt;smith&lt;/span&gt; &lt;span class="s-Atom"&gt;pass&lt;/span&gt; &lt;span class="s-Atom"&gt;threw&lt;/span&gt; &lt;span class="s-Atom"&gt;quarterback&lt;/span&gt; &lt;span class="s-Atom"&gt;touchdown&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;piece&lt;/span&gt; &lt;span class="s-Atom"&gt;concert&lt;/span&gt; &lt;span class="s-Atom"&gt;album&lt;/span&gt; &lt;span class="s-Atom"&gt;dancer&lt;/span&gt; &lt;span class="s-Atom"&gt;performance&lt;/span&gt; &lt;span class="s-Atom"&gt;work&lt;/span&gt; &lt;span class="s-Atom"&gt;band&lt;/span&gt; &lt;span class="s-Atom"&gt;orchestra&lt;/span&gt; &lt;span class="s-Atom"&gt;ms&lt;/span&gt; &lt;span class="s-Atom"&gt;song&lt;/span&gt; &lt;span class="s-Atom"&gt;ballet&lt;/span&gt; &lt;span class="s-Atom"&gt;opera&lt;/span&gt; &lt;span class="s-Atom"&gt;dance&lt;/span&gt; &lt;span class="s-Atom"&gt;mr&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;meeting&lt;/span&gt; &lt;span class="s-Atom"&gt;speech&lt;/span&gt; &lt;span class="s-Atom"&gt;nation&lt;/span&gt; &lt;span class="s-Atom"&gt;israeli&lt;/span&gt; &lt;span class="s-Atom"&gt;sanction&lt;/span&gt; &lt;span class="s-Atom"&gt;president&lt;/span&gt; &lt;span class="s-Atom"&gt;united&lt;/span&gt; &lt;span class="s-Atom"&gt;netanyahu&lt;/span&gt; &lt;span class="s-Atom"&gt;obama&lt;/span&gt; &lt;span class="s-Atom"&gt;israel&lt;/span&gt; &lt;span class="s-Atom"&gt;mr&lt;/span&gt; &lt;span class="s-Atom"&gt;iranian&lt;/span&gt; &lt;span class="s-Atom"&gt;nuclear&lt;/span&gt; &lt;span class="s-Atom"&gt;rouhani&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;These words for each topic are very distinctive.  The first has to do with schools, the second with the economy, and the third with life style.   The forth is baseball, and the firth is legal.   If we had a huge corpus and did not know how to make subsections, thes topics would do.  Infact they line up pretty well with the 19 sections in the NY Times website. &lt;/p&gt;
&lt;p&gt;Instead of looking at the words for each topic, we can look at the headlines assoicated with the articles that are characterist of the topics.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;nmf.top10headlines()

New Topic: 1
A New (Harder?) Admissions Option at Bard College
Children Killed by Guns: Stopping the Scourge
Measuring Poverty and the Income Gap
Preparing Teachers for the Urban Classroom
Private School Admission
Trophies for All, or Just the Deserving?
G.O.P. vs. Health Law and Food Stamps
Two Approaches to Homelessness
Investing in Early Childhood Now, for a Payoff Later
When Evangelicals Adopt Children Abroad

New Topic: 2
Orders for Durable Goods Increased Slightly in August
Consumer Spending Rose Slightly in August
European Unemployment Steady, Hinting at Progress in Crisis
Jobs Data Helps Wall St. Halt a 5-Day Slide
Markets Fall as Investors Rehash the Fed&amp;amp;#8217;s Decision
Housing Recovery Seems Still on Track 
Shadow of Shutdown Looms Over Markets
Wall Street Closes Higher Despite U.S. Shutdown
Fight Over U.S. Budget Weighs on Shares
S.&amp;amp;P. Falls for a 5th Day As Federal Shutdown Looms

New Topic: 3
Spare Times for Sept. 27-Oct. 3
A Monet for Show and Tell
Midnight at the Museum, Breakfast at the Vatican
A New Survey Finds a Drop in Arts Attendance
Passion, Principle or Both? Deciphering Art Vandalism
Newcomb Pottery Will Go on View at Tulane
The Agony of Suspense in Detroit
From Beirut to Bogotá: Art Cities to Watch?
Museum and Gallery Listings for Sept. 27-Oct. 3
Hey ‘Starry Night,’ Say ‘Cheese!’

New Topic: 4
For Yankees, Emotional Conclusion Isn’t End
The Yankees’ Farewell Sundays of 2008 and 2013
Memorable End for Two; Forgettable Year for Yanks
Young Catcher Can Help Tell Ending to Rivera’s Story
Mariano Rivera: A Zen Master With a Mean Cutter
A Final Bow for Rivera
When Rivera Started, and Pettitte Relieved
Mariano Rivera’s Saving Grace
Yankees’ Costly Loss Puts a Damper on Rivera’s Party
Closing Scene: Hugs and Tears in Rivera’s Last Home Game

New Topic: 5
In Supreme Court Opinions, Web Links to Nowhere
Former F.B.I. Agent to Plead Guilty in Press Leak
The Hague: Warrant Issued for Kenyan
Intriguing Tip From a Source Who’s Suspect
Louisiana: New Trial for Man Convicted of Murder in &amp;#39;74
Why Judges Are Scowling at Banks
A Rare Plea to the Court
Citing New Evidence, Urging a Posthumous Pardon in 1992 Case
Rubio Withdraws Support for Gay Black Judge’s Nomination to the Federal Bench
50-Year Sentence Upheld for Ex-President of Liberia

New Topic: 6
German Politician Faces Plagiarism Accusations
A Challenge to European Political Elite
Anti-Euro Party Gaining Steam in Germany
Merkel the Great
After Rout in German Elections, Social Democrats Consider Coalition With Merkel
German Campaign, Amid Fiery Debate Abroad, Shuffles Toward Consensus
Angela Merkel’s Next Challenge
Vote for Merkel Seen as Victory for Austerity
Merkel Re-elected in Show of Strong Support for Party
After Rewarding Merkel, Germans Seek Focus at Home

New Topic: 7
Health Insurance Exchanges Scramble to Be Ready as Opening Day Nears
Opening Rush to Insurance Markets Runs Into Snags
Health Care Choices in the New Era
Lacking Rules, Insurers Balk at Paying for Intensive Psychiatric Care
U.S. Plans to Unveil New Insurance Options
As Some Companies Turn to Health Exchanges, G.E. Seeks a New Path
Day 1: The New World of Health Care
Dawn of a Revolution in Health Care
On the Threshold of Obamacare, Warily
The Landscape of Small-Business Health Insurance

New Topic: 8
Wright Homers Again to Help Mets Past Phillies
Indians Get Wild-Card Slot as Rays and Rangers Go to a Tiebreaker
Scherzer Wins 21st as Tigers Clinch
Cardinals Prevail Behind a One-Hitter
Rays and Rangers Tied as A.L. Race Nears End
Game Ends on Wild Pitch, Giving Marlin a No-Hitter
Wild-Card Race Tightens as Rays Lose to Blue Jays
Red Sox Clinch East; Indians Win, As Do Royals
21-Year Wait Is Over for Playoff-Bound Pirates 
Rays, Royals and Indians Win in A.L. Playoff Race

New Topic: 9
House Bill Links Health Care Law and Budget Plan
Government Shuts Down in Budget Impasse
Senator Persists Battling Health Law, Irking Even Many in His Own Party
Staunch Group of Republicans Outflanks House Leaders
Those Banana Republicans
U.S. Shutdown
Nears as House
Votes to Delay
Health Law
Senate Action on Health Law Moves to Brink of Shutdown
Obama Sets Conditions for Talks: Pass Funding and Raise Debt Ceiling
Conservatives With a Cause: ‘We’re Right’
Shutdown Looms as Senate Passes Budget Bill

New Topic: 10
Coughlin Leads Calls for Giants to Show More Character
Giants’ Battered Line Faces a Tough Test
Favorites? Broncos, by a Wide Margin 
Knicks and Nets, Growing Rivals, Will Work Together to Host All-Star Events
Petke Sobered by Club’s Checkered Past
No Quick-Fix Recipe for the Giants
Hype Machine in Overdrive, N.F.L. Pops Back to London
Cosmos-Rowdies: That ’70s Rivalry, Updated
Where Mets Go Deep
Goalkeeper Makes a Case for Team M.V.P.

New Topic: 11
Race to End for ‘Breaking Bad’ Fans Who Got Behind
In Ratings War, ‘G.M.A.’ Beats ‘Today’ for Full Season
Head of NBC Entertainment Extends Contract to 2017
Networks Go to Extremes to Promote New Shows for the Fall Season
2013 Emmy Award Winners and Nominees
Emmys Highlight a Changing TV Industry
Emmys Draw 17 Million Viewers, Up From Recent Shows
‘Big Bang’ Reinforces Its Status as Biggest Hit on Network TV
‘Agents of S.H.I.E.L.D.’ Gains a Big Audience While ‘The Voice’ Keeps Rolling
‘The Voice’ Propels NBC to a Big Ratings Win on Monday Night

New Topic: 12
Stance on Peace Talks Suggests Syria and West Differ on Tactics
Missed Opportunity in Syria Haunts U.N. Official
For the U.N., Syria Is Both Promise and Peril
Text of Draft United Nations Resolution on Syrian Chemical Weapons
Invoking Sept. 11, Syrian Accuses U.S. of Hypocrisy
Some Progress on Syria
Syria Meets First Test of Accord on Weapons
U.N. Investigates More Alleged Chemical Attacks in Syria
Swift Movement Is Seen on Syria After U.N. Action
U.N. Deal on Syrian Arms Is Milestone After Years of Inertia

New Topic: 13
Japan’s Leader Gives No Ground in Islands Dispute
U.S. Gears Up to Be a Prime Gas Exporter
As Stability Eludes Region, Western Oil Giants Hesitate
Chinese Titan Takes Aim at Hollywood
Hacking U.S. Secrets, China Pushes for Drones
China Is Said to Be Holding a Professor Based in Japan
Volkswagen Expanding Production in China
Volkswagen Expanding Production in China
China Bans Items for Export to North Korea, Fearing Their Use in Weapons
China Ban on Items for Nuclear Use to North Korea May Stall Arms Bid

New Topic: 14
Australia Primed for First Cup Challenge Since 2000
In New Zealand, Jitters Yield to Cheers, Then Sighs
Extended America’s Cup Leaves Some High, Dry and Homeless
New Zealand Is Kept Waiting Again
Oracle Team USA Now Has the Wind at Its Back
Oracle Completes Voyage to History, Winning America’s Cup
Saved by Light Breeze, Oracle Will Race Again
The Cup May Stay, but There’s No Going Back on Speed
Oracle Sweeps Two Races to Tie America’s Cup
After Comeback for the Ages, a Last Dash for America’s Cup

New Topic: 15
Once-Calm Area of Iraq Is Shaken by Bombings
Pakistan Christians Issue Call for Protection
Iraq: Multiple Bomb Attacks at Markets
11 Officers Killed as Taliban Strike Afghan Border Post
Bus Bombing in Pakistan Kills at Least 17 Government Employees
Scores Are Killed by Suicide Bomb Attack at Historic Church in Pakistan
Iraq: Bombings Kill at Least 55
A Deadly Week in Northwestern Pakistan Ends With a Car Bomb Blast
Attacks Kill Scores in Iraq as Violence Surges
Bomber Hits Sunni Funeral as Attacks Mount in Iraq

New Topic: 16
A Challenge to European Political Elite
Norway: New Coalition Tilts Right
Smaller Parties Gain in Austrian National Elections
British Party Leader Suspended After Crude Remark and Swipe at Reporter
Greek Civil Servants Start 2-Day Strike
Greece: A Vow to Erase a ‘Shame’
Greece: Police Under Scrutiny
Greece, in Anti-Fascist Crackdown, Investigates Police
Case Against Greek Far-Right Party Draws Critics
Greece Arrests Senior Members of Far-Right Party

New Topic: 17
Why Nairobi
A Shaken Kenya Is Hit Again in 2 Deadly Attacks by Militants
Kenya Forces Said to Be Securing Mall After Long Standoff
Gunmen Kill Dozens in Terror Attack at Kenyan Mall
Somali Militants Mixing Business and Terror
U.S. Sees Direct Threat in Attack at Kenya Mall
Kenya Presses Assault Against Militants in Mall Siege
Attention Switches to Investigation of Kenyan Mall Siege
Before Kenya Attack, Rehearsals and Planting of Machine Guns
Kenya’s Brutal Coming of Age

New Topic: 18
Fantasy Football: Week 4 Matchup Breakdown
Niners Rebound With a Rout Against St. Louis
College Football Around the Country
Saints Hand Dolphins Their First Defeat
College Football Around the Country
 Ohio State Streak Is at 17 With Win Over Wisconsin
Rare Rushing Feat by a Princeton Quarterback Helps the Tigers Crush Georgetown
Nova Throws for 3 Touchdowns as Rutgers Rallies Past Arkansas
Michigan Hangs On After Scare, Again
In Game of Turnovers, Bengals Get Last One, and a Win

New Topic: 19
Dance Listings for Sept. 27-Oct. 3
Experimenting Begins as the Music Starts to Play
The Dawn of a World, Dreamlike Yet Chaotic
A Sampling of Old and New, Side by Side
It’s Not What You Wear, It’s How You Dance in It
Giddy Freedom (a Little Mambo!), as Well as Pianistic Elegance and Wit
A Swing and a Jaunt Around the Globe
An Impish Faun, Swans, and a Lively Card Deck
Movers and Shapers
A Giant of Dance, Seizing on Musicality to Weave His Spell

New Topic: 20
President Rouhani Comes to Town
Israel and Others in Mideast View Overtures of U.S. and Iran With Suspicion
Israel and Others in Mideast View Overtures of U.S. and Iran With Suspicion
Hassan Does Manhattan
Now, the Hard Part
Iran’s President Responds to Netanyahu
Netanyahu Pushes Back on Iran
Discussing Iran, Obama and Netanyahu Display Unity
Iran’s New President Preaches Tolerance in First U.N. Appearance
Israeli Leader Excoriates New President of Iran
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;These headline reinforce the words results we saw above.  The NMF techniques are finding topics in this corpus.   The question, I am wondering, is how do you know when you have enough topics.  We know from yesterday that 90% of the energy is in the first 500 topics (if SVD can carry over).   But we only have 1400 articles.  This does not see useful.    I will think on this topic.&lt;/p&gt;
&lt;h2&gt;Sklearn NMF&lt;/h2&gt;
&lt;p&gt;As usual, we want to compare our results with the results of Sklearn's implementation.   In this case, eventhough we are using the same algorithm, sklearn is much smarter about the setup.  Looking at thier code, I see that they use the SVD decomposition to make a smart first guess as to the matrixes W and H.  I am sure this leads to quicker convergence.   They are also taking advantage of thier c optimization libraries.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="s-Atom"&gt;from&lt;/span&gt; &lt;span class="s-Atom"&gt;sklearn&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;decomposition&lt;/span&gt; &lt;span class="s-Atom"&gt;import&lt;/span&gt; &lt;span class="nv"&gt;NMF&lt;/span&gt;
&lt;span class="s-Atom"&gt;nmf2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;NMF&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;n_components&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nf"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;tfidf_df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;values&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;row&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="nf"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;tfidf_df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;nmf2&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;components_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;:-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
    &lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Topic {}:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;row&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;tolist&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;obama&lt;/span&gt; &lt;span class="s-Atom"&gt;president&lt;/span&gt; &lt;span class="s-Atom"&gt;people&lt;/span&gt; &lt;span class="s-Atom"&gt;navy&lt;/span&gt; &lt;span class="s-Atom"&gt;prime&lt;/span&gt; &lt;span class="s-Atom"&gt;john&lt;/span&gt; &lt;span class="s-Atom"&gt;mayor&lt;/span&gt; &lt;span class="s-Atom"&gt;alexis&lt;/span&gt; &lt;span class="s-Atom"&gt;political&lt;/span&gt; &lt;span class="s-Atom"&gt;maduro&lt;/span&gt; &lt;span class="s-Atom"&gt;year&lt;/span&gt; &lt;span class="s-Atom"&gt;minister&lt;/span&gt; &lt;span class="s-Atom"&gt;official&lt;/span&gt; &lt;span class="s-Atom"&gt;said&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;rodriguez&lt;/span&gt; &lt;span class="s-Atom"&gt;jeter&lt;/span&gt; &lt;span class="s-Atom"&gt;pitch&lt;/span&gt; &lt;span class="s-Atom"&gt;league&lt;/span&gt; &lt;span class="s-Atom"&gt;baseball&lt;/span&gt; &lt;span class="s-Atom"&gt;girardi&lt;/span&gt; &lt;span class="s-Atom"&gt;said&lt;/span&gt; &lt;span class="s-Atom"&gt;hit&lt;/span&gt; &lt;span class="s-Atom"&gt;run&lt;/span&gt; &lt;span class="s-Atom"&gt;season&lt;/span&gt; &lt;span class="s-Atom"&gt;pettitte&lt;/span&gt; &lt;span class="s-Atom"&gt;inning&lt;/span&gt; &lt;span class="s-Atom"&gt;game&lt;/span&gt; &lt;span class="s-Atom"&gt;rivera&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;care&lt;/span&gt; &lt;span class="s-Atom"&gt;shutdown&lt;/span&gt; &lt;span class="s-Atom"&gt;obamacare&lt;/span&gt; &lt;span class="s-Atom"&gt;conservative&lt;/span&gt; &lt;span class="s-Atom"&gt;government&lt;/span&gt; &lt;span class="s-Atom"&gt;obama&lt;/span&gt; &lt;span class="s-Atom"&gt;law&lt;/span&gt; &lt;span class="s-Atom"&gt;vote&lt;/span&gt; &lt;span class="s-Atom"&gt;party&lt;/span&gt; &lt;span class="s-Atom"&gt;cruz&lt;/span&gt; &lt;span class="s-Atom"&gt;senator&lt;/span&gt; &lt;span class="s-Atom"&gt;democrat&lt;/span&gt; &lt;span class="s-Atom"&gt;senate&lt;/span&gt; &lt;span class="s-Atom"&gt;house&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;hassan&lt;/span&gt; &lt;span class="s-Atom"&gt;speech&lt;/span&gt; &lt;span class="s-Atom"&gt;nation&lt;/span&gt; &lt;span class="s-Atom"&gt;israeli&lt;/span&gt; &lt;span class="s-Atom"&gt;sanction&lt;/span&gt; &lt;span class="s-Atom"&gt;mr&lt;/span&gt; &lt;span class="s-Atom"&gt;president&lt;/span&gt; &lt;span class="s-Atom"&gt;united&lt;/span&gt; &lt;span class="s-Atom"&gt;netanyahu&lt;/span&gt; &lt;span class="s-Atom"&gt;obama&lt;/span&gt; &lt;span class="s-Atom"&gt;israel&lt;/span&gt; &lt;span class="s-Atom"&gt;iranian&lt;/span&gt; &lt;span class="s-Atom"&gt;nuclear&lt;/span&gt; &lt;span class="s-Atom"&gt;rouhani&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;group&lt;/span&gt; &lt;span class="s-Atom"&gt;somali&lt;/span&gt; &lt;span class="s-Atom"&gt;people&lt;/span&gt; &lt;span class="s-Atom"&gt;somalia&lt;/span&gt; &lt;span class="s-Atom"&gt;nairobi&lt;/span&gt; &lt;span class="s-Atom"&gt;official&lt;/span&gt; &lt;span class="s-Atom"&gt;police&lt;/span&gt; &lt;span class="s-Atom"&gt;killed&lt;/span&gt; &lt;span class="s-Atom"&gt;militant&lt;/span&gt; &lt;span class="s-Atom"&gt;said&lt;/span&gt; &lt;span class="s-Atom"&gt;kenyan&lt;/span&gt; &lt;span class="s-Atom"&gt;shabab&lt;/span&gt; &lt;span class="s-Atom"&gt;kenya&lt;/span&gt; &lt;span class="s-Atom"&gt;mall&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;war&lt;/span&gt; &lt;span class="s-Atom"&gt;international&lt;/span&gt; &lt;span class="s-Atom"&gt;al&lt;/span&gt; &lt;span class="s-Atom"&gt;security&lt;/span&gt; &lt;span class="s-Atom"&gt;rebel&lt;/span&gt; &lt;span class="s-Atom"&gt;russia&lt;/span&gt; &lt;span class="s-Atom"&gt;assad&lt;/span&gt; &lt;span class="s-Atom"&gt;council&lt;/span&gt; &lt;span class="s-Atom"&gt;nation&lt;/span&gt; &lt;span class="s-Atom"&gt;resolution&lt;/span&gt; &lt;span class="s-Atom"&gt;united&lt;/span&gt; &lt;span class="s-Atom"&gt;syrian&lt;/span&gt; &lt;span class="s-Atom"&gt;weapon&lt;/span&gt; &lt;span class="s-Atom"&gt;chemical&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;government&lt;/span&gt; &lt;span class="s-Atom"&gt;political&lt;/span&gt; &lt;span class="s-Atom"&gt;social&lt;/span&gt; &lt;span class="s-Atom"&gt;coalition&lt;/span&gt; &lt;span class="s-Atom"&gt;democrat&lt;/span&gt; &lt;span class="s-Atom"&gt;parliament&lt;/span&gt; &lt;span class="s-Atom"&gt;election&lt;/span&gt; &lt;span class="s-Atom"&gt;euro&lt;/span&gt; &lt;span class="s-Atom"&gt;european&lt;/span&gt; &lt;span class="s-Atom"&gt;ms&lt;/span&gt; &lt;span class="s-Atom"&gt;europe&lt;/span&gt; &lt;span class="s-Atom"&gt;german&lt;/span&gt; &lt;span class="s-Atom"&gt;germany&lt;/span&gt; &lt;span class="s-Atom"&gt;merkel&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;said&lt;/span&gt; &lt;span class="s-Atom"&gt;regatta&lt;/span&gt; &lt;span class="s-Atom"&gt;match&lt;/span&gt; &lt;span class="s-Atom"&gt;francisco&lt;/span&gt; &lt;span class="s-Atom"&gt;san&lt;/span&gt; &lt;span class="s-Atom"&gt;racing&lt;/span&gt; &lt;span class="s-Atom"&gt;spithill&lt;/span&gt; &lt;span class="s-Atom"&gt;america&lt;/span&gt; &lt;span class="s-Atom"&gt;club&lt;/span&gt; &lt;span class="s-Atom"&gt;boat&lt;/span&gt; &lt;span class="s-Atom"&gt;zealand&lt;/span&gt; &lt;span class="s-Atom"&gt;oracle&lt;/span&gt; &lt;span class="s-Atom"&gt;team&lt;/span&gt; &lt;span class="s-Atom"&gt;race&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;people&lt;/span&gt; &lt;span class="s-Atom"&gt;act&lt;/span&gt; &lt;span class="s-Atom"&gt;cost&lt;/span&gt; &lt;span class="s-Atom"&gt;insurer&lt;/span&gt; &lt;span class="s-Atom"&gt;medical&lt;/span&gt; &lt;span class="s-Atom"&gt;state&lt;/span&gt; &lt;span class="s-Atom"&gt;federal&lt;/span&gt; &lt;span class="s-Atom"&gt;affordable&lt;/span&gt; &lt;span class="s-Atom"&gt;plan&lt;/span&gt; &lt;span class="s-Atom"&gt;coverage&lt;/span&gt; &lt;span class="s-Atom"&gt;law&lt;/span&gt; &lt;span class="s-Atom"&gt;exchange&lt;/span&gt; &lt;span class="s-Atom"&gt;care&lt;/span&gt; &lt;span class="s-Atom"&gt;insurance&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;woman&lt;/span&gt; &lt;span class="s-Atom"&gt;york&lt;/span&gt; &lt;span class="s-Atom"&gt;writer&lt;/span&gt; &lt;span class="s-Atom"&gt;college&lt;/span&gt; &lt;span class="s-Atom"&gt;life&lt;/span&gt; &lt;span class="s-Atom"&gt;gun&lt;/span&gt; &lt;span class="s-Atom"&gt;new&lt;/span&gt; &lt;span class="s-Atom"&gt;people&lt;/span&gt; &lt;span class="s-Atom"&gt;student&lt;/span&gt; &lt;span class="s-Atom"&gt;teacher&lt;/span&gt; &lt;span class="s-Atom"&gt;child&lt;/span&gt; &lt;span class="mi"&gt;2013&lt;/span&gt; &lt;span class="s-Atom"&gt;school&lt;/span&gt; &lt;span class="s-Atom"&gt;editor&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;investor&lt;/span&gt; &lt;span class="s-Atom"&gt;house&lt;/span&gt; &lt;span class="s-Atom"&gt;washington&lt;/span&gt; &lt;span class="s-Atom"&gt;limit&lt;/span&gt; &lt;span class="s-Atom"&gt;economy&lt;/span&gt; &lt;span class="s-Atom"&gt;obama&lt;/span&gt; &lt;span class="s-Atom"&gt;federal&lt;/span&gt; &lt;span class="s-Atom"&gt;bond&lt;/span&gt; &lt;span class="s-Atom"&gt;congress&lt;/span&gt; &lt;span class="s-Atom"&gt;treasury&lt;/span&gt; &lt;span class="s-Atom"&gt;default&lt;/span&gt; &lt;span class="s-Atom"&gt;ceiling&lt;/span&gt; &lt;span class="s-Atom"&gt;shutdown&lt;/span&gt; &lt;span class="s-Atom"&gt;government&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;korean&lt;/span&gt; &lt;span class="s-Atom"&gt;japanese&lt;/span&gt; &lt;span class="s-Atom"&gt;said&lt;/span&gt; &lt;span class="s-Atom"&gt;state&lt;/span&gt; &lt;span class="s-Atom"&gt;asia&lt;/span&gt; &lt;span class="s-Atom"&gt;south&lt;/span&gt; &lt;span class="s-Atom"&gt;japan&lt;/span&gt; &lt;span class="s-Atom"&gt;nuclear&lt;/span&gt; &lt;span class="s-Atom"&gt;kong&lt;/span&gt; &lt;span class="s-Atom"&gt;beijing&lt;/span&gt; &lt;span class="s-Atom"&gt;hong&lt;/span&gt; &lt;span class="s-Atom"&gt;north&lt;/span&gt; &lt;span class="s-Atom"&gt;korea&lt;/span&gt; &lt;span class="s-Atom"&gt;chinese&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;company&lt;/span&gt; &lt;span class="s-Atom"&gt;drilling&lt;/span&gt; &lt;span class="s-Atom"&gt;putin&lt;/span&gt; &lt;span class="s-Atom"&gt;said&lt;/span&gt; &lt;span class="s-Atom"&gt;carbon&lt;/span&gt; &lt;span class="s-Atom"&gt;coal&lt;/span&gt; &lt;span class="s-Atom"&gt;russia&lt;/span&gt; &lt;span class="s-Atom"&gt;russian&lt;/span&gt; &lt;span class="s-Atom"&gt;plant&lt;/span&gt; &lt;span class="s-Atom"&gt;energy&lt;/span&gt; &lt;span class="s-Atom"&gt;gas&lt;/span&gt; &lt;span class="s-Atom"&gt;greenpeace&lt;/span&gt; &lt;span class="s-Atom"&gt;ship&lt;/span&gt; &lt;span class="s-Atom"&gt;arctic&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;photograph&lt;/span&gt; &lt;span class="s-Atom"&gt;magritte&lt;/span&gt; &lt;span class="s-Atom"&gt;like&lt;/span&gt; &lt;span class="s-Atom"&gt;city&lt;/span&gt; &lt;span class="s-Atom"&gt;drawing&lt;/span&gt; &lt;span class="s-Atom"&gt;curator&lt;/span&gt; &lt;span class="s-Atom"&gt;street&lt;/span&gt; &lt;span class="s-Atom"&gt;collection&lt;/span&gt; &lt;span class="s-Atom"&gt;work&lt;/span&gt; &lt;span class="s-Atom"&gt;exhibition&lt;/span&gt; &lt;span class="s-Atom"&gt;artist&lt;/span&gt; &lt;span class="s-Atom"&gt;painting&lt;/span&gt; &lt;span class="s-Atom"&gt;gallery&lt;/span&gt; &lt;span class="s-Atom"&gt;museum&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;rose&lt;/span&gt; &lt;span class="s-Atom"&gt;year&lt;/span&gt; &lt;span class="s-Atom"&gt;said&lt;/span&gt; &lt;span class="s-Atom"&gt;august&lt;/span&gt; &lt;span class="s-Atom"&gt;stock&lt;/span&gt; &lt;span class="s-Atom"&gt;economist&lt;/span&gt; &lt;span class="s-Atom"&gt;month&lt;/span&gt; &lt;span class="s-Atom"&gt;economy&lt;/span&gt; &lt;span class="s-Atom"&gt;index&lt;/span&gt; &lt;span class="s-Atom"&gt;growth&lt;/span&gt; &lt;span class="s-Atom"&gt;price&lt;/span&gt; &lt;span class="s-Atom"&gt;market&lt;/span&gt; &lt;span class="s-Atom"&gt;rate&lt;/span&gt; &lt;span class="s-Atom"&gt;bank&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;like&lt;/span&gt; &lt;span class="s-Atom"&gt;employee&lt;/span&gt; &lt;span class="s-Atom"&gt;creative&lt;/span&gt; &lt;span class="s-Atom"&gt;vice&lt;/span&gt; &lt;span class="s-Atom"&gt;group&lt;/span&gt; &lt;span class="s-Atom"&gt;advertising&lt;/span&gt; &lt;span class="s-Atom"&gt;brand&lt;/span&gt; &lt;span class="s-Atom"&gt;york&lt;/span&gt; &lt;span class="s-Atom"&gt;chief&lt;/span&gt; &lt;span class="s-Atom"&gt;business&lt;/span&gt; &lt;span class="s-Atom"&gt;new&lt;/span&gt; &lt;span class="s-Atom"&gt;agency&lt;/span&gt; &lt;span class="s-Atom"&gt;said&lt;/span&gt; &lt;span class="s-Atom"&gt;executive&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;league&lt;/span&gt; &lt;span class="s-Atom"&gt;sunday&lt;/span&gt; &lt;span class="s-Atom"&gt;smith&lt;/span&gt; &lt;span class="s-Atom"&gt;manning&lt;/span&gt; &lt;span class="s-Atom"&gt;said&lt;/span&gt; &lt;span class="s-Atom"&gt;player&lt;/span&gt; &lt;span class="s-Atom"&gt;play&lt;/span&gt; &lt;span class="s-Atom"&gt;coach&lt;/span&gt; &lt;span class="s-Atom"&gt;giant&lt;/span&gt; &lt;span class="s-Atom"&gt;quarterback&lt;/span&gt; &lt;span class="s-Atom"&gt;team&lt;/span&gt; &lt;span class="s-Atom"&gt;season&lt;/span&gt; &lt;span class="s-Atom"&gt;touchdown&lt;/span&gt; &lt;span class="s-Atom"&gt;yard&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;season&lt;/span&gt; &lt;span class="s-Atom"&gt;breaking&lt;/span&gt; &lt;span class="s-Atom"&gt;million&lt;/span&gt; &lt;span class="s-Atom"&gt;hbo&lt;/span&gt; &lt;span class="s-Atom"&gt;fox&lt;/span&gt; &lt;span class="s-Atom"&gt;television&lt;/span&gt; &lt;span class="s-Atom"&gt;emmy&lt;/span&gt; &lt;span class="s-Atom"&gt;drama&lt;/span&gt; &lt;span class="s-Atom"&gt;network&lt;/span&gt; &lt;span class="s-Atom"&gt;series&lt;/span&gt; &lt;span class="s-Atom"&gt;abc&lt;/span&gt; &lt;span class="s-Atom"&gt;rating&lt;/span&gt; &lt;span class="s-Atom"&gt;cbs&lt;/span&gt; &lt;span class="s-Atom"&gt;nbc&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;criminal&lt;/span&gt; &lt;span class="s-Atom"&gt;ruling&lt;/span&gt; &lt;span class="s-Atom"&gt;trial&lt;/span&gt; &lt;span class="s-Atom"&gt;supreme&lt;/span&gt; &lt;span class="s-Atom"&gt;department&lt;/span&gt; &lt;span class="s-Atom"&gt;prison&lt;/span&gt; &lt;span class="s-Atom"&gt;sex&lt;/span&gt; &lt;span class="s-Atom"&gt;lawyer&lt;/span&gt; &lt;span class="s-Atom"&gt;federal&lt;/span&gt; &lt;span class="s-Atom"&gt;justice&lt;/span&gt; &lt;span class="s-Atom"&gt;law&lt;/span&gt; &lt;span class="s-Atom"&gt;state&lt;/span&gt; &lt;span class="s-Atom"&gt;case&lt;/span&gt; &lt;span class="s-Atom"&gt;judge&lt;/span&gt;

&lt;span class="nv"&gt;Topic&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
&lt;span class="s-Atom"&gt;piece&lt;/span&gt; &lt;span class="s-Atom"&gt;festival&lt;/span&gt; &lt;span class="s-Atom"&gt;concert&lt;/span&gt; &lt;span class="s-Atom"&gt;album&lt;/span&gt; &lt;span class="s-Atom"&gt;performance&lt;/span&gt; &lt;span class="s-Atom"&gt;dancer&lt;/span&gt; &lt;span class="s-Atom"&gt;work&lt;/span&gt; &lt;span class="s-Atom"&gt;orchestra&lt;/span&gt; &lt;span class="s-Atom"&gt;band&lt;/span&gt; &lt;span class="s-Atom"&gt;song&lt;/span&gt; &lt;span class="s-Atom"&gt;ms&lt;/span&gt; &lt;span class="s-Atom"&gt;opera&lt;/span&gt; &lt;span class="s-Atom"&gt;ballet&lt;/span&gt; &lt;span class="s-Atom"&gt;dance&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The sklearn implmentation was faster, but the results are similar.  They are not identical.   Because we are hill climbing, I am sure that we can get stuck in different local minima than sklearn, and we are not ordering topics.  It seems sklearn is.   &lt;/p&gt;
&lt;p&gt;The topics classifications, however, are almost identical.  That is really cool that there are letent features that help or organize and thinking about these articles.  It is also cool that they match our intuition about what they are.   &lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="nlp"></category><category term="NMF"></category></entry><entry><title>Galvanize - Week 06 - Day 1</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-06-01/" rel="alternate"></link><updated>2015-06-03T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-07-06:galvanize/galvanize-data-science-06-01/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 6 - Day 1&lt;/h2&gt;
&lt;p&gt;Today we had a quiz where we continued yesterday's work of vectorizing documents in a corpus, and finding similar documents.   The idea of two day's miniquiz was to treat a document like a corpus, and treat sentence's like documents.   We then clustered related sentences together to find related topics in the document.   &lt;/p&gt;
&lt;h2&gt;PCA&lt;/h2&gt;
&lt;p&gt;Our morning lesson was on Dimensional Reduction with the focus on Priciple Components Analysis.  PCA is finding orthogonal directions in a feature space that are directed along the direction of maximum variation.  The idea is that you can represent the variation of the data while reducing the number of features in the data set.  Our exploration of this begins with sklearn's digit dataset.&lt;/p&gt;
&lt;h2&gt;Digits&lt;/h2&gt;
&lt;p&gt;The digits dataset is 100 hand written images of numeric digits.   The version we are exploring are 64 pixel square images.  You can see the images below.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;load_digits&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.decomposition&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;PCA&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;StandardScaler&lt;/span&gt;

&lt;span class="n"&gt;digits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_digits&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;digits&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;digits&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;imshow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Greys&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xticks&lt;/span&gt;&lt;span class="p"&gt;([])&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;yticks&lt;/span&gt;&lt;span class="p"&gt;([])&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;off&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D1/output_1_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We can see that most of the digits are clear and distinct for a human to classify.   An algorithm, may have some work cutout for it when it comes to separate some of the 4's, 7's, and 9's.  Despite being 8x8 images, it looks like a large number of them are also cut off.   This likely has to do with the compression that took them from the original 128x128 resolution.&lt;/p&gt;
&lt;p&gt;The PCA algorithm looks for the direction of maximum variation, then projects along the data onto the axis.   The next direction is the new direction of maximimun variation.  The plot of the variance explained is called a Scree plot, and you can see this for the digits dataset.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;scaler = StandardScaler()
sX = scaler.fit_transform(X)
pca = PCA(63)
psX = pca.fit_transform(X)
plt.figure(figsize=(14,6))
plt.subplot(121)
plt.plot(range(63),pca.explained_variance_ratio_,&amp;#39;r--&amp;#39;)
plt.ylabel(&amp;#39;Precent Variance Explained&amp;#39;)
plt.xlabel(&amp;#39;Number of Components&amp;#39;)
plt.subplot(122)
plt.plot(range(63),np.cumsum(pca.explained_variance_ratio_),&amp;#39;g--&amp;#39;)
plt.ylabel(&amp;#39;Precent Cumlative Variance Explained&amp;#39;)
plt.xlabel(&amp;#39;Number of Components&amp;#39;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D1/output_3_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;Each image is 64 features, and we are reduce the number of features, or compress the data, while maintain a fixed amount of variation.   We can keep 80% by compressiong it to 10 features, or 90% if we compress it down to 20 features.  &lt;/p&gt;
&lt;p&gt;Lets look at what these images look like for the 1st, and the 10th compoents.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;scaler = StandardScaler()
sX = scaler.fit_transform(X)
pca = PCA(1)
psX = pca.fit_transform(X)
Xcompressed = pca.inverse_transform(psX)
plt.figure(figsize=(14,14))
for i in range(100):
    plt.subplot(10,10,i+1)
    plt.imshow(Xcompressed[i].reshape(8,8),cmap=&amp;#39;Greys&amp;#39;)
    plt.xticks([])
    plt.yticks([])
    plt.axis(&amp;#39;off&amp;#39;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D1/output_5_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We see that the first axis projects the image into how much like a 3 or a 6 does it look like.  The 6 makes sense because it fills the most space that is not used by other numbers.  That is the bottom left quadrant.  The 3 is other side.  I was surprised the 9 was not the other digit shown.  Reguardless, the 3's look a lot like 3's, and the 6's look a lot like 6's.  The problem is that the information about the other digits are lost.  We can look at the first 10 components.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;scaler = StandardScaler()
sX = scaler.fit_transform(X)
pca = PCA(10)
psX = pca.fit_transform(X)
Xcompressed = pca.inverse_transform(psX)
plt.figure(figsize=(14,14))
for i in range(100):
    plt.subplot(10,10,i+1)
    plt.imshow(Xcompressed[i].reshape(8,8),cmap=&amp;#39;Greys&amp;#39;)
    plt.xticks([])
    plt.yticks([])
    plt.axis(&amp;#39;off&amp;#39;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D1/output_7_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;The images are much clearer than 1 component, but we can see them as being blur.  We have effectively compressed the images.   A human can easily tell which digit most of the images are, but there are some that are still clear.  The first 5 is a good example of that.  Finally, lets look at 20 compoents.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;scaler = StandardScaler()
sX = scaler.fit_transform(X)
pca = PCA(20)
psX = pca.fit_transform(X)
Xcompressed = pca.inverse_transform(psX)
plt.figure(figsize=(14,14))
for i in range(100):
    plt.subplot(10,10,i+1)
    plt.imshow(Xcompressed[i].reshape(8,8),cmap=&amp;#39;Greys&amp;#39;)
    plt.xticks([])
    plt.yticks([])
    plt.axis(&amp;#39;off&amp;#39;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D1/output_9_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;At this point all the images are clear enough for a human with fair eyesight to make out.   We have cut the features size by a 1/3 while maintaining human readibility.  This is the idea behind PCA.  We can still maintain the predictive ability or use case while reducing the feature size.&lt;/p&gt;
&lt;p&gt;You can also see how different digits cluster in the space of the PCA compoents.  Below is a plot of the first PCA direction on the x axis, and the second PCA direction on the y axis.   The color identify which digit the data is for.  We can see that there is overlap, but the same digits cluster together, and related digits cluster next to each other.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;scaler = StandardScaler()
sX = scaler.fit_transform(X)
pca = PCA(2)
psX = pca.fit_transform(X)
plt.figure(figsize=(14,14))
for i in range(10):
    plt.plot(psX[y==i,0],psX[y==i,1],color=plt.cm.Set1(i*3),marker=&amp;#39;o&amp;#39;,alpha=0.9,label=str(i),lw=0,markersize=10)
plt.legend()




&amp;lt;matplotlib.legend.Legend at 0x10db23690&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D1/output_11_1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure(figsize=(14,14))
ax = plt.gca()
for i in range(psX.shape[0]):
    #print psX[i,0],psX[i,1],y[i]
    ax.annotate(str(y[i]),xy=(psX[i,0],psX[i,1]),color=plt.cm.Set1(y[i]*3), fontsize=14,alpha=0.6)
plt.xlim([-40,40])
plt.ylim([-40,40])
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D1/output_12_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We replaced each point with the label of the digit.  In this plot it is clear that 5's are difficult to distingust with the first 2 compoents, but zeros and ones seem well clusted.   The 3's, 9's and 7's have a lot of overlap.   As we add more features, we saw visually the images become more distinct.&lt;/p&gt;
&lt;h2&gt;Cars&lt;/h2&gt;
&lt;p&gt;The cars dataset is a default package in R, and we are going to use it to predict the mpg of the car using a linear fit.   The goals is to do it for the dataset, then for the PCA compoents of the dataset.  The goal is to see that as we increase the pca, our fit matches the full it, but it is well appoximated by a subset of features.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="n"&gt;cars&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_table&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data/cars.tsv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;header&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cars&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cars&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tolist&lt;/span&gt;&lt;span class="p"&gt;()),&lt;/span&gt;&lt;span class="n"&gt;cars&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]]],&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;ignore_index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cars&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cars&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;cars&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;?&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,:&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;cars&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cars&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;convert_objects&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;convert_numeric&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cars&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;mpg&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;cylinders&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;displacement&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;horsepower&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;weight&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;acceleration&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;model_year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;origin&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;cars&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;mpg&lt;/th&gt;
      &lt;th&gt;cylinders&lt;/th&gt;
      &lt;th&gt;displacement&lt;/th&gt;
      &lt;th&gt;horsepower&lt;/th&gt;
      &lt;th&gt;weight&lt;/th&gt;
      &lt;th&gt;acceleration&lt;/th&gt;
      &lt;th&gt;model_year&lt;/th&gt;
      &lt;th&gt;origin&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;307&lt;/td&gt;
      &lt;td&gt;130&lt;/td&gt;
      &lt;td&gt;3504&lt;/td&gt;
      &lt;td&gt;12.0&lt;/td&gt;
      &lt;td&gt;70&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;350&lt;/td&gt;
      &lt;td&gt;165&lt;/td&gt;
      &lt;td&gt;3693&lt;/td&gt;
      &lt;td&gt;11.5&lt;/td&gt;
      &lt;td&gt;70&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;318&lt;/td&gt;
      &lt;td&gt;150&lt;/td&gt;
      &lt;td&gt;3436&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;70&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;304&lt;/td&gt;
      &lt;td&gt;150&lt;/td&gt;
      &lt;td&gt;3433&lt;/td&gt;
      &lt;td&gt;12.0&lt;/td&gt;
      &lt;td&gt;70&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;302&lt;/td&gt;
      &lt;td&gt;140&lt;/td&gt;
      &lt;td&gt;3449&lt;/td&gt;
      &lt;td&gt;10.5&lt;/td&gt;
      &lt;td&gt;70&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;We can produce a scree plot to where we can estiate the number of components necessary for making consistent predictions with the full dataset.   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sca = StandardScaler()
pca = PCA(8)
sCar = sca.fit_transform(cars.values)
pCar = pca.fit_transform(sCar)
plt.plot(range(1,9),np.cumsum(pca.explained_variance_ratio_))




[&amp;lt;matplotlib.lines.Line2D at 0x109c12bd0&amp;gt;]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D1/output_16_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;From this plt we see most fo the variance can be explained with 3 to 4 components depending on if we want 90% or 95% of the variation explained.   I will expect that our adjusted R-square will get better for the first 3 or 4 PCA components, then level off to the adjusted R-square of the full fit.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cross_validation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LinearRegression&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;r2_score&lt;/span&gt;

&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cars&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;mpg&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cars&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;drop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;mpg&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;
&lt;span class="n"&gt;x_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x_tst&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_tst&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;test_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;sca&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;StandardScaler&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;pca&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PCA&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sx_trn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sca&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_trn&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;px_trn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pca&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sx_trn&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;lin1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LinearRegression&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;lin1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_trn&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y_pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;lin1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_tst&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Full Fit Adjusted R-Square&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;r2_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_tst&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_tst&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_tst&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;x_trn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;pca&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PCA&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sx_trn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sca&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_trn&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;px_trn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pca&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sx_trn&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;linP&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LinearRegression&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;linP&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;px_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_trn&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;sx_tst&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sca&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_tst&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;px_tst&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pca&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sx_tst&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;y_pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;linP&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;px_tst&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;adj_r2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;r2_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_tst&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_tst&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_tst&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;PCA Adjusted R-Square {}&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;adj_r2&lt;/span&gt;

&lt;span class="n"&gt;Full&lt;/span&gt; &lt;span class="n"&gt;Fit&lt;/span&gt; &lt;span class="n"&gt;Adjusted&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Square&lt;/span&gt; &lt;span class="mf"&gt;0.817772756314&lt;/span&gt;
&lt;span class="n"&gt;PCA&lt;/span&gt; &lt;span class="n"&gt;Adjusted&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Square&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mf"&gt;0.69397778532&lt;/span&gt;
&lt;span class="n"&gt;PCA&lt;/span&gt; &lt;span class="n"&gt;Adjusted&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Square&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mf"&gt;0.696494130123&lt;/span&gt;
&lt;span class="n"&gt;PCA&lt;/span&gt; &lt;span class="n"&gt;Adjusted&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Square&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mf"&gt;0.791628786462&lt;/span&gt;
&lt;span class="n"&gt;PCA&lt;/span&gt; &lt;span class="n"&gt;Adjusted&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Square&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="mf"&gt;0.797026468934&lt;/span&gt;
&lt;span class="n"&gt;PCA&lt;/span&gt; &lt;span class="n"&gt;Adjusted&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Square&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="mf"&gt;0.807152321105&lt;/span&gt;
&lt;span class="n"&gt;PCA&lt;/span&gt; &lt;span class="n"&gt;Adjusted&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Square&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt; &lt;span class="mf"&gt;0.813375746265&lt;/span&gt;
&lt;span class="n"&gt;PCA&lt;/span&gt; &lt;span class="n"&gt;Adjusted&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Square&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="mf"&gt;0.817772756314&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The above first are just a section of data.  Because we have a small dataset and a 20% split on the data to run on the test set, we will see large variation in the results.  Reguardless of the quality of the fit on the test set, what we always see is the we have dramatic increases in the adjusted r-square until we get to the 4th component, then we get incremental increase. &lt;/p&gt;
&lt;h2&gt;Singular Value Decomposition&lt;/h2&gt;
&lt;p&gt;The idea behind SVD's is that any matrix can be factors into the product of 3 matrixes.  We have a dataset of book reviews for users, and we want to try to decompose these relationships into the idea of topics.  The users will have relationships to topics, and books will have relationships to topics.  This is the beginnings of recommender systems that we will be exploring this week.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;df  = pd.read_csv(&amp;#39;data/book_reviews.csv&amp;#39;)
df.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Unnamed: 0&lt;/th&gt;
      &lt;th&gt;User-ID&lt;/th&gt;
      &lt;th&gt;ISBN&lt;/th&gt;
      &lt;th&gt;Book-Rating&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1083&lt;/td&gt;
      &lt;td&gt;277195&lt;/td&gt;
      &lt;td&gt;0060391626&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1084&lt;/td&gt;
      &lt;td&gt;277195&lt;/td&gt;
      &lt;td&gt;0060502258&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;1089&lt;/td&gt;
      &lt;td&gt;277195&lt;/td&gt;
      &lt;td&gt;0060987561&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;1098&lt;/td&gt;
      &lt;td&gt;277195&lt;/td&gt;
      &lt;td&gt;0316666343&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;1099&lt;/td&gt;
      &lt;td&gt;277195&lt;/td&gt;
      &lt;td&gt;0316734837&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;df.drop(&amp;#39;Unnamed: 0&amp;#39;,axis=1,inplace=True)
df = df.set_index([&amp;#39;User-ID&amp;#39;,&amp;#39;ISBN&amp;#39;]).unstack().fillna(-1)
df.columns = df.columns.droplevel()
df.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;ISBN&lt;/th&gt;
      &lt;th&gt;0006493580&lt;/th&gt;
      &lt;th&gt;000649840X&lt;/th&gt;
      &lt;th&gt;0006512135&lt;/th&gt;
      &lt;th&gt;0006513204&lt;/th&gt;
      &lt;th&gt;0006514855&lt;/th&gt;
      &lt;th&gt;0006547834&lt;/th&gt;
      &lt;th&gt;0006550576&lt;/th&gt;
      &lt;th&gt;0006550681&lt;/th&gt;
      &lt;th&gt;0006550789&lt;/th&gt;
      &lt;th&gt;0007110928&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;8495618605&lt;/th&gt;
      &lt;th&gt;8497593588&lt;/th&gt;
      &lt;th&gt;8804342838&lt;/th&gt;
      &lt;th&gt;8806142100&lt;/th&gt;
      &lt;th&gt;8806143042&lt;/th&gt;
      &lt;th&gt;8807813025&lt;/th&gt;
      &lt;th&gt;8817106100&lt;/th&gt;
      &lt;th&gt;8845205118&lt;/th&gt;
      &lt;th&gt;8873122933&lt;/th&gt;
      &lt;th&gt;8885989403&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;User-ID&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;243&lt;/th&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;254&lt;/th&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;507&lt;/th&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;638&lt;/th&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;805&lt;/th&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 6092 columns&lt;/p&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;U,S,V = np.linalg.svd(df.values)
S




array([  3.73197977e+03,   3.28163606e+02,   2.34177766e+02, ...,
         2.95911201e+00,   2.63616054e+00,   2.25714589e+00])
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now that we have decomposed the User x Book review matrix, we can look at the singular values S.  The rule of thumb is that the energy, $S^2$, is the analogous to the explained variance of the PCA.  We can make a plot of this verse the number of components we want to inclunde in the reduction, and estimate how much information loss will be experience.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.plot(range(1,len(S)+1),np.cumsum(S**2/np.sum(S**2)),&amp;#39;r--&amp;#39;)
plt.xlabel(&amp;#39;Number of SVD Components Included&amp;#39;)
plt.ylabel(&amp;#39;Percent of Total Energy Included&amp;#39;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D1/output_25_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We see that we can maintain 90% of the energy with 1 first 500 components of the 2500 possible singular values.   We can keep 95% with 1000 components.  Interestingly we include 72% of the energy with only 1 component.  What we are going is try to get a feel for the concepts/topics produced by the SVD algorithm.  We are going to load in some book meta data, and try to find characteristic titles for each topics.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;meta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data/book_meta.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;sep&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;usecols&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ISBN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Book-Title&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Book-Author&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Year-Of-Publication&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Publisher&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;meta&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Library&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Python&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;2.7&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;packages&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;io&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;parsers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;1164&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;DtypeWarning&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Columns&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;have&lt;/span&gt; &lt;span class="n"&gt;mixed&lt;/span&gt; &lt;span class="n"&gt;types&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Specify&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt; &lt;span class="n"&gt;option&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;or&lt;/span&gt; &lt;span class="nn"&gt;set&lt;/span&gt; &lt;span class="nn"&gt;low_memory&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
  &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_reader&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nrows&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;ISBN&lt;/th&gt;
      &lt;th&gt;Book-Title&lt;/th&gt;
      &lt;th&gt;Book-Author&lt;/th&gt;
      &lt;th&gt;Year-Of-Publication&lt;/th&gt;
      &lt;th&gt;Publisher&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0195153448&lt;/td&gt;
      &lt;td&gt;Classical Mythology&lt;/td&gt;
      &lt;td&gt;Mark P. O. Morford&lt;/td&gt;
      &lt;td&gt;2002&lt;/td&gt;
      &lt;td&gt;Oxford University Press&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;0002005018&lt;/td&gt;
      &lt;td&gt;Clara Callan&lt;/td&gt;
      &lt;td&gt;Richard Bruce Wright&lt;/td&gt;
      &lt;td&gt;2001&lt;/td&gt;
      &lt;td&gt;HarperFlamingo Canada&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;0060973129&lt;/td&gt;
      &lt;td&gt;Decision in Normandy&lt;/td&gt;
      &lt;td&gt;Carlo D'Este&lt;/td&gt;
      &lt;td&gt;1991&lt;/td&gt;
      &lt;td&gt;HarperPerennial&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;0374157065&lt;/td&gt;
      &lt;td&gt;Flu: The Story of the Great Influenza Pandemic...&lt;/td&gt;
      &lt;td&gt;Gina Bari Kolata&lt;/td&gt;
      &lt;td&gt;1999&lt;/td&gt;
      &lt;td&gt;Farrar Straus Giroux&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;0393045218&lt;/td&gt;
      &lt;td&gt;The Mummies of Urumchi&lt;/td&gt;
      &lt;td&gt;E. J. W. Barber&lt;/td&gt;
      &lt;td&gt;1999&lt;/td&gt;
      &lt;td&gt;W. W. Norton &amp;amp;amp; Company&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The basic idea is our U matrix has rows that represent users and columns that represent latent topcs.  The $\Sigma$ (S) matrix presents the weight of each topic, and the V matrix has rows that represent topics and columns that represent books.   &lt;/p&gt;
&lt;p&gt;We are going to go through the V matrix and find the topic books for the first few topics to see if we can learn what the latent association is.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="s-Atom"&gt;top20_book_indexes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;V&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="p"&gt;])[&lt;/span&gt;&lt;span class="s-Atom"&gt;::-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="s-Atom"&gt;top20_book_isbns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;top20_book_indexes&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="s-Atom"&gt;meta&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;meta&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;ISBN&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;isin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;top20_book_isbns&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;ISBN&lt;/th&gt;
      &lt;th&gt;Book-Title&lt;/th&gt;
      &lt;th&gt;Book-Author&lt;/th&gt;
      &lt;th&gt;Year-Of-Publication&lt;/th&gt;
      &lt;th&gt;Publisher&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;21&lt;/th&gt;
      &lt;td&gt;1841721522&lt;/td&gt;
      &lt;td&gt;New Vegetarian: Bold and Beautiful Recipes for...&lt;/td&gt;
      &lt;td&gt;Celia Brooks Brown&lt;/td&gt;
      &lt;td&gt;2001&lt;/td&gt;
      &lt;td&gt;Ryland Peters &amp;amp;amp; Small Ltd&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1229&lt;/th&gt;
      &lt;td&gt;3257061269&lt;/td&gt;
      &lt;td&gt;Der Alchimist.&lt;/td&gt;
      &lt;td&gt;Paulo Coelho&lt;/td&gt;
      &lt;td&gt;2003&lt;/td&gt;
      &lt;td&gt;Diogenes Verlag, Z�?¼rich&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2587&lt;/th&gt;
      &lt;td&gt;3423105518&lt;/td&gt;
      &lt;td&gt;Name Der Rose&lt;/td&gt;
      &lt;td&gt;Umberto Eco&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;Distribooks Int'l+inc&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3028&lt;/th&gt;
      &lt;td&gt;1844262553&lt;/td&gt;
      &lt;td&gt;Free&lt;/td&gt;
      &lt;td&gt;Paul Vincent&lt;/td&gt;
      &lt;td&gt;2003&lt;/td&gt;
      &lt;td&gt;Upfront Publishing&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3217&lt;/th&gt;
      &lt;td&gt;3548603203&lt;/td&gt;
      &lt;td&gt;Artemis Fowl.&lt;/td&gt;
      &lt;td&gt;Eoin Colfer&lt;/td&gt;
      &lt;td&gt;2003&lt;/td&gt;
      &lt;td&gt;Ullstein TB-Vlg&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5042&lt;/th&gt;
      &lt;td&gt;3257229364&lt;/td&gt;
      &lt;td&gt;Endstation Venedig. Commissario Brunettis zwei...&lt;/td&gt;
      &lt;td&gt;Donna Leon&lt;/td&gt;
      &lt;td&gt;1996&lt;/td&gt;
      &lt;td&gt;Diogenes Verlag&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;7909&lt;/th&gt;
      &lt;td&gt;8817106100&lt;/td&gt;
      &lt;td&gt;Oceano Mare&lt;/td&gt;
      &lt;td&gt;Alessandro Baricco&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;Biblioteca Universale Rizzoli&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;8839&lt;/th&gt;
      &lt;td&gt;3423202327&lt;/td&gt;
      &lt;td&gt;M�?¶rder ohne Gesicht.&lt;/td&gt;
      &lt;td&gt;Henning Mankell&lt;/td&gt;
      &lt;td&gt;1999&lt;/td&gt;
      &lt;td&gt;Dtv&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10786&lt;/th&gt;
      &lt;td&gt;3423201509&lt;/td&gt;
      &lt;td&gt;Die Weiss Lowin / Contemporary German Lit&lt;/td&gt;
      &lt;td&gt;Henning Mankell&lt;/td&gt;
      &lt;td&gt;2002&lt;/td&gt;
      &lt;td&gt;Distribooks&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;11766&lt;/th&gt;
      &lt;td&gt;8807813025&lt;/td&gt;
      &lt;td&gt;Novocento, Un Monologo&lt;/td&gt;
      &lt;td&gt;Alessandro Baricco&lt;/td&gt;
      &lt;td&gt;2003&lt;/td&gt;
      &lt;td&gt;Distribooks Inc&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12842&lt;/th&gt;
      &lt;td&gt;3379015180&lt;/td&gt;
      &lt;td&gt;Schlafes Bruder&lt;/td&gt;
      &lt;td&gt;Robert Schneider&lt;/td&gt;
      &lt;td&gt;1994&lt;/td&gt;
      &lt;td&gt;Reclam, Leipzig&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;27672&lt;/th&gt;
      &lt;td&gt;3462032283&lt;/td&gt;
      &lt;td&gt;Zw�?¶lf.&lt;/td&gt;
      &lt;td&gt;Nick McDonell&lt;/td&gt;
      &lt;td&gt;2003&lt;/td&gt;
      &lt;td&gt;Kiepenheuer &amp;amp;amp; Witsch&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;37478&lt;/th&gt;
      &lt;td&gt;3492238696&lt;/td&gt;
      &lt;td&gt;Balzac und die kleine chinesische Schneiderin.&lt;/td&gt;
      &lt;td&gt;Dai Sijie&lt;/td&gt;
      &lt;td&gt;2003&lt;/td&gt;
      &lt;td&gt;Piper&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;38240&lt;/th&gt;
      &lt;td&gt;3462028189&lt;/td&gt;
      &lt;td&gt;Crazy&lt;/td&gt;
      &lt;td&gt;Benjamin Lebert&lt;/td&gt;
      &lt;td&gt;2000&lt;/td&gt;
      &lt;td&gt;Kiepenheuer &amp;amp;amp; Witsch GmbH &amp;amp;amp; Co. KG, Ve...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;51792&lt;/th&gt;
      &lt;td&gt;3250600555&lt;/td&gt;
      &lt;td&gt;Monsieur Ibrahim und die Blumen des Koran. Erz...&lt;/td&gt;
      &lt;td&gt;Eric-Emmanuel Schmitt&lt;/td&gt;
      &lt;td&gt;2002&lt;/td&gt;
      &lt;td&gt;Ammann&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;91342&lt;/th&gt;
      &lt;td&gt;3442414199&lt;/td&gt;
      &lt;td&gt;Generation X. Geschichten f�?¼r eine immer sch...&lt;/td&gt;
      &lt;td&gt;Douglas Coupland&lt;/td&gt;
      &lt;td&gt;1994&lt;/td&gt;
      &lt;td&gt;Goldmann&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The first topic looks like it has a strong relationship to german titles.  They were all published in the late 90's or early 00's.   I am currious how many reviews these books received.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;print np.sum(df.values[:,top20_book_indexes]&amp;gt;=0,axis=0)
print np.round(np.average(df.values[:,top20_book_indexes],weights=df.values[:,top20_book_indexes]&amp;gt;=0,axis=0),1)

[2 1 1 1 2 5 1 1 1 1 1 2 2 2 2 2 3 1 1 4]
[ 5.   9.   9.   9.   4.5  2.   8.   8.   8.   8.   8.   4.   4.   4.   4.
  4.   2.7  7.   7.   2. ]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;These books have been reviewed between 1 to 5 times, and the average rating is between 2 and 9.  German authors seems to be the biggest association between these books.&lt;/p&gt;
&lt;p&gt;Lets repeat this for a few more topics&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="s-Atom"&gt;top20_book_indexes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;V&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="p"&gt;])[&lt;/span&gt;&lt;span class="s-Atom"&gt;::-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="s-Atom"&gt;top20_book_isbns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;top20_book_indexes&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="s-Atom"&gt;meta&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;meta&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;ISBN&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;isin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;top20_book_isbns&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;ISBN&lt;/th&gt;
      &lt;th&gt;Book-Title&lt;/th&gt;
      &lt;th&gt;Book-Author&lt;/th&gt;
      &lt;th&gt;Year-Of-Publication&lt;/th&gt;
      &lt;th&gt;Publisher&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;107&lt;/th&gt;
      &lt;td&gt;0786868716&lt;/td&gt;
      &lt;td&gt;The Five People You Meet in Heaven&lt;/td&gt;
      &lt;td&gt;Mitch Albom&lt;/td&gt;
      &lt;td&gt;2003&lt;/td&gt;
      &lt;td&gt;Hyperion&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;408&lt;/th&gt;
      &lt;td&gt;0316666343&lt;/td&gt;
      &lt;td&gt;The Lovely Bones: A Novel&lt;/td&gt;
      &lt;td&gt;Alice Sebold&lt;/td&gt;
      &lt;td&gt;2002&lt;/td&gt;
      &lt;td&gt;Little, Brown&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;522&lt;/th&gt;
      &lt;td&gt;0312195516&lt;/td&gt;
      &lt;td&gt;The Red Tent (Bestselling Backlist)&lt;/td&gt;
      &lt;td&gt;Anita Diamant&lt;/td&gt;
      &lt;td&gt;1998&lt;/td&gt;
      &lt;td&gt;Picador USA&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;706&lt;/th&gt;
      &lt;td&gt;0446672211&lt;/td&gt;
      &lt;td&gt;Where the Heart Is (Oprah's Book Club (Paperba...&lt;/td&gt;
      &lt;td&gt;Billie Letts&lt;/td&gt;
      &lt;td&gt;1998&lt;/td&gt;
      &lt;td&gt;Warner Books&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;748&lt;/th&gt;
      &lt;td&gt;0385504209&lt;/td&gt;
      &lt;td&gt;The Da Vinci Code&lt;/td&gt;
      &lt;td&gt;Dan Brown&lt;/td&gt;
      &lt;td&gt;2003&lt;/td&gt;
      &lt;td&gt;Doubleday&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1387&lt;/th&gt;
      &lt;td&gt;0345361792&lt;/td&gt;
      &lt;td&gt;A Prayer for Owen Meany&lt;/td&gt;
      &lt;td&gt;John Irving&lt;/td&gt;
      &lt;td&gt;1990&lt;/td&gt;
      &lt;td&gt;Ballantine Books&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1496&lt;/th&gt;
      &lt;td&gt;0743418174&lt;/td&gt;
      &lt;td&gt;Good in Bed&lt;/td&gt;
      &lt;td&gt;Jennifer Weiner&lt;/td&gt;
      &lt;td&gt;2002&lt;/td&gt;
      &lt;td&gt;Washington Square Press&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1863&lt;/th&gt;
      &lt;td&gt;0446610038&lt;/td&gt;
      &lt;td&gt;1st to Die: A Novel&lt;/td&gt;
      &lt;td&gt;James Patterson&lt;/td&gt;
      &lt;td&gt;2002&lt;/td&gt;
      &lt;td&gt;Warner Vision&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1922&lt;/th&gt;
      &lt;td&gt;067976402X&lt;/td&gt;
      &lt;td&gt;Snow Falling on Cedars&lt;/td&gt;
      &lt;td&gt;David Guterson&lt;/td&gt;
      &lt;td&gt;1995&lt;/td&gt;
      &lt;td&gt;Vintage Books USA&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2001&lt;/th&gt;
      &lt;td&gt;0316569321&lt;/td&gt;
      &lt;td&gt;White Oleander : A Novel&lt;/td&gt;
      &lt;td&gt;Janet Fitch&lt;/td&gt;
      &lt;td&gt;1999&lt;/td&gt;
      &lt;td&gt;Little, Brown&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2143&lt;/th&gt;
      &lt;td&gt;059035342X&lt;/td&gt;
      &lt;td&gt;Harry Potter and the Sorcerer's Stone (Harry P...&lt;/td&gt;
      &lt;td&gt;J. K. Rowling&lt;/td&gt;
      &lt;td&gt;1999&lt;/td&gt;
      &lt;td&gt;Arthur A. Levine Books&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2290&lt;/th&gt;
      &lt;td&gt;0385484518&lt;/td&gt;
      &lt;td&gt;Tuesdays with Morrie: An Old Man, a Young Man,...&lt;/td&gt;
      &lt;td&gt;MITCH ALBOM&lt;/td&gt;
      &lt;td&gt;1997&lt;/td&gt;
      &lt;td&gt;Doubleday&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2910&lt;/th&gt;
      &lt;td&gt;0380718340&lt;/td&gt;
      &lt;td&gt;Cruel &amp;amp;amp; Unusual (Kay Scarpetta Mysteries (...&lt;/td&gt;
      &lt;td&gt;Patricia D. Cornwell&lt;/td&gt;
      &lt;td&gt;1994&lt;/td&gt;
      &lt;td&gt;Avon&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3939&lt;/th&gt;
      &lt;td&gt;0316096199&lt;/td&gt;
      &lt;td&gt;Lucky : A Memoir&lt;/td&gt;
      &lt;td&gt;Alice Sebold&lt;/td&gt;
      &lt;td&gt;2002&lt;/td&gt;
      &lt;td&gt;Back Bay Books&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4430&lt;/th&gt;
      &lt;td&gt;0375727345&lt;/td&gt;
      &lt;td&gt;House of Sand and Fog&lt;/td&gt;
      &lt;td&gt;Andre Dubus III&lt;/td&gt;
      &lt;td&gt;2000&lt;/td&gt;
      &lt;td&gt;Vintage Books&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5070&lt;/th&gt;
      &lt;td&gt;014028009X&lt;/td&gt;
      &lt;td&gt;Bridget Jones's Diary&lt;/td&gt;
      &lt;td&gt;Helen Fielding&lt;/td&gt;
      &lt;td&gt;1999&lt;/td&gt;
      &lt;td&gt;Penguin Books&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5873&lt;/th&gt;
      &lt;td&gt;0312966091&lt;/td&gt;
      &lt;td&gt;Three To Get Deadly : A Stephanie Plum Novel (...&lt;/td&gt;
      &lt;td&gt;Janet Evanovich&lt;/td&gt;
      &lt;td&gt;1998&lt;/td&gt;
      &lt;td&gt;St. Martin's Paperbacks&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5887&lt;/th&gt;
      &lt;td&gt;0671001795&lt;/td&gt;
      &lt;td&gt;Two for the Dough&lt;/td&gt;
      &lt;td&gt;Janet Evanovich&lt;/td&gt;
      &lt;td&gt;1996&lt;/td&gt;
      &lt;td&gt;Pocket&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;6401&lt;/th&gt;
      &lt;td&gt;0609804138&lt;/td&gt;
      &lt;td&gt;The Sweet Potato Queens' Book of Love&lt;/td&gt;
      &lt;td&gt;JILL CONNER BROWNE&lt;/td&gt;
      &lt;td&gt;1999&lt;/td&gt;
      &lt;td&gt;Three Rivers Press&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;7852&lt;/th&gt;
      &lt;td&gt;0553280341&lt;/td&gt;
      &lt;td&gt;B Is for Burglar (Kinsey Millhone Mysteries (P...&lt;/td&gt;
      &lt;td&gt;Sue Grafton&lt;/td&gt;
      &lt;td&gt;1986&lt;/td&gt;
      &lt;td&gt;Bantam&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;These topics seem to be with popular fiction, maybe for teenagers.  One more topics before I move one.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="s-Atom"&gt;top20_book_indexes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;V&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="p"&gt;])[&lt;/span&gt;&lt;span class="s-Atom"&gt;::-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="s-Atom"&gt;top20_book_isbns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;top20_book_indexes&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="s-Atom"&gt;meta&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;meta&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;ISBN&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;isin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;top20_book_isbns&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;ISBN&lt;/th&gt;
      &lt;th&gt;Book-Title&lt;/th&gt;
      &lt;th&gt;Book-Author&lt;/th&gt;
      &lt;th&gt;Year-Of-Publication&lt;/th&gt;
      &lt;th&gt;Publisher&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;48&lt;/th&gt;
      &lt;td&gt;042518630X&lt;/td&gt;
      &lt;td&gt;Purity in Death&lt;/td&gt;
      &lt;td&gt;J.D. Robb&lt;/td&gt;
      &lt;td&gt;2002&lt;/td&gt;
      &lt;td&gt;Berkley Publishing Group&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;368&lt;/th&gt;
      &lt;td&gt;0515128554&lt;/td&gt;
      &lt;td&gt;Heart of the Sea (Irish Trilogy)&lt;/td&gt;
      &lt;td&gt;Nora Roberts&lt;/td&gt;
      &lt;td&gt;2000&lt;/td&gt;
      &lt;td&gt;Jove Books&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1202&lt;/th&gt;
      &lt;td&gt;0373484224&lt;/td&gt;
      &lt;td&gt;Stanislaski Brothers (Silhouette Promo)&lt;/td&gt;
      &lt;td&gt;Nora Roberts&lt;/td&gt;
      &lt;td&gt;2000&lt;/td&gt;
      &lt;td&gt;Silhouette&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2784&lt;/th&gt;
      &lt;td&gt;051513287X&lt;/td&gt;
      &lt;td&gt;Face the Fire (Three Sisters Island Trilogy)&lt;/td&gt;
      &lt;td&gt;Nora Roberts&lt;/td&gt;
      &lt;td&gt;2002&lt;/td&gt;
      &lt;td&gt;Jove Books&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3163&lt;/th&gt;
      &lt;td&gt;0515114693&lt;/td&gt;
      &lt;td&gt;Born in Fire&lt;/td&gt;
      &lt;td&gt;Nora Roberts&lt;/td&gt;
      &lt;td&gt;1994&lt;/td&gt;
      &lt;td&gt;Jove Books&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4544&lt;/th&gt;
      &lt;td&gt;0515132020&lt;/td&gt;
      &lt;td&gt;Heaven and Earth (Three Sisters Island Trilogy)&lt;/td&gt;
      &lt;td&gt;Nora Roberts&lt;/td&gt;
      &lt;td&gt;2003&lt;/td&gt;
      &lt;td&gt;Jove Books&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4546&lt;/th&gt;
      &lt;td&gt;0515131229&lt;/td&gt;
      &lt;td&gt;Dance upon the Air (Three Sisters Island Trilogy)&lt;/td&gt;
      &lt;td&gt;Nora Roberts&lt;/td&gt;
      &lt;td&gt;2003&lt;/td&gt;
      &lt;td&gt;Jove Books&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;8977&lt;/th&gt;
      &lt;td&gt;039914840X&lt;/td&gt;
      &lt;td&gt;Three Fates&lt;/td&gt;
      &lt;td&gt;Nora Roberts&lt;/td&gt;
      &lt;td&gt;2002&lt;/td&gt;
      &lt;td&gt;Putnam Publishing Group&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10929&lt;/th&gt;
      &lt;td&gt;0515128546&lt;/td&gt;
      &lt;td&gt;Tears of the Moon (Irish Trilogy)&lt;/td&gt;
      &lt;td&gt;Nora Roberts&lt;/td&gt;
      &lt;td&gt;2000&lt;/td&gt;
      &lt;td&gt;Jove Books&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;11633&lt;/th&gt;
      &lt;td&gt;0399148248&lt;/td&gt;
      &lt;td&gt;Midnight Bayou&lt;/td&gt;
      &lt;td&gt;Nora Roberts&lt;/td&gt;
      &lt;td&gt;2001&lt;/td&gt;
      &lt;td&gt;Putnam Publishing Group&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;15358&lt;/th&gt;
      &lt;td&gt;0399149848&lt;/td&gt;
      &lt;td&gt;Birthright&lt;/td&gt;
      &lt;td&gt;Nora Roberts&lt;/td&gt;
      &lt;td&gt;2003&lt;/td&gt;
      &lt;td&gt;Putnam Publishing Group&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;15513&lt;/th&gt;
      &lt;td&gt;0553265741&lt;/td&gt;
      &lt;td&gt;Sacred Sins&lt;/td&gt;
      &lt;td&gt;Nora Roberts&lt;/td&gt;
      &lt;td&gt;1990&lt;/td&gt;
      &lt;td&gt;Bantam Books&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;16198&lt;/th&gt;
      &lt;td&gt;0515136379&lt;/td&gt;
      &lt;td&gt;Key of Knowledge (Key Trilogy (Paperback))&lt;/td&gt;
      &lt;td&gt;Nora Roberts&lt;/td&gt;
      &lt;td&gt;2003&lt;/td&gt;
      &lt;td&gt;Jove Books&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;16199&lt;/th&gt;
      &lt;td&gt;0515136530&lt;/td&gt;
      &lt;td&gt;Key of Valor (Roberts, Nora. Key Trilogy, 3.)&lt;/td&gt;
      &lt;td&gt;Nora Roberts&lt;/td&gt;
      &lt;td&gt;2003&lt;/td&gt;
      &lt;td&gt;Jove Pubns&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;16203&lt;/th&gt;
      &lt;td&gt;051513628X&lt;/td&gt;
      &lt;td&gt;Key of Light (Key Trilogy (Paperback))&lt;/td&gt;
      &lt;td&gt;Nora Roberts&lt;/td&gt;
      &lt;td&gt;2003&lt;/td&gt;
      &lt;td&gt;Jove Books&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;17665&lt;/th&gt;
      &lt;td&gt;0373483503&lt;/td&gt;
      &lt;td&gt;Macgregor Brides (Macgregors)&lt;/td&gt;
      &lt;td&gt;Nora Roberts&lt;/td&gt;
      &lt;td&gt;1997&lt;/td&gt;
      &lt;td&gt;Silhouette&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;18414&lt;/th&gt;
      &lt;td&gt;0425183971&lt;/td&gt;
      &lt;td&gt;Reunion in Death&lt;/td&gt;
      &lt;td&gt;J. D. Robb&lt;/td&gt;
      &lt;td&gt;2002&lt;/td&gt;
      &lt;td&gt;Berkley Publishing Group&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;18476&lt;/th&gt;
      &lt;td&gt;0425189031&lt;/td&gt;
      &lt;td&gt;Portrait in Death&lt;/td&gt;
      &lt;td&gt;Nora Roberts&lt;/td&gt;
      &lt;td&gt;2003&lt;/td&gt;
      &lt;td&gt;Berkley Publishing Group&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;19926&lt;/th&gt;
      &lt;td&gt;0515126772&lt;/td&gt;
      &lt;td&gt;Jewels of the Sun (Irish Trilogy)&lt;/td&gt;
      &lt;td&gt;Nora Roberts&lt;/td&gt;
      &lt;td&gt;2004&lt;/td&gt;
      &lt;td&gt;Jove Books&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;26087&lt;/th&gt;
      &lt;td&gt;0515116750&lt;/td&gt;
      &lt;td&gt;Born in Ice&lt;/td&gt;
      &lt;td&gt;Nora Roberts&lt;/td&gt;
      &lt;td&gt;1996&lt;/td&gt;
      &lt;td&gt;Berkley Publishing Group&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;We have an obvious connection here for topic three:  Nora Roberts.   The singular value decomposition of these book and user ratings is interesting, but I am not seeing how it is scalable.&lt;/p&gt;
&lt;p&gt;We can also investigate the user topic preferences by exploring the U matrix.  Remember that each row is a user, and each column a topic.  Lets looka the first user.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="s-Atom"&gt;top10&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;U&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="p"&gt;])[&lt;/span&gt;&lt;span class="s-Atom"&gt;::-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s-Atom"&gt;top10&lt;/span&gt;
&lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;round&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nv"&gt;U&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;top10&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;U&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;std&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;U&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2108&lt;/span&gt; &lt;span class="mi"&gt;2038&lt;/span&gt; &lt;span class="mi"&gt;2037&lt;/span&gt; &lt;span class="mi"&gt;2272&lt;/span&gt; &lt;span class="mi"&gt;2128&lt;/span&gt; &lt;span class="mi"&gt;2015&lt;/span&gt; &lt;span class="mi"&gt;1820&lt;/span&gt; &lt;span class="mi"&gt;2025&lt;/span&gt; &lt;span class="mi"&gt;2054&lt;/span&gt; &lt;span class="mi"&gt;2232&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="mf"&gt;4.38&lt;/span&gt;  &lt;span class="mf"&gt;4.19&lt;/span&gt;  &lt;span class="mf"&gt;3.62&lt;/span&gt;  &lt;span class="mf"&gt;3.48&lt;/span&gt;  &lt;span class="mf"&gt;3.45&lt;/span&gt;  &lt;span class="mf"&gt;3.36&lt;/span&gt;  &lt;span class="mf"&gt;3.3&lt;/span&gt;   &lt;span class="mf"&gt;3.25&lt;/span&gt;  &lt;span class="mf"&gt;3.&lt;/span&gt;    &lt;span class="mf"&gt;2.98&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The first user is associated with these topics, and has standard scores associated with them that at or above 3. &lt;br /&gt;
We can look at this user's book reviews.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;original = pd.read_csv(&amp;#39;data/book_reviews.csv&amp;#39;)
print original[original[&amp;#39;User-ID&amp;#39;]==df.index[0]].shape
user1_fav = original[(original[&amp;#39;User-ID&amp;#39;]==df.index[0]) &amp;amp; (original[&amp;#39;Book-Rating&amp;#39;] &amp;gt;= 9)]
user1_fav

(66, 4)
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Unnamed: 0&lt;/th&gt;
      &lt;th&gt;User-ID&lt;/th&gt;
      &lt;th&gt;ISBN&lt;/th&gt;
      &lt;th&gt;Book-Rating&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1147&lt;/th&gt;
      &lt;td&gt;9955&lt;/td&gt;
      &lt;td&gt;243&lt;/td&gt;
      &lt;td&gt;0060915544&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1152&lt;/th&gt;
      &lt;td&gt;9962&lt;/td&gt;
      &lt;td&gt;243&lt;/td&gt;
      &lt;td&gt;0316601950&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1156&lt;/th&gt;
      &lt;td&gt;9966&lt;/td&gt;
      &lt;td&gt;243&lt;/td&gt;
      &lt;td&gt;0316776963&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1163&lt;/th&gt;
      &lt;td&gt;9976&lt;/td&gt;
      &lt;td&gt;243&lt;/td&gt;
      &lt;td&gt;0375400117&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1178&lt;/th&gt;
      &lt;td&gt;9994&lt;/td&gt;
      &lt;td&gt;243&lt;/td&gt;
      &lt;td&gt;0425163407&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1187&lt;/th&gt;
      &lt;td&gt;10005&lt;/td&gt;
      &lt;td&gt;243&lt;/td&gt;
      &lt;td&gt;0446364800&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The first user rated 66 books, and 6 of the books were rated at a 9 or a 10.  These are this users favorite books.  We will want to see if these books are associated with topics that user has been grouped into.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;user1_fav_indexes = np.where(df.columns.isin(user1_fav.ISBN.values))[0]
np.argmax(V[:,user1_fav_indexes],axis=0)




array([ 155,   77,  112,  291,   35, 2893])
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;They are not characteristic of the topics that the first user is associated with.  Lets how deep we need to go before we find the topics overlap between this person's best reviewed books and the topics this person is associated with.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;V&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;user1_fav_indexes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;&lt;span class="s-Atom"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="s-Atom"&gt;::-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s-Atom"&gt;top10&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;




&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;532&lt;/span&gt;&lt;span class="p"&gt;]),)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is very interesting for when we get to recommendation systems.  This user's top books are not remotely associated with the top topics the user is associated with.   This user did rate 66 books, and so the average topic could be different than the individual books would be associated with.   But if we are going to recommend a new book to this user, would we do it by topic, or by book similarity, or by user similarity.   To be continued...&lt;/p&gt;
&lt;h2&gt;Senate&lt;/h2&gt;
&lt;p&gt;We were given data for Senate voting records and asked to visualize the polarization for the 101st through 111th congresses.  The hard part of this project was cleaning and formating the data.   I will save you that processes because it was not informative.  &lt;/p&gt;
&lt;p&gt;Once the data was clean, we use distance measurements between the voting records, mapped these differences onto a 2D manifold, then displayed them with a color coding of 'Republican' and 'Democrate'.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.manifold&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;MDS&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy.spatial.distance&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pdist&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;squareform&lt;/span&gt;
&lt;span class="n"&gt;mds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MDS&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;101&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;112&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;df1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;data/senate/s{}.csv&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;df2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fillna&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;d101&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;squareform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; 
    &lt;span class="n"&gt;mds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d101&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;party&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embedding_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;mds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embedding_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ro&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embedding_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;mds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embedding_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;bo&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Senate {}&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xticks&lt;/span&gt;&lt;span class="p"&gt;([])&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;yticks&lt;/span&gt;&lt;span class="p"&gt;([])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D1/output_45_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;In this space, the voting vectors of republicans and democrats are very different.  As the years have move one, we see that it looks like they are drifiting appart.   We can remake this graph using PCA instead distance mapped onto a 2D manifold.  This coordinate system will capture directions of most variation.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.decomposition&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;PCA&lt;/span&gt;
&lt;span class="n"&gt;pca&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PCA&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_components&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;101&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;112&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;df1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;data/senate/s{}.csv&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;df2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fillna&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="mf"&gt;0.000001&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pca&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;party&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ro&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;bo&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Senate {}&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xticks&lt;/span&gt;&lt;span class="p"&gt;([])&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;yticks&lt;/span&gt;&lt;span class="p"&gt;([])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW06D1/output_47_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;This representation does not illustrate the same level of polarization as the previous graphs, but it does have a more sensible interpretation.   &lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="nlp"></category><category term="PCA"></category><category term="SVD"></category></entry><entry><title>Galvanize - Week 05 - Day 4</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-05-04/" rel="alternate"></link><updated>2015-07-03T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-07-03:galvanize/galvanize-data-science-05-04/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 5 - Day 4&lt;/h2&gt;
&lt;p&gt;Today we covered clutering.  Our morning quiz was a fun one because it involved A/B testing for 3 different pages.  We are told that the landing page was changed, and we have the number of useres that registered based on the page, and of those registered, we have the number who later purchased.   &lt;/p&gt;
&lt;p&gt;The business goal is increasing sales, not registrations.   The page the converts the most people to buy is the ultimate goal of this test.  The data we were given is shown below.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Visitors&lt;/th&gt;
&lt;th&gt;Registrations&lt;/th&gt;
&lt;th&gt;Purchases&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Landing Page 1&lt;/td&gt;
&lt;td&gt;998,832&lt;/td&gt;
&lt;td&gt;331,912&lt;/td&gt;
&lt;td&gt;18,255&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Landing Page 2&lt;/td&gt;
&lt;td&gt;1,012,285&lt;/td&gt;
&lt;td&gt;349,643&lt;/td&gt;
&lt;td&gt;18,531&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Landing Page 3&lt;/td&gt;
&lt;td&gt;995,750&lt;/td&gt;
&lt;td&gt;320,432&lt;/td&gt;
&lt;td&gt;18,585&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;What is really cool is that we can perform a series of two sample hypothesis test and determine which page leads to the highest proportion of purchases.   The other method is that we can visualize the beta distribution and see which page leads to the most favoriable pdf.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;scipy.stats&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sp&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;

&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.0175&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.0195&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10001&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;plot_beta&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;success&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;total&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;beta&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;success&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;total&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;success&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plot_beta&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;18255&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;998832&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Page 1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plot_beta&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;18531&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1012285&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Page 2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plot_beta&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;18585&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;995750&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Page 3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW05D4/output_1_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We can visually see that page 3 is better than page 1 and page 2, but this level of visualization does not capture how much better page 3 is than page 2 and page 1.   To do that we need to pick randomly from the distributions, and see how often page 3 is better than page 1 and page 2.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;page3betterthan2 = 0.
page3betterthan1 = 0.
sim_size = 100000
for i in range(sim_size):
    if sp.beta.rvs(18585,995750) &amp;gt; sp.beta.rvs(18531,1012285):
        page3betterthan2 += 1.
    if sp.beta.rvs(18585,995750) &amp;gt; sp.beta.rvs(18255,998832):
        page3betterthan1 += 1.

print page3betterthan1/sim_size, page3betterthan2/sim_size

0.97701 0.96717
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In our simulation, page 3 is statisically better than page 1 or page 2 are converting people who purchase products at the 5% level.   Our company should go with page 3.&lt;/p&gt;
&lt;p&gt;If registrations was the metric, however, we might want to go with page two, as shown in the following plot.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x = np.linspace(0.31,0.35,1001)
plot_beta(x,331912,998832,&amp;quot;Page 1&amp;quot;)
plot_beta(x,349643,1012285,&amp;quot;Page 2&amp;quot;)
plot_beta(x,320432,995750,&amp;quot;Page 3&amp;quot;)
plt.legend()
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW05D4/output_5_0.png" /&gt;&lt;/p&gt;
&lt;h2&gt;K-means&lt;/h2&gt;
&lt;p&gt;Our task for today is to create a k-means algorithm that has a random initialization of k centroids, then we recluster the data tot he closest centroids, move the centroid to the mean of the cluster, and repeat until there is convergence.&lt;/p&gt;
&lt;p&gt;The random initalization will lead to different results from trial to trial.  To help mitigate this we will run the algorithm a fixed and setable number of times, and return the cluster with the lowest mean squared error.&lt;/p&gt;
&lt;p&gt;We are going to try this data on the iris data set from sklearn.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;load_iris&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_iris&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_iris&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I am calling my class kNice, cause i'm in a silly mood today!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="n"&gt;kNice:&lt;/span&gt;

    &lt;span class="n"&gt;def&lt;/span&gt; &lt;span class="n"&gt;__init__&lt;/span&gt;(&lt;span class="k"&gt;self&lt;/span&gt;,&lt;span class="n"&gt;k&lt;/span&gt;,&lt;span class="n"&gt;max_iter&lt;/span&gt;=&lt;span class="mi"&gt;100&lt;/span&gt;,&lt;span class="n"&gt;n_runs&lt;/span&gt;=&lt;span class="mi"&gt;10&lt;/span&gt;):
        &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;k&lt;/span&gt; = &lt;span class="n"&gt;k&lt;/span&gt;
        &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;max_iter&lt;/span&gt; = &lt;span class="n"&gt;max_iter&lt;/span&gt;
        &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;n_runs&lt;/span&gt; = &lt;span class="n"&gt;n_runs&lt;/span&gt;
        &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;best_clusters&lt;/span&gt; = &lt;span class="n"&gt;None&lt;/span&gt;
        &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;best_centroids&lt;/span&gt; = &lt;span class="n"&gt;None&lt;/span&gt;
        &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;best_sse&lt;/span&gt; = &lt;span class="mf"&gt;1e17&lt;/span&gt;


    &lt;span class="n"&gt;def&lt;/span&gt; &lt;span class="n"&gt;fit&lt;/span&gt;(&lt;span class="k"&gt;self&lt;/span&gt;,&lt;span class="o"&gt;X&lt;/span&gt;):
        &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;sse&lt;/span&gt; = &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="o"&gt;X&lt;/span&gt; = &lt;span class="o"&gt;X&lt;/span&gt;

        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;range&lt;/span&gt;(&lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;n_runs&lt;/span&gt;):
            &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;clusters&lt;/span&gt; = &lt;span class="n"&gt;np&lt;/span&gt;.&lt;span class="n"&gt;random&lt;/span&gt;.&lt;span class="n"&gt;randint&lt;/span&gt;(&lt;span class="mi"&gt;0&lt;/span&gt;,&lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;k&lt;/span&gt;,&lt;span class="n"&gt;size&lt;/span&gt;=&lt;span class="o"&gt;X&lt;/span&gt;.&lt;span class="nb"&gt;shape&lt;/span&gt;[&lt;span class="mi"&gt;0&lt;/span&gt;])
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;range&lt;/span&gt;(&lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;k&lt;/span&gt;):
                &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;clusters&lt;/span&gt;[&lt;span class="n"&gt;i&lt;/span&gt;] = &lt;span class="n"&gt;i&lt;/span&gt;
            &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;centroids&lt;/span&gt; = &lt;span class="n"&gt;np&lt;/span&gt;.&lt;span class="n"&gt;zeros&lt;/span&gt;((&lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;k&lt;/span&gt;,&lt;span class="o"&gt;X&lt;/span&gt;.&lt;span class="nb"&gt;shape&lt;/span&gt;[&lt;span class="mi"&gt;1&lt;/span&gt;]))
            &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;_calculate_centroids&lt;/span&gt;()
            &lt;span class="n"&gt;local_centroids&lt;/span&gt; = &lt;span class="n"&gt;np&lt;/span&gt;.&lt;span class="n"&gt;zeros&lt;/span&gt;((&lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;k&lt;/span&gt;,&lt;span class="o"&gt;X&lt;/span&gt;.&lt;span class="nb"&gt;shape&lt;/span&gt;[&lt;span class="mi"&gt;1&lt;/span&gt;]))
            &lt;span class="n"&gt;iters&lt;/span&gt; = &lt;span class="mi"&gt;0&lt;/span&gt;

            &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;.&lt;span class="nb"&gt;all&lt;/span&gt;(&lt;span class="n"&gt;local_centroids&lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;centroids&lt;/span&gt;) &lt;span class="o"&gt;and&lt;/span&gt; (&lt;span class="n"&gt;iters&lt;/span&gt; &amp;lt;= &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;max_iter&lt;/span&gt;):
                &lt;span class="n"&gt;local_centroids&lt;/span&gt; = &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;centroids&lt;/span&gt;.&lt;span class="k"&gt;copy&lt;/span&gt;()
                &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;_update_centroids&lt;/span&gt;()
                &lt;span class="n"&gt;iters&lt;/span&gt; += &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="n"&gt;sse&lt;/span&gt; = &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;_sse&lt;/span&gt;()
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;sse&lt;/span&gt; &amp;lt; &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;best_sse:&lt;/span&gt;
                &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;best_sse&lt;/span&gt; = &lt;span class="n"&gt;sse&lt;/span&gt;
                &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;best_clusters&lt;/span&gt; = &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;clusters&lt;/span&gt;
                &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;best_centroids&lt;/span&gt; = &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;centroids&lt;/span&gt;

        &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;centroids&lt;/span&gt; = &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;best_centroids&lt;/span&gt;
        &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;clusters&lt;/span&gt; = &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;best_clusters&lt;/span&gt;
        &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;sse&lt;/span&gt; = &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;best_sse&lt;/span&gt;

    &lt;span class="n"&gt;def&lt;/span&gt; &lt;span class="n"&gt;_sse&lt;/span&gt;(&lt;span class="k"&gt;self&lt;/span&gt;):
        &lt;span class="n"&gt;sse&lt;/span&gt; = &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;range&lt;/span&gt;(&lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;k&lt;/span&gt;):
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;.&lt;span class="nb"&gt;any&lt;/span&gt;(&lt;span class="n"&gt;np&lt;/span&gt;.&lt;span class="n"&gt;isnan&lt;/span&gt;(&lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;centroids&lt;/span&gt;[&lt;span class="n"&gt;i&lt;/span&gt;])):
                &lt;span class="n"&gt;sse&lt;/span&gt; = &lt;span class="mf"&gt;1e16&lt;/span&gt;
                &lt;span class="k"&gt;break&lt;/span&gt;
            &lt;span class="n"&gt;else:&lt;/span&gt;
                &lt;span class="n"&gt;sse&lt;/span&gt; += &lt;span class="n"&gt;np&lt;/span&gt;.&lt;span class="nb"&gt;sum&lt;/span&gt;(&lt;span class="n"&gt;np&lt;/span&gt;.&lt;span class="n"&gt;power&lt;/span&gt;(&lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="o"&gt;X&lt;/span&gt;[&lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;clusters&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;]-&lt;span class="n"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;centroids&lt;/span&gt;[&lt;span class="n"&gt;i&lt;/span&gt;] ,&lt;span class="mi"&gt;2&lt;/span&gt;))
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;sse&lt;/span&gt;



    &lt;span class="n"&gt;def&lt;/span&gt; &lt;span class="n"&gt;_calculate_centroids&lt;/span&gt;(&lt;span class="k"&gt;self&lt;/span&gt;):
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;range&lt;/span&gt;(&lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;k&lt;/span&gt;):
            &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;centroids&lt;/span&gt;[&lt;span class="n"&gt;i&lt;/span&gt;] = &lt;span class="n"&gt;np&lt;/span&gt;.&lt;span class="n"&gt;mean&lt;/span&gt;(&lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="o"&gt;X&lt;/span&gt;[&lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;clusters&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;,:],&lt;span class="n"&gt;axis&lt;/span&gt;=&lt;span class="mi"&gt;0&lt;/span&gt;)
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;.&lt;span class="nb"&gt;any&lt;/span&gt;(&lt;span class="n"&gt;np&lt;/span&gt;.&lt;span class="n"&gt;isnan&lt;/span&gt;(&lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;centroids&lt;/span&gt;[&lt;span class="n"&gt;i&lt;/span&gt;])):
                &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;centroids&lt;/span&gt;[&lt;span class="n"&gt;i&lt;/span&gt;] = &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="o"&gt;X&lt;/span&gt;[&lt;span class="n"&gt;np&lt;/span&gt;.&lt;span class="n"&gt;random&lt;/span&gt;.&lt;span class="n"&gt;randint&lt;/span&gt;(&lt;span class="mi"&gt;0&lt;/span&gt;,&lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="o"&gt;X&lt;/span&gt;.&lt;span class="nb"&gt;shape&lt;/span&gt;[&lt;span class="mi"&gt;0&lt;/span&gt;])]


    &lt;span class="n"&gt;def&lt;/span&gt; &lt;span class="n"&gt;_update_centroids&lt;/span&gt;(&lt;span class="k"&gt;self&lt;/span&gt;):
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;k&lt;/span&gt; &amp;gt; &lt;span class="mi"&gt;1&lt;/span&gt;:
            &lt;span class="n"&gt;results&lt;/span&gt; = &lt;span class="n"&gt;np&lt;/span&gt;.&lt;span class="n"&gt;linalg&lt;/span&gt;.&lt;span class="n"&gt;norm&lt;/span&gt;(&lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="o"&gt;X-&lt;/span&gt;&lt;span class="n"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;centroids&lt;/span&gt;[&lt;span class="mi"&gt;0&lt;/span&gt;],&lt;span class="n"&gt;axis&lt;/span&gt;=&lt;span class="mi"&gt;1&lt;/span&gt;)
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;range&lt;/span&gt;(&lt;span class="mi"&gt;1&lt;/span&gt;,&lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;k&lt;/span&gt;):
                &lt;span class="n"&gt;results&lt;/span&gt; = &lt;span class="n"&gt;np&lt;/span&gt;.&lt;span class="n"&gt;vstack&lt;/span&gt;((&lt;span class="n"&gt;results&lt;/span&gt;,&lt;span class="n"&gt;np&lt;/span&gt;.&lt;span class="n"&gt;linalg&lt;/span&gt;.&lt;span class="n"&gt;norm&lt;/span&gt;(&lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="o"&gt;X-&lt;/span&gt;&lt;span class="n"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;centroids&lt;/span&gt;[&lt;span class="n"&gt;i&lt;/span&gt;],&lt;span class="n"&gt;axis&lt;/span&gt;=&lt;span class="mi"&gt;1&lt;/span&gt;)))
            &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;clusters&lt;/span&gt; = &lt;span class="n"&gt;np&lt;/span&gt;.&lt;span class="n"&gt;argmin&lt;/span&gt;(&lt;span class="n"&gt;results&lt;/span&gt;,&lt;span class="n"&gt;axis&lt;/span&gt;=&lt;span class="mi"&gt;0&lt;/span&gt;)
            &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;_calculate_centroids&lt;/span&gt;()

&lt;span class="n"&gt;clus&lt;/span&gt; = &lt;span class="n"&gt;kNice&lt;/span&gt;(&lt;span class="n"&gt;k&lt;/span&gt;=&lt;span class="mi"&gt;3&lt;/span&gt;,&lt;span class="n"&gt;n_runs&lt;/span&gt;=&lt;span class="mi"&gt;10&lt;/span&gt;)

&lt;span class="n"&gt;clus&lt;/span&gt;.&lt;span class="n"&gt;fit&lt;/span&gt;(&lt;span class="n"&gt;data&lt;/span&gt;)

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;.&lt;span class="n"&gt;unique&lt;/span&gt;(&lt;span class="n"&gt;y&lt;/span&gt;):
    &lt;span class="n"&gt;mask&lt;/span&gt; = &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;.&lt;span class="n"&gt;plot&lt;/span&gt;(&lt;span class="n"&gt;data&lt;/span&gt;[&lt;span class="n"&gt;mask&lt;/span&gt;,&lt;span class="mi"&gt;0&lt;/span&gt;],&lt;span class="n"&gt;data&lt;/span&gt;[&lt;span class="n"&gt;mask&lt;/span&gt;,&lt;span class="mi"&gt;1&lt;/span&gt;],&lt;span class="n"&gt;marker&lt;/span&gt;=&lt;span class="s"&gt;&amp;#39;o&amp;#39;&lt;/span&gt;,&lt;span class="n"&gt;lw&lt;/span&gt;=&lt;span class="mi"&gt;0&lt;/span&gt;)
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;x&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;clus&lt;/span&gt;.&lt;span class="n"&gt;centroids:&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;.&lt;span class="n"&gt;plot&lt;/span&gt;(&lt;span class="o"&gt;x&lt;/span&gt;[&lt;span class="mi"&gt;0&lt;/span&gt;],&lt;span class="o"&gt;x&lt;/span&gt;[&lt;span class="mi"&gt;1&lt;/span&gt;],&lt;span class="s"&gt;&amp;#39;ys&amp;#39;&lt;/span&gt;,&lt;span class="n"&gt;markersize&lt;/span&gt;=&lt;span class="mi"&gt;25&lt;/span&gt;)
&lt;span class="nb"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;SSE: &amp;quot;&lt;/span&gt;, &lt;span class="n"&gt;clus&lt;/span&gt;.&lt;span class="n"&gt;sse&lt;/span&gt;

&lt;span class="n"&gt;SSE:&lt;/span&gt;  &lt;span class="mf"&gt;78.9408414261&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW05D4/output_9_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;We can see in this case that 3 clusters seems to match the different types of iris flowers.   If we did not already know this, we can use the elbow method of the sum of square errors (SSE), and pick the number of clusters where the elbow is.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;for i in range(1,20):
    clus = kNice(i)
    clus.fit(data)
    plt.plot(i,clus.sse,&amp;#39;ro&amp;#39;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW05D4/output_11_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We see that this happens to be n=3, which is also the number of clusters that are in the data set.   There is also the silhouette score from sklearn that finds the mean intercluster distance.  The best value is 1, and the worst values is -1.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;silhouette_score&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;clus&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kNice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;clus&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;silhouette_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;clus&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clusters&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;metric&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;euclidean&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ro&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW05D4/output_13_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We see that in this case, the best cluster size is 2, followed by 3 and so forth.   With the overlap of the two of the iris data, it makes sense that two clusters would be better by this metric.&lt;/p&gt;
&lt;h2&gt;Random 3D Plot.&lt;/h2&gt;
&lt;p&gt;Its the day before we leave for the 4th of July.   I feel like plotting 3D!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;mpl_toolkits.mplot3d&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Axes3D&lt;/span&gt;


&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cluster&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;KMeans&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;


&lt;span class="n"&gt;iris&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_iris&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;iris&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;iris&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;

&lt;span class="n"&gt;fig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Axes3D&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rect&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;95&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;elev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;azim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;134&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cla&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;nice&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kNice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;nice&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nice&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clusters&lt;/span&gt;

&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w_xaxis&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ticklabels&lt;/span&gt;&lt;span class="p"&gt;([])&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w_yaxis&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ticklabels&lt;/span&gt;&lt;span class="p"&gt;([])&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w_zaxis&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ticklabels&lt;/span&gt;&lt;span class="p"&gt;([])&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Petal width&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Sepal length&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_zlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Petal length&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW05D4/output_15_0.png" /&gt;&lt;/p&gt;
&lt;h2&gt;NY Times - Clustering&lt;/h2&gt;
&lt;p&gt;In the afternoon spirt, we are trying to identify topics in the New York Times by clustering.   We have 1400+ articles saved in a pickle file.   We will read them in, TFIDF them, and cluster.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_pickle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;data/articles.pkl&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;




&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1405&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;




&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.feature_extraction.text&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;TfidfVectorizer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cluster&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;KMeans&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;re&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RegexpTokenizer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;stopwords&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.stem.porter&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;PorterStemmer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.stem.snowball&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SnowballStemmer&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;    INPUT: string&lt;/span&gt;
&lt;span class="sd"&gt;    OUTPUT: list of strings&lt;/span&gt;

&lt;span class="sd"&gt;    Tokenize and stem/lemmatize the document.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;sw&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stopwords&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;snowball&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SnowballStemmer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;reg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RegexpTokenizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;r&amp;#39;\w+&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;flags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;UNICODE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;doc_tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;reg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sw&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;snowball&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stem&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;doc_tokens&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;    
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;doc_tokens&lt;/span&gt;



&lt;span class="n"&gt;vectorizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TfidfVectorizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tokenize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;stop_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;strip_accents&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;unicode&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;max_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tfidf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vectorizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="n"&gt;num_clust&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;
&lt;span class="n"&gt;clus&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;KMeans&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_clust&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;clus&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_clust&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Cluster: &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;temp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;clus&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cluster_centers_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;temp&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;clus&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cluster_centers_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;:]]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;temp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;temp&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linalg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;norm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;temp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;top 10 words&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;vectorizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inverse_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;temp&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;top 5 headlines&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;clus&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;labels_&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;



&lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;care&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;cruz&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;debt&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;democrat&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;govern&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;health&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;hous&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;law&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;mr&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;obama&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;parti&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;republican&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;senat&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;shutdown&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;vote&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;headlines&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt;                      &lt;span class="n"&gt;New&lt;/span&gt; &lt;span class="n"&gt;Immigration&lt;/span&gt; &lt;span class="n"&gt;Bill&lt;/span&gt; &lt;span class="n"&gt;Put&lt;/span&gt; &lt;span class="n"&gt;Forward&lt;/span&gt;
&lt;span class="mi"&gt;17&lt;/span&gt;                                  &lt;span class="n"&gt;Congress&lt;/span&gt; &lt;span class="n"&gt;Breaks&lt;/span&gt; &lt;span class="n"&gt;Bad&lt;/span&gt;
&lt;span class="mi"&gt;18&lt;/span&gt;                            &lt;span class="n"&gt;Excuses&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Excuses&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Excuses&lt;/span&gt;
&lt;span class="mi"&gt;48&lt;/span&gt;    &lt;span class="n"&gt;Obama&lt;/span&gt; &lt;span class="n"&gt;Sets&lt;/span&gt; &lt;span class="n"&gt;Conditions&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;Talks&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Pass&lt;/span&gt; &lt;span class="n"&gt;Funding&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;78&lt;/span&gt;                            &lt;span class="n"&gt;Our&lt;/span&gt; &lt;span class="n"&gt;Democracy&lt;/span&gt; &lt;span class="n"&gt;Is&lt;/span&gt; &lt;span class="n"&gt;at&lt;/span&gt; &lt;span class="n"&gt;Stake&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;

&lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;buffalo&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;defens&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;game&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;holm&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;jet&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;lankster&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;quarterback&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;ryan&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;said&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;season&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;smith&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;titan&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;turnov&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;week&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;yard&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;headlines&lt;/span&gt;
&lt;span class="mi"&gt;55&lt;/span&gt;                  &lt;span class="n"&gt;Titans&lt;/span&gt; &lt;span class="n"&gt;Quarterback&lt;/span&gt; &lt;span class="n"&gt;Out&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="n"&gt;Few&lt;/span&gt; &lt;span class="n"&gt;Weeks&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;
&lt;span class="mi"&gt;129&lt;/span&gt;                     &lt;span class="n"&gt;Time&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;Smith&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Learn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Quickly&lt;/span&gt;
&lt;span class="mi"&gt;231&lt;/span&gt;                                        &lt;span class="n"&gt;Jets&lt;/span&gt; &lt;span class="n"&gt;Close&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Up&lt;/span&gt;
&lt;span class="mi"&gt;253&lt;/span&gt;    &lt;span class="n"&gt;Tennessee&lt;/span&gt; &lt;span class="n"&gt;Turns&lt;/span&gt; &lt;span class="n"&gt;Smith&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;Giveaways&lt;/span&gt; &lt;span class="n"&gt;Into&lt;/span&gt; &lt;span class="n"&gt;Touchdowns&lt;/span&gt;
&lt;span class="mi"&gt;329&lt;/span&gt;                           &lt;span class="n"&gt;Jets&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;at&lt;/span&gt; &lt;span class="n"&gt;Titans&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;

&lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;attack&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;chemic&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;govern&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;kill&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;mr&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;offici&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;peopl&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;polic&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;rebel&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;said&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;secur&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;syria&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;syrian&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;unit&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;weapon&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;headlines&lt;/span&gt;
&lt;span class="mi"&gt;22&lt;/span&gt;                   &lt;span class="n"&gt;Libya&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Mob&lt;/span&gt; &lt;span class="n"&gt;Attacks&lt;/span&gt; &lt;span class="n"&gt;Russian&lt;/span&gt; &lt;span class="n"&gt;Embassy&lt;/span&gt;
&lt;span class="mi"&gt;38&lt;/span&gt;    &lt;span class="n"&gt;Man&lt;/span&gt; &lt;span class="n"&gt;Charged&lt;/span&gt; &lt;span class="n"&gt;With&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt; &lt;span class="n"&gt;Report&lt;/span&gt; &lt;span class="n"&gt;After&lt;/span&gt; &lt;span class="n"&gt;Airport&lt;/span&gt; &lt;span class="n"&gt;Cl&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;42&lt;/span&gt;     &lt;span class="n"&gt;Missed&lt;/span&gt; &lt;span class="n"&gt;Opportunity&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;Syria&lt;/span&gt; &lt;span class="n"&gt;Haunts&lt;/span&gt; &lt;span class="n"&gt;U&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Official&lt;/span&gt;
&lt;span class="mi"&gt;62&lt;/span&gt;                      &lt;span class="n"&gt;Airport&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;Florida&lt;/span&gt; &lt;span class="n"&gt;Is&lt;/span&gt; &lt;span class="n"&gt;Evacuated&lt;/span&gt;
&lt;span class="mi"&gt;82&lt;/span&gt;    &lt;span class="n"&gt;Libya&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;27&lt;/span&gt; &lt;span class="n"&gt;Tortured&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Death&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;Jails&lt;/span&gt; &lt;span class="n"&gt;Run&lt;/span&gt; &lt;span class="n"&gt;by&lt;/span&gt; &lt;span class="n"&gt;Mi&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;

&lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;coach&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;game&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;hit&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;inning&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;l&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;leagu&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;n&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;play&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;player&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;run&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;said&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;score&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;season&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;team&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;win&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;headlines&lt;/span&gt;
&lt;span class="mi"&gt;6&lt;/span&gt;               &lt;span class="n"&gt;Bayern&lt;/span&gt; &lt;span class="n"&gt;Munich&lt;/span&gt; &lt;span class="n"&gt;Dominates&lt;/span&gt; &lt;span class="n"&gt;Manchester&lt;/span&gt; &lt;span class="n"&gt;City&lt;/span&gt;
&lt;span class="mi"&gt;8&lt;/span&gt;                      &lt;span class="n"&gt;Brodeur&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;Starting&lt;/span&gt; &lt;span class="n"&gt;Streak&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;End&lt;/span&gt;
&lt;span class="mi"&gt;21&lt;/span&gt;    &lt;span class="n"&gt;Finally&lt;/span&gt; &lt;span class="n"&gt;Secure&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;Desert&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;Coyotes&lt;/span&gt; &lt;span class="n"&gt;Devo&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;26&lt;/span&gt;    &lt;span class="n"&gt;Braves&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="n"&gt;Free&lt;/span&gt; &lt;span class="n"&gt;Swingers&lt;/span&gt; &lt;span class="n"&gt;Face&lt;/span&gt; &lt;span class="n"&gt;Dodgers&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="n"&gt;Staff&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;Aces&lt;/span&gt;
&lt;span class="mi"&gt;35&lt;/span&gt;       &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;Follow&lt;/span&gt; &lt;span class="n"&gt;Crisp&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;Lead&lt;/span&gt; &lt;span class="n"&gt;Back&lt;/span&gt; &lt;span class="n"&gt;Into&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;Playoffs&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;

&lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;coalit&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;dawn&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;democrat&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;elect&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;europ&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;german&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;germani&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;golden&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;govern&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;merkel&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;mr&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;parliament&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;parti&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;polit&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;said&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;headlines&lt;/span&gt;
&lt;span class="mi"&gt;34&lt;/span&gt;     &lt;span class="n"&gt;Risk&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Averse&lt;/span&gt; &lt;span class="n"&gt;Gandhi&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;Move&lt;/span&gt; &lt;span class="n"&gt;Rattles&lt;/span&gt; &lt;span class="n"&gt;Indian&lt;/span&gt; &lt;span class="n"&gt;Election&lt;/span&gt;
&lt;span class="mi"&gt;44&lt;/span&gt;      &lt;span class="n"&gt;Case&lt;/span&gt; &lt;span class="n"&gt;Against&lt;/span&gt; &lt;span class="n"&gt;Greek&lt;/span&gt; &lt;span class="n"&gt;Far&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Right&lt;/span&gt; &lt;span class="n"&gt;Party&lt;/span&gt; &lt;span class="n"&gt;Draws&lt;/span&gt; &lt;span class="n"&gt;Critics&lt;/span&gt;
&lt;span class="mi"&gt;49&lt;/span&gt;             &lt;span class="n"&gt;Mutiny&lt;/span&gt; &lt;span class="n"&gt;Halts&lt;/span&gt; &lt;span class="n"&gt;Italian&lt;/span&gt; &lt;span class="n"&gt;Gambit&lt;/span&gt; &lt;span class="n"&gt;by&lt;/span&gt; &lt;span class="n"&gt;Berlusconi&lt;/span&gt;
&lt;span class="mi"&gt;95&lt;/span&gt;     &lt;span class="n"&gt;Internal&lt;/span&gt; &lt;span class="n"&gt;Dissent&lt;/span&gt; &lt;span class="n"&gt;Imperils&lt;/span&gt; &lt;span class="n"&gt;Berlusconi&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;Long&lt;/span&gt; &lt;span class="n"&gt;Re&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;154&lt;/span&gt;                    &lt;span class="n"&gt;Norway&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;New&lt;/span&gt; &lt;span class="n"&gt;Coalition&lt;/span&gt; &lt;span class="n"&gt;Tilts&lt;/span&gt; &lt;span class="n"&gt;Right&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;

&lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;0&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;1&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;2&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;3&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;coughlin&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;defens&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;game&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;giant&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;offens&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;play&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;quarterback&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;season&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;team&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;touchdown&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;yard&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;headlines&lt;/span&gt;
&lt;span class="mi"&gt;0&lt;/span&gt;      &lt;span class="n"&gt;Week&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;Probabilities&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Why&lt;/span&gt; &lt;span class="n"&gt;Offense&lt;/span&gt; &lt;span class="n"&gt;Is&lt;/span&gt; &lt;span class="n"&gt;More&lt;/span&gt; &lt;span class="n"&gt;Impo&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;73&lt;/span&gt;     &lt;span class="n"&gt;Woes&lt;/span&gt; &lt;span class="n"&gt;Continue&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;Giants&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;Snee&lt;/span&gt; &lt;span class="n"&gt;Considers&lt;/span&gt; &lt;span class="n"&gt;Sur&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;131&lt;/span&gt;         &lt;span class="n"&gt;Nowhere&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Look&lt;/span&gt; &lt;span class="n"&gt;but&lt;/span&gt; &lt;span class="n"&gt;Ahead&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;Winless&lt;/span&gt; &lt;span class="n"&gt;Giants&lt;/span&gt;
&lt;span class="mi"&gt;134&lt;/span&gt;              &lt;span class="n"&gt;Saints&lt;/span&gt; &lt;span class="n"&gt;Hand&lt;/span&gt; &lt;span class="n"&gt;Dolphins&lt;/span&gt; &lt;span class="n"&gt;Their&lt;/span&gt; &lt;span class="n"&gt;First&lt;/span&gt; &lt;span class="n"&gt;Defeat&lt;/span&gt;
&lt;span class="mi"&gt;225&lt;/span&gt;    &lt;span class="n"&gt;Week&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="n"&gt;Quick&lt;/span&gt; &lt;span class="n"&gt;Hits&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Corners&lt;/span&gt; &lt;span class="n"&gt;Cover&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;Patriots&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;

&lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;citi&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;court&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;like&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;mr&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;ms&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;new&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;peopl&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;race&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;said&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;school&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;sept&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;state&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;time&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;world&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;headlines&lt;/span&gt;
&lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="n"&gt;Arizona&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Judge&lt;/span&gt; &lt;span class="n"&gt;Orders&lt;/span&gt; &lt;span class="n"&gt;Monitor&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Oversee&lt;/span&gt; &lt;span class="n"&gt;Maric&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="n"&gt;Texas&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;State&lt;/span&gt; &lt;span class="n"&gt;Bought&lt;/span&gt; &lt;span class="n"&gt;Execution&lt;/span&gt; &lt;span class="n"&gt;Drugs&lt;/span&gt; &lt;span class="n"&gt;From&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;Com&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;4&lt;/span&gt;                        &lt;span class="n"&gt;Nadal&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;Track&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;No&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;Spot&lt;/span&gt;
&lt;span class="mi"&gt;7&lt;/span&gt;        &lt;span class="n"&gt;American&lt;/span&gt; &lt;span class="n"&gt;Leads&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;World&lt;/span&gt; &lt;span class="n"&gt;Gymnastics&lt;/span&gt; &lt;span class="n"&gt;All&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Around&lt;/span&gt;
&lt;span class="mi"&gt;9&lt;/span&gt;                           &lt;span class="n"&gt;Vonn&lt;/span&gt; &lt;span class="n"&gt;Is&lt;/span&gt; &lt;span class="n"&gt;Close&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Returning&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;

&lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;basebal&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;cano&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;game&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;girardi&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;inning&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;jeter&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;mariano&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;pettitt&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;pitch&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;rivera&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;rodriguez&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;said&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;season&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;stadium&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;yanke&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;headlines&lt;/span&gt;
&lt;span class="mi"&gt;87&lt;/span&gt;                        &lt;span class="n"&gt;YES&lt;/span&gt; &lt;span class="n"&gt;Viewers&lt;/span&gt; &lt;span class="n"&gt;Say&lt;/span&gt; &lt;span class="n"&gt;Their&lt;/span&gt; &lt;span class="n"&gt;Goodbyes&lt;/span&gt;
&lt;span class="mi"&gt;243&lt;/span&gt;    &lt;span class="n"&gt;For&lt;/span&gt; &lt;span class="n"&gt;Girardi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Yanks&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="n"&gt;Goodbyes&lt;/span&gt; &lt;span class="n"&gt;Won&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="n"&gt;Get&lt;/span&gt; &lt;span class="n"&gt;Any&lt;/span&gt; &lt;span class="n"&gt;Easier&lt;/span&gt;
&lt;span class="mi"&gt;263&lt;/span&gt;    &lt;span class="n"&gt;Memorable&lt;/span&gt; &lt;span class="n"&gt;End&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;Two&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;Forgettable&lt;/span&gt; &lt;span class="n"&gt;Year&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;Yanks&lt;/span&gt;
&lt;span class="mi"&gt;326&lt;/span&gt;      &lt;span class="n"&gt;Rivera&lt;/span&gt; &lt;span class="n"&gt;Says&lt;/span&gt; &lt;span class="n"&gt;There&lt;/span&gt; &lt;span class="n"&gt;Will&lt;/span&gt; &lt;span class="n"&gt;Be&lt;/span&gt; &lt;span class="n"&gt;No&lt;/span&gt; &lt;span class="n"&gt;Encore&lt;/span&gt; &lt;span class="n"&gt;Performance&lt;/span&gt;
&lt;span class="mi"&gt;331&lt;/span&gt;    &lt;span class="n"&gt;With&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;Win&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;Ending&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Pettitte&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;Illustrio&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;

&lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;212&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;art&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;artist&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;citi&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;design&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;exhibit&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;galleri&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;like&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;m&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;mr&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;museum&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;paint&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;said&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;street&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;work&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;headlines&lt;/span&gt;
&lt;span class="mi"&gt;13&lt;/span&gt;     &lt;span class="n"&gt;On&lt;/span&gt; &lt;span class="n"&gt;Fashion&lt;/span&gt; &lt;span class="n"&gt;Runway&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;South&lt;/span&gt; &lt;span class="n"&gt;Sudan&lt;/span&gt; &lt;span class="n"&gt;Takes&lt;/span&gt; &lt;span class="n"&gt;Steps&lt;/span&gt; &lt;span class="n"&gt;Tow&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;31&lt;/span&gt;                 &lt;span class="n"&gt;Surrounding&lt;/span&gt; &lt;span class="n"&gt;Art&lt;/span&gt; &lt;span class="n"&gt;With&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;Sounds&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;60&lt;/span&gt;
&lt;span class="mi"&gt;41&lt;/span&gt;      &lt;span class="n"&gt;Midnight&lt;/span&gt; &lt;span class="n"&gt;at&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;Museum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Breakfast&lt;/span&gt; &lt;span class="n"&gt;at&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;Vatican&lt;/span&gt;
&lt;span class="mi"&gt;130&lt;/span&gt;             &lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="n"&gt;Monument&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;West&lt;/span&gt; &lt;span class="n"&gt;That&lt;/span&gt; &lt;span class="n"&gt;Many&lt;/span&gt; &lt;span class="n"&gt;Pass&lt;/span&gt; &lt;span class="n"&gt;By&lt;/span&gt;
&lt;span class="mi"&gt;175&lt;/span&gt;           &lt;span class="n"&gt;Storytelling&lt;/span&gt; &lt;span class="n"&gt;Coming&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Life&lt;/span&gt; &lt;span class="n"&gt;at&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;Library&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;

&lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;america&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;boat&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;club&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;cup&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;francisco&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;golf&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;oracl&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;race&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;regatta&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;said&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;san&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;spithil&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;team&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;yacht&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;zealand&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;headlines&lt;/span&gt;
&lt;span class="mi"&gt;5&lt;/span&gt;                  &lt;span class="n"&gt;Judge&lt;/span&gt; &lt;span class="n"&gt;Halts&lt;/span&gt; &lt;span class="n"&gt;Work&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;World&lt;/span&gt; &lt;span class="n"&gt;Cup&lt;/span&gt; &lt;span class="n"&gt;Stadium&lt;/span&gt;
&lt;span class="mi"&gt;10&lt;/span&gt;           &lt;span class="n"&gt;Whitney&lt;/span&gt; &lt;span class="n"&gt;Winner&lt;/span&gt; &lt;span class="n"&gt;Out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;Breeders&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="n"&gt;Cup&lt;/span&gt; &lt;span class="n"&gt;Classic&lt;/span&gt;
&lt;span class="mi"&gt;125&lt;/span&gt;    &lt;span class="n"&gt;Australia&lt;/span&gt; &lt;span class="n"&gt;Primed&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;First&lt;/span&gt; &lt;span class="n"&gt;Cup&lt;/span&gt; &lt;span class="n"&gt;Challenge&lt;/span&gt; &lt;span class="n"&gt;Since&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;311&lt;/span&gt;        &lt;span class="n"&gt;Presidents&lt;/span&gt; &lt;span class="n"&gt;Cup&lt;/span&gt; &lt;span class="n"&gt;Is&lt;/span&gt; &lt;span class="n"&gt;Custom&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Made&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;Tiger&lt;/span&gt; &lt;span class="n"&gt;Woods&lt;/span&gt;
&lt;span class="mi"&gt;312&lt;/span&gt;    &lt;span class="n"&gt;Nick&lt;/span&gt; &lt;span class="n"&gt;Price&lt;/span&gt; &lt;span class="n"&gt;Has&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;Mission&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Motivate&lt;/span&gt; &lt;span class="n"&gt;at&lt;/span&gt; &lt;span class="n"&gt;Presid&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;

&lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;carbon&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;china&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;coal&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;emiss&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;gas&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;japan&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;korea&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;korean&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;mr&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;north&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;nuclear&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;oil&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;plant&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;said&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;south&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;headlines&lt;/span&gt;
&lt;span class="mi"&gt;12&lt;/span&gt;              &lt;span class="n"&gt;Fuel&lt;/span&gt; &lt;span class="n"&gt;From&lt;/span&gt; &lt;span class="n"&gt;Landfill&lt;/span&gt; &lt;span class="n"&gt;Methane&lt;/span&gt; &lt;span class="n"&gt;Goes&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;Sale&lt;/span&gt;
&lt;span class="mi"&gt;23&lt;/span&gt;               &lt;span class="n"&gt;Evidence&lt;/span&gt; &lt;span class="n"&gt;North&lt;/span&gt; &lt;span class="n"&gt;Korea&lt;/span&gt; &lt;span class="n"&gt;Restarted&lt;/span&gt; &lt;span class="n"&gt;Reactor&lt;/span&gt;
&lt;span class="mi"&gt;28&lt;/span&gt;    &lt;span class="n"&gt;Another&lt;/span&gt; &lt;span class="n"&gt;Shutdown&lt;/span&gt; &lt;span class="n"&gt;Victim&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;U&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;S&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Efforts&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Offse&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;45&lt;/span&gt;    &lt;span class="n"&gt;Back&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;Asia&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Hagel&lt;/span&gt; &lt;span class="n"&gt;Pursues&lt;/span&gt; &lt;span class="n"&gt;Shift&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;50&lt;/span&gt;    &lt;span class="n"&gt;U&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;S&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;South&lt;/span&gt; &lt;span class="n"&gt;Korea&lt;/span&gt; &lt;span class="n"&gt;Set&lt;/span&gt; &lt;span class="n"&gt;Defense&lt;/span&gt; &lt;span class="n"&gt;Strategy&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;

&lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;iran&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;iranian&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;israel&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;mr&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;nation&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;negoti&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;netanyahu&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;nuclear&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;obama&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;presid&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;rouhani&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;said&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;sanction&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;state&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;unit&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;headlines&lt;/span&gt;
&lt;span class="mi"&gt;20&lt;/span&gt;                &lt;span class="n"&gt;Iran&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;President&lt;/span&gt; &lt;span class="n"&gt;Responds&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Netanyahu&lt;/span&gt;
&lt;span class="mi"&gt;149&lt;/span&gt;               &lt;span class="n"&gt;Iran&lt;/span&gt; &lt;span class="n"&gt;Staggers&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;Sanctions&lt;/span&gt; &lt;span class="n"&gt;Hit&lt;/span&gt; &lt;span class="n"&gt;Economy&lt;/span&gt;
&lt;span class="mi"&gt;261&lt;/span&gt;    &lt;span class="n"&gt;Amid&lt;/span&gt; &lt;span class="n"&gt;Nuclear&lt;/span&gt; &lt;span class="n"&gt;Issue&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Israel&lt;/span&gt; &lt;span class="n"&gt;Said&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Arrest&lt;/span&gt; &lt;span class="n"&gt;Iran&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;310&lt;/span&gt;       &lt;span class="n"&gt;Dueling&lt;/span&gt; &lt;span class="n"&gt;Narratives&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;Iran&lt;/span&gt; &lt;span class="n"&gt;Over&lt;/span&gt; &lt;span class="n"&gt;U&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;S&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Relations&lt;/span&gt;
&lt;span class="mi"&gt;323&lt;/span&gt;    &lt;span class="n"&gt;Israel&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;Others&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;Mideast&lt;/span&gt; &lt;span class="n"&gt;View&lt;/span&gt; &lt;span class="n"&gt;Overtures&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;

&lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;afford&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;care&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;employe&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;exchang&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;feder&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;govern&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;health&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;hous&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;insur&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;law&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;new&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;republican&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;said&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;state&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;worker&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;headlines&lt;/span&gt;
&lt;span class="mi"&gt;15&lt;/span&gt;                                 &lt;span class="n"&gt;New&lt;/span&gt; &lt;span class="n"&gt;York&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Two&lt;/span&gt; &lt;span class="n"&gt;Cities&lt;/span&gt;&lt;span class="err"&gt;?&lt;/span&gt;
&lt;span class="mi"&gt;16&lt;/span&gt;                      &lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="n"&gt;Blind&lt;/span&gt; &lt;span class="n"&gt;Spot&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;Rearview&lt;/span&gt; &lt;span class="n"&gt;Cameras&lt;/span&gt;
&lt;span class="mi"&gt;37&lt;/span&gt;     &lt;span class="n"&gt;As&lt;/span&gt; &lt;span class="n"&gt;Demand&lt;/span&gt; &lt;span class="n"&gt;Stays&lt;/span&gt; &lt;span class="n"&gt;High&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Officials&lt;/span&gt; &lt;span class="n"&gt;Try&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Address&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;98&lt;/span&gt;       &lt;span class="n"&gt;Justices&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Hear&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="n"&gt;Raging&lt;/span&gt; &lt;span class="n"&gt;Bull&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="n"&gt;Copyright&lt;/span&gt; &lt;span class="n"&gt;Appeal&lt;/span&gt;
&lt;span class="mi"&gt;105&lt;/span&gt;     &lt;span class="n"&gt;Invitation&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;Dialogue&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Distrust&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;Government&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;

&lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;album&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;band&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;drake&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;dylan&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;festiv&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;guitar&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;like&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;lyric&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;mr&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;music&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;play&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;pop&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;record&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;song&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;sound&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;headlines&lt;/span&gt;
&lt;span class="mi"&gt;89&lt;/span&gt;                           &lt;span class="n"&gt;Movement&lt;/span&gt; &lt;span class="n"&gt;Made&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;Listening&lt;/span&gt;
&lt;span class="mi"&gt;174&lt;/span&gt;        &lt;span class="n"&gt;At&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;Festival&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Molly&lt;/span&gt; &lt;span class="n"&gt;Danced&lt;/span&gt; &lt;span class="n"&gt;but&lt;/span&gt; &lt;span class="n"&gt;Didn&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="n"&gt;Cut&lt;/span&gt; &lt;span class="n"&gt;In&lt;/span&gt;
&lt;span class="mi"&gt;177&lt;/span&gt;    &lt;span class="n"&gt;Congressman&lt;/span&gt; &lt;span class="n"&gt;Proposes&lt;/span&gt; &lt;span class="n"&gt;New&lt;/span&gt; &lt;span class="n"&gt;Rules&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;Music&lt;/span&gt; &lt;span class="n"&gt;Royal&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;191&lt;/span&gt;    &lt;span class="n"&gt;Traditional&lt;/span&gt; &lt;span class="n"&gt;Folk&lt;/span&gt; &lt;span class="n"&gt;Frolic&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;With&lt;/span&gt; &lt;span class="n"&gt;Old&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Time&lt;/span&gt; &lt;span class="n"&gt;Fervor&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;193&lt;/span&gt;                 &lt;span class="n"&gt;The&lt;/span&gt; &lt;span class="n"&gt;Blow&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;Haim&lt;/span&gt; &lt;span class="n"&gt;Release&lt;/span&gt; &lt;span class="n"&gt;New&lt;/span&gt; &lt;span class="n"&gt;Albums&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;

&lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;14&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;compani&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;concert&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;levin&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;met&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;mr&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;ms&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;music&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;new&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;night&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;opera&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;orchestra&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;perform&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;said&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;season&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;work&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;headlines&lt;/span&gt;
&lt;span class="mi"&gt;33&lt;/span&gt;       &lt;span class="n"&gt;Praying&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;Moon&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;While&lt;/span&gt; &lt;span class="n"&gt;Lashing&lt;/span&gt; &lt;span class="n"&gt;Out&lt;/span&gt; &lt;span class="n"&gt;at&lt;/span&gt; &lt;span class="n"&gt;Fate&lt;/span&gt;
&lt;span class="mi"&gt;39&lt;/span&gt;       &lt;span class="n"&gt;Minnesota&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Orchestra&lt;/span&gt; &lt;span class="n"&gt;Cancels&lt;/span&gt; &lt;span class="n"&gt;New&lt;/span&gt; &lt;span class="n"&gt;York&lt;/span&gt; &lt;span class="n"&gt;Concerts&lt;/span&gt;
&lt;span class="mi"&gt;52&lt;/span&gt;    &lt;span class="n"&gt;Fact&lt;/span&gt; &lt;span class="n"&gt;Slides&lt;/span&gt; &lt;span class="n"&gt;Into&lt;/span&gt; &lt;span class="n"&gt;Fiction&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;National&lt;/span&gt; &lt;span class="n"&gt;Theater&lt;/span&gt; &lt;span class="n"&gt;V&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;90&lt;/span&gt;    &lt;span class="n"&gt;It&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;No&lt;/span&gt; &lt;span class="n"&gt;Longer&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;His&lt;/span&gt; &lt;span class="n"&gt;Face&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;It&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;Got&lt;/span&gt; &lt;span class="n"&gt;Ambit&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;93&lt;/span&gt;               &lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="n"&gt;Plucky&lt;/span&gt; &lt;span class="n"&gt;Opera&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;Poignant&lt;/span&gt; &lt;span class="n"&gt;Death&lt;/span&gt; &lt;span class="n"&gt;Rattle&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;

&lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;abc&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;cbs&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;drama&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;emmi&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;fox&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;hbo&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;m&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;nbc&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;network&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;p&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;rate&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;season&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;seri&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;televis&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;viewer&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;headlines&lt;/span&gt;
&lt;span class="mi"&gt;29&lt;/span&gt;                       &lt;span class="n"&gt;Family&lt;/span&gt; &lt;span class="n"&gt;Trees&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;Familiar&lt;/span&gt; &lt;span class="n"&gt;Scions&lt;/span&gt;
&lt;span class="mi"&gt;203&lt;/span&gt;    &lt;span class="n"&gt;More&lt;/span&gt; &lt;span class="n"&gt;Than&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;Million&lt;/span&gt; &lt;span class="n"&gt;Watch&lt;/span&gt; &lt;span class="n"&gt;Finale&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="n"&gt;Breaking&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;226&lt;/span&gt;                                     &lt;span class="n"&gt;What&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;Monday&lt;/span&gt;
&lt;span class="mi"&gt;257&lt;/span&gt;                                     &lt;span class="n"&gt;What&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;On&lt;/span&gt; &lt;span class="n"&gt;Sunday&lt;/span&gt;
&lt;span class="mi"&gt;427&lt;/span&gt;                                   &lt;span class="n"&gt;What&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;On&lt;/span&gt; &lt;span class="n"&gt;Saturday&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;

&lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;arctic&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;attack&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;greenpeac&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;kenya&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;kenyan&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;mall&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;milit&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;nairobi&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;offici&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;said&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;shabab&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;ship&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;somali&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;somalia&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;westgat&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;headlines&lt;/span&gt;
&lt;span class="mi"&gt;63&lt;/span&gt;     &lt;span class="n"&gt;During&lt;/span&gt; &lt;span class="n"&gt;Siege&lt;/span&gt; &lt;span class="n"&gt;at&lt;/span&gt; &lt;span class="n"&gt;Kenyan&lt;/span&gt; &lt;span class="n"&gt;Mall&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Government&lt;/span&gt; &lt;span class="n"&gt;Forces&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;207&lt;/span&gt;          &lt;span class="n"&gt;Somali&lt;/span&gt; &lt;span class="n"&gt;Militants&lt;/span&gt; &lt;span class="n"&gt;Mixing&lt;/span&gt; &lt;span class="n"&gt;Business&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;Terror&lt;/span&gt;
&lt;span class="mi"&gt;394&lt;/span&gt;    &lt;span class="n"&gt;Somali&lt;/span&gt; &lt;span class="n"&gt;Community&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;U&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;S&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Fears&lt;/span&gt; &lt;span class="n"&gt;New&lt;/span&gt; &lt;span class="n"&gt;Wave&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;Sti&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;442&lt;/span&gt;            &lt;span class="n"&gt;Tale&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="n"&gt;White&lt;/span&gt; &lt;span class="n"&gt;Widow&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="n"&gt;Fills&lt;/span&gt; &lt;span class="n"&gt;British&lt;/span&gt; &lt;span class="n"&gt;Press&lt;/span&gt;
&lt;span class="mi"&gt;444&lt;/span&gt;    &lt;span class="n"&gt;Narrow&lt;/span&gt; &lt;span class="n"&gt;Escapes&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;Questions&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;Emergency&lt;/span&gt; &lt;span class="n"&gt;Resp&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;

&lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;17&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;0&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;bank&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;econom&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;economi&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;euro&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;govern&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;growth&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;index&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;investor&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;market&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;percent&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;price&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;rate&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;said&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;zone&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;headlines&lt;/span&gt;
&lt;span class="mi"&gt;46&lt;/span&gt;     &lt;span class="n"&gt;With&lt;/span&gt; &lt;span class="n"&gt;Inflation&lt;/span&gt; &lt;span class="n"&gt;Low&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;European&lt;/span&gt; &lt;span class="n"&gt;Central&lt;/span&gt; &lt;span class="n"&gt;Bank&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;72&lt;/span&gt;     &lt;span class="n"&gt;Growth&lt;/span&gt; &lt;span class="n"&gt;Forecast&lt;/span&gt; &lt;span class="n"&gt;Is&lt;/span&gt; &lt;span class="n"&gt;Trimmed&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;Developing&lt;/span&gt; &lt;span class="n"&gt;Nati&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;106&lt;/span&gt;       &lt;span class="n"&gt;Vatican&lt;/span&gt; &lt;span class="n"&gt;Bank&lt;/span&gt; &lt;span class="n"&gt;Publishes&lt;/span&gt; &lt;span class="n"&gt;Its&lt;/span&gt; &lt;span class="n"&gt;First&lt;/span&gt; &lt;span class="n"&gt;Annual&lt;/span&gt; &lt;span class="n"&gt;Report&lt;/span&gt;
&lt;span class="mi"&gt;112&lt;/span&gt;    &lt;span class="n"&gt;European&lt;/span&gt; &lt;span class="n"&gt;Unemployment&lt;/span&gt; &lt;span class="n"&gt;Steady&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Hinting&lt;/span&gt; &lt;span class="n"&gt;at&lt;/span&gt; &lt;span class="n"&gt;Progr&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;118&lt;/span&gt;      &lt;span class="n"&gt;Japan&lt;/span&gt; &lt;span class="n"&gt;Sales&lt;/span&gt; &lt;span class="n"&gt;Tax&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Increase&lt;/span&gt; &lt;span class="n"&gt;Next&lt;/span&gt; &lt;span class="n"&gt;Year&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Abe&lt;/span&gt; &lt;span class="n"&gt;Says&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;

&lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;18&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;advertis&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;agenc&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;brand&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;c&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;chief&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;compani&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;e&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;execut&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;jpmorgan&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;market&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;mr&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;new&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;pay&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;said&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;vice&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;headlines&lt;/span&gt;
&lt;span class="mi"&gt;30&lt;/span&gt;     &lt;span class="n"&gt;Peter&lt;/span&gt; &lt;span class="n"&gt;Schlessel&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Lead&lt;/span&gt; &lt;span class="n"&gt;Universal&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;Focus&lt;/span&gt; &lt;span class="n"&gt;Feat&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;81&lt;/span&gt;       &lt;span class="n"&gt;Groceries&lt;/span&gt; &lt;span class="n"&gt;Are&lt;/span&gt; &lt;span class="n"&gt;Cleaning&lt;/span&gt; &lt;span class="n"&gt;Up&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;Store&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Brand&lt;/span&gt; &lt;span class="n"&gt;Aisles&lt;/span&gt;
&lt;span class="mi"&gt;86&lt;/span&gt;     &lt;span class="n"&gt;Worried&lt;/span&gt; &lt;span class="n"&gt;About&lt;/span&gt; &lt;span class="n"&gt;Land&lt;/span&gt; &lt;span class="n"&gt;Grabs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Group&lt;/span&gt; &lt;span class="n"&gt;Presses&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="n"&gt;Corp&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;108&lt;/span&gt;         &lt;span class="n"&gt;Merck&lt;/span&gt; &lt;span class="n"&gt;Plans&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Lay&lt;/span&gt; &lt;span class="n"&gt;Off&lt;/span&gt; &lt;span class="n"&gt;Another&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt; &lt;span class="n"&gt;Workers&lt;/span&gt;
&lt;span class="mi"&gt;110&lt;/span&gt;    &lt;span class="n"&gt;HarperCollins&lt;/span&gt; &lt;span class="n"&gt;Joins&lt;/span&gt; &lt;span class="n"&gt;Scribd&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Book&lt;/span&gt; &lt;span class="n"&gt;Subscript&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;

&lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;19&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;artist&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;ballet&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;choreograph&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;danc&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;dancer&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;mr&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;ms&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;music&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;new&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;perform&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;piec&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;program&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;stage&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;theater&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;work&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;headlines&lt;/span&gt;
&lt;span class="mi"&gt;279&lt;/span&gt;             &lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="n"&gt;Swing&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;Jaunt&lt;/span&gt; &lt;span class="n"&gt;Around&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;Globe&lt;/span&gt;
&lt;span class="mi"&gt;282&lt;/span&gt;    &lt;span class="n"&gt;An&lt;/span&gt; &lt;span class="n"&gt;Impish&lt;/span&gt; &lt;span class="n"&gt;Faun&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Swans&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;Lively&lt;/span&gt; &lt;span class="n"&gt;Card&lt;/span&gt; &lt;span class="n"&gt;Deck&lt;/span&gt;
&lt;span class="mi"&gt;335&lt;/span&gt;                &lt;span class="n"&gt;Another&lt;/span&gt; &lt;span class="n"&gt;Title&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;Japanese&lt;/span&gt; &lt;span class="n"&gt;Skater&lt;/span&gt;
&lt;span class="mi"&gt;415&lt;/span&gt;    &lt;span class="n"&gt;After&lt;/span&gt; &lt;span class="mi"&gt;45&lt;/span&gt; &lt;span class="n"&gt;Years&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Freedom&lt;/span&gt; &lt;span class="n"&gt;Salted&lt;/span&gt; &lt;span class="n"&gt;With&lt;/span&gt; &lt;span class="n"&gt;Hindsight&lt;/span&gt;
&lt;span class="mi"&gt;421&lt;/span&gt;                   &lt;span class="n"&gt;Interpreting&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="n"&gt;Rite&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="n"&gt;Parts&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This clustering method works pretty well for establishing topics, but we need to label them by hand.  Also the number of times we run it we get different results.&lt;/p&gt;
&lt;p&gt;We also do not know the correct number of clusters.  Above we have 20 clusters that seem well defined.  Below we have 3 clusters that also seem well defined.   This is where we get into art and not science.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;num_clust = 3
clus = KMeans(num_clust)
clus.fit(tfidf)
for i in range(num_clust):
    print &amp;quot;&amp;quot;
    print &amp;quot;Cluster: &amp;quot; + str(i)
    temp = np.zeros(clus.cluster_centers_[i].shape)
    temp[np.argsort(clus.cluster_centers_[i])[-15:]] = 1
    temp = temp/np.linalg.norm(temp)
    print &amp;quot;top 10 words&amp;quot;
    print vectorizer.inverse_transform(temp)[0]
    print &amp;quot;top 5 headlines&amp;quot;
    print df.headline[clus.labels_==i][:5]


Cluster: 0
top 10 words
[u&amp;#39;chemic&amp;#39; u&amp;#39;iran&amp;#39; u&amp;#39;iranian&amp;#39; u&amp;#39;israel&amp;#39; u&amp;#39;mr&amp;#39; u&amp;#39;nation&amp;#39; u&amp;#39;nuclear&amp;#39; u&amp;#39;obama&amp;#39;
 u&amp;#39;presid&amp;#39; u&amp;#39;rouhani&amp;#39; u&amp;#39;said&amp;#39; u&amp;#39;syria&amp;#39; u&amp;#39;syrian&amp;#39; u&amp;#39;unit&amp;#39; u&amp;#39;weapon&amp;#39;]
top 5 headlines
20                Iran’s President Responds to Netanyahu
42      Missed Opportunity in Syria Haunts U.N. Official
96     Citing Efforts to Prevent Attack on Syria, Gro...
149               Iran Staggers as Sanctions Hit Economy
209    Invoking Sept. 11, Syrian Accuses U.S. of Hypo...
Name: headline, dtype: object

Cluster: 1
top 10 words
[u&amp;#39;0&amp;#39; u&amp;#39;1&amp;#39; u&amp;#39;game&amp;#39; u&amp;#39;leagu&amp;#39; u&amp;#39;n&amp;#39; u&amp;#39;play&amp;#39; u&amp;#39;player&amp;#39; u&amp;#39;rivera&amp;#39; u&amp;#39;run&amp;#39; u&amp;#39;said&amp;#39;
 u&amp;#39;season&amp;#39; u&amp;#39;team&amp;#39; u&amp;#39;win&amp;#39; u&amp;#39;yanke&amp;#39; u&amp;#39;yard&amp;#39;]
top 5 headlines
0     Week 5 Probabilities: Why Offense Is More Impo...
6               Bayern Munich Dominates Manchester City
8                      Brodeur’s Starting Streak to End
10          Whitney Winner Out of Breeders’ Cup Classic
21    Finally Secure in the Desert, the Coyotes Devo...
Name: headline, dtype: object

Cluster: 2
top 10 words
[u&amp;#39;compani&amp;#39; u&amp;#39;govern&amp;#39; u&amp;#39;hous&amp;#39; u&amp;#39;like&amp;#39; u&amp;#39;mr&amp;#39; u&amp;#39;ms&amp;#39; u&amp;#39;new&amp;#39; u&amp;#39;parti&amp;#39; u&amp;#39;peopl&amp;#39;
 u&amp;#39;percent&amp;#39; u&amp;#39;republican&amp;#39; u&amp;#39;said&amp;#39; u&amp;#39;state&amp;#39; u&amp;#39;work&amp;#39; u&amp;#39;year&amp;#39;]
top 5 headlines
1                     New Immigration Bill Put Forward
2    Arizona: Judge Orders Monitor to Oversee Maric...
3    Texas: State Bought Execution Drugs From a Com...
4                        Nadal on Track for No. 1 Spot
5                Judge Halts Work on World Cup Stadium
Name: headline, dtype: object
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Hierarchical Clustering&lt;/h2&gt;
&lt;p&gt;We have been working with kmean's clustering, that relies heavily on a distance metric.  This is a general problem in machine linearing.   We have seen the importance of picking the right metric for the right problem.   The number of clusters, however, has been a variable that we do not need to pick.  Hierarchical Clustering is a method of clustering that breaks the data into subgroups, then subgroups into smaller subgroups, once a metric is determined.   In there no apriori reason to pick a cluster size. &lt;/p&gt;
&lt;p&gt;We are going to do this on the Time's data.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;articles&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;section&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;section_name&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;()[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;section&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;section_name&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;section&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;articles&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;section_name&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;section&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;articles&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;vectorizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TfidfVectorizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tokenize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;stop_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;strip_accents&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;unicode&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tfidf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vectorizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;articles&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tfidf&lt;/span&gt;

&lt;span class="n"&gt;Sports&lt;/span&gt; &lt;span class="mi"&gt;340&lt;/span&gt;
&lt;span class="n"&gt;U&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;S&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="mi"&gt;190&lt;/span&gt;
&lt;span class="n"&gt;Business&lt;/span&gt; &lt;span class="n"&gt;Day&lt;/span&gt; &lt;span class="mi"&gt;209&lt;/span&gt;
&lt;span class="n"&gt;World&lt;/span&gt; &lt;span class="mi"&gt;260&lt;/span&gt;
&lt;span class="n"&gt;Opinion&lt;/span&gt; &lt;span class="mi"&gt;224&lt;/span&gt;
&lt;span class="mi"&gt;100&lt;/span&gt;





&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="n"&gt;x5488&lt;/span&gt; &lt;span class="n"&gt;sparse&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;lt;type &amp;#39;&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float64&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&amp;gt;&amp;#39;&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="mi"&gt;15919&lt;/span&gt; &lt;span class="n"&gt;stored&lt;/span&gt; &lt;span class="n"&gt;elements&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;Compressed&lt;/span&gt; &lt;span class="n"&gt;Sparse&lt;/span&gt; &lt;span class="n"&gt;Row&lt;/span&gt; &lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;




&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy.cluster.hierarchy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;dendrogram&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy.cluster.hierarchy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;linkage&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy.spatial.distance&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pdist&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy.spatial.distance&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;squareform&lt;/span&gt;

&lt;span class="n"&gt;distances&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;squareform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;todense&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
&lt;span class="n"&gt;linkage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;distances&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gca&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;R&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dendrogram&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;linkage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;distances&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;truncate_mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;level&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;leaf_label_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;headline&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ascii&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ignore&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; 
                   &lt;span class="s"&gt;&amp;quot; |||| &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;section_name&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ascii&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ignore&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
               &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;orientation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;left&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;leaf_font_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;no_plot&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;1.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW05D4/output_24_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy.cluster.hierarchy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;dendrogram&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy.cluster.hierarchy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;linkage&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy.spatial.distance&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pdist&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy.spatial.distance&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;squareform&lt;/span&gt;

&lt;span class="n"&gt;distances&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;squareform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;todense&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
&lt;span class="n"&gt;linkage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;distances&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gca&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;R&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dendrogram&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;linkage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;distances&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;truncate_mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;level&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;leaf_label_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;section_name&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;orientation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;left&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;leaf_font_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;no_plot&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;1.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW05D4/output_25_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;distances = squareform(pdist(tfidf.todense(),metric=&amp;#39;cosine&amp;#39;))
linkage(distances)
plt.figure(figsize=(14,20))
ax = plt.gca()
R = dendrogram(linkage(distances),p=25,truncate_mode=&amp;#39;level&amp;#39;,
               leaf_label_func=lambda x: df[df.index==x].section_name.values + &amp;quot; - &amp;quot; + df[df.index==x].headline.values,
               ax=ax,
               orientation=&amp;#39;left&amp;#39;,
               leaf_font_size=20,
               no_plot=False)

plt.xlim([0.4,1.45])
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW05D4/output_26_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;distances = squareform(pdist(tfidf.todense(),metric=&amp;#39;braycurtis&amp;#39;))
linkage(distances)
plt.figure(figsize=(14,20))
ax = plt.gca()
R = dendrogram(linkage(distances),p=25,truncate_mode=&amp;#39;level&amp;#39;,
               leaf_label_func=lambda x: df[df.index==x].section_name.values + &amp;quot; - &amp;quot; + df[df.index==x].headline.values,
               ax=ax,
               orientation=&amp;#39;left&amp;#39;,
               leaf_font_size=20,
               no_plot=False)

plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW05D4/output_27_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;distances = squareform(pdist(tfidf.todense(),metric=&amp;#39;hamming&amp;#39;))
linkage(distances)
plt.figure(figsize=(14,20))
ax = plt.gca()
R = dendrogram(linkage(distances),p=25,truncate_mode=&amp;#39;level&amp;#39;,
               leaf_label_func=lambda x: df[df.index==x].section_name.values + &amp;quot; - &amp;quot; + df[df.index==x].headline.values,
               ax=ax,
               orientation=&amp;#39;left&amp;#39;,
               leaf_font_size=20,
               no_plot=False)

plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW05D4/output_28_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We can see immediately that the metric changes the results of the clustering.  We can use the linkage to cluster articles together because it lists the index of each cluster, as well as the distance between clusteres.   It is a different, and computationally more expensive, way to do clustering.&lt;/p&gt;
&lt;p&gt;We can also take the transpose of the tfidf matrix to do clustering by words.  To do this we will remake the tfidf matrix and limit the number of words.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;vectorizer = TfidfVectorizer(tokenizer=tokenize,stop_words=&amp;#39;english&amp;#39;,strip_accents=&amp;#39;unicode&amp;#39;,min_df=0.2,max_features=1000)
tfidf = vectorizer.fit_transform(df.content.values)


vocab = dict()
for k,v in vectorizer.vocabulary_.iteritems():
    vocab[v]=k


distances = squareform(pdist(tfidf.todense().T,metric=&amp;#39;cosine&amp;#39;))
plt.figure(figsize=(14,20))
ax = plt.gca()
R = dendrogram(linkage(distances),p=100,truncate_mode=&amp;#39;level&amp;#39;,
               leaf_label_func=lambda x: vocab[int(x)] if x in vocab else x,
               ax=ax,
               orientation=&amp;#39;left&amp;#39;,
               #leaf_rotation=90,
               leaf_font_size=8,
               no_plot=False)


plt.xlim([0.6,1.2])
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW05D4/output_32_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;There are some interesting connections.   "State", "nation", and "president" are cluster together.   So is "game" and "season". We limited this to a reasonable number of words, but there are clear word clusters in the corpus.&lt;/p&gt;
&lt;p&gt;Since the day is now over - and tomorrow is the 4th of July Holiday.  I'm off!&lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="nlp"></category><category term="clustering"></category><category term="kmeans clustering"></category><category term="hierachrical cluster"></category><category term=""></category></entry><entry><title>Galvanize - Week 05 - Day 3</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-05-03/" rel="alternate"></link><updated>2015-07-01T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-07-01:galvanize/galvanize-data-science-05-03/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 5 - Day 3&lt;/h2&gt;
&lt;p&gt;Today we covered natural language processing and and NaiveBayes methods of machine learning.   We were introduced to the NLTK package of python, and the sklearn text processing packagages.&lt;/p&gt;
&lt;h2&gt;Yelp&lt;/h2&gt;
&lt;p&gt;We started of with a daily quiz, per usual.   We were suppose to signup for the Yelp! API and find out how many gastropubs are in San Francisco.  &lt;/p&gt;
&lt;p&gt;Looking at the Yelp! API I see there is a 'category_filter' term and one of the valid inputs is 'gastropubs'.   &lt;/p&gt;
&lt;p&gt;Yelp, unlike any service we used before, requires oAuth.   This was the most difficult part of the quiz for me.  Not difficult in hard, but in that I had zero experience and it was a tall order to get it figured out in a short time.  One convoluting factor was that Yelp! gives you your tokens and keys, but they do not work for the first 10 minutes if you have a new account.   Once I refreshed them, everything worked beautifully&lt;/p&gt;
&lt;p&gt;Today is my first day attending Galvanize's Immersive Data Science Program in San Francisco, CA.   The program is a 12 week program that is approximately 10 hours a day of learning and activities to reinforce and refine the learning.   I am very excited to be a part of this program.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;urllib2&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;oauth2&lt;/span&gt;


&lt;span class="n"&gt;url_params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;category_filter&amp;#39;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;gastropubs&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;location&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;San Francisco&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;http://api.yelp.com/v2/search/?&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;consumer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Consumer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;CONSUMER_KEY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;CONSUMER_SECRET&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;oauth_request&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;GET&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;parameters&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;url_params&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;oauth_request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s"&gt;&amp;#39;oauth_nonce&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;generate_nonce&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
        &lt;span class="s"&gt;&amp;#39;oauth_timestamp&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;generate_timestamp&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
        &lt;span class="s"&gt;&amp;#39;oauth_token&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;TOKEN&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s"&gt;&amp;#39;oauth_consumer_key&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;CONSUMER_KEY&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Token&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TOKEN&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;TOKEN_SECRET&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;oauth_request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sign_request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SignatureMethod_HMAC_SHA1&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;consumer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;signed_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;oauth_request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_url&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;conn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;signed_url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;total&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;businesses&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="k"&gt;finally&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The YELP! API limits you to twenty detailed responses, but it does let you know that there are 48 Businesses in San Francisco listed in the gastropub category.&lt;/p&gt;
&lt;h2&gt;Natural Language Processing&lt;/h2&gt;
&lt;p&gt;The goal of today's morning sprint is to use a subset of New York Times articles and attempt to find related articles.   We are also starting out by going through the process ourselves, then using sklearn's packages for processing text.&lt;/p&gt;
&lt;p&gt;First we will need to pull articles from the database.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pymongo&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;MongoClient&lt;/span&gt;
&lt;span class="n"&gt;client&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MongoClient&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;db&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;client&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nyt_dump&lt;/span&gt;
&lt;span class="n"&gt;coll&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;articles&lt;/span&gt;
&lt;span class="n"&gt;docs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coll&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;()):&lt;/span&gt;
    &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;utf8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;replace&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;utf8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;docs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;section_name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;docs&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="mi"&gt;984&lt;/span&gt; &lt;span class="mi"&gt;984&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Of the 999 documents that are in our subset, a few are empty of text.  The web scraper must not have found the text when pulling it from the ny times.   We will drop these words from our corpus.  &lt;/p&gt;
&lt;p&gt;For our purpose we have going to take the words in the NY Times articles and lemmatize them, then stem them.   The lemmatize them will take words that are in difference contexts but have similar meaning to a signular word.  The stemmmer will remove other 'decorative' aspect of the word to capture just the word.   &lt;/p&gt;
&lt;p&gt;The reason I am lemmatize this is that NY times is documented of having one of the highest vocabularities online, which means that there will be a pleathor of word choice for similar ideas.   If we want to capture related articles, then we will need to attempt to captures words that are similar.&lt;/p&gt;
&lt;p&gt;We also removed the common english stopwords.  Because of the unicode characters, I will be using a regular expression tokenizer.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;word_tokenize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;wordpunct_tokenize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;RegexpTokenizer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;stopwords&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.stem.porter&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;PorterStemmer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.stem.snowball&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SnowballStemmer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.stem.wordnet&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;WordNetLemmatizer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Text&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;re&lt;/span&gt;

&lt;span class="n"&gt;sw&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stopwords&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;porter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PorterStemmer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;snowball&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SnowballStemmer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;wordnet&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;WordNetLemmatizer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;reg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RegexpTokenizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;r&amp;#39;\w+&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;flags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;UNICODE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;stemmer_words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;doc_tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;docs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;reg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sw&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;l&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;wordnet&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lemmatize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;snowball&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stem&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;stemmer_words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;porter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stem&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;snowball&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stem&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;wordnet&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lemmatize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;snowball&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stem&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;wordnet&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lemmatize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;))])&lt;/span&gt;
            &lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;      
    &lt;span class="n"&gt;doc_tokens&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you inspect the above code you noticed that I make a list of each word and the results of the different stemmers.  We can see for a random selection of 20 words that the the stemming all lead to the same outcome.   The lemmatizer gave different results, but once that result was fed to the stemmer it was identical.   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;stemmer_words&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stemmer_words&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;

&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;fashion&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;fashion&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;fashion&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;fashion&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;mr&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;mr&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;mr&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;mr&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;could&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;could&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;could&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;could&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;u&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;u&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;u&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;u&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;3&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;3&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;3&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;3&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;day&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;day&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;day&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;day&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;flagship&lt;/span&gt;&lt;span class="se"&gt;\xe2&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;flagship&lt;/span&gt;&lt;span class="se"&gt;\xe2&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;flagship&lt;/span&gt;&lt;span class="se"&gt;\xe2&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;flagship&lt;/span&gt;&lt;span class="se"&gt;\xe2&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;germani&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;germani&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;germany&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;germani&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;bleak&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;bleak&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;bleak&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;bleak&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;one&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;one&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;one&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;one&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;would&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;would&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;would&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;would&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;make&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;make&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;making&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;make&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;point&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;point&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;point&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;point&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;also&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;also&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;also&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;also&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;spi&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;spi&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;spy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;spi&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;sergeant&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;sergeant&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;sergeant&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;sergeant&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;divorc&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;divorc&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;divorced&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;divorc&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;deni&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;deni&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;denied&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;deni&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;don&lt;/span&gt;&lt;span class="se"&gt;\xe2&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;don&lt;/span&gt;&lt;span class="se"&gt;\xe2&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;don&lt;/span&gt;&lt;span class="se"&gt;\xe2&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;don&lt;/span&gt;&lt;span class="se"&gt;\xe2&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;battl&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;battl&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;battle&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;battl&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Bag of Words&lt;/h2&gt;
&lt;p&gt;Now that we have stemmed all the words in our document, we likely have duplicates.  We want to get a vocabulary of our corpus, the 984 new york times articles.   We can do this with a simple list comprehension to flatten the list, perform a set operation, then turn it back into a list.  I will sort it just because.&lt;/p&gt;
&lt;p&gt;Because we will be cycling through this list, it will be able to look up the location of a particlar word.  We will also make a dictionary of each word and its index in the list.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;bag = [item for row in doc_tokens for item in row]
bag = set(bag)
bag = sorted(list(bag))

bag_dict = dict()
for i,word in enumerate(bag):
    bag_dict[word] = i

print len(bag),len(bag_dict)

26505 26505
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The next step in finding similarity between documents is finding the frequency of each word in each document.   For our purposes, each document has a potential of having some number of the 26505 words in our bag, and we have 984 documents.   That means we need a matrix that has a shape of (984,26505)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;#make word frequency
word_freq = np.zeros((len(doc_tokens),len(bag_dict)))

#iterate through each doc
for i, tokens in enumerate(doc_tokens):
    #iterate through the word tokens of the doc
    for token in tokens:
        #us the lookup dictionary and add one to that word position
        word_freq[i,bag_dict[token]] +=1
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now that we have the word frequency, we need a way to find if this is a relevant similarity between two documents.  If a word is popular in all documents, then it is not particularly special.  If a word is only freqnency in a 2 or 3 docs, there is an increased likelihood that they are related.&lt;/p&gt;
&lt;p&gt;Unlike the word frequency, the document frequency does not care how many times the word appears in the document.  It is a boolean measure.   Either 'USS' appears in the document or not.  It does not mater that it apears 10 times in an article about a naval yard.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;#Convert the word frequency to a bool, then an int.  Sum along the documents.
#Use the sum along the documents to identify how many documents the word apears in
#Divide by the number of documents to get the document frequency for each word
doc_freq = np.sum((word_freq&amp;gt;0).astype(int),axis=0).astype(float)/word_freq.shape[0]
doc_freq.shape




(26505,)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;One problem we have at the moment is that we have word frequencies, but articles have different length.  They also have a different number of words.   Two articles on the same topic many have different lengths, thus different word counts.  The relative frequency is not necessarily similary, but if you just copied and pasted the same document it should also not be different.  To address this we need to normalize the rows in our word freqency matrix.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;#calculate the row norms
row_norms = np.linalg.norm(word_freq,axis=1)
#if we have empty documents we need this line (but we dont!)
row_norms[row_norms==0] = 1
#reshape so that we can use broadcast division in numpy
row_norms = row_norms.reshape(row_norms.shape[0],1)
#have a row normalized row frequency
norm_word_freq = word_freq/row_norms
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The final feature vector we are constructing is the tf-idf vector that is the product of the normalized term frequency times the log of one over the document frquency of the term.   This operation changes the scale of the vector, so they must be renormalized after.   &lt;/p&gt;
&lt;p&gt;There are theoretical reason for the log, but I honestly have not understood them yet.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;#make tfidf vector
tfidf = norm_word_freq*np.log(1/doc_freq)
#find norms of each row
tfidf_norms = np.linalg.norm(tfidf,axis=1)
#needs this line for empty documents
tfidf_norms[tfidf_norms==0] = 1
#reshape for numpy broadcast division
tfidf_norms = tfidf_norms.reshape(tfidf_norms.shape[0],1)
#normlize tfidf
norm_tfidf = tfidf/tfidf_norms
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now that we have these tfidf vectors, we can find document vectors that are similar to each other.   Similarity in a normalized vector space is similarity in direction.  This is known as cosign similarity.&lt;/p&gt;
&lt;p&gt;I am going to cycle through the 984x984 similarity calculations of similarity by the linear_kernel function of sklearn.   If the vectors are less than 30 degrees appart in this word-vector space, I will find the second most similar article.   I skip the first most because that will be its self.   They will have a similarity of 1.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="s-Atom"&gt;from&lt;/span&gt; &lt;span class="s-Atom"&gt;sklearn&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;metrics&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;pairwise&lt;/span&gt; &lt;span class="s-Atom"&gt;import&lt;/span&gt; &lt;span class="s-Atom"&gt;linear_kernel&lt;/span&gt;
&lt;span class="s-Atom"&gt;cosine_similarities&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;linear_kernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;norm_tfidf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;norm_tfidf&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;row&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="nf"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;cosine_similarities&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
    &lt;span class="s-Atom"&gt;if&lt;/span&gt; &lt;span class="s-Atom"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;row&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="s-Atom"&gt;::-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mf"&gt;0.707&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
        &lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;row&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="s-Atom"&gt;::-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="mi"&gt;158&lt;/span&gt;
&lt;span class="mi"&gt;113&lt;/span&gt; &lt;span class="mi"&gt;712&lt;/span&gt;
&lt;span class="mi"&gt;158&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;
&lt;span class="mi"&gt;174&lt;/span&gt; &lt;span class="mi"&gt;521&lt;/span&gt;
&lt;span class="mi"&gt;187&lt;/span&gt; &lt;span class="mi"&gt;960&lt;/span&gt;
&lt;span class="mi"&gt;240&lt;/span&gt; &lt;span class="mi"&gt;251&lt;/span&gt;
&lt;span class="mi"&gt;251&lt;/span&gt; &lt;span class="mi"&gt;251&lt;/span&gt;
&lt;span class="mi"&gt;260&lt;/span&gt; &lt;span class="mi"&gt;425&lt;/span&gt;
&lt;span class="mi"&gt;289&lt;/span&gt; &lt;span class="mi"&gt;474&lt;/span&gt;
&lt;span class="mi"&gt;335&lt;/span&gt; &lt;span class="mi"&gt;372&lt;/span&gt;
&lt;span class="mi"&gt;372&lt;/span&gt; &lt;span class="mi"&gt;372&lt;/span&gt;
&lt;span class="mi"&gt;425&lt;/span&gt; &lt;span class="mi"&gt;260&lt;/span&gt;
&lt;span class="mi"&gt;431&lt;/span&gt; &lt;span class="mi"&gt;810&lt;/span&gt;
&lt;span class="mi"&gt;439&lt;/span&gt; &lt;span class="mi"&gt;615&lt;/span&gt;
&lt;span class="mi"&gt;444&lt;/span&gt; &lt;span class="mi"&gt;445&lt;/span&gt;
&lt;span class="mi"&gt;445&lt;/span&gt; &lt;span class="mi"&gt;444&lt;/span&gt;
&lt;span class="mi"&gt;463&lt;/span&gt; &lt;span class="mi"&gt;700&lt;/span&gt;
&lt;span class="mi"&gt;474&lt;/span&gt; &lt;span class="mi"&gt;289&lt;/span&gt;
&lt;span class="mi"&gt;508&lt;/span&gt; &lt;span class="mi"&gt;508&lt;/span&gt;
&lt;span class="mi"&gt;509&lt;/span&gt; &lt;span class="mi"&gt;508&lt;/span&gt;
&lt;span class="mi"&gt;521&lt;/span&gt; &lt;span class="mi"&gt;174&lt;/span&gt;
&lt;span class="mi"&gt;615&lt;/span&gt; &lt;span class="mi"&gt;439&lt;/span&gt;
&lt;span class="mi"&gt;700&lt;/span&gt; &lt;span class="mi"&gt;463&lt;/span&gt;
&lt;span class="mi"&gt;710&lt;/span&gt; &lt;span class="mi"&gt;756&lt;/span&gt;
&lt;span class="mi"&gt;712&lt;/span&gt; &lt;span class="mi"&gt;920&lt;/span&gt;
&lt;span class="mi"&gt;756&lt;/span&gt; &lt;span class="mi"&gt;710&lt;/span&gt;
&lt;span class="mi"&gt;767&lt;/span&gt; &lt;span class="mi"&gt;767&lt;/span&gt;
&lt;span class="mi"&gt;768&lt;/span&gt; &lt;span class="mi"&gt;767&lt;/span&gt;
&lt;span class="mi"&gt;810&lt;/span&gt; &lt;span class="mi"&gt;431&lt;/span&gt;
&lt;span class="mi"&gt;919&lt;/span&gt; &lt;span class="mi"&gt;756&lt;/span&gt;
&lt;span class="mi"&gt;920&lt;/span&gt; &lt;span class="mi"&gt;712&lt;/span&gt;
&lt;span class="mi"&gt;939&lt;/span&gt; &lt;span class="mi"&gt;956&lt;/span&gt;
&lt;span class="mi"&gt;956&lt;/span&gt; &lt;span class="mi"&gt;939&lt;/span&gt;
&lt;span class="mi"&gt;960&lt;/span&gt; &lt;span class="mi"&gt;187&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;We have a match&lt;/h2&gt;
&lt;p&gt;We can see that document 7 and 158 should be similar to each other.  I will print them out.  &lt;/p&gt;
&lt;p&gt;As you read through them you will find that they are two different articles on the same story about crashed cruise ship, both writen by the same author.   That is awesome that it found this.    &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;print docs[7]

giglio, italy â after a costly, painstaking and potentially perilous operation to raise the battered hull of the cruise ship costa concordia, engineers said early tuesday that they had succeeded in righting the ship, removing it from two granite reefs where it ran aground last year, killing 32 people.


the 19-hour, highly complicated salvage operation had managed to completely rotate the ship, leaning it on an underwater platform built underneath, the engineers said.        
âthis was an important, visible step,â franco gabrielli, head of italyâs civil protection agency, told reporters at 4 a.m., accompanied by applause from a few residents who had stayed up all night to follow the operation.        
âthe rotation happened in the way we thought and hoped it would happen,â echoed franco porcellacchia, project manager for costa cruises, the shipâs operator. âthere is no evidence so far of any impact to the environment. if there are debris to be removed, we will do it tomorrow.â        
as parts of the vessel emerged in the later afternoon on monday, discolored and rusting, from the waters where the concordia had languished, listing on its side, engineers said the operation would most likely take longer than initially planned.        
salvage experts have said the dimensions of the stricken 951-foot vessel made the operation unparalleled in the annals of marine salvage, as more than 500 divers, technicians, engineers and biologists prepared the ship for what is known as âparbucklingâ to bring it upright and minimize environmental risks to giglio island, a marine sanctuary.        
using huge jacks, cables, pulleys and specialized equipment, the salvage effort had been set to begin at first light, but a sudden storm prevented workers from moving a barge and rubber booms close to the ship.        
three hours after work started, engineers said the first phase of the operation â easing the vessel away from its rocky perch â was going according to plan. âthese hours were the most uncertain, as we could not establish how much the hull was wedged,â said sergio girotto, project manager with micoperi, the projectâs underwater construction and offshore contractor. ânow we have to guide it into the desired position.â        
the next phase of the salvage, engineers said, involved settling the wreck on an artificial seabed made of bags of cement next to underwater steel platforms. to achieve that, the cruise liner needed to be rotated about 65 degrees, they said. if it all goes well, the ship will be towed away and broken up for scrap by spring.        
the operation was broadcast live on television and the internet. the italian news media portrayed the salvage as a chance for italy to revamp its image after the wreck, in which the captain fled the damaged ship and the evacuation was chaotic.        
the leading national daily, corriere della sera, called the shipwreck âa monument to human stupidityâ and a âhumiliationâ for italy. it said it hoped that the salvage effort would provide a ânew and different storyâ for the country.        
the shipâs captain, francesco schettino, is scheduled to go on trial this fall on charges of multiple manslaughter, causing a shipwreck and abandoning â the vessel before everyone was safe. he has denied wrongdoing. a company official and four crew members have already pleaded guilty to reduced charges.        
preparations for the salvage operation took 14 months, and the cost has increased to $799 million from $300 million and could rise further, according to costa cruises. the costa concordia has been stabilized with anchors and cement bags, and underwater platforms have been built on the port side. salvage crews used pulleys, strand jacks and steel cables placed on nine caissons attached to the left side of the ship to slowly dislodge it on monday from the two rocks where it had been resting.        
the operation was monitored by engineers and remotely operated vehicle pilots from a control room on a barge close to the bow of the ship. if images or sonar showed dangerous twisting, the technicians could adjust the process. at a command center onshore, engineers could intervene if the ship did not rotate, or did not rotate properly.        
salvage masters and the italian authorities had prepared for complications. most of the fuel was siphoned off within months of the wreck. but the vessel that once transported and entertained 4,229 people still contains chemicals and diesel fuel that could leak into the pristine waters for which giglio, a popular tourist spot, is known.        
during the rotation process, the regionâs environmental agency took samples to monitor water quality.        
âdetaching the ship from the rocks was the most complicated phase, which is probably why they decided to do it very cautiously,â said emilio campana, the director of the research office for naval and maritime engineering at italyâs national research council. âwe have to keep in mind that the structure is heavily damaged, and see if and how it holds together from now on.â




gaia pianigiani reported from giglio, and alan cowell from london.



print docs[158]

giglio, italy â salvage workers righted the scarred and discolored hull of the cruise ship costa concordia early tuesday after coaxing it from two granite reefs it ran aground on just off this tiny tourist island 20 months ago, killing 32 people.


as the vast hull slowly emerged during the complex, 19-hour salvage operation, the full extent of damage to the vessel became apparent. it looked as if a giant fist had driven into the shipâs flank.        
shipsâ horns blared over giglioâs tiny port to celebrate the moment, and some of the islandâs 1,500 residents hugged salvage workers as they came ashore from what is likely to be seen as a bold step toward redressing some of italyâs anguish after the costa concordia, the length of three football fields, careened into the reefs on a wintry night in january 2012.        
âthis was an important, visible step,â franco gabrielli, head of italyâs civil protection agency, told reporters at 4 a.m., accompanied by applause from a few residents who had stayed up all night to follow the operation.        
he was echoed by franco porcellacchia, project manager for costa cruises, the shipâs operator. âthere is no evidence so far of any impact to the environment,â he said. âif there are debris to be removed, we will do it tomorrow.â        
on tuesday morning, at a crowded news conference on giglio port, italian officials seemed almost surprised by how precisely their calculations had worked, but expressed caution about future steps to secure the vessel before it can be towed away and scrapped, probably in the spring. âthe phases to come will be just as complicated,â mr. porcellacchia said.        
nick sloane, the salvage master, said the operation exceeded his expectations. âit was nice to see that at 4 a.m.,â he told reporters tuesday afternoon.        
mr. sloane explained that a full survey of the damage, which he called substantial, would be possible only after italian authorities carried out their inspections and searched for the bodies of two people aboard the ship who are still missing.        
the operation left the 951-foot ship resting on an artificial platform 90 feet below the surface, with only about a third of its once-sleek white lines visible above water. engineers said the badly damaged starboard side would need to be welded and reinforced, so that other steel chambers, known as caissons and crucial to the operation to right the ship, can be attached. the vessel will also need to be further secured to withstand winter weather, engineers said.        
âwe will consider the operation concluded once the ship leaves giglio island,â mr. gabrielli told reporters, acknowledging that risks remained while the wreck was at sea. âweâll carry out all the needed interventions to mitigate it and allow the ship to face the next winter in secure conditions,â he said.        
mr. sloane said he could hear workers jumping around with relief and delight as the ship was gently laid on the platform. âit was like a roller coaster,â he said.        
the righting of the vessel did not draw universal applause.        
âi donât necessarily think that this is a great victory for italy, maybe for the italian and american companies involved,â said suzanne kmetyko, 50, a tourist from austria who has visited the island for the past seven years.        
âand the real success for the island will come only once people around the world will stop remembering it for the shipwreck rather than for its natural beauty,â she said. âa long way to go.â        
italian news media, by contrast, portrayed the salvage, broadcast live on television and the internet, as a chance for the country to revamp its image after the wreck, in which the captain fled the damaged ship and the evacuation was chaotic. the leading national daily, corriere della sera, called the shipwreck âa monument to human stupidityâ and a âhumiliationâ for italy. it said it hoped that the salvage effort would provide a ânew and different storyâ for the country.        
it was not always clear what that story would be.        
as parts of the concordia emerged in the late afternoon on monday, stained and rusting, from the waters where the vessel had languished, engineers had said the operation would most likely take longer than initially planned.        
the sheer size of the concordia had created what salvage specialists called unparalleled challenges not only to right the ship but also to protect giglio island, a marine sanctuary, from environmental hazard.        
salvage workers used huge jacks, cables, pulleys and specialized equipment, first to ease the vessel off its rocky perch and then to right it. the first few hours âwere the most uncertain, as we could not establish how much the hull was wedged,â sergio girotto, project manager with micoperi, the projectâs underwater construction and offshore contractor, said on monday.        
the shipâs captain, francesco schettino, is scheduled to go on trial this fall on charges of multiple manslaughter, causing a shipwreck and abandoning the vessel before everyone was safe. he has denied wrongdoing. a company official and four crew members have already pleaded guilty to reduced charges.        
salvage masters and the italian authorities had prepared for complications. most of the fuel was siphoned off within months of the wreck. but the vessel that once transported and entertained 4,229 people still contains chemicals and diesel fuel that could leak into the pristine mediterranean waters for which giglio, a popular tourist spot, is known.




gaia pianigiani reported from giglio, and alan cowell from london.
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Sklearn&lt;/h2&gt;
&lt;p&gt;In this section I will redo the procedure we did above using sklearn's methods.   To get similar results, I have to use the same tokenizer I used above.   Sklearn makes that relatively easy.  I just need to defien it and pass it into the constructor of the text processing object I am using.  I am going to include the sklearn stopwords the strip unicode.  This will lead to a slightly smaller word-matrix than in the previous part. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.feature_extraction.text&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;CountVectorizer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;TfidfVectorizer&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;    INPUT: string&lt;/span&gt;
&lt;span class="sd"&gt;    OUTPUT: list of strings&lt;/span&gt;

&lt;span class="sd"&gt;    Tokenize and stem/lemmatize the document.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;sw&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stopwords&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;snowball&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SnowballStemmer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;wordnet&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;WordNetLemmatizer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;reg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RegexpTokenizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;r&amp;#39;\w+&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;flags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;UNICODE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;doc_tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;reg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sw&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;l&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;wordnet&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lemmatize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;snowball&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stem&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;doc_tokens&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;    
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;doc_tokens&lt;/span&gt;

&lt;span class="n"&gt;vect&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CountVectorizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stop_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tokenize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;strip_accents&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;unicode&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;word_counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vect&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;docs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;word_counts&lt;/span&gt;




&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;984&lt;/span&gt;&lt;span class="n"&gt;x26280&lt;/span&gt; &lt;span class="n"&gt;sparse&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;lt;type &amp;#39;&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&amp;gt;&amp;#39;&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="mi"&gt;220702&lt;/span&gt; &lt;span class="n"&gt;stored&lt;/span&gt; &lt;span class="n"&gt;elements&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;Compressed&lt;/span&gt; &lt;span class="n"&gt;Sparse&lt;/span&gt; &lt;span class="n"&gt;Row&lt;/span&gt; &lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We do not need construct the wordcount, however, to get the tfidf.  Sklearn can construct it directly.  When can then do the same calculation and find the most related documents by the measure of cosign similarity.   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="s-Atom"&gt;from&lt;/span&gt; &lt;span class="s-Atom"&gt;sklearn&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;feature_extraction&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;text&lt;/span&gt; &lt;span class="s-Atom"&gt;import&lt;/span&gt; &lt;span class="nv"&gt;TfidfVectorizer&lt;/span&gt;
&lt;span class="s-Atom"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;TfidfVectorizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s-Atom"&gt;tokenize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;strip_accents=&amp;#39;unicode&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;stop_words=&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s-Atom"&gt;sp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;results&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;docs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s-Atom"&gt;sp&lt;/span&gt;




&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;984&lt;/span&gt;&lt;span class="s-Atom"&gt;x26280&lt;/span&gt; &lt;span class="s-Atom"&gt;sparse&lt;/span&gt; &lt;span class="s-Atom"&gt;matrix&lt;/span&gt; &lt;span class="s-Atom"&gt;of&lt;/span&gt; &lt;span class="s-Atom"&gt;type&lt;/span&gt; &lt;span class="s-Atom"&gt;&amp;#39;&amp;lt;type &amp;#39;numpy&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;float64&amp;#39;&amp;gt;&amp;#39;&lt;/span&gt;
    &lt;span class="s-Atom"&gt;with&lt;/span&gt; &lt;span class="mi"&gt;220702&lt;/span&gt; &lt;span class="s-Atom"&gt;stored&lt;/span&gt; &lt;span class="s-Atom"&gt;elements&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;Compressed&lt;/span&gt; &lt;span class="nv"&gt;Sparse&lt;/span&gt; &lt;span class="nv"&gt;Row&lt;/span&gt; &lt;span class="s-Atom"&gt;format&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;




&lt;span class="s-Atom"&gt;from&lt;/span&gt; &lt;span class="s-Atom"&gt;sklearn&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;metrics&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;pairwise&lt;/span&gt; &lt;span class="s-Atom"&gt;import&lt;/span&gt; &lt;span class="s-Atom"&gt;linear_kernel&lt;/span&gt;
&lt;span class="s-Atom"&gt;cosine_similarities&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;linear_kernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;sp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;sp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;row&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="nf"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;cosine_similarities&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
    &lt;span class="s-Atom"&gt;if&lt;/span&gt; &lt;span class="s-Atom"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;row&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="s-Atom"&gt;::-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mf"&gt;0.707&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
        &lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;row&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="s-Atom"&gt;::-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="mi"&gt;158&lt;/span&gt;
&lt;span class="mi"&gt;113&lt;/span&gt; &lt;span class="mi"&gt;712&lt;/span&gt;
&lt;span class="mi"&gt;158&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;
&lt;span class="mi"&gt;174&lt;/span&gt; &lt;span class="mi"&gt;521&lt;/span&gt;
&lt;span class="mi"&gt;187&lt;/span&gt; &lt;span class="mi"&gt;960&lt;/span&gt;
&lt;span class="mi"&gt;240&lt;/span&gt; &lt;span class="mi"&gt;251&lt;/span&gt;
&lt;span class="mi"&gt;251&lt;/span&gt; &lt;span class="mi"&gt;251&lt;/span&gt;
&lt;span class="mi"&gt;253&lt;/span&gt; &lt;span class="mi"&gt;563&lt;/span&gt;
&lt;span class="mi"&gt;260&lt;/span&gt; &lt;span class="mi"&gt;425&lt;/span&gt;
&lt;span class="mi"&gt;289&lt;/span&gt; &lt;span class="mi"&gt;474&lt;/span&gt;
&lt;span class="mi"&gt;335&lt;/span&gt; &lt;span class="mi"&gt;372&lt;/span&gt;
&lt;span class="mi"&gt;372&lt;/span&gt; &lt;span class="mi"&gt;372&lt;/span&gt;
&lt;span class="mi"&gt;425&lt;/span&gt; &lt;span class="mi"&gt;260&lt;/span&gt;
&lt;span class="mi"&gt;439&lt;/span&gt; &lt;span class="mi"&gt;615&lt;/span&gt;
&lt;span class="mi"&gt;444&lt;/span&gt; &lt;span class="mi"&gt;445&lt;/span&gt;
&lt;span class="mi"&gt;445&lt;/span&gt; &lt;span class="mi"&gt;444&lt;/span&gt;
&lt;span class="mi"&gt;463&lt;/span&gt; &lt;span class="mi"&gt;700&lt;/span&gt;
&lt;span class="mi"&gt;474&lt;/span&gt; &lt;span class="mi"&gt;289&lt;/span&gt;
&lt;span class="mi"&gt;508&lt;/span&gt; &lt;span class="mi"&gt;509&lt;/span&gt;
&lt;span class="mi"&gt;509&lt;/span&gt; &lt;span class="mi"&gt;509&lt;/span&gt;
&lt;span class="mi"&gt;521&lt;/span&gt; &lt;span class="mi"&gt;174&lt;/span&gt;
&lt;span class="mi"&gt;563&lt;/span&gt; &lt;span class="mi"&gt;253&lt;/span&gt;
&lt;span class="mi"&gt;615&lt;/span&gt; &lt;span class="mi"&gt;439&lt;/span&gt;
&lt;span class="mi"&gt;700&lt;/span&gt; &lt;span class="mi"&gt;463&lt;/span&gt;
&lt;span class="mi"&gt;710&lt;/span&gt; &lt;span class="mi"&gt;756&lt;/span&gt;
&lt;span class="mi"&gt;712&lt;/span&gt; &lt;span class="mi"&gt;920&lt;/span&gt;
&lt;span class="mi"&gt;756&lt;/span&gt; &lt;span class="mi"&gt;710&lt;/span&gt;
&lt;span class="mi"&gt;767&lt;/span&gt; &lt;span class="mi"&gt;767&lt;/span&gt;
&lt;span class="mi"&gt;768&lt;/span&gt; &lt;span class="mi"&gt;767&lt;/span&gt;
&lt;span class="mi"&gt;919&lt;/span&gt; &lt;span class="mi"&gt;756&lt;/span&gt;
&lt;span class="mi"&gt;920&lt;/span&gt; &lt;span class="mi"&gt;712&lt;/span&gt;
&lt;span class="mi"&gt;939&lt;/span&gt; &lt;span class="mi"&gt;956&lt;/span&gt;
&lt;span class="mi"&gt;956&lt;/span&gt; &lt;span class="mi"&gt;939&lt;/span&gt;
&lt;span class="mi"&gt;960&lt;/span&gt; &lt;span class="mi"&gt;187&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Shockingly they produce the same pairs!   That is so cool.   Maybe I should be less surprised than I am, but I think this is cool.   We just made word vector, found vectors pointing in similar directions, and the documents are similar.   Abstractly it makes complete and simple sense.  On an emotional level, this is fracking cool!&lt;/p&gt;
&lt;h2&gt;Part of speech tagging&lt;/h2&gt;
&lt;p&gt;I did not end up pursuing this today because we had to move onto the afternoon assignment, but I am leaving this here as a reminder to go back an explore it.   It is realted to a topic in AI called 'Incremental Concept Learning' that allow an agent to learn concepts.   When I learned it at the time I thought it was a cool concept, but not practical.  Now I see some direct applications.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.tokenize&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;word_tokenize&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pos_tag&lt;/span&gt;
&lt;span class="n"&gt;tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;word_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;docs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;304&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;pos_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;




&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;after&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;IN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;DT&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;costly&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;JJ&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;painstaking&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;VBG&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;and&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;CC&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;potentially&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;RB&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;perilous&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;JJ&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;operation&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;NN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;to&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;TO&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;raise&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;VB&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;the&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;DT&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;battered&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;VBN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;hull&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;NN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;of&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;IN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;the&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;DT&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;cruise&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;NN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;ship&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;NN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;costa&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;NN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;concordia&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;NN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;engineers&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;NNS&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;said&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;VBD&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;early&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;RB&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;tuesday&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;NN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;that&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;IN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;they&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;PRP&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;had&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;VBD&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;succeeded&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;VBN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;in&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;IN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;righting&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;NN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;the&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;DT&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;ship&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;NN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;removing&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;VBG&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;it&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;PRP&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;from&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;IN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;two&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;CD&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;granite&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;JJ&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;reefs&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;NNS&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;where&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;WRB&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;it&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;PRP&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;ran&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;VBD&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;aground&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;NN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;last&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;JJ&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;NN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;killing&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;VBG&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;CD&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;people&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;NNS&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Naive Bayes&lt;/h2&gt;
&lt;p&gt;The afternoon assignment was on Naive Bayes, and its use with text classification.   Our first goal was to implement our own Naive Bayes algorithm, then to use in on a text problem.&lt;/p&gt;
&lt;p&gt;The Naive part of Naive bases is the assumption that all the features are independant of each other.  Bayes Rule states:&lt;/p&gt;
&lt;p&gt;$$P(C|X) = \mbox{Probability of Label C given data X} = \frac{P(X|C) \ P(C)}{P(X)}$$&lt;/p&gt;
&lt;p&gt;The naive assumption of Naive Bayes assumed the data is independant.  This is expressed using the following formula.&lt;/p&gt;
&lt;p&gt;$$P(C|X) = \mbox{Probability of Label C given data X} = \frac{P(x_1|C) \ P(x_2|C) \ ... \ P(x_n|C) \ P(C)}{P(X)}$$&lt;/p&gt;
&lt;p&gt;So given the data, we choose the c with the maximium probability or likely hood.&lt;/p&gt;
&lt;p&gt;$$\mbox{argmax}_c \left[ \ P(C|X) \ \right]  = \mbox{argmax}_c \left[ \  P(C) \ P(x_1|C) \ P(x_2|C) \ ... \ P(x_n|C)  \ \right]$$&lt;/p&gt;
&lt;p&gt;We can ignore the Probability of getting the data X becuase that is independant of the C.  For a host of reason, but mostly floating point limitations, we often calculated the log maximum and solve this equation.&lt;/p&gt;
&lt;p&gt;$$\mbox{argmax}_c \left[ \ logP(C|X) \ \right]  = \mbox{argmax}_c \left[ \ log(P(C)) + \sum_i log(P(x_i|C))  \ \right]$$&lt;/p&gt;
&lt;p&gt;Another limitation is dealing with data/featuers that are zero or missing.  We can not compute the log of zero, so we have to do a smoothing on the probability to allow it to be small, but not zero.  The standard is to perform a Laplace smoothing:&lt;/p&gt;
&lt;p&gt;$$P(x_i|C) = \frac{\sum x_{iC} + \alpha}{\sum X + \alpha \ p}$$&lt;/p&gt;
&lt;p&gt;Where $p$ is the number of features in the dataset and $\alpha$ is a smoothing parameter.   It is commonly chosen to be 1.   This is also assuming we are dealing with count data.   If we are not, then we use a normal distrubtion for the probability.&lt;/p&gt;
&lt;p&gt;Below is my implementation of the NaiveBayes function&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;collections&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;


&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NaiveBayes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;        - alpha: float, laplace smoothing constant&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;class_totals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;class_feature_totals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;class_counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_features&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_trains&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_compute_likelihood&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;        - X: 2d numpy array, feature matrix&lt;/span&gt;
&lt;span class="sd"&gt;        - y: numpy array, labels&lt;/span&gt;

&lt;span class="sd"&gt;        Compute the totals for each class and the totals for each feature&lt;/span&gt;
&lt;span class="sd"&gt;        and class.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_features&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_trains&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;class_totals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;yp&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;class_totals&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;yp&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;yp&lt;/span&gt;&lt;span class="p"&gt;,:])&lt;/span&gt;


        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;class_feature_totals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;yp&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;class_feature_totals&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;yp&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;yp&lt;/span&gt;&lt;span class="p"&gt;,:],&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,:]&lt;/span&gt;


    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;        - X: 2d numpy array, feature matrix&lt;/span&gt;
&lt;span class="sd"&gt;        - y: numpy array, labels&lt;/span&gt;

&lt;span class="sd"&gt;        OUTPUT: None&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

        &lt;span class="c"&gt;# compute priors&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;class_counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c"&gt;#print Counter(y)&lt;/span&gt;

        &lt;span class="c"&gt;# compute likelihoods&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_compute_likelihood&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;        - X: 2d numpy array, feature matrix&lt;/span&gt;

&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;        - predictions: numpy array&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

        &lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;ys&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;class_counts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;best_y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
            &lt;span class="n"&gt;logs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;yp&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;ys&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;loglike&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;p_feature&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;yp&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="n"&gt;loglike&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;class_counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;yp&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_trains&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;logs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loglike&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ys&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logs&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;p_feature&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;yp&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;class_feature_totals&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;yp&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;
        &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;class_totals&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;yp&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_features&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;        - X: 2d numpy array, feature matrix&lt;/span&gt;
&lt;span class="sd"&gt;        - y: numpy array, labels&lt;/span&gt;

&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;        - accuracy: float between 0 and 1&lt;/span&gt;

&lt;span class="sd"&gt;        Calculate the accuracy, the percent predicted correctly.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We are going to test this classifier against the sklearn implementation of Naive Bayese by taking a secion of Spors and Fasion articles from our new york times MongoDB database.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pymongo&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;MongoClient&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.tokenize&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;word_tokenize&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.feature_extraction.text&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;CountVectorizer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;TfidfVectorizer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.stem.snowball&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SnowballStemmer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;preprocessing&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cross_validation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.naive_bayes&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;MultinomialNB&lt;/span&gt;
&lt;span class="c"&gt;#from naive_bayes import NaiveBayes&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT: string&lt;/span&gt;
&lt;span class="sd"&gt;        OUTPUT: list of strings&lt;/span&gt;

&lt;span class="sd"&gt;        Tokenize and stem/lemmatize the document.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="n"&gt;snowball&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SnowballStemmer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;snowball&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stem&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;word_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;())]&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;load_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sections&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;client&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MongoClient&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;db&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;client&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nyt_dump&lt;/span&gt;
    &lt;span class="n"&gt;coll&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;articles&lt;/span&gt;
    &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="n"&gt;docs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;article&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;coll&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;section_name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;$in&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;sections&lt;/span&gt;&lt;span class="p"&gt;}}):&lt;/span&gt;
        &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;article&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;section_name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;article&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;utf8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;replace&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;utf8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;docs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TfidfVectorizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tokenize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;strip_accents&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;unicode&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;stop_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;tfidf_vectorized&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;docs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sections&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tfidf_vectorized&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sections&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;run_trial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sections&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Fashion &amp;amp; Style&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
    &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sections&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;todense&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Train shape:&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;shape&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Test shape:&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;shape&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;My Implementation:&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;my_nb&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;NaiveBayes&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;my_nb&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Accuracy:&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;my_nb&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;my_predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="n"&gt;my_nb&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;my_predictions&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;sklearn&amp;#39;s Implementation&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;mnb&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MultinomialNB&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;mnb&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Accuracy:&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mnb&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sklearn_predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mnb&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;sklearn_predictions&lt;/span&gt;

    &lt;span class="c"&gt;# Assert I get the same results as sklearn&lt;/span&gt;
    &lt;span class="c"&gt;# (will give an error if different)&lt;/span&gt;
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sklearn_predictions&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;my_predictions&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;run_trial&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;Train&lt;/span&gt; &lt;span class="kp"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;134&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;11470&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Test&lt;/span&gt; &lt;span class="kp"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;45&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;11470&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;My&lt;/span&gt; &lt;span class="n"&gt;Implementation&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.755555555556&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Sports&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;sklearn&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;s Implementation&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.755555555556&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Sports&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The lack of an error of the last line says they're prediction match.  Now this is not a well defined measure of consistency between the two classes both prediction all articles are sports pages.   What we would like to see is there to be same predictions when there are different precictions for each article.   We can see in going through the counts of articles we have text for that the "World" section and the "Sports" section have a similar count.   We will re-run this for those two sections.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;client = MongoClient()&lt;/span&gt;
&lt;span class="x"&gt;db = client.nyt_dump&lt;/span&gt;
&lt;span class="x"&gt;coll = db.articles&lt;/span&gt;
&lt;span class="x"&gt;coll.distinct(&amp;#39;section_name&amp;#39;)&lt;/span&gt;
&lt;span class="x"&gt;for x in coll.aggregate([&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;group&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;:&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;_id&amp;#39;:&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;section_name&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;,&amp;#39;count&amp;#39;:&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;sum&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;:1}}}]):&lt;/span&gt;
&lt;span class="x"&gt;    print x&lt;/span&gt;

&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 5, u&amp;#39;_id&amp;#39;: u&amp;#39;Automobiles&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 2, u&amp;#39;_id&amp;#39;: u&amp;#39;Crosswords &amp;amp; Games&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 5, u&amp;#39;_id&amp;#39;: u&amp;#39;Great Homes and Destinations&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 11, u&amp;#39;_id&amp;#39;: u&amp;#39;Paid Death Notices&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 9, u&amp;#39;_id&amp;#39;: u&amp;#39;Travel&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 7, u&amp;#39;_id&amp;#39;: u&amp;#39;Booming&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 11, u&amp;#39;_id&amp;#39;: u&amp;#39;Magazine&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 10, u&amp;#39;_id&amp;#39;: u&amp;#39;Corrections&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 16, u&amp;#39;_id&amp;#39;: u&amp;#39;Theater&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 133, u&amp;#39;_id&amp;#39;: u&amp;#39;Sports&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 91, u&amp;#39;_id&amp;#39;: u&amp;#39;Arts&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 88, u&amp;#39;_id&amp;#39;: u&amp;#39;U.S.&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 46, u&amp;#39;_id&amp;#39;: u&amp;#39;Fashion &amp;amp; Style&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 92, u&amp;#39;_id&amp;#39;: u&amp;#39;N.Y. / Region&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 100, u&amp;#39;_id&amp;#39;: u&amp;#39;Business Day&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 28, u&amp;#39;_id&amp;#39;: u&amp;#39;Movies&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 18, u&amp;#39;_id&amp;#39;: u&amp;#39;Science&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 13, u&amp;#39;_id&amp;#39;: u&amp;#39;Technology&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 10, u&amp;#39;_id&amp;#39;: u&amp;#39;Home &amp;amp; Garden&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 84, u&amp;#39;_id&amp;#39;: u&amp;#39;Opinion&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 131, u&amp;#39;_id&amp;#39;: u&amp;#39;World&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 6, u&amp;#39;_id&amp;#39;: u&amp;#39;Your Money&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 19, u&amp;#39;_id&amp;#39;: u&amp;#39;Dining &amp;amp; Wine&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 10, u&amp;#39;_id&amp;#39;: u&amp;#39;Health&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 4, u&amp;#39;_id&amp;#39;: u&amp;#39;Education&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 13, u&amp;#39;_id&amp;#39;: u&amp;#39;Real Estate&amp;#39;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 37, u&amp;#39;_id&amp;#39;: u&amp;#39;Books&amp;#39;}&lt;/span&gt;



&lt;span class="x"&gt;run_trial([&amp;#39;Sports&amp;#39;,&amp;#39;World&amp;#39;])&lt;/span&gt;

&lt;span class="x"&gt;Train shape: (198, 12872)&lt;/span&gt;
&lt;span class="x"&gt;Test shape: (66, 12872)&lt;/span&gt;

&lt;span class="x"&gt;My Implementation:&lt;/span&gt;
&lt;span class="x"&gt;Accuracy: 0.984848484848&lt;/span&gt;
&lt;span class="x"&gt;[&amp;#39;World&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;World&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;Sports&amp;#39;&lt;/span&gt;
&lt;span class="x"&gt; &amp;#39;World&amp;#39; &amp;#39;World&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;World&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;World&amp;#39; &amp;#39;World&amp;#39; &amp;#39;World&amp;#39;&lt;/span&gt;
&lt;span class="x"&gt; &amp;#39;World&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;World&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;Sports&amp;#39;&lt;/span&gt;
&lt;span class="x"&gt; &amp;#39;Sports&amp;#39; &amp;#39;World&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;World&amp;#39; &amp;#39;World&amp;#39; &amp;#39;World&amp;#39; &amp;#39;World&amp;#39;&lt;/span&gt;
&lt;span class="x"&gt; &amp;#39;Sports&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;World&amp;#39; &amp;#39;World&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;World&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;Sports&amp;#39;&lt;/span&gt;
&lt;span class="x"&gt; &amp;#39;Sports&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;World&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;World&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;Sports&amp;#39;&lt;/span&gt;
&lt;span class="x"&gt; &amp;#39;Sports&amp;#39; &amp;#39;World&amp;#39; &amp;#39;World&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;World&amp;#39; &amp;#39;World&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;World&amp;#39; &amp;#39;World&amp;#39;&lt;/span&gt;
&lt;span class="x"&gt; &amp;#39;Sports&amp;#39; &amp;#39;World&amp;#39; &amp;#39;World&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;World&amp;#39; &amp;#39;Sports&amp;#39; &amp;#39;World&amp;#39; &amp;#39;World&amp;#39;]&lt;/span&gt;
&lt;span class="x"&gt;sklearn&amp;#39;s Implementation&lt;/span&gt;
&lt;span class="x"&gt;Accuracy: 0.984848484848&lt;/span&gt;
&lt;span class="x"&gt;[u&amp;#39;World&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;Sports&amp;#39;&lt;/span&gt;
&lt;span class="x"&gt; u&amp;#39;Sports&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;Sports&amp;#39;&lt;/span&gt;
&lt;span class="x"&gt; u&amp;#39;World&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;World&amp;#39;&lt;/span&gt;
&lt;span class="x"&gt; u&amp;#39;Sports&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;Sports&amp;#39;&lt;/span&gt;
&lt;span class="x"&gt; u&amp;#39;World&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;World&amp;#39;&lt;/span&gt;
&lt;span class="x"&gt; u&amp;#39;Sports&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;Sports&amp;#39;&lt;/span&gt;
&lt;span class="x"&gt; u&amp;#39;World&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;World&amp;#39;&lt;/span&gt;
&lt;span class="x"&gt; u&amp;#39;World&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;Sports&amp;#39;&lt;/span&gt;
&lt;span class="x"&gt; u&amp;#39;World&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;Sports&amp;#39; u&amp;#39;World&amp;#39; u&amp;#39;World&amp;#39;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we have a more likely comparision between the classifieres.  Here there is high accuracy and diversity in choices.   The two classifieres still match, so I am more conviced they are implementing the same algorithm.&lt;/p&gt;
&lt;h2&gt;News Groups&lt;/h2&gt;
&lt;p&gt;A common natural language processing task is to explore and find related posts among the 20 news groupds datasets that come with a number of packages including sklearn and nltk.  Another task is to find important topics among the news groups.   We will be exploring both in our afternoon assignment.   I will start off by taking 4 groups from the newgroups and transforming their text into a text frequuency, inverse document frequency vector for each post.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="s-Atom"&gt;from&lt;/span&gt; &lt;span class="s-Atom"&gt;sklearn&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;datasets&lt;/span&gt; &lt;span class="s-Atom"&gt;import&lt;/span&gt; &lt;span class="s-Atom"&gt;fetch_20newsgroups&lt;/span&gt;
&lt;span class="s-Atom"&gt;newsgroups_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;fetch_20newsgroups&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;subset=&amp;#39;train&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;categories&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;&amp;#39;sci.crypt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                     &lt;span class="s-Atom"&gt;&amp;#39;sci.electronics&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                     &lt;span class="s-Atom"&gt;&amp;#39;sci.med&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                     &lt;span class="s-Atom"&gt;&amp;#39;sci.space&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="s-Atom"&gt;vectorizor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;TfidfVectorizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;stop_words=&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;strip_accents=&amp;#39;unicode&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s-Atom"&gt;tfidf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;vectorizor&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;newsgroups_train&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s-Atom"&gt;tfidf&lt;/span&gt;




&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;2373&lt;/span&gt;&lt;span class="s-Atom"&gt;x38375&lt;/span&gt; &lt;span class="s-Atom"&gt;sparse&lt;/span&gt; &lt;span class="s-Atom"&gt;matrix&lt;/span&gt; &lt;span class="s-Atom"&gt;of&lt;/span&gt; &lt;span class="s-Atom"&gt;type&lt;/span&gt; &lt;span class="s-Atom"&gt;&amp;#39;&amp;lt;type &amp;#39;numpy&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;float64&amp;#39;&amp;gt;&amp;#39;&lt;/span&gt;
    &lt;span class="s-Atom"&gt;with&lt;/span&gt; &lt;span class="mi"&gt;283932&lt;/span&gt; &lt;span class="s-Atom"&gt;stored&lt;/span&gt; &lt;span class="s-Atom"&gt;elements&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;Compressed&lt;/span&gt; &lt;span class="nv"&gt;Sparse&lt;/span&gt; &lt;span class="nv"&gt;Row&lt;/span&gt; &lt;span class="s-Atom"&gt;format&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;




&lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;top10index&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;vectorizor&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;vocabulary_&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;values&lt;/span&gt;&lt;span class="p"&gt;())[&lt;/span&gt;&lt;span class="s-Atom"&gt;::-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
    &lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s-Atom"&gt;vectorizor&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;vocabulary_&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="s-Atom"&gt;top10index&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="s-Atom"&gt;vectorizor&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;vocabulary_&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;values&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="s-Atom"&gt;top10index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

 &lt;span class="s-Atom"&gt;zzz&lt;/span&gt; &lt;span class="mi"&gt;38374&lt;/span&gt;
&lt;span class="s-Atom"&gt;zzi776&lt;/span&gt; &lt;span class="mi"&gt;38373&lt;/span&gt;
&lt;span class="s-Atom"&gt;zzcrm&lt;/span&gt; &lt;span class="mi"&gt;38372&lt;/span&gt;
&lt;span class="s-Atom"&gt;zz&lt;/span&gt; &lt;span class="mi"&gt;38371&lt;/span&gt;
&lt;span class="s-Atom"&gt;zysv&lt;/span&gt; &lt;span class="mi"&gt;38370&lt;/span&gt;
&lt;span class="s-Atom"&gt;zy&lt;/span&gt; &lt;span class="mi"&gt;38369&lt;/span&gt;
&lt;span class="s-Atom"&gt;zxgxrggwf6wp2edst&lt;/span&gt; &lt;span class="mi"&gt;38368&lt;/span&gt;
&lt;span class="s-Atom"&gt;zwp4q&lt;/span&gt; &lt;span class="mi"&gt;38367&lt;/span&gt;
&lt;span class="s-Atom"&gt;zwl76&lt;/span&gt; &lt;span class="mi"&gt;38366&lt;/span&gt;
&lt;span class="s-Atom"&gt;zwarte&lt;/span&gt; &lt;span class="mi"&gt;38365&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;These are the most frequently used words in the corpus, and to someone who did not use news groups, it looks like garbage.  We can do this another way by using the tfidf vector, taking the words with the greatest score.  We can do this by summing or averaging over the tfidf values over the documents for each word.   When we average, we will remove zero values.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="s-Atom"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;vectorizor&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;vocabulary_&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="s-Atom"&gt;tfdif_scores_by_wordl&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;tfidf&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;todense&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="s-Atom"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="s-Atom"&gt;words&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;tfdif_scores_by_wordl&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="s-Atom"&gt;::-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;




&lt;span class="nf"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s-Atom"&gt;u&amp;#39;iv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;contestents&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;jams&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;noah&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;aloud&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;taf&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;chen&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
       &lt;span class="s-Atom"&gt;u&amp;#39;19600&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;sensitive&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;pjs269&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
      &lt;span class="s-Atom"&gt;dtype=&amp;#39;&amp;lt;U180&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;




&lt;span class="s-Atom"&gt;tfdif_avg_scores_by_word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;average&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;tfidf&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;todense&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="s-Atom"&gt;weights&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s-Atom"&gt;tfidf&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;todense&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="nf"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;bool&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="s-Atom"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nf"&gt;tolist&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="s-Atom"&gt;words&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;tfdif_avg_scores_by_word&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="s-Atom"&gt;::-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;




&lt;span class="nf"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s-Atom"&gt;u&amp;#39;mjzzs&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;7394&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;casserole&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;1r47l1inn8gq&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;perihelions&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
       &lt;span class="s-Atom"&gt;u&amp;#39;transistors&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;afoxx&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;92621&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;curt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;necisa&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
      &lt;span class="s-Atom"&gt;dtype=&amp;#39;&amp;lt;U180&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In all of these methods, we are left with words that do not given human insight into the problem. We are left with words that are not anchor words.   What I mean by that is that if a new's article mentions President Obama then we know it is highly likely for it be in some sections, like World, and not others, like Fashion.  If we break the newsgroups up by category we might see some anchor words for that section. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;c&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;&amp;#39;sci.crypt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;&amp;#39;sci.electronics&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;&amp;#39;sci.med&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;&amp;#39;sci.space&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
    &lt;span class="s-Atom"&gt;newsgroups_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;fetch_20newsgroups&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;subset=&amp;#39;train&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;categories&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;c&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="s-Atom"&gt;vectorizor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;TfidfVectorizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;stop_words=&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;strip_accents=&amp;#39;unicode&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="s-Atom"&gt;tfidf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;vectorizor&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;newsgroups_train&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s-Atom"&gt;c&lt;/span&gt;
    &lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;vectorizor&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;vocabulary_&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;())[&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;tfidf&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;todense&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="s-Atom"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nf"&gt;tolist&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))[&lt;/span&gt;&lt;span class="s-Atom"&gt;::-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
    &lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;vectorizor&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;vocabulary_&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;())[&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;average&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;tfidf&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;todense&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="s-Atom"&gt;weights&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s-Atom"&gt;tfidf&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;todense&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="nf"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;bool&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="s-Atom"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nf"&gt;tolist&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))[&lt;/span&gt;&lt;span class="s-Atom"&gt;::-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
    &lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;vectorizor&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;vocabulary_&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;())[&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;vectorizor&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;vocabulary_&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;values&lt;/span&gt;&lt;span class="p"&gt;()))[&lt;/span&gt;&lt;span class="s-Atom"&gt;::-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
    &lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class="s-Atom"&gt;sci&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;crypt&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;u&amp;#39;93apr21095141&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;kennedys&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;kronos&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;reasonable&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;roomful&amp;#39;&lt;/span&gt;
 &lt;span class="s-Atom"&gt;u&amp;#39;adventurers&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;decwrl&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;altran&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;patterns&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;usage&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;u&amp;#39;sacrifice&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;incrimination&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;archived&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;enemy&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;figure&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;sudden&amp;#39;&lt;/span&gt;
 &lt;span class="s-Atom"&gt;u&amp;#39;invent&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;doen&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;inversions&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;u&amp;#39;zzi776&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zzcrm&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zz&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zysv&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zy&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zxgxrggwf6wp2edst&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zwp4q&amp;#39;&lt;/span&gt;
 &lt;span class="s-Atom"&gt;u&amp;#39;zwl76&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zvt&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zusman&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="s-Atom"&gt;sci&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;electronics&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;u&amp;#39;dissertation&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;w1gsl&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;advance&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;facetious&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;amplified&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;dealt&amp;#39;&lt;/span&gt;
 &lt;span class="s-Atom"&gt;u&amp;#39;gerg&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;site&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;govern&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;finite&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;u&amp;#39;illuminators&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;constructs&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;lc&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;laserjet&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;drove&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;floors&amp;#39;&lt;/span&gt;
 &lt;span class="s-Atom"&gt;u&amp;#39;sincerely&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;136&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;9995&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;confirms&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;u&amp;#39;zucchini&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;ztimer&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zstewart&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zoology&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zoo&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zone&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zlau&amp;#39;&lt;/span&gt;
 &lt;span class="s-Atom"&gt;u&amp;#39;zl1ttg&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zklf0b&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zjoc01&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="s-Atom"&gt;sci&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;med&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;u&amp;#39;fermi&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;merkle&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;weinreigh&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;steve&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;scallop&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;jmeritt&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;chairs&amp;#39;&lt;/span&gt;
 &lt;span class="s-Atom"&gt;u&amp;#39;wg&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;reduce&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;britain&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;u&amp;#39;gw&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;iastate&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;126645&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;donnell&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;l988&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;mini&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;pot&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;2423&amp;#39;&lt;/span&gt;
 &lt;span class="s-Atom"&gt;u&amp;#39;smoky&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;foxxjac&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;u&amp;#39;zzz&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zz&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zurich&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zubkoff&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zooid&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zonker&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zone&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zonal&amp;#39;&lt;/span&gt;
 &lt;span class="s-Atom"&gt;u&amp;#39;zoloft&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zolft&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="s-Atom"&gt;sci&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s-Atom"&gt;space&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;u&amp;#39;206265&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;507&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;mmc&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;convenient&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;gap&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;maneuvers&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;3rds&amp;#39;&lt;/span&gt;
 &lt;span class="s-Atom"&gt;u&amp;#39;extension&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;gateway&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;winner&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;u&amp;#39;wesley&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;lonely&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;flexibility&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;replacement&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;curry&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;robert&amp;#39;&lt;/span&gt;
 &lt;span class="s-Atom"&gt;u&amp;#39;barium&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;restricted&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;dia&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;164655&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;u&amp;#39;zwarte&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zware&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zwakke&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zwak&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zwaartepunten&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zurbrin&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zulu&amp;#39;&lt;/span&gt;
 &lt;span class="s-Atom"&gt;u&amp;#39;zullen&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zowie&amp;#39;&lt;/span&gt; &lt;span class="s-Atom"&gt;u&amp;#39;zoology&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We do not see clear anchor words in the top 10 rankings, but we do ahve some likely words.   Seeing 'patterns' and 'inversions' in the crypto section is suggestive.  As is 'amplified' and 'illuminators' in the electronics section.   I do not know enough abou thte medical words to know if some of those are distincitive, but I do know the space ones are not.   I would argue that 'maneuvers' is consistent with 'space', but 'space' is not the MLE from 'maneuvers'.   &lt;/p&gt;
&lt;p&gt;The most frequent words do not tells us anything useful in these corpuses, but the sum and average of the TFIDF vector along documents for each word does give us some interesting words.  &lt;/p&gt;
&lt;h2&gt;Searching Newsgroups&lt;/h2&gt;
&lt;p&gt;After exploring the most important words in the corpus, we were asked to use a text file with search terms to search the documents and find the top 3 results for each search.  Our search is going to do something naive.  Since each tfidf vector is a normalized, we can find the difference in direction of the two vectors.  If they are small, we assume they are related documents.   If they are in very different directions, we will assume they are very different documents.   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics.pairwise&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pairwise_distances&lt;/span&gt;

&lt;span class="n"&gt;search_terms&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data/queries.txt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;header&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;newsgroups_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fetch_20newsgroups&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;subset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;train&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;vectorizor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TfidfVectorizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stop_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tfidf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vectorizor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;newsgroups_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;search&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vectorizor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;search_terms&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cos_sim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pairwise_distances&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;tfidf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;metric&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;cosine&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;top_3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cos_sim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)[:,:&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;search_terms&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;top_3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;budget&lt;/span&gt; &lt;span class="n"&gt;rental&lt;/span&gt; &lt;span class="n"&gt;cars&lt;/span&gt;   &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;5769&lt;/span&gt; &lt;span class="mi"&gt;10771&lt;/span&gt;  &lt;span class="mi"&gt;4253&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;children&lt;/span&gt; &lt;span class="n"&gt;who&lt;/span&gt; &lt;span class="n"&gt;have&lt;/span&gt; &lt;span class="n"&gt;died&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;moms&lt;/span&gt; &lt;span class="nn"&gt;postpartum&lt;/span&gt; &lt;span class="nn"&gt;depression&lt;/span&gt;   &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;197&lt;/span&gt;  &lt;span class="mi"&gt;798&lt;/span&gt; &lt;span class="mi"&gt;2240&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;compaq&lt;/span&gt; &lt;span class="n"&gt;presario&lt;/span&gt; &lt;span class="n"&gt;notebook&lt;/span&gt; &lt;span class="n"&gt;v5005us&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2561&lt;/span&gt; &lt;span class="mi"&gt;7748&lt;/span&gt; &lt;span class="mi"&gt;8640&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;boxed&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;fruits&lt;/span&gt; &lt;span class="n"&gt;basket&lt;/span&gt;  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4644&lt;/span&gt; &lt;span class="mi"&gt;8917&lt;/span&gt; &lt;span class="mi"&gt;7505&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;sun&lt;/span&gt; &lt;span class="n"&gt;sentinal&lt;/span&gt; &lt;span class="n"&gt;news&lt;/span&gt; &lt;span class="n"&gt;paper&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3110&lt;/span&gt; &lt;span class="mi"&gt;5378&lt;/span&gt; &lt;span class="mi"&gt;3719&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;puerto&lt;/span&gt; &lt;span class="n"&gt;rico&lt;/span&gt; &lt;span class="n"&gt;economy&lt;/span&gt;  &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;4179&lt;/span&gt; &lt;span class="mi"&gt;10372&lt;/span&gt;  &lt;span class="mi"&gt;4811&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;wireless&lt;/span&gt; &lt;span class="n"&gt;networking&lt;/span&gt;  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;10486&lt;/span&gt;  &lt;span class="mi"&gt;7180&lt;/span&gt;   &lt;span class="mi"&gt;695&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;hidden&lt;/span&gt; &lt;span class="n"&gt;valley&lt;/span&gt; &lt;span class="n"&gt;ranch&lt;/span&gt; &lt;span class="n"&gt;commercials&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1410&lt;/span&gt; &lt;span class="mi"&gt;1228&lt;/span&gt; &lt;span class="mi"&gt;4285&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;jimmy&lt;/span&gt; &lt;span class="n"&gt;carter&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;panama&lt;/span&gt; &lt;span class="n"&gt;canal&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;10580&lt;/span&gt;  &lt;span class="mi"&gt;3322&lt;/span&gt;   &lt;span class="mi"&gt;147&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;



&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;newsgroups_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]][:&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;From&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;joes&lt;/span&gt;&lt;span class="nd"&gt;@telxon.mis.telxon.com&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Joe&lt;/span&gt; &lt;span class="n"&gt;Staudt&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Subject&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Re&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Renting&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;Alamo&lt;/span&gt; 
&lt;span class="n"&gt;Organization&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;TELXON&lt;/span&gt; &lt;span class="n"&gt;Corporation&lt;/span&gt;
&lt;span class="n"&gt;Lines&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;45&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="n"&gt;article&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1993&lt;/span&gt;&lt;span class="n"&gt;Apr20&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mf"&gt;142818.14969&lt;/span&gt;&lt;span class="nd"&gt;@ericsson.se&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;etxmst&lt;/span&gt;&lt;span class="nd"&gt;@sta.ericsson.se&lt;/span&gt; &lt;span class="n"&gt;writes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;Hello&lt;/span&gt; &lt;span class="n"&gt;netters&lt;/span&gt;&lt;span class="err"&gt;!&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;I&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;m visiting the US (I&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;Sweden&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;August&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;I&lt;/span&gt; &lt;span class="n"&gt;will&lt;/span&gt; &lt;span class="n"&gt;probably&lt;/span&gt; &lt;span class="n"&gt;rent&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;Chevy&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;Beretta&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;Alamo.&lt;/span&gt; &lt;span class="nn"&gt;I&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ve been quoted $225 for a week/ $54 for additional days.&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;This&lt;/span&gt; &lt;span class="n"&gt;would&lt;/span&gt; &lt;span class="n"&gt;include&lt;/span&gt; &lt;span class="n"&gt;free&lt;/span&gt; &lt;span class="n"&gt;driving&lt;/span&gt; &lt;span class="n"&gt;distance&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;but&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;local&lt;/span&gt; &lt;span class="n"&gt;taxes&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Baltimore&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;They&lt;/span&gt; &lt;span class="n"&gt;also&lt;/span&gt; &lt;span class="n"&gt;told&lt;/span&gt; &lt;span class="n"&gt;me&lt;/span&gt; &lt;span class="nb"&gt;all&lt;/span&gt; &lt;span class="n"&gt;insurance&lt;/span&gt; &lt;span class="n"&gt;thats&lt;/span&gt; &lt;span class="n"&gt;necessary&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="n"&gt;included&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;but&lt;/span&gt; &lt;span class="n"&gt;I&lt;/span&gt; &lt;span class="n"&gt;doubt&lt;/span&gt; &lt;span class="n"&gt;that&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;cause a friend rented a car last year and it turned out he needed a lot more&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;insurance&lt;/span&gt; &lt;span class="n"&gt;than&lt;/span&gt; &lt;span class="n"&gt;what&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;s included in the base price. But on the other hand he &lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;didn&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;t rent it from Alamo.&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;Does&lt;/span&gt; &lt;span class="n"&gt;anyone&lt;/span&gt; &lt;span class="n"&gt;have&lt;/span&gt; &lt;span class="n"&gt;some&lt;/span&gt; &lt;span class="n"&gt;info&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;this&lt;/span&gt;&lt;span class="err"&gt;?&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;Is&lt;/span&gt; &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="mi"&gt;225&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;rip&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;off&lt;/span&gt;&lt;span class="err"&gt;?&lt;/span&gt; 
&lt;span class="n"&gt;No&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;that&lt;/span&gt; &lt;span class="n"&gt;sounds&lt;/span&gt; &lt;span class="n"&gt;pretty&lt;/span&gt; &lt;span class="n"&gt;reasonable&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;that&lt;/span&gt; &lt;span class="n"&gt;car&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;that&lt;/span&gt; &lt;span class="n"&gt;city&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;Probability&lt;/span&gt; &lt;span class="n"&gt;that&lt;/span&gt; &lt;span class="n"&gt;I&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ll be needing more insurance?&lt;/span&gt;
&lt;span class="n"&gt;Unless&lt;/span&gt; &lt;span class="n"&gt;you&lt;/span&gt; &lt;span class="n"&gt;have&lt;/span&gt; &lt;span class="n"&gt;an&lt;/span&gt; &lt;span class="n"&gt;accident&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;you&lt;/span&gt; &lt;span class="n"&gt;won&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;t need more.  If you plan on&lt;/span&gt;
&lt;span class="n"&gt;paying&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;car&lt;/span&gt; &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;credit&lt;/span&gt; &lt;span class="n"&gt;card&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;



&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;newsgroups_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]][:&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;From&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;cds7k&lt;/span&gt;&lt;span class="nd"&gt;@Virginia.EDU&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Christopher&lt;/span&gt; &lt;span class="n"&gt;Douglas&lt;/span&gt; &lt;span class="n"&gt;Saady&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Subject&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Re&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Looking&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;MOVIES&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;BIKES&lt;/span&gt;
&lt;span class="n"&gt;Organization&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;University&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;Virginia&lt;/span&gt;
&lt;span class="n"&gt;Lines&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;

&lt;span class="n"&gt;There&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;s also Billy Jack, The Wild One, Smokey and the Bandit&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Where&lt;/span&gt; &lt;span class="n"&gt;Jerry&lt;/span&gt; &lt;span class="n"&gt;Reed&lt;/span&gt; &lt;span class="n"&gt;runs&lt;/span&gt; &lt;span class="n"&gt;his&lt;/span&gt; &lt;span class="n"&gt;truck&lt;/span&gt; &lt;span class="n"&gt;over&lt;/span&gt; &lt;span class="n"&gt;Motorcycle&lt;/span&gt; &lt;span class="n"&gt;Gangs&lt;/span&gt; &lt;span class="n"&gt;Bikes&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;video&lt;/span&gt; &lt;span class="n"&gt;tape&lt;/span&gt; &lt;span class="n"&gt;documentary&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;Hell&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;s Angels I&lt;/span&gt;
&lt;span class="n"&gt;found&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;rental&lt;/span&gt; &lt;span class="n"&gt;store&lt;/span&gt; &lt;span class="n"&gt;once&lt;/span&gt;




&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;newsgroups_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]][:&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;From&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Clinton&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;HQ&lt;/span&gt;&lt;span class="nd"&gt;@Campaign92.Org&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Clinton&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Gore&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;92)&lt;/span&gt;
&lt;span class="n"&gt;Subject&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;CLINTON&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;President&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;s Radio Interview in Pittsburgh 4.17.93&lt;/span&gt;
&lt;span class="n"&gt;Organization&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;MIT&lt;/span&gt; &lt;span class="n"&gt;Artificial&lt;/span&gt; &lt;span class="n"&gt;Intelligence&lt;/span&gt; &lt;span class="n"&gt;Lab&lt;/span&gt;
&lt;span class="n"&gt;Lines&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;212&lt;/span&gt;
&lt;span class="n"&gt;NNTP&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Posting&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Host&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;life&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ai&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mit&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;edu&lt;/span&gt;





                         &lt;span class="n"&gt;THE&lt;/span&gt; &lt;span class="n"&gt;WHITE&lt;/span&gt; &lt;span class="n"&gt;HOUSE&lt;/span&gt;

                  &lt;span class="n"&gt;Office&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;Press&lt;/span&gt; &lt;span class="n"&gt;Secretary&lt;/span&gt;
                    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Pittsburgh&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Pennsylvania&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;______________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;For&lt;/span&gt; &lt;span class="n"&gt;Immediate&lt;/span&gt; &lt;span class="n"&gt;Release&lt;/span&gt;                         &lt;span class="n"&gt;April&lt;/span&gt; &lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1993&lt;/span&gt;


                    &lt;span class="n"&gt;INTERVIEW&lt;/span&gt; &lt;span class="n"&gt;OF&lt;/span&gt; &lt;span class="n"&gt;THE&lt;/span&gt; &lt;span class="n"&gt;PRESIDENT&lt;/span&gt;
                      &lt;span class="n"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;MICHAEL&lt;/span&gt; &lt;span class="n"&gt;WHITELY&lt;/span&gt; &lt;span class="n"&gt;OF&lt;/span&gt;
                    &lt;span class="n"&gt;KDKA&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;AM&lt;/span&gt; &lt;span class="n"&gt;RADIO&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;PITTSBURGH&lt;/span&gt;

                 &lt;span class="n"&gt;Pittsburgh&lt;/span&gt; &lt;span class="n"&gt;International&lt;/span&gt; &lt;span class="n"&gt;Airport&lt;/span&gt;
                     &lt;span class="n"&gt;Pittsburgh&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Pennsylvania&lt;/span&gt;



&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;M&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;EDT&lt;/span&gt;


         &lt;span class="n"&gt;Q&lt;/span&gt;    &lt;span class="n"&gt;For&lt;/span&gt; &lt;span class="n"&gt;everyone&lt;/span&gt; &lt;span class="n"&gt;listening&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;KDKA&lt;/span&gt; &lt;span class="n"&gt;Radio&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;I&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;m Mike &lt;/span&gt;
&lt;span class="n"&gt;Whitely&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;KDKA&lt;/span&gt; &lt;span class="n"&gt;Radio&lt;/span&gt; &lt;span class="n"&gt;News&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;  &lt;span class="n"&gt;We&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;re here at the Pittsburgh &lt;/span&gt;
&lt;span class="n"&gt;International&lt;/span&gt; &lt;span class="n"&gt;Airport&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;me&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;President&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;United&lt;/span&gt; 
&lt;span class="n"&gt;States&lt;/span&gt; &lt;span class="n"&gt;Bill&lt;/span&gt; &lt;span class="n"&gt;Clinton&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;

         &lt;span class="n"&gt;And&lt;/span&gt; &lt;span class="n"&gt;I&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;d like to wel&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can see the first response is spot on.  The second two values are not similar in the way of topics, but the preseidential document says budget a lot.   From the TFIDF perspective, the search term has a high ration of budget, a word with a low frequency over the documents.   The same is true for this presidential interview.   Obviously this can help find related documents, but there are obvious limitations for this methodology.   I am impressed that it does as well as it does, but as we get more documents there will be more overlap.   We need an additional filter in finding related documents before we measure similarity.   &lt;/p&gt;
&lt;h2&gt;NLP with SQL&lt;/h2&gt;
&lt;p&gt;The goal of this section is to perform natural language processing using SQL for our New York times article data.  To do this we will need to make a table of documents, a table of words, and a connecting table between words and documents.   I am going to be doing this in a local PostgreSQL database where I created a new database called articles.&lt;/p&gt;
&lt;p&gt;The structure of the database is there are 3 tables.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;article_id =&amp;gt; url, category  &lt;/li&gt;
&lt;li&gt;word_id =&amp;gt; word  &lt;/li&gt;
&lt;li&gt;
&lt;p&gt;id =&amp;gt; article_id, word_id, location  &lt;/p&gt;
&lt;p&gt;import psycopg2&lt;/p&gt;
&lt;p&gt;conn = psycopg2.connect(dbname='articles', 
                        user='postgres',
                        password='password', 
                        host='/tmp')
cur = conn.cursor()&lt;/p&gt;
&lt;p&gt;client = MongoClient()
db = client.nyt_dump
coll = db.articles
article_dict = dict()
for i, article in enumerate(coll.find()):
    article_dict[article['_id']] = i
    cur.execute("INSERT INTO url VALUES (%s,%s,%s);", [i,article['web_url'], article['section_name']])
    conn.commit()&lt;/p&gt;
&lt;p&gt;from nltk import RegexpTokenizer
from nltk.corpus import stopwords
from nltk.stem.snowball import SnowballStemmer
from nltk import Text
import re&lt;/p&gt;
&lt;p&gt;sw = set(stopwords.words('english'))
snowball = SnowballStemmer('english')
reg = RegexpTokenizer(r'\w+',flags=re.UNICODE)
words = []
doc_tokens = []
for doc in coll.find():
    doc = "".join(doc['content']).strip()
    tokens = []
    for t in reg.tokenize(doc):
        if t not in sw:
            t = t.encode('ascii','ignore')
            if str(t) != str():
                s = snowball.stem(str(t))
                tokens.append(s)
                words.append(s)
    doc_tokens.append(tokens)
words = set(words)&lt;/p&gt;
&lt;p&gt;len(words)&lt;/p&gt;
&lt;p&gt;23917&lt;/p&gt;
&lt;p&gt;word_dict = dict()
for i, word in enumerate(words):
    word_dict[word] = i
    cur.execute("INSERT INTO wordlist VALUES (%s,%s);", [i,word])
    conn.commit()&lt;/p&gt;
&lt;p&gt;cur.execute("SELECT COUNT(&lt;em&gt;) FROM url;")
print "Article Count: ", cur.fetchone()
cur.execute("SELECT COUNT(&lt;/em&gt;) FROM wordlist;")
print "Stemmed Word Count: ", cur.fetchone()&lt;/p&gt;
&lt;p&gt;Article Count:  (999L,)
Stemmed Word Count:  (23917L,)&lt;/p&gt;
&lt;p&gt;for i, tokens in enumerate(doc_tokens):
    for j, token in enumerate(tokens):
        cur.execute("INSERT INTO wordlocation VALUES (%s, %s, %s,%s);", [100000*i+j,i,word_dict[token],j])
        conn.commit()&lt;/p&gt;
&lt;p&gt;cur.execute("SELECT COUNT(*) FROM wordlocation;")
cur.fetchone()&lt;/p&gt;
&lt;p&gt;(374759L,)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So far we have set up the SQL tables, tokenized the words, recorded the 374759 locations of the 23917 stemmed words in 99 articles.&lt;/p&gt;
&lt;p&gt;The next step we are going to engage in is the bag of words method.   Previous, we used sparse matrixes to represent the words in each article.  That is not a realisitic option for an sql table.  We do not want wide tables.  Instead we are going to make a new table and record the counts appropriately.&lt;/p&gt;
&lt;h2&gt;Bag of words&lt;/h2&gt;
&lt;p&gt;The bag of words model counts the number of occurence of each word in each article.   We are going to create a new table that uses the url id (article id) the word id, and the count of occurance.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;cur.execute(&amp;quot;&amp;quot;&amp;quot;
            CREATE TABLE bagofwords AS
              SELECT a.id, b.word_id, COUNT(*) 
              FROM url a 
              JOIN wordlocation b
              ON a.id = b.url_id
              GROUP BY a.id, b.word_id;
            &amp;quot;&amp;quot;&amp;quot;)
conn.commit()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;From the bagofwords table we created, we can construct the term frequency and inverse document frequency.   There are many definitions of &lt;a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf"&gt;term frequency&lt;/a&gt;, and we will use the double normalized 0.5 defintion:&lt;/p&gt;
&lt;p&gt;$$tf(t,d) = 0.5 + \frac{0.5 \ f(t,d)}{ max(f(w,d): \ w \in d) } $$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;cur.execute(&amp;quot;&amp;quot;&amp;quot;
            SELECT a.id, a.word_id, (0.5 + 0.5*a.count/b.max) as tf 
            FROM bagofwords a JOIN
            (SELECT id, MAX(count) as max 
                FROM bagofwords 
                GROUP BY id) b
            ON a.id=b.id
            ORDER BY a.id, a.word_id;
            &amp;quot;&amp;quot;&amp;quot;)
cur.fetchmany(10)




[(0, 75, Decimal(&amp;#39;0.55555555555555555556&amp;#39;)),
 (0, 124, Decimal(&amp;#39;0.55555555555555555556&amp;#39;)),
 (0, 247, Decimal(&amp;#39;0.66666666666666666667&amp;#39;)),
 (0, 315, Decimal(&amp;#39;0.61111111111111111111&amp;#39;)),
 (0, 516, Decimal(&amp;#39;0.55555555555555555556&amp;#39;)),
 (0, 590, Decimal(&amp;#39;0.55555555555555555556&amp;#39;)),
 (0, 728, Decimal(&amp;#39;0.55555555555555555556&amp;#39;)),
 (0, 885, Decimal(&amp;#39;0.55555555555555555556&amp;#39;)),
 (0, 930, Decimal(&amp;#39;0.55555555555555555556&amp;#39;)),
 (0, 993, Decimal(&amp;#39;0.55555555555555555556&amp;#39;))]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The inverse document frequency also has many definitions, but we will use the base definition:&lt;/p&gt;
&lt;p&gt;$$idf(t,D) = log_{10}(\frac{N_{D}}{N_{D,t}})$$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;cur.execute(&amp;quot;&amp;quot;&amp;quot;
            SELECT word_id, 
                   LOG( (SELECT COUNT(*) FROM url) / doc_count ) as df 
            FROM (SELECT word_id, COUNT(1) as doc_count 
                  FROM bagofwords 
                  GROUP BY word_id) a;
            &amp;quot;&amp;quot;&amp;quot;)
cur.fetchmany(10)




[(21370, 1.43136376415899),
 (2848, 2.99956548822598),
 (2026, 1.53147891704226),
 (10295, 2.99956548822598),
 (11890, 2.99956548822598),
 (17928, 2.52244423350632),
 (22262, 2.99956548822598),
 (16703, 2.09342168516224),
 (9545, 2.39619934709574),
 (14724, 2.99956548822598)]




cur.execute(&amp;quot;&amp;quot;&amp;quot; CREATE TABLE tfidf AS
            SELECT tf.id, tf.word_id, tf.tf*idf.idf as tfidf
            FROM (SELECT a.id, a.word_id, (0.5 + 0.5*a.count/b.max) as tf 
                  FROM bagofwords a JOIN
                    (SELECT id, MAX(count) as max 
                     FROM bagofwords 
                     GROUP BY id) b
                  ON a.id=b.id
                  ) tf 
            JOIN (SELECT word_id, 
                         LOG( (SELECT COUNT(*) FROM url) / doc_count ) as idf 
                  FROM (SELECT word_id, COUNT(1) as doc_count 
                        FROM bagofwords 
                        GROUP BY word_id) a 
                  ) idf 
            ON tf.word_id=idf.word_id;
            &amp;quot;&amp;quot;&amp;quot;
           )
conn.commit()
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;SQL NYT Ranking&lt;/h2&gt;
&lt;p&gt;We are going to write a query function that will take a search term and return the top 3 articles that 'match' the query by summing the tfidf scores.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;def query(string):&lt;/span&gt;
&lt;span class="x"&gt;    query_string = &amp;quot;&amp;quot;&amp;quot;SELECT a.id, SUM(a.tfidf) as total &lt;/span&gt;
&lt;span class="x"&gt;                      FROM tfidf a &lt;/span&gt;
&lt;span class="x"&gt;                      JOIN (SELECT id FROM wordlist WHERE word in (&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;})) b &lt;/span&gt;
&lt;span class="x"&gt;                      ON a.word_id = b.id GROUP BY a.id ORDER BY total DESC limit 3;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="x"&gt;    string = &amp;quot; &amp;quot;.join([snowball.stem(word) for word in string.split()])&lt;/span&gt;
&lt;span class="x"&gt;    cur.execute(query_string.format(&amp;quot;&amp;#39;&amp;quot;+&amp;quot;&amp;#39;,&amp;#39;&amp;quot;.join(string.split())+&amp;quot;&amp;#39;&amp;quot;))&lt;/span&gt;
&lt;span class="x"&gt;    print string&lt;/span&gt;
&lt;span class="x"&gt;    return [x[0] for x in cur.fetchall()]&lt;/span&gt;


&lt;span class="x"&gt;def get_headlines(query_string):&lt;/span&gt;
&lt;span class="x"&gt;    results = query(query_string)&lt;/span&gt;
&lt;span class="x"&gt;    article_ids = [article_dict.keys()[article_dict.values().index(x)] for x in results]&lt;/span&gt;
&lt;span class="x"&gt;    print&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="x"&gt;    for art in coll.find(&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;_id&amp;quot;:&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;in&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;:article_ids}}):&lt;/span&gt;
&lt;span class="x"&gt;        print art[&amp;#39;headline&amp;#39;][&amp;#39;print_headline&amp;#39;]&lt;/span&gt;
&lt;span class="x"&gt;        print &amp;quot;&amp;quot;&lt;/span&gt;


&lt;span class="x"&gt;get_headlines(&amp;quot;Obama upsets Congress&amp;quot;)&lt;/span&gt;

&lt;span class="x"&gt;obama upset congress&lt;/span&gt;

&lt;span class="x"&gt;5 Years After Financial Collapse, Obama Says House G.O.P. Could Reverse Gains&lt;/span&gt;

&lt;span class="x"&gt;As Budget Fight Looms, Obama Sees Defiance in His Own Party&lt;/span&gt;

&lt;span class="x"&gt;Obama Highlights Fiscal Risks in Addressing Business Group&lt;/span&gt;




&lt;span class="x"&gt;get_headlines(&amp;quot;Cowboys win&amp;quot;)&lt;/span&gt;

&lt;span class="x"&gt;cowboy win&lt;/span&gt;

&lt;span class="x"&gt;The Good and the Bad Of the Saints, Reversed&lt;/span&gt;

&lt;span class="x"&gt;Giants Hope for U-Turn On Familiar Road Trip&lt;/span&gt;

&lt;span class="x"&gt;Overhaul Of Red Sox Is Beyond Their Chins&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We see that the search for terms related to Obama, a common topic in the NYT, return relavant results.  Searching for something the NYTimes does not normally cover returns unrelated results.   &lt;/p&gt;
&lt;p&gt;Another method we could use to filter would be to select based on word location.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;def query_by_location(query):&lt;/span&gt;
&lt;span class="x"&gt;    query_string = &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="x"&gt;    SELECT a.url_id, 1./SUM(a.min) as loc &lt;/span&gt;
&lt;span class="x"&gt;    FROM (SELECT a.url_id, a.word_id, MIN(a.location) &lt;/span&gt;
&lt;span class="x"&gt;          FROM wordlocation a &lt;/span&gt;
&lt;span class="x"&gt;          WHERE word_id IN&lt;/span&gt;
&lt;span class="x"&gt;             (SELECT id FROM wordlist &lt;/span&gt;
&lt;span class="x"&gt;              WHERE word IN (&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;})) &lt;/span&gt;
&lt;span class="x"&gt;              GROUP BY a.url_id, a.word_id) a &lt;/span&gt;
&lt;span class="x"&gt;    GROUP BY a.url_id ORDER BY loc DESC LIMIT 3;&lt;/span&gt;
&lt;span class="x"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="x"&gt;    query = &amp;quot; &amp;quot;.join([snowball.stem(word) for word in query.split()])&lt;/span&gt;
&lt;span class="x"&gt;    cur.execute(query_string.format(&amp;quot;&amp;#39;&amp;quot;+&amp;quot;&amp;#39;,&amp;#39;&amp;quot;.join(query.split())+&amp;quot;&amp;#39;&amp;quot;))&lt;/span&gt;
&lt;span class="x"&gt;    print query&lt;/span&gt;
&lt;span class="x"&gt;    return [x[0] for x in cur.fetchall()]&lt;/span&gt;

&lt;span class="x"&gt;query_by_location(&amp;quot;Obama upsets Congress&amp;quot;)&lt;/span&gt;

&lt;span class="x"&gt;obama upset congress&lt;/span&gt;





&lt;span class="x"&gt;[314, 193, 17]&lt;/span&gt;




&lt;span class="x"&gt;def get_headlines_by_location(query_string):&lt;/span&gt;
&lt;span class="x"&gt;    results = query_by_location(query_string)&lt;/span&gt;
&lt;span class="x"&gt;    article_ids = [article_dict.keys()[article_dict.values().index(x)] for x in results]&lt;/span&gt;
&lt;span class="x"&gt;    print&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="x"&gt;    for art in coll.find(&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;_id&amp;quot;:&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;in&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;:article_ids}}):&lt;/span&gt;
&lt;span class="x"&gt;        print art[&amp;#39;headline&amp;#39;][&amp;#39;print_headline&amp;#39;]&lt;/span&gt;
&lt;span class="x"&gt;        print &amp;quot;&amp;quot;&lt;/span&gt;


&lt;span class="x"&gt;get_headlines_by_location(&amp;quot;Obama upsets Congress&amp;quot;)&lt;/span&gt;

&lt;span class="x"&gt;obama upset congress&lt;/span&gt;

&lt;span class="x"&gt;How Old a Democracy?&lt;/span&gt;

&lt;span class="x"&gt;Wage Law Will Cover Home Aides&lt;/span&gt;

&lt;span class="x"&gt;New Chief Nominated For Justice Dept. Division&lt;/span&gt;




&lt;span class="x"&gt;def get_content_by_location(query_string):&lt;/span&gt;
&lt;span class="x"&gt;    results = query_by_location(query_string)&lt;/span&gt;
&lt;span class="x"&gt;    article_ids = [article_dict.keys()[article_dict.values().index(x)] for x in results]&lt;/span&gt;
&lt;span class="x"&gt;    print&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="x"&gt;    for art in coll.find(&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;_id&amp;quot;:&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;in&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;:article_ids}}):&lt;/span&gt;
&lt;span class="x"&gt;        print &amp;quot;&amp;quot;.join(art[&amp;#39;content&amp;#39;]).strip()[:500]&lt;/span&gt;
&lt;span class="x"&gt;        print &amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="x"&gt;get_content_by_location(&amp;quot;Obama upsets Congress&amp;quot;)&lt;/span&gt;

&lt;span class="x"&gt;obama upset congress&lt;/span&gt;

&lt;span class="x"&gt;President Obama recently declared that the United States is âthe worldâs oldest constitutional democracy,â and he is echoed by Timothy Egan (âA brilliant mess,â Sept. 14), without challenge. It is, nonetheless, a historically dubious claim. That honor might belong to either Iceland or Switzerland, though the details are open to debate. But since the United States did not allow equal voting rights for all its citizens until 1965, its democracy, by that standard, must be counted young. A&lt;/span&gt;

&lt;span class="x"&gt;The Obama administration announced on Tuesday that it was extending minimum wage and overtime protections to the nationâs nearly two million home care workers.         &lt;/span&gt;
&lt;span class="x"&gt;Advocates for low-wage workers have pushed for this change, asserting that home care workers, who care for elderly and disabled Americans, were wrongly classified into the same âcompanionship servicesâ category as baby sitters â a group that is exempt from minimum wage and overtime coverage. Under the new rule, home care&lt;/span&gt;

&lt;span class="x"&gt;President Obama on Tuesday nominated Leslie R. Caldwell, a defense lawyer specializing in white-collar cases, to be assistant attorney general for the Justice Departmentâs criminal division. From 2002 to 2004, Ms. Caldwell, a former federal prosecutor, was the director of the Justice Departmentâs task force that handled prosecutions related to the 2001 collapse of Enron. Ms. Caldwell is a graduate of Penn State and George Washington University Law School and has worked in the United States a&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;These results give different values.   We could potentially combine these two metrics in a way to give the most relavant results using a weighting sceme.  That way we can use both word location and word uniqueness to determine which articles are most important to show.&lt;/p&gt;
&lt;h2&gt;Tuning and Model Comparison&lt;/h2&gt;
&lt;p&gt;We are going through the New York Times articles and attempt to identify which section they are apprt of using different supervised learning techniques.  First we need to encode the section names to variables, then we need to make a training and testing set.&lt;/p&gt;
&lt;p&gt;We will make a tfidf on the training set, train our algorithm on the training set, then convert the test set and predict.  We will be using accuracy as our metrics.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LabelEncoder&lt;/span&gt;
&lt;span class="n"&gt;le_section_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LabelEncoder&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;le_section_name&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coll&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;distinct&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;section_name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;le_section_name&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;docs&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;




&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;984&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;984&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;




&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cross_validation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;
&lt;span class="n"&gt;doc_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;doc_tst&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_tst&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;docs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;test_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.feature_extraction.text&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;TfidfVectorizer&lt;/span&gt;
&lt;span class="n"&gt;vectorizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TfidfVectorizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tokenize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;strip_accents&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;unicode&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;stop_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tfidf_trn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vectorizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc_trn&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tfidf_tst&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vectorizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc_tst&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we are going to compare the different algorithms.  Today I will stick with the methods that have built-in multi-classification.  I could us One vs. One or One vs All, but I will save that for another time.  Today's work has already taken a significant amount of time!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;clf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MultinomialNB&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__class__&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__name__&lt;/span&gt;




&lt;span class="s"&gt;&amp;#39;MultinomialNB&amp;#39;&lt;/span&gt;




&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.naive_bayes&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;MultinomialNB&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.tree&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DecisionTreeClassifier&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.ensemble&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;AdaBoostClassifier&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.neighbors&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;KNeighborsClassifier&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;supervise_time&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__class__&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__name__&lt;/span&gt;
    &lt;span class="n"&gt;start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_trn&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;end&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Time to Fit:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;end&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;
    &lt;span class="n"&gt;start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_tst&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;end&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Time to Predict:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;end&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Accuracy: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_tst&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;supervise_time&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MultinomialNB&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;supervise_time&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;supervise_time&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;supervise_time&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;AdaBoostClassifier&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;supervise_time&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;KNeighborsClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;supervise_time&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;AdaBoostClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;base_estimator&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;MultinomialNB&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5000&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;


&lt;span class="n"&gt;MultinomialNB&lt;/span&gt;
&lt;span class="n"&gt;Time&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Fit&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.0335011482239&lt;/span&gt;
&lt;span class="n"&gt;Time&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Predict&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.00691485404968&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.493243243243&lt;/span&gt;

&lt;span class="n"&gt;DecisionTreeClassifier&lt;/span&gt;
&lt;span class="n"&gt;Time&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Fit&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.796107053757&lt;/span&gt;
&lt;span class="n"&gt;Time&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Predict&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.00192499160767&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.371621621622&lt;/span&gt;

&lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;
&lt;span class="n"&gt;Time&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Fit&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;10.8660159111&lt;/span&gt;
&lt;span class="n"&gt;Time&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Predict&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.547387123108&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.614864864865&lt;/span&gt;

&lt;span class="n"&gt;AdaBoostClassifier&lt;/span&gt;
&lt;span class="n"&gt;Time&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Fit&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;3.87863016129&lt;/span&gt;
&lt;span class="n"&gt;Time&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Predict&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.0303628444672&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.222972972973&lt;/span&gt;

&lt;span class="n"&gt;KNeighborsClassifier&lt;/span&gt;
&lt;span class="n"&gt;Time&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Fit&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.000900983810425&lt;/span&gt;
&lt;span class="n"&gt;Time&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Predict&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.037672996521&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.652027027027&lt;/span&gt;

&lt;span class="n"&gt;AdaBoostClassifier&lt;/span&gt;
&lt;span class="n"&gt;Time&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Fit&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;233.7222929&lt;/span&gt;
&lt;span class="n"&gt;Time&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Predict&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;276.877113819&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.652027027027&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We see that the classification of text (sparse) data is not well done by untuned classifiers.   The KNN method does well, and I am sure that if we used a cosine similarity metric, it would do even better.&lt;/p&gt;
&lt;p&gt;The most interest point of this exercise was that I Adaboosted a NaiveBayes classifier to the point that it gave the exact results of the nearest neighbor method.   I am wondering if the sparse data lead to this fact, and if this can be generalized in other contexts&lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="natural language processing"></category><category term="nlp"></category><category term="yelp"></category><category term="new york times"></category><category term=""></category></entry><entry><title>Galvanize - Week 05 - Day 1</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-05-01/" rel="alternate"></link><updated>2015-06-29T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-29:galvanize/galvanize-data-science-05-01/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 5 - Day 1&lt;/h2&gt;
&lt;p&gt;Today we had an introduction to webscraping, web apis, and &lt;a href="http://www.mongodb.org/"&gt;MongoDB&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;The morning quiz was on answer questions using data stored in a 5 table PostgreSQL database that were suppose to simulate &lt;a href="http://hitchapp.com"&gt;Hithc&lt;/a&gt;.  An example question is: Find the number of unique users that used the service over the last 10 days that were driven by drivers who started driving between DATE1 and DATE2.  Are not important.  &lt;/p&gt;
&lt;h2&gt;MongoDB&lt;/h2&gt;
&lt;p&gt;We started off by downloading and installing a local copy of MongoDB from &lt;a href="http://www.mongodb.org/downloads?_ga=1.2370361.886345798.1422741448"&gt;here&lt;/a&gt;.  Some of the issues my cohort ran into was the database locking because proper permissions were to given to the 'data/db/' directory on the mac.   Other then that, it was a very easy processes.   &lt;/p&gt;
&lt;p&gt;Though it was not part of the exercise, I also installed pymongo and used that.   I would then do what was asked directly in the database terminal, then replicate it with pymongo in an IPython Notebook.  We were given an option of downloading some GUI interfaces, but I opted not to use them.   Just incase I change my mind in the future I will list them here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://robomongo.org/"&gt;Robomongo (Multiplatform)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fotonauts/MongoHub-Mac"&gt;MongoHub (Mac OSX)&lt;/a&gt; 
   with down-loadable &lt;a href="https://mongohub.s3.amazonaws.com/MongoHub.zip"&gt;binary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bagwanpankaj/humongous"&gt;Humongous (web based)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Mongo Queries&lt;/h2&gt;
&lt;p&gt;Our first task was to load in some messy click data into our MongoDB database.  I used the command line for this.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;mongoimport --db clicks --collection log &amp;lt; click_log.json&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I then used the mongo db to findOne() and find().limit(3).  There are over 2000 click results of different lengths.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;db.log.findOne()&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;{ "&lt;em&gt;id" : ObjectId("559198d72c8e29706d471d8e"), "_heartbeat&lt;/em&gt;" : 1368774601 }&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;db.log.find().limit(3)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p -116.345802_="-116.345802," 0_="0," 1368774179_="1368774179," 33.7724="33.7724" 6_1_3="6_1_3" :=":" AppleWebKit_536.26="AppleWebKit/536.26" CPU="CPU" Desert_="Desert&amp;quot;," Gecko_="Gecko)" ISODate_2013-05-17T07:09:59Z_="ISODate(&amp;quot;2013-05-17T07:09:59Z&amp;quot;)," Mac="Mac" Mobile_10B329_="Mobile/10B329&amp;quot;," OS="OS" ObjectId_559198d72c8e29706d471d90_="ObjectId(&amp;quot;559198d72c8e29706d471d90&amp;quot;)," X_="X)" _="]" _1.usa.gov_="&amp;quot;1.usa.gov&amp;quot;," _1084Psg_="&amp;quot;1084Psg&amp;quot;," _19Cztuz_="&amp;quot;19Cztuz&amp;quot;," _America_Los_Angeles_="&amp;quot;America/Los_Angeles&amp;quot;," _CA_="&amp;quot;CA&amp;quot;," _KHTML_="(KHTML," _Mozilla_5.0="&amp;quot;Mozilla/5.0" _Palm="&amp;quot;Palm" _US_="&amp;quot;US&amp;quot;," __id_="&amp;quot;_id&amp;quot;" _a_="&amp;quot;a&amp;quot;" _al_="&amp;quot;al&amp;quot;" _c_="&amp;quot;c&amp;quot;" _cy_="&amp;quot;cy&amp;quot;" _en-us_="&amp;quot;en-us&amp;quot;," _g_="&amp;quot;g&amp;quot;" _gr_="&amp;quot;gr&amp;quot;" _h_="&amp;quot;h&amp;quot;" _hc_="&amp;quot;hc&amp;quot;" _hh_="&amp;quot;hh&amp;quot;" _http:_science.nasa.gov_science-news_science-at-nasa_2013_16may_lunarimpact_="&amp;quot;http://science.nasa.gov/science-news/science-at-nasa/2013/16may_lunarimpact/&amp;quot;," _http:_t.co_btKvKFBaF5_="&amp;quot;http://t.co/btKvKFBaF5&amp;quot;," _iPhone_="(iPhone;" _l_="&amp;quot;l&amp;quot;" _ll_="&amp;quot;ll&amp;quot;" _nk_="&amp;quot;nk&amp;quot;" _r_="&amp;quot;r&amp;quot;" _t_="&amp;quot;t&amp;quot;" _tweetdeckapi_="&amp;quot;tweetdeckapi&amp;quot;," _tz_="&amp;quot;tz&amp;quot;" _u_="&amp;quot;u&amp;quot;" iPhone="iPhone" like="like"&gt;{ "&lt;em&gt;id" : ObjectId("559198d72c8e29706d471d8e"), "_heartbeat&lt;/em&gt;" : 1368774601 }
{ "_id" : ObjectId("559198d72c8e29706d471d8f"), "a" : "Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)", "c" : "NL", "nk" : 0, "tz" : "Europe/Amsterdam", "gr" : "06", "g" : "15r91", "h" : "10OBm3W", "l" : "pontifier", "al" : "en-GB", "hh" : "j.mp", "r" : "direct", "u" : "http://www.nsa.gov/", "t" : ISODate("2013-05-17T07:09:59Z"), "hc" : 1365701422, "cy" : "Oss", "ll" : [ 5.5333, 51.766701 ] }&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pymongo&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;MongoClient&lt;/span&gt;
&lt;span class="n"&gt;client&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MongoClient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;localhost&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;27017&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;db_nyt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;client&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;test_database&lt;/span&gt;
&lt;span class="n"&gt;ny&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;db_nyt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ny_times&lt;/span&gt;
&lt;span class="n"&gt;db&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;client&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clicks&lt;/span&gt;
&lt;span class="n"&gt;log&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_one&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Limit 3&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; 
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;limit&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;


&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;_id&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;ObjectId&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;559198d72c8e29706d471d8e&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;_heartbeat_&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1368774601&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;Limit&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;

&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;_id&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;ObjectId&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;559198d72c8e29706d471d8e&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;_heartbeat_&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1368774601&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;c&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;NL&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;nk&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;tz&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Europe/Amsterdam&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;gr&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;06&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;g&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;15r91&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;h&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;10OBm3W&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;cy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Oss&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;l&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;pontifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;al&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;en-GB&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;hh&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;j.mp&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;direct&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;u&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;http://www.nsa.gov/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;t&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2013&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;59&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;hc&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1365701422&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;_id&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;ObjectId&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;559198d72c8e29706d471d8f&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;ll&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;5.5333&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;51.766701&lt;/span&gt;&lt;span class="p"&gt;]}&lt;/span&gt;

&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Mozilla/5.0 (iPhone; CPU iPhone OS 6_1_3 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) Mobile/10B329&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;c&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;US&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;nk&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;tz&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;America/Los_Angeles&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;gr&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;CA&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;g&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;1084Psg&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;h&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;19Cztuz&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;cy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;Palm Desert&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;l&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;tweetdeckapi&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;al&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;en-us&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;hh&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;1.usa.gov&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;http://t.co/btKvKFBaF5&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;u&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;http://science.nasa.gov/science-news/science-at-nasa/2013/16may_lunarimpact/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;t&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2013&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;59&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;hc&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1368774179&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;_id&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;ObjectId&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;559198d72c8e29706d471d90&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;ll&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;116.345802&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;33.7724&lt;/span&gt;&lt;span class="p"&gt;]}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can see the pymongo results are identical to the commandline results.   What I like about pymongo, as we will see later, is that I can pull data from different sources and use that information to make queries to the MongoDB database.&lt;/p&gt;
&lt;p&gt;Our next task was to find out how many clicks were in San Francisco.  This is relatively easy becasue we can see that the records that are clearly user click have an element 'cy' which looks to be the city they are in.  It seems the two users above are in Palm Desert and Oss.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;db.log.find({'cy':'San Francisco'}).count()&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;11&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;log.find({&amp;#39;cy&amp;#39;:&amp;#39;San Francisco&amp;#39;}).count()




11
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Back in my "I want to be a front end web developer" days, I was very much aware that there are different browsers, and they can have different features avaialbe or represent css in slightly different ways.   I had no idea how many different browers there were.  We can see in the query results there is an element 'a' that is the webbrowser.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;db.log.distinct('a').length&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;559&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;p&gt;There are over 559 different browers types/versions in this dataset.   I do not miss front end development in the least! &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;len(log.distinct(&amp;#39;a&amp;#39;))




559
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We learned that one of the strong use cases for MongoDB is text data.   We did an afternoon project that will be covered later scaping the New York Times.  More on that to come.&lt;/p&gt;
&lt;p&gt;MongoDB, like almost all other databases, support regular expressions.  We can do a simple query and find out how many user use Mozilla, Opera, or both.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;db.log.find({'a': {'\$regex':'Mozilla|Opera'} }).count()&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2830&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;db.log.find({'a': {'\$regex':'Mozilla'} }).count()&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2723&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;db.log.find({'a': {'\$regex':'Opera'} }).count()&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;107&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;print log.find(&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;a&amp;#39;: &lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;regex&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;:&amp;#39;Mozilla|Opera&amp;#39;} }).count()&lt;/span&gt;
&lt;span class="x"&gt;print log.find(&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;a&amp;#39;: &lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;regex&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;:&amp;#39;Mozilla&amp;#39;} }).count()&lt;/span&gt;
&lt;span class="x"&gt;print log.find(&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;a&amp;#39;: &lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;regex&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;:&amp;#39;Opera&amp;#39;} }).count()&lt;/span&gt;

&lt;span class="x"&gt;2830&lt;/span&gt;
&lt;span class="x"&gt;2723&lt;/span&gt;
&lt;span class="x"&gt;107&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A careful inspect will show that there is a variable 't' that is a DateTime object.   Originally it was the unix timestamp in seconds.   We had ot convert it to the datetime object, that was was doing with the following code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;   &lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;find&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;t&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;\$exists&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;}}).&lt;/span&gt;&lt;span class="nx"&gt;forEach&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt; 
       &lt;span class="nx"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;Data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;t&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; 
       &lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;update&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;_id&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="nx"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;_id&lt;/span&gt;&lt;span class="p"&gt;},{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;$set&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="nx"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;
   &lt;span class="p"&gt;})&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is important because we were next asked to findout how many clicks were in the first hours.  I just happened to notice this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;db.log.find({'t':{\$exists:1}}).sort({'t':-1})[0].t&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ISODate("2013-05-17T08:09:56Z")&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;db.log.find({'t':{\$exists:1}}).sort({'t':1})[0].t&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ISODate("2013-05-17T07:09:57Z")&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;p&gt;We were were given only 1 hours worth of data!  So all the records should be there when we do the correct query.  The query to do this if we did not notice this fact would look like:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;t1 = db.log.find({'t':{'\$exists':'true'}}).sort({'t':1})[0].t&lt;/p&gt;
&lt;p&gt;t2 = new Date(t1.getTime()+3600000)&lt;/p&gt;
&lt;p&gt;db.log.find({'t':{\$gte:t1,\$lte:t2}}).count()&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2949&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;p&gt;And if were just to count rectors where the 't' variable exists:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;db.log.find({'t':{'$exists':'true'}}).count()&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2949&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;datetime&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timedelta&lt;/span&gt;
&lt;span class="n"&gt;t1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;t&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;$exists&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;true&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;}})&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;t&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;limit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;t&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;t2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;t1&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;timedelta&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hours&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;t&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;$gte&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;t1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;$lte&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;t2&lt;/span&gt;&lt;span class="p"&gt;}})&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;




&lt;span class="mi"&gt;2949&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The last question we had to answer was about what links the users clicked on the most.   This was an introduction to MongoDB's &lt;a href="http://docs.mongodb.org/manual/reference/sql-aggregation-comparison/"&gt;aggregation&lt;/a&gt; functionality.&lt;/p&gt;
&lt;p&gt;My first idea worked.  In terms of SQL I would group by the link address, count the number of records for each link, and sort by the link results.  In MongoDB this looks like the following:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;db.log.aggregate([{\$group:{_id:'\$u',count:{\$sum:1}}},{\$sort:{count:-1}},{\$limit:1}])&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;{ "_id" : "http://www.nsa.gov/", "count" : 478 }&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;pipeline = [&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;group&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;: &lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;_id&amp;#39;:&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;u&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;,&amp;#39;count&amp;#39;:&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;sum&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;:1}}},&lt;/span&gt;
&lt;span class="x"&gt;            &lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;sort&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;: &lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;count&amp;quot;: -1}},&lt;/span&gt;
&lt;span class="x"&gt;            &lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;limit&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;: 1}]&lt;/span&gt;
&lt;span class="x"&gt;for r in log.aggregate(pipeline):&lt;/span&gt;
&lt;span class="x"&gt;    print str(r) + &amp;quot;\n&amp;quot;&lt;/span&gt;

&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;u&amp;#39;count&amp;#39;: 478, u&amp;#39;_id&amp;#39;: u&amp;#39;http://www.nsa.gov/&amp;#39;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Geospacial&lt;/h2&gt;
&lt;p&gt;We were given some extra-credit MongoDB tasks involving &lt;a href="http://docs.mongodb.org/manual/administration/indexes-geo/"&gt;geospatial&lt;/a&gt; data.  MongoDB requires that the data be longitude, latitude, but our data is stored as latitude, longitude.  We need to go through the data base and fix this.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;    &lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;find&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ll&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="err"&gt;\&lt;/span&gt;&lt;span class="nx"&gt;$exists&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;true&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;}}).&lt;/span&gt;&lt;span class="nx"&gt;forEach&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt; 
        &lt;span class="nx"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;ll&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;entry.ll&lt;/span&gt;&lt;span class="err"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;ll&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt; 
        &lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;update&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;_id&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="nx"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;_id&lt;/span&gt;&lt;span class="p"&gt;},{&lt;/span&gt;&lt;span class="nx"&gt;$set&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="nx"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt; 
    &lt;span class="p"&gt;})&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now that our database is in the correct format, we need to create an 2D Spacial indexo n the data.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;db.log.createIndex( { ll : "2d" } )&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now we can ask questions about how many clicks are within 50 miles of San Francisco:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;db.log.find( { 'll' : { \$geoWithin :{ \$centerSphere : [ [  -122.4167, 37.7833 ] , 50 / 3963.2 ] } } } ).count()&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;226&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;log.find(&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;ll&amp;#39;:&lt;/span&gt;
&lt;span class="x"&gt;          &lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;geoWithin&lt;/span&gt;&lt;span class="x"&gt;&amp;#39; :&lt;/span&gt;
&lt;span class="x"&gt;           &lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;centerSphere&lt;/span&gt;&lt;span class="x"&gt;&amp;#39; : [ [ -122.4167, 37.7833 ] , 50 / 3963.2 ] } &lt;/span&gt;&lt;span class="cp"&gt;#&lt;/span&gt;&lt;span class="nf"&gt;Lat&lt;/span&gt;&lt;span class="x"&gt;,Lng SF 50 Miles/3964.2 Miles/Degree&lt;/span&gt;
&lt;span class="x"&gt;          } &lt;/span&gt;
&lt;span class="x"&gt;         }).count()&lt;/span&gt;




&lt;span class="x"&gt;226&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We could ask the questions:  "How many users are in Maine?" &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;db.log.find({'gr':'ME'}).count()&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;log.find({&amp;#39;gr&amp;#39;:&amp;#39;ME&amp;#39;}).count()




2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That was easy, but if we did not have the state information, we would use the location data.   I found a site that hosts maps of the state boundries as polylines of gps coordinates.   This is where pymongo comes in handy over the command line.  I read in the data from a webrequest, then constructed a query from the GPS data using MongoDB's geo-features.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;xml.etree.ElementTree&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;ET&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;urllib2&lt;/span&gt;
&lt;span class="n"&gt;request&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;http://econym.org.uk/gmap/states.xml&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;contents&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;ll&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;lng&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;lat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ET&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fromstring&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;contents&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;child&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getchildren&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;child&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;attrib&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Maine&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;child&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getchildren&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
            &lt;span class="n"&gt;ll&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;attrib&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;lng&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;attrib&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;lat&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])])&lt;/span&gt;
            &lt;span class="n"&gt;lng&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;attrib&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;lng&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="n"&gt;lat&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;attrib&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;lat&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;ll&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ll&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;ll&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;$geoWithin&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;$geometry&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;type&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Polygon&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;coordinates&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ll&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="p"&gt;}}})&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;




&lt;span class="mi"&gt;2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We also get 2, without using any pre-identified cate information.   This allows us to check for consistency incase we need to clean data.  This is awesome.   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lng&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lat&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;seagreen&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gr&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ME&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;}):&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ll&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ll&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;go&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;72&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;62&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Longitude&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Latitude&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW05D1/output_19_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We can see where our two Maine users in the map.  This is a feature of using pymongo that is not avaialble in just the termial application of MongoDB.&lt;/p&gt;
&lt;p&gt;Just for reference I wanted to list the geospacial tools listed for us if we wanted to explore them.  I did not, but I am using this post as a reference.  &lt;/p&gt;
&lt;p&gt;-&lt;a href="http://cartodb.com/"&gt;CartoDB&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;-&lt;a href="http://blog.cartodb.com/post/66687861735/torque-is-live-try-it-on-your-cartodb-maps-today"&gt;torque map&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Web Scraping:  Ebay&lt;/h2&gt;
&lt;p&gt;In the afternoon we were asked to engage in a couple of web scraping projects.  One was to find a topic on ebay, and retreive all the images on the search result page.   I, of course, searched for &lt;a href="http://www.ebay.com/sch/i.html?_from=R40&amp;amp;_trksid=p2050601.m570.l1313.TR5.TRC0.A0.H0.Xtesla.TRS0&amp;amp;_nkw=tesla&amp;amp;_sacat=0"&gt;Teslas&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The first thing we need is a place to store our images:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nf"&gt;%mkdir&lt;/span&gt; &lt;span class="n"&gt;tesla&lt;/span&gt;
&lt;span class="nf"&gt;%ls&lt;/span&gt; &lt;span class="n"&gt;tesla&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can see I just made the directory and that it is empty.  Now its type to scrape the webpage and pull out the images features.  The process we will do is request the webpage, use Beautiful soup to get the image sources, then down load each image source and store it in the tesla directory&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bs4&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;


&lt;span class="n"&gt;tesla_html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;http://www.ebay.com/sch/i.html?_from=R40&amp;amp;_trksid=p2050601.m570.l1313.TR5.TRC0.A0.H0.Xtesla.TRS0&amp;amp;_nkw=tesla&amp;amp;_sacat=0&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tesla_html&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;imgs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;el&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;src&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;el&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;select&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;div.lvpicinner a img&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;img_str&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;imgs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img_str&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;
    &lt;span class="n"&gt;to_img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;tesla/&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;img_str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;to_img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;ls&lt;/span&gt; &lt;span class="n"&gt;tesla&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;

&lt;span class="n"&gt;m0Q3jSK6NQ9_Hu_YIl38T9g&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;  &lt;span class="n"&gt;mbbybBkxozI9joXb1CgjfKQ&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;
&lt;span class="n"&gt;m45xVWpc86gaOwXzaWdXXOQ&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;  &lt;span class="n"&gt;mgTnEkhYXi4kepjp3aNCx7Q&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;
&lt;span class="n"&gt;m52qwfleCJ&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;encMaAJO9Taw&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;  &lt;span class="n"&gt;mgoIrvmOD&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;scAVdqXD1pirA&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;
&lt;span class="n"&gt;mDbg8VxsScOpYeQ6VH1TBEg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;  &lt;span class="n"&gt;mjMTLKMNaSsJNsRzn&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;zhQPg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;
&lt;span class="n"&gt;mEDv_smHtanyCtScA1bCnpA&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;  &lt;span class="n"&gt;ml5LUVDTC8ysTyvl70jOZMQ&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;
&lt;span class="n"&gt;mEEQdnmeKYAH32KJpZElmfw&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;  &lt;span class="n"&gt;mmstVHfStN09f4KjbYZpQyA&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;
&lt;span class="n"&gt;mE_xrXWO7xW9JF0uKYi6YZA&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;  &lt;span class="n"&gt;mpSnWCeMxvy3kVTjq3Ij44A&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;
&lt;span class="n"&gt;mV4lwZBpH6&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;wbB6xoZhRB1A&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;  &lt;span class="n"&gt;mu5fgrRMhaOCwRhDu_eI1sw&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;
&lt;span class="n"&gt;mVP1Wc7_ekfxObQrj4DaqtQ&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;  &lt;span class="n"&gt;mwdcx7MTbRMNuGi_4k7FiSw&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;
&lt;span class="n"&gt;mWrzlrW8xau7TE3WtJJtE9Q&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;  &lt;span class="n"&gt;mzqPumoh3YFjZ8kvXLi2oMw&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;
&lt;span class="n"&gt;mXyFRK9gbpV9&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="n"&gt;f3&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="n"&gt;QVuzA&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;  &lt;span class="n"&gt;s_1x2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gif&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We see that we have downlaoded 22&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;img = plt.imread(open(&amp;#39;tesla/m0Q3jSK6NQ9_Hu_YIl38T9g.jpg&amp;#39;))
plt.imshow(img)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW05D1/output_26_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;I'm in love!!!!!   Only 55K, what a steal!&lt;/p&gt;
&lt;p&gt;This was fun, but my partner got burned out.  Ebay is full of iframes when looking at an individual description of a car, and I had us jumping to thhose pages to also scrape descriptions and prices.   Since we were not asked to do this, we moved on with our afternoon sprint. &lt;/p&gt;
&lt;h1&gt;New York Times Scraping&lt;/h1&gt;
&lt;p&gt;The NY times has, as we learned, over 15 Million articles posted on this website, some going back to 1851.   These are images/pdfs that you can view, but text you can easily scrape.  Reguardless, they are there.  &lt;/p&gt;
&lt;p&gt;Probably because of people like us, the New York Times also has an API to access aspects of their data base.  This makes it easier for us to get data and allows them to manage/mitigate the affect these requests have on their servers.&lt;/p&gt;
&lt;p&gt;The api requires an api.  You will see reference to it as a variable, but for obvious reasons I will not post my actual api key.  We have a simple function that allows us to send and process the response from the NY Times API.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;single_query&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;payload&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;payload&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;status_code&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;WARNING&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;status_code&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;pay&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sort&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;oldest&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;api-key&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;ny_key&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;link&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;http://api.nytimes.com/svc/search/v2/articlesearch.json&amp;#39;&lt;/span&gt;

&lt;span class="n"&gt;ny_articles&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;single_query&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;pay&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;ny_articles&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;status&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;response&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;copyright&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The response is a JSON document, and the first level has data about the query.   The next level has information about the responses, and then we have meta data about the article documents.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;ny_articles[&amp;#39;response&amp;#39;].keys()




[u&amp;#39;docs&amp;#39;, u&amp;#39;meta&amp;#39;]




ny_articles[&amp;#39;response&amp;#39;][&amp;#39;meta&amp;#39;]




{u&amp;#39;hits&amp;#39;: 15569986, u&amp;#39;offset&amp;#39;: 0, u&amp;#39;time&amp;#39;: 179}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We see that our response has 15,569,986 matches, taking 179ms to response.  Our offset is 0.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;ny_articles[&amp;#39;response&amp;#39;][&amp;#39;docs&amp;#39;][0]




{u&amp;#39;_id&amp;#39;: u&amp;#39;4fbfd23e45c1498b0d004db6&amp;#39;,
 u&amp;#39;abstract&amp;#39;: None,
 u&amp;#39;blog&amp;#39;: [],
 u&amp;#39;byline&amp;#39;: None,
 u&amp;#39;document_type&amp;#39;: u&amp;#39;article&amp;#39;,
 u&amp;#39;headline&amp;#39;: {u&amp;#39;kicker&amp;#39;: u&amp;#39;1&amp;#39;,
  u&amp;#39;main&amp;#39;: u&amp;#39;??itive Salve Case in Philadelphia&amp;#39;},
 u&amp;#39;keywords&amp;#39;: [],
 u&amp;#39;lead_paragraph&amp;#39;: None,
 u&amp;#39;multimedia&amp;#39;: [],
 u&amp;#39;news_desk&amp;#39;: None,
 u&amp;#39;print_page&amp;#39;: u&amp;#39;4&amp;#39;,
 u&amp;#39;pub_date&amp;#39;: u&amp;#39;1851-09-18T00:03:58Z&amp;#39;,
 u&amp;#39;section_name&amp;#39;: None,
 u&amp;#39;snippet&amp;#39;: None,
 u&amp;#39;source&amp;#39;: u&amp;#39;The New York Times&amp;#39;,
 u&amp;#39;subsection_name&amp;#39;: None,
 u&amp;#39;type_of_material&amp;#39;: u&amp;#39;Article&amp;#39;,
 u&amp;#39;web_url&amp;#39;: u&amp;#39;http://query.nytimes.com/gst/abstract.html?res=9904E7DE1430EF33A2575BC1A96F9C946092D7CF&amp;#39;,
 u&amp;#39;word_count&amp;#39;: 74}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The docs are a list of 10 document's JSON formated meta data.  We originally sorted by oldest, but we can look at the meta data for current documents.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pay = {&amp;#39;sort&amp;#39;:&amp;#39;newest&amp;#39;, &amp;#39;api-key&amp;#39;:ny_key}
ny_articles = single_query(link,pay)
print ny_articles[&amp;#39;response&amp;#39;][&amp;#39;docs&amp;#39;][0]

{u&amp;#39;type_of_material&amp;#39;: u&amp;#39;Op-Ed&amp;#39;, u&amp;#39;blog&amp;#39;: [], u&amp;#39;news_desk&amp;#39;: u&amp;#39;OpEd&amp;#39;, u&amp;#39;lead_paragraph&amp;#39;: u&amp;#39;The Greek debt crisis taxes the best minds of Europe.&amp;#39;, u&amp;#39;headline&amp;#39;: {u&amp;#39;main&amp;#39;: u&amp;#39;Do We Have a Plan?&amp;#39;, u&amp;#39;content_kicker&amp;#39;: u&amp;#39;Op-Ed Columnist&amp;#39;}, u&amp;#39;abstract&amp;#39;: None, u&amp;#39;print_page&amp;#39;: None, u&amp;#39;word_count&amp;#39;: u&amp;#39;10&amp;#39;, u&amp;#39;_id&amp;#39;: u&amp;#39;557ec00038f0d86829e412aa&amp;#39;, u&amp;#39;snippet&amp;#39;: u&amp;#39;The Greek debt crisis taxes the best minds of Europe.&amp;#39;, u&amp;#39;source&amp;#39;: u&amp;#39;The New York Times&amp;#39;, u&amp;#39;web_url&amp;#39;: u&amp;#39;http://www.nytimes.com/2015/07/12/opinion/do-we-have-a-plan.html&amp;#39;, u&amp;#39;multimedia&amp;#39;: [{u&amp;#39;subtype&amp;#39;: u&amp;#39;wide&amp;#39;, u&amp;#39;url&amp;#39;: u&amp;#39;images/2015/06/15/opinion/15edchapart/15edchapart-thumbWide.jpg&amp;#39;, u&amp;#39;height&amp;#39;: 126, u&amp;#39;width&amp;#39;: 190, u&amp;#39;legacy&amp;#39;: {u&amp;#39;wide&amp;#39;: u&amp;#39;images/2015/06/15/opinion/15edchapart/15edchapart-thumbWide.jpg&amp;#39;, u&amp;#39;wideheight&amp;#39;: u&amp;#39;126&amp;#39;, u&amp;#39;widewidth&amp;#39;: u&amp;#39;190&amp;#39;}, u&amp;#39;type&amp;#39;: u&amp;#39;image&amp;#39;}, {u&amp;#39;subtype&amp;#39;: u&amp;#39;xlarge&amp;#39;, u&amp;#39;url&amp;#39;: u&amp;#39;images/2015/06/15/opinion/15edchapart/15edchapart-articleLarge.jpg&amp;#39;, u&amp;#39;height&amp;#39;: 443, u&amp;#39;width&amp;#39;: 600, u&amp;#39;legacy&amp;#39;: {u&amp;#39;xlargewidth&amp;#39;: u&amp;#39;600&amp;#39;, u&amp;#39;xlarge&amp;#39;: u&amp;#39;images/2015/06/15/opinion/15edchapart/15edchapart-articleLarge.jpg&amp;#39;, u&amp;#39;xlargeheight&amp;#39;: u&amp;#39;443&amp;#39;}, u&amp;#39;type&amp;#39;: u&amp;#39;image&amp;#39;}, {u&amp;#39;subtype&amp;#39;: u&amp;#39;thumbnail&amp;#39;, u&amp;#39;url&amp;#39;: u&amp;#39;images/2015/06/15/opinion/15edchapart/15edchapart-thumbStandard.jpg&amp;#39;, u&amp;#39;height&amp;#39;: 75, u&amp;#39;width&amp;#39;: 75, u&amp;#39;legacy&amp;#39;: {u&amp;#39;thumbnailheight&amp;#39;: u&amp;#39;75&amp;#39;, u&amp;#39;thumbnail&amp;#39;: u&amp;#39;images/2015/06/15/opinion/15edchapart/15edchapart-thumbStandard.jpg&amp;#39;, u&amp;#39;thumbnailwidth&amp;#39;: u&amp;#39;75&amp;#39;}, u&amp;#39;type&amp;#39;: u&amp;#39;image&amp;#39;}], u&amp;#39;subsection_name&amp;#39;: None, u&amp;#39;keywords&amp;#39;: [{u&amp;#39;value&amp;#39;: u&amp;#39;European Sovereign Debt Crisis (2010- )&amp;#39;, u&amp;#39;is_major&amp;#39;: u&amp;#39;N&amp;#39;, u&amp;#39;rank&amp;#39;: u&amp;#39;1&amp;#39;, u&amp;#39;name&amp;#39;: u&amp;#39;subject&amp;#39;}, {u&amp;#39;value&amp;#39;: u&amp;#39;Greece&amp;#39;, u&amp;#39;is_major&amp;#39;: u&amp;#39;N&amp;#39;, u&amp;#39;rank&amp;#39;: u&amp;#39;2&amp;#39;, u&amp;#39;name&amp;#39;: u&amp;#39;glocations&amp;#39;}, {u&amp;#39;value&amp;#39;: u&amp;#39;Europe&amp;#39;, u&amp;#39;is_major&amp;#39;: u&amp;#39;N&amp;#39;, u&amp;#39;rank&amp;#39;: u&amp;#39;3&amp;#39;, u&amp;#39;name&amp;#39;: u&amp;#39;glocations&amp;#39;}, {u&amp;#39;value&amp;#39;: u&amp;#39;European Union&amp;#39;, u&amp;#39;is_major&amp;#39;: u&amp;#39;N&amp;#39;, u&amp;#39;rank&amp;#39;: u&amp;#39;4&amp;#39;, u&amp;#39;name&amp;#39;: u&amp;#39;organizations&amp;#39;}, {u&amp;#39;value&amp;#39;: u&amp;#39;European Central Bank&amp;#39;, u&amp;#39;is_major&amp;#39;: u&amp;#39;N&amp;#39;, u&amp;#39;rank&amp;#39;: u&amp;#39;5&amp;#39;, u&amp;#39;name&amp;#39;: u&amp;#39;organizations&amp;#39;}, {u&amp;#39;value&amp;#39;: u&amp;#39;Eurozone&amp;#39;, u&amp;#39;is_major&amp;#39;: u&amp;#39;N&amp;#39;, u&amp;#39;rank&amp;#39;: u&amp;#39;6&amp;#39;, u&amp;#39;name&amp;#39;: u&amp;#39;organizations&amp;#39;}], u&amp;#39;byline&amp;#39;: {u&amp;#39;person&amp;#39;: [{u&amp;#39;organization&amp;#39;: u&amp;#39;&amp;#39;, u&amp;#39;role&amp;#39;: u&amp;#39;reported&amp;#39;, u&amp;#39;rank&amp;#39;: 1, u&amp;#39;firstname&amp;#39;: u&amp;#39;Patrick&amp;#39;, u&amp;#39;lastname&amp;#39;: u&amp;#39;CHAPPATTE&amp;#39;}], u&amp;#39;original&amp;#39;: u&amp;#39;By PATRICK CHAPPATTE&amp;#39;}, u&amp;#39;document_type&amp;#39;: u&amp;#39;article&amp;#39;, u&amp;#39;pub_date&amp;#39;: u&amp;#39;2015-07-12T00:00:00Z&amp;#39;, u&amp;#39;section_name&amp;#39;: u&amp;#39;Opinion&amp;#39;}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The NYT has different information for different articles.  We decided we would see how many we would download before we reached our daily limit.  It turns out that it was over 30,000 articles.   Since we were encoraged to see how many articles we could pull, we did not do it thoughtfully.  The NY times is fill of videos and receipes and other content that is not text based.   In retrospect I wish we focused on only 'News' articles.&lt;/p&gt;
&lt;p&gt;A number of our cohort had trouble getting past 1000 articles.  This is because the NY Times limits the pagation of their response to 99.  We got around this by cycling through endates as well as pages in the response.   We also found, that because of the type of material that they post, some days have more than 1000 articles.  We limited our selves to 1000 articles from a given day, then moved on to the previous day.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;

&lt;span class="c"&gt;#day we did the assignment&lt;/span&gt;
&lt;span class="n"&gt;end_date&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;20150622&amp;#39;&lt;/span&gt;

&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;pay&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sort&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;newest&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;end_date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;end_date&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;api-key&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;ny_key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;page&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;articles&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;single_query&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;pay&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;articles&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;response&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;docs&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
        &lt;span class="c"&gt;##We upsert into the database because we when change the &lt;/span&gt;
        &lt;span class="c"&gt;##enddate we get some redundant articles&lt;/span&gt;
        &lt;span class="n"&gt;ny&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;_id&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]},&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;upsert&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="mi"&gt;49&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
    &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; 
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;99&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;end_date&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;articles&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;response&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;docs&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;pub_date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;-&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;end_date&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;end_date&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

    &lt;span class="c"&gt;##Avoid being blocked by a too high query rate&lt;/span&gt;
    &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I am not going to run this code for this post, but it allowed us to pull 30,000+ articles and store them in our MongoDB database.  But we can look at the results.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;ny.find().count()




31140
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is only meta-data however, and not the actual articles from the website.   The final project was to download all the article text for each article.  It is clear that we were not expected to be able to download 30,000+ articles for this assignment.   We started the project by only downloading the articles a few news articles.&lt;/p&gt;
&lt;p&gt;We we also structured it in a way that allowed us to look for articles that have not yet been scraped and stored in our database.   We wanted to avoid double scraping at all cost.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;pull_articles&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;ny&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;type_of_material&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;News&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;HTML_content&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;$exists&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;web_url&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;$exists&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;true&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;}})&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;limit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;pub_date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;sup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;web_url&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;art&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;select&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;.story-content&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;art&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;75&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;HTML_content&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;art&lt;/span&gt;
        &lt;span class="n"&gt;ny&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;_id&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;_id&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]},&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;pull_articles&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;The&lt;/span&gt; &lt;span class="n"&gt;movable&lt;/span&gt; &lt;span class="n"&gt;feast&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;fashion&lt;/span&gt; &lt;span class="n"&gt;weeks&lt;/span&gt; &lt;span class="n"&gt;continues&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;After&lt;/span&gt; &lt;span class="n"&gt;Valentino&lt;/span&gt; &lt;span class="n"&gt;decided&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;ho&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I did not print out the entire articles because I am affid of being in violation of copyright with the New York Times.  We did scrape a modest amount of articles.  After pulling the meta data for 30,000 articles we did not want to continue to scrape the web articles as well&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;ny.find(&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;HTML_content&amp;#39;: &lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;exists&lt;/span&gt;&lt;span class="x"&gt;&amp;#39;:1}}).count()&lt;/span&gt;




&lt;span class="x"&gt;65&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="web scraping"></category></entry><entry><title>Galvanize - Week 04 - Day 5</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-04-05/" rel="alternate"></link><updated>2015-06-26T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-26:galvanize/galvanize-data-science-04-05/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 4 - Day 5&lt;/h2&gt;
&lt;p&gt;Today we had an accessment on regression and classification methods we have covered the prevous two weeks.  It was a conceptional test, making sure we understood the underlying models and their applications.  &lt;/p&gt;
&lt;p&gt;We then had a lecture on blogging.  Personally, I did not appreciate it.   I am obviously already blogging about what I am doing at Galvanize, but I also did not appreciate the frame given to the presentation: "I know you don't want to do this, but..."  It reminds me that we can all take issues based on attributes of an interaction that are not content based.  Good to be reminded of this going forward.&lt;/p&gt;
&lt;h2&gt;Profit Curves&lt;/h2&gt;
&lt;p&gt;The afternoon sprint was on a profit curves.  You and read about them from chapter 8 of &lt;a href="http://www.amazon.com/Data-Science-Business-data-analytic-thinking/dp/1449361323"&gt;Data Science For Business&lt;/a&gt;.   &lt;/p&gt;
&lt;p&gt;The goal of the assignment is to define a cost-benefit matrix for a business problem.  An example from the book involves calculating Lift, the increase in conversions.&lt;/p&gt;
&lt;p&gt;$$ \left( \begin{array}{cc}  TP &amp;amp; FP \ FN &amp;amp; TN \end{array} \right) =&amp;gt; \left( \begin{array}{cc}  4 &amp;amp; -5 \ 0 &amp;amp; 0 \end{array} \right) $$&lt;/p&gt;
&lt;p&gt;In this case if we correct identify someone who will convert, we can spend mondy to convert them and make 5 dollars.   On the other hand, if we have a false positive and invest in someone who will not convert, we lose the 5 dollars of cost.   &lt;/p&gt;
&lt;p&gt;If we do not predict someone to churn, we do not assume any cost.  But we also do not make any profit.   &lt;/p&gt;
&lt;p&gt;In this case the best model will maximize True Positive and Minimize False Positives.   It needs high precisions, but not necessarily hight accuracy or recall.&lt;/p&gt;
&lt;p&gt;The data set we are working with today is a cell phone dataset of users that churned.  We will start with the obligitory cleaning.   Since we have worked with this dataset before I will not be exploring it.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;

&lt;span class="n"&gt;churn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data/churn.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;drop&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;State&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Area Code&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Phone&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;churn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;yes&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inplace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;churn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;no&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;inplace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;churn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;False.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;inplace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;churn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;True.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;inplace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;churn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Account Length&lt;/th&gt;
      &lt;th&gt;Int'l Plan&lt;/th&gt;
      &lt;th&gt;VMail Plan&lt;/th&gt;
      &lt;th&gt;VMail Message&lt;/th&gt;
      &lt;th&gt;Day Mins&lt;/th&gt;
      &lt;th&gt;Day Calls&lt;/th&gt;
      &lt;th&gt;Day Charge&lt;/th&gt;
      &lt;th&gt;Eve Mins&lt;/th&gt;
      &lt;th&gt;Eve Calls&lt;/th&gt;
      &lt;th&gt;Eve Charge&lt;/th&gt;
      &lt;th&gt;Night Mins&lt;/th&gt;
      &lt;th&gt;Night Calls&lt;/th&gt;
      &lt;th&gt;Night Charge&lt;/th&gt;
      &lt;th&gt;Intl Mins&lt;/th&gt;
      &lt;th&gt;Intl Calls&lt;/th&gt;
      &lt;th&gt;Intl Charge&lt;/th&gt;
      &lt;th&gt;CustServ Calls&lt;/th&gt;
      &lt;th&gt;Churn?&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;128&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;265.1&lt;/td&gt;
      &lt;td&gt;110&lt;/td&gt;
      &lt;td&gt;45.07&lt;/td&gt;
      &lt;td&gt;197.4&lt;/td&gt;
      &lt;td&gt;99&lt;/td&gt;
      &lt;td&gt;16.78&lt;/td&gt;
      &lt;td&gt;244.7&lt;/td&gt;
      &lt;td&gt;91&lt;/td&gt;
      &lt;td&gt;11.01&lt;/td&gt;
      &lt;td&gt;10.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;2.70&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;107&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;161.6&lt;/td&gt;
      &lt;td&gt;123&lt;/td&gt;
      &lt;td&gt;27.47&lt;/td&gt;
      &lt;td&gt;195.5&lt;/td&gt;
      &lt;td&gt;103&lt;/td&gt;
      &lt;td&gt;16.62&lt;/td&gt;
      &lt;td&gt;254.4&lt;/td&gt;
      &lt;td&gt;103&lt;/td&gt;
      &lt;td&gt;11.45&lt;/td&gt;
      &lt;td&gt;13.7&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;3.70&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;137&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;243.4&lt;/td&gt;
      &lt;td&gt;114&lt;/td&gt;
      &lt;td&gt;41.38&lt;/td&gt;
      &lt;td&gt;121.2&lt;/td&gt;
      &lt;td&gt;110&lt;/td&gt;
      &lt;td&gt;10.30&lt;/td&gt;
      &lt;td&gt;162.6&lt;/td&gt;
      &lt;td&gt;104&lt;/td&gt;
      &lt;td&gt;7.32&lt;/td&gt;
      &lt;td&gt;12.2&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;3.29&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;84&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;299.4&lt;/td&gt;
      &lt;td&gt;71&lt;/td&gt;
      &lt;td&gt;50.90&lt;/td&gt;
      &lt;td&gt;61.9&lt;/td&gt;
      &lt;td&gt;88&lt;/td&gt;
      &lt;td&gt;5.26&lt;/td&gt;
      &lt;td&gt;196.9&lt;/td&gt;
      &lt;td&gt;89&lt;/td&gt;
      &lt;td&gt;8.86&lt;/td&gt;
      &lt;td&gt;6.6&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;1.78&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;166.7&lt;/td&gt;
      &lt;td&gt;113&lt;/td&gt;
      &lt;td&gt;28.34&lt;/td&gt;
      &lt;td&gt;148.3&lt;/td&gt;
      &lt;td&gt;122&lt;/td&gt;
      &lt;td&gt;12.61&lt;/td&gt;
      &lt;td&gt;186.9&lt;/td&gt;
      &lt;td&gt;121&lt;/td&gt;
      &lt;td&gt;8.41&lt;/td&gt;
      &lt;td&gt;10.1&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;2.73&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;y = churn.pop(&amp;quot;Churn?&amp;quot;).values
x = churn.values
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Because we are dealing with a cell phone companies, the model is different.   I wil fillow suit with the Data Science For Buisness example and not worry about the fixed cost of the business.  Instead we will make a simple model that if we correcy identify someone who will churn then we will invest and make a profit.  If we incorrectly predict someone is going to churn and invest in keeping them, we lose the investment of cost.  &lt;/p&gt;
&lt;p&gt;$$ \mbox{Profit Matrix} = \left( \begin{array}{cc}  80 &amp;amp; -20 \ 0 &amp;amp; 0 \end{array} \right)$$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;profit_matrix = np.array([[80,-20],[0,0]])
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The profit for a sample of uses will change if the total number of users changes.  For this reason we need make a rate to estimate the average profit per user.   We will have some model with a confusion matrix, and we will want to convert it a rate:&lt;/p&gt;
&lt;p&gt;$$ \left( \begin{array}{cc}  TP &amp;amp; FP \ FN &amp;amp; TN \end{array} \right) =&amp;gt; \left( \begin{array}{cc}  \frac{TP}{TP+FP} &amp;amp; \frac{FN}{FN+TN} \ \frac{FP}{TP+FP} &amp;amp; \frac{TN}{FN+TN} \end{array} \right) $$&lt;/p&gt;
&lt;p&gt;This will allow us to get a feel for the acutal rate of misclassification and correct classification in the populations we are concerned with if we know the population proportions $P_+$ and $P_-$.&lt;/p&gt;
&lt;p&gt;$$ \left( \begin{array}{cc}  \frac{TP}{TP+FP} \ P_+ &amp;amp; \frac{FN}{FN+TN} \ P_- \ \frac{FP}{TP+FP} \ P_+ &amp;amp; \frac{TN}{FN+TN} \ P_- \end{array} \right)$$&lt;/p&gt;
&lt;p&gt;In our dataset we have approximately 14% churn rate.  We can check that in the two extreams what will happen.   &lt;/p&gt;
&lt;p&gt;If our model predicts that everyone will churn, our confusion matrix and rate look like:&lt;/p&gt;
&lt;p&gt;$$ \left( \begin{array}{cc}  N_+ &amp;amp; N_- \ 0 &amp;amp; 0 \end{array} \right) =&amp;gt; \left( \begin{array}{cc}  1 &amp;amp; 1 \ 0 &amp;amp; 0 \end{array} \right) $$&lt;/p&gt;
&lt;p&gt;Since our $P_+ = .14$ and our $P_- = 0.86$, we have the error rate that looks like:&lt;/p&gt;
&lt;p&gt;$$\left( \begin{array}{cc}  .14 &amp;amp; .86 \ 0 &amp;amp; 0 \end{array} \right) $$&lt;/p&gt;
&lt;p&gt;The element wise multipication with our cost matrix gives:&lt;/p&gt;
&lt;p&gt;$$\left( \begin{array}{cc}  11.2 &amp;amp; -17.2 \ 0 &amp;amp; 0 \end{array} \right) $$&lt;/p&gt;
&lt;p&gt;We sum all the elements of this matrix together to get the expected profit:&lt;/p&gt;
&lt;p&gt;$$E[\mbox{Profit}] = 11.2 - 17.2 + 0 + 0 = -6$$&lt;/p&gt;
&lt;p&gt;This is obviously a bad strategy.  If we look at the other extreme and guess no one will churn we get the following results&lt;/p&gt;
&lt;p&gt;$$ \left( \begin{array}{cc}  0 &amp;amp; 0 \ N+ &amp;amp; N- \end{array} \right) =&amp;gt; \left( \begin{array}{cc}  0 &amp;amp; 0 \ 1 &amp;amp; 1 \end{array} \right) $$&lt;/p&gt;
&lt;p&gt;$$\left( \begin{array}{cc}  0 &amp;amp; 0 \  .14 &amp;amp; .86  \end{array} \right) $$&lt;/p&gt;
&lt;p&gt;The element wise multipication with our cost matrix gives:&lt;/p&gt;
&lt;p&gt;$$\left( \begin{array}{cc}  0 &amp;amp; 0 \ 0 &amp;amp; 0 \end{array} \right) $$&lt;/p&gt;
&lt;p&gt;$$E[\mbox{Profit}] = 0 + 0 + 0 + 0 = 0$$ &lt;/p&gt;
&lt;p&gt;So we have two extreme predictions.  One where we lose money, and one where we do not make a profit.   The idea is that if we can make smart prediction about who will churn and who will not churn, we can target our spending in the right places.   That will allow us to maximize our profit.   The smarter the predictions in terms of this problem and population, the better the results.  &lt;/p&gt;
&lt;h2&gt;Smart Classifiers&lt;/h2&gt;
&lt;p&gt;We are going to make somem smart predictors.  By smart I mean genertic, untuned, machine learning algorithms.   We will try a Logistic Regression, Support Vector Machine, Random Forest, Gradient Boosting, and AdaBoost methods and compare their results.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;confusion_matrix&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.ensemble&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;GradientBoostingClassifier&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;AdaBoostClassifier&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.svm&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SVC&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;StandardScaler&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cross_validation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;

&lt;span class="n"&gt;smart_classifiers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;LogisticRegression&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="n"&gt;SVC&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;probability&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;GradientBoostingClassifier&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;AdaBoostClassifier&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Because sklearn's confusion matrix calculation is in a different format that I was expecting, we built a helper function to calculate the rate and format it into the form we were expencting&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def confusion_rates(matrix):
    new = np.zeros(matrix.shape)
    new[0,0] = matrix[1,1]
    new[1,1] = matrix[0,0]
    new[1,0] = matrix[1,0]
    new[0,1] = matrix[0,1]
    return new.astype(float)/np.sum(new,axis=0)

confusion_rates(np.array([[94,6],[96,4]]))




array([[ 0.04,  0.06],
       [ 0.96,  0.94]])
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Profit Curves Theory&lt;/h2&gt;
&lt;p&gt;The idea behind the profit curves we are producing is that each classifier is fitted to training data.   Then test data is given to the classifier, the classifier predicts if it is a positive example or negative example.   The classifieres we are testing also estimate how strongly the algorithm believes each instance is a positive example (or negative example).    &lt;/p&gt;
&lt;p&gt;We can now take the strength of these believes and asked the question:  If we only take the test example with the strongest belief as a positive example, and guess that all other test examples as negative example, how profitable is this. We should get something close to zero in our churn example.&lt;/p&gt;
&lt;p&gt;We can then ask the question for the two strongest predictions, then the three strongest predictions, and so on.  We do this until we just guess everything is a positive example.   That would lead us back to the -6 dollar profits in our churn model.  &lt;/p&gt;
&lt;h3&gt;Example&lt;/h3&gt;
&lt;p&gt;$$truth = [1, \ 1, \ 0, \ 0, \ 1]$$
$$ \mbox{model 1} = [0.9, \ 0.4, \ 0.2, \ 0.8, \ 0.7] $$
$$\mbox{model 2} = [0.8, \ 0.7, \ 0.2, \ 0.3, \ 0.6] $$&lt;/p&gt;
&lt;p&gt;Model 1 and Model 2 have the same strongest predictor, so we would precict the following for our first question:&lt;/p&gt;
&lt;p&gt;$$ \mbox{model 1} = [1, \ 0, \ 0, \ 0, \ 0]$$
$$ \mbox{model 2} = [1, \ 0, \ 0, \ 0, \ 0]$$&lt;/p&gt;
&lt;p&gt;Leading to the confusion matrix:&lt;/p&gt;
&lt;p&gt;$$ \left( \begin{array}{cc}  1 &amp;amp; 0 \ 2 &amp;amp; 1 \end{array} \right) =&amp;gt; \left( \begin{array}{cc}  0.33 &amp;amp; 0 \ 0.67 &amp;amp; 1 \end{array} \right) $$&lt;/p&gt;
&lt;p&gt;We have the proportion of positive examples $P_+ = 0.6$ and $P_- = 0.4$.  That leads to the classification rates of:&lt;/p&gt;
&lt;p&gt;$$\left( \begin{array}{cc}  0.2 &amp;amp; 0 \ 0.4 &amp;amp; 0.4 \end{array} \right) $$&lt;/p&gt;
&lt;p&gt;Using the cost matrix from the Data Science for Business School of 4 dollars profit for true positives and -5 dollars profit for false positives we get a profit matrix of:&lt;/p&gt;
&lt;p&gt;$$\left( \begin{array}{cc}  0.8 &amp;amp; 0 \ 0 &amp;amp; 0 \end{array} \right) $$&lt;/p&gt;
&lt;p&gt;For if we only take the strongest predictor we expect an average profit of 0.8 per costomer for both models.&lt;/p&gt;
&lt;p&gt;$$E(\mbox{Profit}) = 0.8 + 0 + 0 + 0 = 0.8$$&lt;/p&gt;
&lt;p&gt;We can now ask the second question of what is the expected profit if we take two two strongest predictors.  In this case we have the following predecitions:&lt;/p&gt;
&lt;p&gt;$$ \mbox{model 1} = [1, \ 0, \ 0, \ 1, \ 0]$$
$$ \mbox{model 2} = [1, \ 1, \ 0, \ 0, \ 0]$$&lt;/p&gt;
&lt;p&gt;Now the two models make different predictions!&lt;/p&gt;
&lt;p&gt;The confusion matrix for model 1 (left) and model 2 (right) right are next. &lt;/p&gt;
&lt;p&gt;$$ \left( \begin{array}{cc}  1 &amp;amp; 1 \ 2 &amp;amp; 1 \end{array} \right) \ ,  \ \left( \begin{array}{cc}  2 &amp;amp; 0 \ 1 &amp;amp; 2 \end{array} \right) $$&lt;/p&gt;
&lt;p&gt;The rate matrixes become:&lt;/p&gt;
&lt;p&gt;$$ \left( \begin{array}{cc}  0.33 &amp;amp; .5 \ .67 &amp;amp; .5 \end{array} \right) \ , \ \left( \begin{array}{cc}  0.67 &amp;amp; 0 \ 0.33 &amp;amp; 1 \end{array} \right) $$&lt;/p&gt;
&lt;p&gt;The population proportions have not changed. The proportion of positive examples $P_+ = 0.6$ and $P_- = 0.4$. &lt;/p&gt;
&lt;p&gt;$$\left( \begin{array}{cc}  0.2 &amp;amp; 0.2 \ 0.4 &amp;amp; 0.2 \end{array} \right) \ , \ \left( \begin{array}{cc}  0.4 &amp;amp; 0 \ 0.2 &amp;amp; 0.4 \end{array} \right) $$&lt;/p&gt;
&lt;p&gt;That then makes the final profit matrix look like:&lt;/p&gt;
&lt;p&gt;$$\left( \begin{array}{cc}  0.8 &amp;amp; -1 \ 0 &amp;amp; 0 \end{array} \right) \ , \ \left( \begin{array}{cc}  1.6 &amp;amp; 0 \ 0 &amp;amp; 0 \end{array} \right)  $$&lt;/p&gt;
&lt;p&gt;Now there is a clear difference in the models if we take the two strongest predictors.&lt;/p&gt;
&lt;p&gt;$$E(\mbox{Profit Model 1}) = 0.8 + -1 + 0 + 0 = -0.2$$&lt;/p&gt;
&lt;p&gt;$$E(\mbox{Profit Model 2}) = 1.6 + 0 + 0 + 0 = 1.6$$&lt;/p&gt;
&lt;p&gt;Model 2 is much better model if we limit ourselves to the two strongest predictions.  To find the most profitable model, we should conditinue to do these calcuations.  Becausse they are so repetative, its time for some automation&lt;/p&gt;
&lt;h2&gt;Plotting Profit Curves&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="s-Atom"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;profit_curve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;classifiers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;cb&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;
    &lt;span class="s-Atom"&gt;#split&lt;/span&gt; &lt;span class="s-Atom"&gt;data&lt;/span&gt; &lt;span class="s-Atom"&gt;into&lt;/span&gt; &lt;span class="s-Atom"&gt;a&lt;/span&gt; &lt;span class="s-Atom"&gt;training&lt;/span&gt; &lt;span class="s-Atom"&gt;and&lt;/span&gt; &lt;span class="s-Atom"&gt;test&lt;/span&gt; &lt;span class="s-Atom"&gt;set&lt;/span&gt;
    &lt;span class="s-Atom"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;test_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.35&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="s-Atom"&gt;#get&lt;/span&gt; &lt;span class="s-Atom"&gt;the&lt;/span&gt; &lt;span class="s-Atom"&gt;true&lt;/span&gt; &lt;span class="s-Atom"&gt;proportions&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="s-Atom"&gt;the&lt;/span&gt; &lt;span class="s-Atom"&gt;test&lt;/span&gt; &lt;span class="s-Atom"&gt;set&lt;/span&gt;
    &lt;span class="s-Atom"&gt;p_pos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;y_test&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nf"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nf"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="s-Atom"&gt;p_neg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="s-Atom"&gt;p_pos&lt;/span&gt;

    &lt;span class="s-Atom"&gt;#scale&lt;/span&gt; &lt;span class="s-Atom"&gt;the&lt;/span&gt; &lt;span class="s-Atom"&gt;training&lt;/span&gt; &lt;span class="s-Atom"&gt;data&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="s-Atom"&gt;important&lt;/span&gt; &lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;some&lt;/span&gt; &lt;span class="s-Atom"&gt;classifiers&lt;/span&gt; &lt;span class="s-Atom"&gt;and&lt;/span&gt; &lt;span class="s-Atom"&gt;to&lt;/span&gt; &lt;span class="s-Atom"&gt;get&lt;/span&gt; &lt;span class="s-Atom"&gt;consistent&lt;/span&gt; &lt;span class="s-Atom"&gt;results&lt;/span&gt;
    &lt;span class="s-Atom"&gt;s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;StandardScaler&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="s-Atom"&gt;xtrn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;s&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="s-Atom"&gt;xtst&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;s&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;c&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="nn"&gt;classifiers&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="s-Atom"&gt;prob&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;xtrn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nf"&gt;predict_proba&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;xtst&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

        &lt;span class="s-Atom"&gt;#&lt;/span&gt;&lt;span class="nv"&gt;Get&lt;/span&gt; &lt;span class="s-Atom"&gt;the&lt;/span&gt; &lt;span class="s-Atom"&gt;indexes&lt;/span&gt; &lt;span class="s-Atom"&gt;of&lt;/span&gt; &lt;span class="s-Atom"&gt;the&lt;/span&gt; &lt;span class="s-Atom"&gt;data&lt;/span&gt; &lt;span class="s-Atom"&gt;most&lt;/span&gt; &lt;span class="s-Atom"&gt;likely&lt;/span&gt; &lt;span class="s-Atom"&gt;to&lt;/span&gt; &lt;span class="s-Atom"&gt;be&lt;/span&gt; &lt;span class="s-Atom"&gt;positive&lt;/span&gt;
        &lt;span class="s-Atom"&gt;indicies&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;prob&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="s-Atom"&gt;::-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="s-Atom"&gt;costs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="s-Atom"&gt;x_axis&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="s-Atom"&gt;#&lt;/span&gt;&lt;span class="nv"&gt;For&lt;/span&gt; &lt;span class="s-Atom"&gt;each&lt;/span&gt; &lt;span class="s-Atom"&gt;data&lt;/span&gt; &lt;span class="s-Atom"&gt;point&lt;/span&gt;
        &lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;i&lt;/span&gt; &lt;span class="s-Atom"&gt;in&lt;/span&gt; &lt;span class="nn"&gt;indicies&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;

            &lt;span class="s-Atom"&gt;#predict&lt;/span&gt; &lt;span class="s-Atom"&gt;the&lt;/span&gt; &lt;span class="s-Atom"&gt;all&lt;/span&gt; &lt;span class="s-Atom"&gt;probabilities&lt;/span&gt; &lt;span class="s-Atom"&gt;above&lt;/span&gt; &lt;span class="s-Atom"&gt;the&lt;/span&gt; &lt;span class="s-Atom"&gt;ith&lt;/span&gt; &lt;span class="s-Atom"&gt;strongest&lt;/span&gt; &lt;span class="s-Atom"&gt;predicters&lt;/span&gt; &lt;span class="o"&gt;is&lt;/span&gt; &lt;span class="s-Atom"&gt;positive&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;else&lt;/span&gt; &lt;span class="s-Atom"&gt;negative&lt;/span&gt;
            &lt;span class="s-Atom"&gt;y_pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;prob&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="s-Atom"&gt;prob&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]).&lt;/span&gt;&lt;span class="nf"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

            &lt;span class="s-Atom"&gt;#calculate&lt;/span&gt; &lt;span class="s-Atom"&gt;the&lt;/span&gt; &lt;span class="s-Atom"&gt;confusion&lt;/span&gt; &lt;span class="s-Atom"&gt;matrix&lt;/span&gt; &lt;span class="s-Atom"&gt;for&lt;/span&gt; &lt;span class="s-Atom"&gt;the&lt;/span&gt; &lt;span class="s-Atom"&gt;predictions&lt;/span&gt;
            &lt;span class="s-Atom"&gt;matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;confusion_rates&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;confusion_matrix&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="s-Atom"&gt;#matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;nan_to_num&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

            &lt;span class="s-Atom"&gt;#calculate&lt;/span&gt; &lt;span class="s-Atom"&gt;the&lt;/span&gt; &lt;span class="s-Atom"&gt;cost&lt;/span&gt; &lt;span class="s-Atom"&gt;matrix&lt;/span&gt; &lt;span class="s-Atom"&gt;through&lt;/span&gt; &lt;span class="s-Atom"&gt;element&lt;/span&gt; &lt;span class="s-Atom"&gt;wise&lt;/span&gt; &lt;span class="s-Atom"&gt;product&lt;/span&gt; &lt;span class="s-Atom"&gt;and&lt;/span&gt; &lt;span class="s-Atom"&gt;sum&lt;/span&gt;
            &lt;span class="s-Atom"&gt;cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="s-Atom"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="s-Atom"&gt;cb&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nf"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="s-Atom"&gt;p_pos&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="s-Atom"&gt;p_neg&lt;/span&gt;&lt;span class="p"&gt;]])))&lt;/span&gt;

            &lt;span class="s-Atom"&gt;#append&lt;/span&gt; &lt;span class="s-Atom"&gt;the&lt;/span&gt; &lt;span class="s-Atom"&gt;cost&lt;/span&gt; &lt;span class="s-Atom"&gt;and&lt;/span&gt; &lt;span class="s-Atom"&gt;proportion&lt;/span&gt; &lt;span class="s-Atom"&gt;of&lt;/span&gt; &lt;span class="s-Atom"&gt;test&lt;/span&gt; &lt;span class="s-Atom"&gt;predictions&lt;/span&gt; &lt;span class="s-Atom"&gt;we&lt;/span&gt; &lt;span class="s-Atom"&gt;set&lt;/span&gt; &lt;span class="s-Atom"&gt;positive&lt;/span&gt;
            &lt;span class="s-Atom"&gt;x_axis&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nf"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nf"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="s-Atom"&gt;costs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="s-Atom"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;prob&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;indicies&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;costs&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="s-Atom"&gt;::-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]]]&lt;/span&gt;

        &lt;span class="s-Atom"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;x_axis&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;costs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s-Atom"&gt;c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;__&lt;/span&gt;&lt;span class="s-Atom"&gt;class__&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;__&lt;/span&gt;&lt;span class="s-Atom"&gt;name__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;



&lt;span class="s-Atom"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;figsize=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nf"&gt;profit_curve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;smart_classifiers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;profit_matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s-Atom"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s-Atom"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="s-Atom"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;&amp;#39;Expected Profit Rate&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s-Atom"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;&amp;#39;% Test Predictions Set Positive&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s-Atom"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D5/output_14_0.png" /&gt;&lt;/p&gt;
&lt;h2&gt;Analysis&lt;/h2&gt;
&lt;p&gt;The plots we have generated match our intuition we developed.  If we do not guess anyone churns (left), then we expect the profit to be zero.   If we guess everyone churns (right), we expect the profit to be -6.  The acutal value is different be the actual proportion in the test set is different from 14%.  Inbetween we are using smart classifier to predict who will churn and who will not churn.  Even the worst model leads to some profitability, which is promising for our cell phone company.   &lt;/p&gt;
&lt;p&gt;The best model, in this trial, is the GradientBoostingClassifier, followed closely by the Support Vector Machine and Randome Forest.  The peak profitability for all the models seem to be taking the 18% of strongest predictors in the models.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.35)

#Prediction Probabilities on the test set
probs = GradientBoostingClassifier().fit(x_train,y_train).predict_proba(x_test)[:,1]

#class probabilities ~ [.14,.86]
class_prob = np.array([sum(y_test).astype(float)/len(y_test), sum(y_test==0).astype(float)/len(y_test) ])

#get the cutoff for the tope 18%, 100-18 - 82
percentile = np.percentile(probs,82)
print &amp;quot;If probabibility is larger than this predict Churn:&amp;quot;, percentile
y_pred = (probs &amp;gt;= percentile).astype(int)
rates = confusion_rates(confusion_matrix(y_test,y_pred))

print &amp;quot;Predicted Profit Rate:&amp;quot;, np.sum(rates*class_prob*profit_matrix)

print &amp;quot;% Costomers Affected/Targed, %of Correct Costomers:&amp;quot;, np.sum((rates*class_prob)[0]),(rates*class_prob)[0,0]

If probabibility is larger than this predict Churn: 0.184275129582
Predicted Profit Rate: 6.51242502142
% Costomers Affected/Targed, %of Correct Costomers: 0.179948586118 0.101113967438
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For our gradient model we will predict a costomer to be likely churn if their prediciton probability is above 0.18, and we have expected profit rate of $6.5/prediction.   We estimate that we will target approximately 18% of our costomers using this model, with 10% of them being the group we want to target.&lt;/p&gt;
&lt;p&gt;If we have an unlimited budget, or a budget larger than the cost of targeting every costomer, then we would choose this model.  &lt;/p&gt;
&lt;p&gt;If we have a limited budget that want to be profitable (near term) but are willing to not persue maximal profit to reach the largest number of customers and reduce churn, then we will want a differnet strategy.  Because the cost of targeting a customer is fixed, we will want to optimize precision by moving to the left of the graph.  In our case of the cell phone churn, the the top models move in lock-step.   &lt;/p&gt;
&lt;p&gt;We would just increase the threshold for our GradientBoostedClassifier.  If we increase the threshold to be the top 10% of predictions instead of the top 18%, we get reduce profitability but increase targeting rate.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;#Prediction Probabilities on the test set
probs = GradientBoostingClassifier().fit(x_train,y_train).predict_proba(x_test)[:,1]

#class probabilities ~ [.14,.86]
class_prob = np.array([sum(y_test).astype(float)/len(y_test), sum(y_test==0).astype(float)/len(y_test) ])

#get the cutoff for the tope 18%, 100-18 - 82
percentile = np.percentile(probs,92)
print &amp;quot;If probabibility is larger than this predict Churn:&amp;quot;, percentile
y_pred = (probs &amp;gt;= percentile).astype(int)
rates = confusion_rates(confusion_matrix(y_test,y_pred))

print &amp;quot;Predicted Profit Rate:&amp;quot;, np.sum(rates*class_prob*profit_matrix)

print &amp;quot;% Costomers Affected/Targed, %of Correct Costomers:&amp;quot;, np.sum((rates*class_prob)[0]),(rates*class_prob)[0,0]

If probabibility is larger than this predict Churn: 0.5623562992
Predicted Profit Rate: 5.8440445587
% Costomers Affected/Targed, %of Correct Costomers: 0.0805484147386 0.0745501285347
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here, our expected profit drops to 5.8 from 6.5, and our threshold is increased to 0.56.   What we like to see is now we are only targeting 8% of our customers, but 7.5% of them are the ones we want to target.  That takes our precision to approximately 93% from 56%.  We are not getting the most profit, but we are spending our money in the most targeted way in this campaign.  If we know what percentage of our customers we can target with our budget, we can move down the curve and clacluate our expected results.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;10.1/17.99, 0.07455/0.08055




(0.5614230127848805, 0.9255121042830541)
&lt;/pre&gt;&lt;/div&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="Profit Curves"></category></entry><entry><title>Galvanize - Week 04 - Day 4</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-04-04/" rel="alternate"></link><updated>2015-06-25T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-25:galvanize/galvanize-data-science-04-04/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 4 - Day 4&lt;/h2&gt;
&lt;p&gt;Our quiz today had to do with the birthday problem and another problem that involved two hunting hounds.  The question was if there are two hunting hounds that successfully track with a probability p, is the strategy of following both hounds if they go in the same direction on a fork in the round, otherwise randomly guessing, better then just following 1 hound?  &lt;/p&gt;
&lt;p&gt;The probability of both hounds being successful and matching is $p^2$ and the probability of both hounds matching and being unsuccessful is $(1-p)^2$.   The probability of not matching is $2p(1-p)$, and half of each time the hunter will randomly pick correct.  The exepected odds of success is $p^2 + p(1-p) = p^2 + p - p^2 = p$, the same as following one hound.   When I first read the problem I was not expecting that solution.   I like when I see something I was not expected!&lt;/p&gt;
&lt;h2&gt;Morning Boosting&lt;/h2&gt;
&lt;p&gt;This morning we discussed boosting, and our morning sprint was to predict the bosting house prices using boosting on regression classifieres in &lt;a href="http://scikit-learn.org/stable/"&gt;sklearn&lt;/a&gt;.   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.tree&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DecisionTreeRegressor&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.ensemble&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RandomForestRegressor&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.ensemble&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;GradientBoostingRegressor&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.ensemble&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;AdaBoostRegressor&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;load_boston&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cross_validation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cross_val_score&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.grid_search&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;GridSearchCV&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;mean_squared_error&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;r2_score&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.ensemble.partial_dependence&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;plot_partial_dependence&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;

&lt;span class="n"&gt;boston&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_boston&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c"&gt;# House Prices&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;boston&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;
&lt;span class="c"&gt;# The other 13 features&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;boston&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;

&lt;span class="c"&gt;#train and test set&lt;/span&gt;
&lt;span class="n"&gt;x_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;test_size&lt;/span&gt;&lt;span class="o"&gt;=.&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])):&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;steelblue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;marker&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;o&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D4/output_1_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;For this sprint we really are not concerned with the distributions, but I still like to plot.   We see the house prices targets vary from 5 to 50.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pd.Series(y).describe()




count    506.000000
mean      22.532806
std        9.197104
min        5.000000
25%       17.025000
50%       21.200000
75%       25.000000
max       50.000000
dtype: float64




print &amp;quot;MSE From Average: &amp;quot;, np.sum(np.power(y-y.mean(),2))/len(y)

MSE From Average:  84.4195561562
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now that we have some baselines, we can now start to train our regressors and compare thier performance.  For this first trail I am going to make a Random Forest, GradientBoostingRegressor, and a AdaBoostRegressor.   I will be comparing the cross validated MSE and $r^2$ on the training set.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;rf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomForestRegressor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="n"&gt;n_jobs&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;gdbr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GradientBoostingRegressor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=.&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                 &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ls&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                 &lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                 &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;abr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AdaBoostRegressor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;DecisionTreeRegressor&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
                        &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;linear&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;mse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;mean_squared_error&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;mean_squared_error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;r2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;r2_score&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;power&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;power&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;rf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__class__&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__name__&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;cross_val_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;scoring&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;mse&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;cv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="n"&gt;cross_val_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;scoring&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;r2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;cv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;gdbr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__class__&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__name__&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;cross_val_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gdbr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;scoring&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;mse&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;cv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="n"&gt;cross_val_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gdbr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;scoring&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;r2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;cv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;abr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__class__&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__name__&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;cross_val_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;abr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;scoring&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;mse&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;cv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="n"&gt;cross_val_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;abr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;scoring&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;r2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;cv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;



&lt;span class="n"&gt;RandomForestRegressor&lt;/span&gt; &lt;span class="mf"&gt;11.6404925079&lt;/span&gt; &lt;span class="mf"&gt;0.848311635198&lt;/span&gt;
&lt;span class="n"&gt;GradientBoostingRegressor&lt;/span&gt; &lt;span class="mf"&gt;9.78445216743&lt;/span&gt; &lt;span class="mf"&gt;0.871926100237&lt;/span&gt;
&lt;span class="n"&gt;AdaBoostRegressor&lt;/span&gt; &lt;span class="mf"&gt;11.757802439&lt;/span&gt; &lt;span class="mf"&gt;0.846590661377&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The 10 fold cross validation on the training set gives MSE of order 10, much smaller than the naive estimate of 80.   All three of these models are doing well on the training set.   I would not pick one model over until I have tested them on the hold out set.  We can plot the performance of these models as we trained them.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;stage_score_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;mean_squared_error&lt;/span&gt;
    &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;train_y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;mse_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mean_squared_error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;yy&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;staged_predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_x&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="n"&gt;mse_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mean_squared_error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;yy&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;staged_predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_x&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="n"&gt;xx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mse_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__class__&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot; {} - Learning Rate &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;mse_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Train&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;mse_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Test&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Number of Iterations&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Mean Square Error&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;stage_score_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gdbr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D4/output_8_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;Looking at the Gradient Boosting Regressor we see that as we add more weak learners/iterations, the training and test error drop together.  The Training error is still dropping, but the test error has leveled off around 8.  This result is also affected by the learning rate.  If we change it we get different results.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure(figsize=(14,10))
stage_score_plot(GradientBoostingRegressor(learning_rate=.1,loss=&amp;#39;ls&amp;#39;, n_estimators=100, random_state=1), x_trn, y_trn, x_test, y_test)
stage_score_plot(GradientBoostingRegressor(learning_rate=1,loss=&amp;#39;ls&amp;#39;, n_estimators=100, random_state=1), x_trn, y_trn, x_test, y_test)
plt.legend()
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D4/output_10_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;The higher learning rate leads to over fitting.   The training error goes to zero almost immediately, but the error on the test set is very high.&lt;/p&gt;
&lt;p&gt;We can also lower the learning rate.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure(figsize=(16,8))
plt.subplot(1,2,1)
stage_score_plot(GradientBoostingRegressor(learning_rate=.1,loss=&amp;#39;ls&amp;#39;, n_estimators=100, random_state=1), x_trn, y_trn, x_test, y_test)
stage_score_plot(GradientBoostingRegressor(learning_rate=.01,loss=&amp;#39;ls&amp;#39;, n_estimators=100, random_state=1), x_trn, y_trn, x_test, y_test)
plt.legend()
plt.subplot(1,2,2)
stage_score_plot(GradientBoostingRegressor(learning_rate=.1,loss=&amp;#39;ls&amp;#39;, n_estimators=1000, random_state=1), x_trn, y_trn, x_test, y_test)
stage_score_plot(GradientBoostingRegressor(learning_rate=.01,loss=&amp;#39;ls&amp;#39;, n_estimators=1000, random_state=1), x_trn, y_trn, x_test, y_test)
plt.legend()
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D4/output_12_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;In this case we see that the test error levels off to the same place for these two rates, but the lower learning rate takes more iterations to get there.&lt;/p&gt;
&lt;p&gt;We can also compare the results of the gradient boosting to the random forest algorithm.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure(figsize=(14,10))
stage_score_plot(GradientBoostingRegressor(learning_rate=.1,loss=&amp;#39;ls&amp;#39;, n_estimators=100, random_state=1), x_trn, y_trn, x_test, y_test)
plt.axhline(y=mean_squared_error(rf.fit(x_trn,y_trn).predict(x_test),y_test),color=&amp;#39;orange&amp;#39;,lw=3,linestyle=&amp;#39;--&amp;#39;,label=&amp;#39;Random Forest Test&amp;#39;)
plt.legend()
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D4/output_15_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;The random forest does not have the stage predict function that allows you to retroactively calculate the predictions at each stage of the training.   The end result is that for the same number of estimators/iterations, the Gradient Boosting Regressor does better on the Boston dataset.  &lt;/p&gt;
&lt;p&gt;We can also look at the AdaBoostingRegessor because it does have stage predict.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure(figsize=(14,10))
plt.subplot(1,2,1)
stage_score_plot(AdaBoostRegressor(learning_rate=1,loss=&amp;#39;linear&amp;#39;, n_estimators=100, random_state=1), x_trn, y_trn, x_test, y_test)
stage_score_plot(AdaBoostRegressor(learning_rate=.1,loss=&amp;#39;linear&amp;#39;, n_estimators=100, random_state=1), x_trn, y_trn, x_test, y_test)
#stage_score_plot(AdaBoostRegressor(learning_rate=.01,loss=&amp;#39;linear&amp;#39;, n_estimators=100, random_state=1), x_trn, y_trn, x_test, y_test)
plt.axhline(y=mean_squared_error(rf.fit(x_trn,y_trn).predict(x_test),y_test),color=&amp;#39;orange&amp;#39;,linestyle=&amp;#39;--&amp;#39;,label=&amp;#39;Random Forest&amp;#39;)
plt.legend()
plt.subplot(1,2,2)
stage_score_plot(AdaBoostRegressor(learning_rate=1,loss=&amp;#39;linear&amp;#39;, n_estimators=1000, random_state=1), x_trn, y_trn, x_test, y_test)
stage_score_plot(AdaBoostRegressor(learning_rate=.1,loss=&amp;#39;linear&amp;#39;, n_estimators=1000, random_state=1), x_trn, y_trn, x_test, y_test)
#stage_score_plot(AdaBoostRegressor(learning_rate=.01,loss=&amp;#39;linear&amp;#39;, n_estimators=100, random_state=1), x_trn, y_trn, x_test, y_test)
plt.axhline(y=mean_squared_error(rf.fit(x_trn,y_trn).predict(x_test),y_test),color=&amp;#39;orange&amp;#39;,linestyle=&amp;#39;--&amp;#39;,label=&amp;#39;Random Forest&amp;#39;)
plt.legend()
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D4/output_17_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;In this case the AdaBoostRegressor does not do better than RandomForest on the test set.  Even allowing for more iterations (which takes a fair amoutn of time to fit).   We are using the naive parameters to fit the model.  We should really search for the best parameters in each model.&lt;/p&gt;
&lt;h2&gt;Grid Search&lt;/h2&gt;
&lt;p&gt;The goal of grid searching is to fit the model using different parameters, and choose the result that has the best cross validated score.   This is not guaranteed to give the best results, but currently I do not know a better way to tune a model.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;random_forest_grid = {&amp;#39;max_depth&amp;#39;: [3, None],
                      &amp;#39;max_features&amp;#39;: [&amp;#39;sqrt&amp;#39;, &amp;#39;log2&amp;#39;, None],
                      &amp;#39;min_samples_split&amp;#39;: [1, 2, 4],
                      &amp;#39;min_samples_leaf&amp;#39;: [1, 2, 4],
                      &amp;#39;bootstrap&amp;#39;: [True, False],
                      &amp;#39;n_estimators&amp;#39;: [40, 80, 160, 320],
                      &amp;#39;random_state&amp;#39;: [1]}

rf_gridsearch = GridSearchCV(RandomForestRegressor(),
                             random_forest_grid,
                             n_jobs=-1,
                             verbose=True,
                             scoring=&amp;#39;mean_squared_error&amp;#39;)
rf_gridsearch.fit(x_trn, y_trn)

print &amp;quot;best parameters:&amp;quot;, rf_gridsearch.best_params_
print &amp;quot;best score:&amp;quot;,rf_gridsearch.best_score_
best_rf_model = rf_gridsearch.best_estimator_


Fitting 3 folds for each of 432 candidates, totalling 1296 fits


[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.1s
[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:    1.9s
[Parallel(n_jobs=-1)]: Done 200 jobs       | elapsed:    8.2s
[Parallel(n_jobs=-1)]: Done 450 jobs       | elapsed:   19.9s
[Parallel(n_jobs=-1)]: Done 800 jobs       | elapsed:   42.4s
[Parallel(n_jobs=-1)]: Done 1250 jobs       | elapsed:  1.2min
[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed:  1.3min finished


best parameters: {&amp;#39;bootstrap&amp;#39;: True, &amp;#39;min_samples_leaf&amp;#39;: 1, &amp;#39;n_estimators&amp;#39;: 40, &amp;#39;min_samples_split&amp;#39;: 1, &amp;#39;random_state&amp;#39;: 1, &amp;#39;max_features&amp;#39;: &amp;#39;sqrt&amp;#39;, &amp;#39;max_depth&amp;#39;: None}
best score: -14.0843113088
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can see the MSE is negative, but that is an artifact of the fit used by sklearn.  The MSE is just the absolute value of that parameter.   We can use the best model from the search and get a feel for the results on the test set.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;mean_squared_error(best_rf_model.predict(x_test),y_test),mean_squared_error(RandomForestRegressor().fit(x_trn,y_trn).predict(x_test),y_test)




(12.737843504901965, 9.5049568627450984)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Our tuned random forest did worse on the test set than our untuned model.  We would need to estimate the uncertainty of the MSE of both classifiers to get a feel for if this is a statisically significant difference. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gb_grid = {&amp;#39;learning_rate&amp;#39;: [1,0.1,0.01],
                      &amp;#39;max_depth&amp;#39;: [2,4,6],
                      &amp;#39;min_samples_leaf&amp;#39;: [1, 2, 4],
                      &amp;#39;n_estimators&amp;#39;: [20, 40, 80, 160],
                      &amp;#39;max_features&amp;#39;: [&amp;#39;sqrt&amp;#39;,&amp;#39;log2&amp;#39;,None],
                      &amp;#39;random_state&amp;#39;: [1]}

gb_gridsearch = GridSearchCV(GradientBoostingRegressor(),
                             gb_grid,
                             n_jobs=-1,
                             verbose=True,
                             scoring=&amp;#39;mean_squared_error&amp;#39;)
gb_gridsearch.fit(x_trn, y_trn)

print &amp;quot;best parameters:&amp;quot;, gb_gridsearch.best_params_
print &amp;quot;best score:&amp;quot;, gb_gridsearch.best_score_
best_gb_model = gb_gridsearch.best_estimator_


Fitting 3 folds for each of 324 candidates, totalling 972 fits


[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.0s
[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:    0.3s
[Parallel(n_jobs=-1)]: Done 200 jobs       | elapsed:    1.8s
[Parallel(n_jobs=-1)]: Done 450 jobs       | elapsed:    4.7s
[Parallel(n_jobs=-1)]: Done 800 jobs       | elapsed:   10.7s
[Parallel(n_jobs=-1)]: Done 972 out of 972 | elapsed:   13.9s finished


best parameters: {&amp;#39;learning_rate&amp;#39;: 0.1, &amp;#39;min_samples_leaf&amp;#39;: 4, &amp;#39;n_estimators&amp;#39;: 160, &amp;#39;random_state&amp;#39;: 1, &amp;#39;max_features&amp;#39;: &amp;#39;sqrt&amp;#39;, &amp;#39;max_depth&amp;#39;: 4}
best score: -13.2445739497



mean_squared_error(best_gb_model.predict(x_test),y_test),mean_squared_error(GradientBoostingRegressor().fit(x_trn,y_trn).predict(x_test),y_test)




(10.363886409362564, 6.8593273937564954)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We see a similar result in the Gradient Boosting Regressor.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;ada_grid = {&amp;#39;base_estimator&amp;#39;: [best_gb_model,best_rf_model],
            &amp;#39;learning_rate&amp;#39;: [1,0.1,0.01],
            &amp;#39;n_estimators&amp;#39;: [20, 40, 80, 160],
            &amp;#39;random_state&amp;#39;: [1]}

ada_gridsearch = GridSearchCV(AdaBoostRegressor(),
                             ada_grid,
                             n_jobs=-1,
                             verbose=True,
                             scoring=&amp;#39;mean_squared_error&amp;#39;)
ada_gridsearch.fit(x_trn, y_trn)

print &amp;quot;best parameters:&amp;quot;, ada_gridsearch.best_params_
print &amp;quot;best score:&amp;quot;, ada_gridsearch.best_score_
best_ada_model = ada_gridsearch.best_estimator_


Fitting 3 folds for each of 24 candidates, totalling 72 fits


[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    1.6s
[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:  1.0min
[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:  1.6min finished


best parameters: {&amp;#39;n_estimators&amp;#39;: 20, &amp;#39;base_estimator&amp;#39;: GradientBoostingRegressor(alpha=0.9, init=None, learning_rate=0.1, loss=&amp;#39;ls&amp;#39;,
             max_depth=4, max_features=&amp;#39;sqrt&amp;#39;, max_leaf_nodes=None,
             min_samples_leaf=4, min_samples_split=2,
             min_weight_fraction_leaf=0.0, n_estimators=160,
             random_state=1, subsample=1.0, verbose=0, warm_start=False), &amp;#39;random_state&amp;#39;: 1, &amp;#39;learning_rate&amp;#39;: 0.1}
best score: -12.8839320317



mean_squared_error(best_ada_model.predict(x_test),y_test),mean_squared_error(AdaBoostRegressor().fit(x_trn,y_trn).predict(x_test),y_test)




(11.267204239234372, 12.438897032159721)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The AdaBoostRegressor did improve over the default values, but in the end they all gave around the same MSE on the test set using the Bosting Housing Data.  &lt;/p&gt;
&lt;h1&gt;Afternoon - AdaBoost&lt;/h1&gt;
&lt;p&gt;We started out the afternoon buliding our own AdaBoost Classification Algorithm, then we explored using sklearn's implementation to explore partial dependency plots.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.tree&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DecisionTreeClassifier&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.base&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;clone&lt;/span&gt;


&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;AdaBoostBinaryClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;    INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;    - n_estimator (int)&lt;/span&gt;
&lt;span class="sd"&gt;      * The number of estimators to use in boosting&lt;/span&gt;
&lt;span class="sd"&gt;      * Default: 50&lt;/span&gt;

&lt;span class="sd"&gt;    - learning_rate (float)&lt;/span&gt;
&lt;span class="sd"&gt;      * Determines how fast the error would shrink&lt;/span&gt;
&lt;span class="sd"&gt;      * Lower learning rate means more accurate decision boundary,&lt;/span&gt;
&lt;span class="sd"&gt;        but slower to converge&lt;/span&gt;
&lt;span class="sd"&gt;      * Default: 1&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                 &lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                 &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;base_estimator&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max_depth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n_estimator&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;n_estimators&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;

        &lt;span class="c"&gt;# Will be filled-in in the fit() step&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;estimators_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;estimator_weight_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n_estimator&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kp"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;        - x: 2d numpy array, feature matrix&lt;/span&gt;
&lt;span class="sd"&gt;        - y: numpy array, labels&lt;/span&gt;

&lt;span class="sd"&gt;        Build the estimators for the AdaBoost estimator.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n_estimator&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;estimator&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_boost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;estimators_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;estimator&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;estimator_weight_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;


    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_I&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;temp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y1&lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="n"&gt;y2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="c"&gt;#print temp&lt;/span&gt;
        &lt;span class="c"&gt;#return temp&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_boost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sample_weight&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;        - x: 2d numpy array, feature matrix&lt;/span&gt;
&lt;span class="sd"&gt;        - y: numpy array, labels&lt;/span&gt;
&lt;span class="sd"&gt;        - sample_weight: numpy array&lt;/span&gt;

&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;        - estimator: DecisionTreeClassifier&lt;/span&gt;
&lt;span class="sd"&gt;        - sample_weight: numpy array (updated weights)&lt;/span&gt;
&lt;span class="sd"&gt;        - estimator_weight: float (weight of estimator)&lt;/span&gt;

&lt;span class="sd"&gt;        Go through one iteration of the AdaBoost algorithm. Build one estimator.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

        &lt;span class="n"&gt;estimator&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;clone&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;base_estimator&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;estimator&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;sample_weight&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;sample_weight&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;ypred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;estimator&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;err_m&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sample_weight&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ypred&lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sample_weight&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;log&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;err_m&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;err_m&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


        &lt;span class="n"&gt;yp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;ypred&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="n"&gt;yy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sample_weight&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ypred&lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;estimator&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;


    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;        - x: 2d numpy array, feature matrix&lt;/span&gt;

&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;        - labels: numpy array of predictions (0 or 1)&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="n"&gt;pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;

        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;estimator&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;estimators_&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;pred&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;estimator_weight_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;estimator&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="c"&gt;#pred += self.estimator_weight_[i]*estimator.predict(x)&lt;/span&gt;

        &lt;span class="n"&gt;pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;pred&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;



    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;        - x: 2d numpy array, feature matrix&lt;/span&gt;
&lt;span class="sd"&gt;        - y: numpy array, labels&lt;/span&gt;

&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;        - score: float (accuracy score between 0 and 1)&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The above is our AdaBoost Classifory class.  We will be using it on spam data.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="s-Atom"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;genfromtxt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;&amp;#39;boosting/data/spam.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;delimiter=&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s-Atom"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="s-Atom"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s-Atom"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="s-Atom"&gt;train_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;test_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;train_y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;test_y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="s-Atom"&gt;my_ada&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;AdaBoostBinaryClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s-Atom"&gt;my_ada&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;train_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;train_y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s-Atom"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Accuracy:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;my_ada&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s-Atom"&gt;test_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s-Atom"&gt;test_y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nv"&gt;Accuracy&lt;/span&gt;&lt;span class="s-Atom"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt; &lt;span class="mf"&gt;0.&lt;/span&gt;  &lt;span class="mf"&gt;0.&lt;/span&gt;  &lt;span class="mf"&gt;1.&lt;/span&gt; &lt;span class="p"&gt;...,&lt;/span&gt;  &lt;span class="mf"&gt;1.&lt;/span&gt;  &lt;span class="mf"&gt;1.&lt;/span&gt;  &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="mf"&gt;0.917463075586&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Our out of the box score is around 92% accuracy.   We will be exploring feature importance using sklearn's implementation, so I will read in the naems from the clipboard.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;df = pd.read_clipboard()
names = df.values[:,0]
names




array([&amp;#39;word_freq_make:&amp;#39;, &amp;#39;word_freq_address:&amp;#39;, &amp;#39;word_freq_all:&amp;#39;,
       &amp;#39;word_freq_3d:&amp;#39;, &amp;#39;word_freq_our:&amp;#39;, &amp;#39;word_freq_over:&amp;#39;,
       &amp;#39;word_freq_remove:&amp;#39;, &amp;#39;word_freq_internet:&amp;#39;, &amp;#39;word_freq_order:&amp;#39;,
       &amp;#39;word_freq_mail:&amp;#39;, &amp;#39;word_freq_receive:&amp;#39;, &amp;#39;word_freq_will:&amp;#39;,
       &amp;#39;word_freq_people:&amp;#39;, &amp;#39;word_freq_report:&amp;#39;, &amp;#39;word_freq_addresses:&amp;#39;,
       &amp;#39;word_freq_free:&amp;#39;, &amp;#39;word_freq_business:&amp;#39;, &amp;#39;word_freq_email:&amp;#39;,
       &amp;#39;word_freq_you:&amp;#39;, &amp;#39;word_freq_credit:&amp;#39;, &amp;#39;word_freq_your:&amp;#39;,
       &amp;#39;word_freq_font:&amp;#39;, &amp;#39;word_freq_000:&amp;#39;, &amp;#39;word_freq_money:&amp;#39;,
       &amp;#39;word_freq_hp:&amp;#39;, &amp;#39;word_freq_hpl:&amp;#39;, &amp;#39;word_freq_george:&amp;#39;,
       &amp;#39;word_freq_650:&amp;#39;, &amp;#39;word_freq_lab:&amp;#39;, &amp;#39;word_freq_labs:&amp;#39;,
       &amp;#39;word_freq_telnet:&amp;#39;, &amp;#39;word_freq_857:&amp;#39;, &amp;#39;word_freq_data:&amp;#39;,
       &amp;#39;word_freq_415:&amp;#39;, &amp;#39;word_freq_85:&amp;#39;, &amp;#39;word_freq_technology:&amp;#39;,
       &amp;#39;word_freq_1999:&amp;#39;, &amp;#39;word_freq_parts:&amp;#39;, &amp;#39;word_freq_pm:&amp;#39;,
       &amp;#39;word_freq_direct:&amp;#39;, &amp;#39;word_freq_cs:&amp;#39;, &amp;#39;word_freq_meeting:&amp;#39;,
       &amp;#39;word_freq_original:&amp;#39;, &amp;#39;word_freq_project:&amp;#39;, &amp;#39;word_freq_re:&amp;#39;,
       &amp;#39;word_freq_edu:&amp;#39;, &amp;#39;word_freq_table:&amp;#39;, &amp;#39;word_freq_conference:&amp;#39;,
       &amp;#39;char_freq_;:&amp;#39;, &amp;#39;char_freq_(:&amp;#39;, &amp;#39;char_freq_[:&amp;#39;, &amp;#39;char_freq_!:&amp;#39;,
       &amp;#39;char_freq_$:&amp;#39;, &amp;#39;char_freq_#:&amp;#39;, &amp;#39;capital_run_length_average:&amp;#39;,
       &amp;#39;capital_run_length_longest:&amp;#39;, &amp;#39;capital_run_length_total:&amp;#39;], dtype=object)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To explore this we want to get a feel for the misclassification error of databoost.  We redefined our plot function to score misclassification instead of MSE.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;stage_score_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;
    &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;train_y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;acc_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;yy&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;staged_predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_x&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="n"&gt;acc_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;yy&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;staged_predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_x&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="n"&gt;xx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;acc_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__class__&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot; {} - Learning Rate &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;acc_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Train&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;acc_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Test&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Number of Iterations&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Misclassification&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.ensemble&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;AdaBoostClassifier&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;GradientBoostingClassifier&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.tree&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DecisionTreeClassifier&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;clf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AdaBoostClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max_depth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;stage_score_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;train_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;clf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GradientBoostingClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;stage_score_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;train_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;clf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GradientBoostingClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;max_depth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;stage_score_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;train_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;clf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AdaBoostClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max_depth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;stage_score_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;train_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;clf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GradientBoostingClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;max_depth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;stage_score_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;train_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;clf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GradientBoostingClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;max_depth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;stage_score_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;train_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D4/output_36_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D4/output_36_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;The top plot shows AdaBoost vs GradientBoosting with differnt max depths set.   The Ada performas better on the test set.  As we increase the depth of the trees used in the GradientBoosting, we see in the bottom plot the over fitting is abundant.   We need to have week learners to get optimal results with this method.  A strong learner will still overfit the data when boosted.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.grid_search&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;GridSearchCV&lt;/span&gt;

&lt;span class="n"&gt;gb_grid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;learning_rate&amp;#39;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
           &lt;span class="s"&gt;&amp;#39;n_estimators&amp;#39;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
           &lt;span class="s"&gt;&amp;#39;max_depth&amp;#39;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
           &lt;span class="s"&gt;&amp;#39;max_features&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sqrt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;log2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
           &lt;span class="s"&gt;&amp;#39;random_state&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]}&lt;/span&gt;

&lt;span class="n"&gt;gb_gridsearch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GridSearchCV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;GradientBoostingClassifier&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
                             &lt;span class="n"&gt;gb_grid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                             &lt;span class="n"&gt;n_jobs&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                             &lt;span class="n"&gt;verbose&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                             &lt;span class="n"&gt;scoring&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;gb_gridsearch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;best parameters:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gb_gridsearch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_params_&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;best score:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gb_gridsearch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_score_&lt;/span&gt;

&lt;span class="n"&gt;best_gb_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gb_gridsearch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_estimator_&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;
&lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;best_gb_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_x&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;test_y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;Fitting&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="n"&gt;folds&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;108&lt;/span&gt; &lt;span class="n"&gt;candidates&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;totalling&lt;/span&gt; &lt;span class="mi"&gt;324&lt;/span&gt; &lt;span class="n"&gt;fits&lt;/span&gt;


&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Parallel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_jobs&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]:&lt;/span&gt; &lt;span class="n"&gt;Done&lt;/span&gt;   &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;jobs&lt;/span&gt;       &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;elapsed&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;    &lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Parallel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_jobs&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]:&lt;/span&gt; &lt;span class="n"&gt;Done&lt;/span&gt;  &lt;span class="mi"&gt;50&lt;/span&gt; &lt;span class="n"&gt;jobs&lt;/span&gt;       &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;elapsed&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;    &lt;span class="mf"&gt;8.1&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Parallel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_jobs&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]:&lt;/span&gt; &lt;span class="n"&gt;Done&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt; &lt;span class="n"&gt;jobs&lt;/span&gt;       &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;elapsed&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="nb"&gt;min&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Parallel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_jobs&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]:&lt;/span&gt; &lt;span class="n"&gt;Done&lt;/span&gt; &lt;span class="mi"&gt;318&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;324&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;elapsed&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;1.5&lt;/span&gt;&lt;span class="nb"&gt;min&lt;/span&gt; &lt;span class="n"&gt;remaining&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;    &lt;span class="mf"&gt;1.7&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Parallel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_jobs&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]:&lt;/span&gt; &lt;span class="n"&gt;Done&lt;/span&gt; &lt;span class="mi"&gt;324&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;324&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;elapsed&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;1.6&lt;/span&gt;&lt;span class="nb"&gt;min&lt;/span&gt; &lt;span class="n"&gt;finished&lt;/span&gt;


&lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;parameters&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;max_features&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;log2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;n_estimators&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;learning_rate&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;random_state&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;max_depth&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.952463768116&lt;/span&gt;





&lt;span class="mf"&gt;0.95221546481320596&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is a good improvement over the previous model.   With GradientBoosting, we cal now explore which features are the most important features for identifying spam.&lt;/p&gt;
&lt;h2&gt;Feature Importance&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;indexes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;best_gb_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;feature_importances_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;fig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;x_ind&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;best_gb_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;feature_importances_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;barh&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_ind&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;best_gb_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;feature_importances_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;indexes&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="o"&gt;=.&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;align&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;center&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_ind&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;min&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_ind&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;max&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;yticks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_ind&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;names&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;indexes&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D4/output_40_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We see that use of excessive capitalizaiton and expclaimations are important for predicting spam.   The use of 'cs' or 'telnet' are not.   The use of a partial dependency plot allows us to get a feel for how changing the values of these features affect the outcome of the predictions.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.ensemble.partial_dependence&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;plot_partial_dependence&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.ensemble.partial_dependence&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;partial_dependence&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gca&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;indexes&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;partial_dependence&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;best_gb_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;train_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;grid_resolution&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="p"&gt;()),&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;names&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="c"&gt;#plot_partial_dependence(best_gb_model, train_x,indexes[:12],feature_names=names,n_jobs=3, grid_resolution=50,ax=ax)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bbox_to_anchor&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;1.25&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;1.005&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D4/output_42_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;As we increase the freq_lab or freq_address, we have a incrasing and decreasing accuracy of spam classification.  The parital dependency on these features is high.  Lab and telenet are also more than most, which is interesting because telent is low feature importance. &lt;/p&gt;
&lt;p&gt;It is possible to make 2D plots and 3D plots of partial dependancies.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.ensemble.partial_dependence&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;partial_dependence&lt;/span&gt;

&lt;span class="n"&gt;couple_of_tuples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;indexes&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;indexes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;plot_partial_dependence&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;best_gb_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;couple_of_tuples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;n_jobs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;grid_resolution&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D4/output_44_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;From these plots we can see that word-frequency has co-dependency with freq data and freq_parts &lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="Boosting"></category><category term="AdaBoost"></category><category term="GradientBoosting"></category><category term="machines"></category></entry><entry><title>Galvanize - Week 04 - Day 3</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-04-03/" rel="alternate"></link><updated>2015-06-24T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-24:galvanize/galvanize-data-science-04-03/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 4 - Day 3&lt;/h2&gt;
&lt;p&gt;Our quiz toda was about making change.  Given a sufficient amount US coins what is the minimum number of coins needed to give change for a specificied amount?   &lt;/p&gt;
&lt;p&gt;We were suppose to build a function to do this.  My solution was to sort the list of coins from largest to smallest.   We then make the maximum amount of change using the largest denomination, then continue this until we have given change back.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def find_change(coins,value):
    coins.sort(reverse=True)
    n = 0
    v = value
    for x in coins:
        m =  v / x
        n += m
        v = v - m*x       
    return n

coins = [1,5,10,25]
print &amp;quot;Correct Answer 4, Your Answer: &amp;quot;, find_change(coins,100)
print &amp;quot;Correct Answer 8, Your Answer: &amp;quot;,find_change(coins,74)

Correct Answer 4, Your Answer:  4
Correct Answer 8, Your Answer:  8
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After the quiz we had a lecture on Support Vector Machines.  The afternoon lecture was on kernel tricks for SVMs.   &lt;/p&gt;
&lt;h2&gt;Morning: Maximal Margin Classifier&lt;/h2&gt;
&lt;p&gt;We learned that a support vectore machine is a maximum margin classifier, trying to construct a hyper plane that maximize the margin of linearly seperable data.   &lt;/p&gt;
&lt;p&gt;To help get a feel between SVMs and other classifiers we looked up some made up data about the number of hours emailing and number of hours spent at the gym for a people labeled as a data scientist or not a data scientist.&lt;/p&gt;
&lt;p&gt;This dataset is special in that it is linearly seperable and easily displayed in two dimensions&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;

&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data/data_scientist.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data_scientist&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;scatter&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;email_hours&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gym_hours&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;steelblue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Not Data Scientist&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data_scientist&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;scatter&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;email_hours&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gym_hours&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;seagreen&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Data Scientist&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Hours Emailing&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Hours At Gym&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D3/(output_3_0.png" /&gt;&lt;/p&gt;
&lt;h2&gt;Margin of Logistic Regression Boundary&lt;/h2&gt;
&lt;p&gt;We learned previously that logistic regression minimizes the log-loss function:&lt;/p&gt;
&lt;p&gt;$$ - \ \sum_{i=1}^m [ \ y_i \ log(h_\theta (x_i)) \ + \ (1-y_i) \ log(1-h_\theta (x_i)) \ ]$$&lt;/p&gt;
&lt;p&gt;Where $$h_\theta(x) = \frac{1}{1+e^{x\theta}}$$.  &lt;/p&gt;
&lt;p&gt;This is different that explicitly maximizing the margin of a decision boundary.  &lt;/p&gt;
&lt;p&gt;We can fit a logistic regression model on our data that has 100% accuracy.  I have plotted the theta dotted the data on the x-axis, and the data scientist status on the y-axis.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;
&lt;span class="n"&gt;lin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fit_intercept&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;lin&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;email_hours&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gym_hours&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data_scientist&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;email_hours&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gym_hours&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lin&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coef_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;lin&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intercept_&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;z&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;z&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data_scientist&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;scatter&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;z&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data_scientist&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;steelblue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Not Data Scientist&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data_scientist&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;scatter&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;z&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data_scientist&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;seagreen&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Data Scientist&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;zp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;yp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;zp&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;yp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;indianred&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Logistic Fit&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Accuracy: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lin&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;email_hours&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gym_hours&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data_scientist&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D3/output_5_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;1.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Fun Fact!&lt;/h3&gt;
&lt;p&gt;I origianlly fit this without regulariaiton, but the algorithm was converging before finding the optimal solution.  I added a regularization term to make a better (100%) fit to the classification.  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Write a function to compute and plot the decision boundary. Remember &lt;code&gt;y&lt;/code&gt; is &lt;code&gt;0&lt;/code&gt; at the decision boundary when
   the probability of a positive class is &lt;code&gt;0.5&lt;/code&gt;. You should also define a range over one of your features (&lt;code&gt;gym_hours&lt;/code&gt;
   for example) and compute the &lt;code&gt;email_hours&lt;/code&gt; at the decision boundary.&lt;/p&gt;
&lt;p&gt;x = np.linspace(0,50,100)
y = np.linspace(0,50,100)
xx, yy = np.meshgrid(x,y)
Z = lin.predict(np.c_[xx.ravel(), yy.ravel()])
zz = Z.reshape(xx.shape)&lt;/p&gt;
&lt;h1&gt;zz = 1/(1+np.exp(xx&lt;em&gt;lin.coef_[0,0]+yy&lt;/em&gt;lin.coef_[0,1]+lin.intercept_))&lt;/h1&gt;
&lt;p&gt;extent = [0,50,0,50]
plt.figure(figsize=(14,8))
plt.pcolormesh(xx, yy, zz, cmap='winter',alpha=0.1, ) #plt.cm.Paired)&lt;/p&gt;
&lt;p&gt;ax = plt.subplot(1,1,1)&lt;/p&gt;
&lt;h1&gt;b = (0.5 - lin.intercept_)/lin.coef_[0,1]&lt;/h1&gt;
&lt;h1&gt;m = -lin.coef_[0,0]/lin.coef_[0,1]&lt;/h1&gt;
&lt;h1&gt;plt.plot(x,m*x+b,linestyle='--',color='black')&lt;/h1&gt;
&lt;p&gt;df[df.data_scientist==0].plot(kind='scatter',x='email_hours',y='gym_hours',color='steelblue',s=100,label='Not Data Scientist',alpha=0.8,ax=ax)
df[df.data_scientist==1].plot(kind='scatter',x='email_hours',y='gym_hours',color='seagreen',s=100,label='Data Scientist',alpha=0.8, ax=ax)
plt.xlim([0,50])
plt.ylim([0,50])
plt.xlabel('Hours Emailing')
plt.ylabel('Hours At Gym')
plt.legend(loc=2)
plt.show()&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D3/output_8_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;The distance each point is from the margin is given by the following equations &lt;/p&gt;
&lt;p&gt;$$\mbox{distance} = \frac{\beta_0+\beta x^T}{||\beta||}$$&lt;/p&gt;
&lt;p&gt;A line perpendicular to a line will always have a slope that is $\frac{1}{\mbox{slope}}.  We can use this equation and make our plot to illustrate the distance from the margin using the size property.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def distance(x,slopes,intercept):
    return (intercept+x.dot(slopes))/np.sqrt(intercept**2+slopes.T.dot(slopes))

df[&amp;#39;s&amp;#39;] = np.abs(250*distance(df[[&amp;#39;email_hours&amp;#39;,&amp;#39;gym_hours&amp;#39;]].values,lin.coef_.T,lin.intercept_))
x = np.linspace(0,50,100)
y = np.linspace(0,50,100)
xx, yy = np.meshgrid(x,y)
Z = lin.predict(np.c_[xx.ravel(), yy.ravel()])
zz = Z.reshape(xx.shape)
#zz = 1/(1+np.exp(xx*lin.coef_[0,0]+yy*lin.coef_[0,1]+lin.intercept_)) 
extent = [0,50,0,50]
plt.figure(figsize=(14,8))
plt.pcolormesh(xx, yy, zz, cmap=&amp;#39;winter&amp;#39;,alpha=0.1, ) #plt.cm.Paired)

ax = plt.subplot(1,1,1)
#b = (0.5 - lin.intercept_)/lin.coef_[0,1]
#m = -lin.coef_[0,0]/lin.coef_[0,1]
#plt.plot(x,m*x+b,linestyle=&amp;#39;--&amp;#39;,color=&amp;#39;black&amp;#39;)
df[df.data_scientist==0].plot(kind=&amp;#39;scatter&amp;#39;,x=&amp;#39;email_hours&amp;#39;,
                              y=&amp;#39;gym_hours&amp;#39;,color=&amp;#39;steelblue&amp;#39;,
                              s=df[df.data_scientist==0].s,
                              label=&amp;#39;Not Data Scientist&amp;#39;,
                              alpha=0.8,ax=ax)
df[df.data_scientist==1].plot(kind=&amp;#39;scatter&amp;#39;,x=&amp;#39;email_hours&amp;#39;,
                              y=&amp;#39;gym_hours&amp;#39;,color=&amp;#39;seagreen&amp;#39;,
                              s=df[df.data_scientist==1].s,
                              label=&amp;#39;Data Scientist&amp;#39;,alpha=0.8, 
                              ax=ax)
plt.xlim([0,50])
plt.ylim([0,50])
plt.xlabel(&amp;#39;Hours Emailing&amp;#39;)
plt.ylabel(&amp;#39;Hours At Gym&amp;#39;)
plt.legend(loc=2)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D3/output_11_0.png" /&gt;&lt;/p&gt;
&lt;h2&gt;Margin of Support Vector Machines&lt;/h2&gt;
&lt;p&gt;We learned that the SVM is a maximal margin classifier which in theory would have a larger margin than Logistic Regression. We will go through the same process that we just did for logistic regression.   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.svm&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SVC&lt;/span&gt;

&lt;span class="n"&gt;svc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SVC&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;linear&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;svc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;email_hours&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gym_hours&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data_scientist&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;svc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;email_hours&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gym_hours&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data_scientist&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;




&lt;span class="mf"&gt;1.0&lt;/span&gt;




&lt;span class="n"&gt;svc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coef_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;svc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intercept_&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;yy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;meshgrid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;zz&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;distance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()],&lt;/span&gt;&lt;span class="n"&gt;svc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coef_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;svc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intercept_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;zz&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;zz&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;Z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;svc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()])&lt;/span&gt;
&lt;span class="n"&gt;zz&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Z&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ss&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;distance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;email_hours&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gym_hours&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;svc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coef_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;svc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intercept_&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pcolormesh&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zz&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;winter&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c"&gt;#plt.cm.Paired)&lt;/span&gt;


&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;svc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intercept_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;svc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coef_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;svc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coef_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;svc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coef_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;linestyle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;--&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;svc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intercept_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;linestyle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;-&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;svc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intercept_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;linestyle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;-&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data_scientist&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;scatter&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;email_hours&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                              &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gym_hours&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;steelblue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                              &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data_scientist&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ss&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                              &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Not Data Scientist&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                              &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data_scientist&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;scatter&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;email_hours&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                              &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gym_hours&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;seagreen&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                              &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data_scientist&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ss&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                              &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Data Scientist&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                              &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Hours Emailing&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Hours At Gym&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D3/output_14_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;The SVM classifier seems to match my intuition for what the optimal boundary should be, and the logistic regression did not capture that.  If we had a new data point at 10 hours of emailing and 15 hours at the gym, I would expect that person to be a data scientist because it is closer to the cluster of data scientists.  The logistic regression fit we did previously would have classifed it as a non-data scientist.  This is despit it is so far from the cluster.&lt;/p&gt;
&lt;p&gt;Just because this is my intuition does not mean that its correct.   There are problems that this intuition is incorrect.   That is why you might have some insight into the problem because picking a classifier.  That is also why you cross validate and test on a unseen test set.   &lt;/p&gt;
&lt;h2&gt;Scaling&lt;/h2&gt;
&lt;p&gt;We just worked a problem where the scaling of the two variables are the same, but if they are not this will mess with the results the svm will produce.   The distance measurements change with units.  It is standard practice to scale variables before fitting an SVM on a data set.   If we do not, we can get different results.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.pipeline&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Pipeline&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;StandardScaler&lt;/span&gt;

&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data/non_sep.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;header&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;
&lt;span class="n"&gt;pipeline&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Pipeline&lt;/span&gt;&lt;span class="p"&gt;([(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;scaler&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;StandardScaler&lt;/span&gt;&lt;span class="p"&gt;()),&lt;/span&gt;
                    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;svc&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;SVC&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;linear&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))])&lt;/span&gt;
&lt;span class="n"&gt;pipeline&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;svc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pipeline&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;named_steps&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;svc&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;xvals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;yvals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;svc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intercept_&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;svc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coef_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;xvals&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;svc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coef_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;yy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;meshgrid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;Z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pipeline&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()])&lt;/span&gt;
&lt;span class="n"&gt;zz&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Z&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pcolormesh&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;zz&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;BrBG&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;seagreen&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;marker&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;o&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;1&lt;/span&gt;&lt;span class="se"&gt;\&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;s&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;burlywood&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;marker&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;o&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;0&lt;/span&gt;&lt;span class="se"&gt;\&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;s&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D3/output_16_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;In this case the data is not linearly seperable.  You will have noticed I change the colors from the previous spot to values that contrast better.  That way you can see when values are misclassified more easily.  The overlap is not very much in this instance, so we can still git fair accuracy.   A 5-Fold cross validation shows above 90% accuracy.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cross_validation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;cross_val_score&lt;/span&gt;
&lt;span class="n"&gt;cross_val_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pipeline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;scoring&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;cv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;




&lt;span class="mf"&gt;0.93000000000000005&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Tuning SVMs&lt;/h2&gt;
&lt;p&gt;The SVM has a C parameter that acts like $\frac{1}{\lambda}$ for regularization in Lasso and Ridge Regression.  Changing this values allows allowing error.  We get get a feel for how it affect the accuracy of a prediction by scanning through a number of values of this tuning paramter.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;cv_score = []
Cs = np.logspace(-3, 1, 100)
for c in Cs:
    pipeline = Pipeline([(&amp;#39;scaler&amp;#39;, StandardScaler()),
                    (&amp;#39;svc&amp;#39;, SVC(kernel=&amp;#39;linear&amp;#39;, C=c))])
    cv_score.append(cross_val_score(pipeline, x, y, scoring=&amp;#39;accuracy&amp;#39;, cv=10).mean())

plt.figure(figsize=(14,8))
plt.plot(Cs,cv_score,lw=2,color=&amp;#39;seagreen&amp;#39;)
plt.xlabel(&amp;quot;Tuning Paramter&amp;quot;)
plt.ylabel(&amp;quot;Accuracy&amp;quot;)
plt.xscale(&amp;quot;log&amp;quot;)
plt.ylim([0.9,.95])
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D3/output_20_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We can see that by changing the tuning parameter that we change the accuracy of the SVM, but there are similar accuracies for different C values.  To show what the algorithm is doing we can plot the decision boundaries for two very different C's on the non-seperable dataset we have started investigating.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pipeline1 = Pipeline([(&amp;#39;scaler&amp;#39;, StandardScaler()),
                    (&amp;#39;svc&amp;#39;, SVC(kernel=&amp;#39;linear&amp;#39;,C=.01))])
pipeline1.fit(x, y)
pipeline2= Pipeline([(&amp;#39;scaler&amp;#39;, StandardScaler()),
                    (&amp;#39;svc&amp;#39;, SVC(kernel=&amp;#39;linear&amp;#39;,C=10))])
pipeline2.fit(x, y)

mask = y==1
xx,yy = np.meshgrid(np.linspace(-5,5,100),np.linspace(-5,5,100))
Z1 = pipeline1.predict(np.c_[xx.ravel(),yy.ravel()])
zz1 = Z1.reshape(xx.shape)

Z2 = pipeline2.predict(np.c_[xx.ravel(),yy.ravel()])
zz2 = Z2.reshape(xx.shape)

plt.figure(figsize=(14,8))
plt.pcolormesh(xx,yy,zz1,cmap=&amp;#39;BrBG&amp;#39;,alpha=0.2)
plt.pcolormesh(xx,yy,zz2,cmap=&amp;#39;binary&amp;#39;,alpha=0.2)
plt.plot(x[mask,0],x[mask,1],color=&amp;#39;seagreen&amp;#39;,marker=&amp;#39;o&amp;#39;, markersize=10,lw=0,label=&amp;#39;1\&amp;#39;s&amp;#39;)
plt.plot(x[~mask,0],x[~mask,1],color=&amp;#39;burlywood&amp;#39;,marker=&amp;#39;o&amp;#39;,markersize=10,lw=0,label=&amp;#39;0\&amp;#39;s&amp;#39;)
plt.legend()
plt.xlim([-5,5])
plt.ylim([-5,5])
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D3/output_22_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We see that the two regions have different slopes.  I mapped a binary (black/white) colormap over the large C fit.   This makes the background darker.  The smaller C has the hyperplane seperator with a more negative slope than the larger C.   By changing the hyperparameter, we are ultimately move the hyperplane that is attempting to fit the data.&lt;/p&gt;
&lt;h2&gt;Kernels&lt;/h2&gt;
&lt;p&gt;SVM's can accept a kernal argument that effectively maps the data into a higher dimension, potentially making the data linearably seperable when it otherwise might not be.  We can illustrate this with a simple example using random data.  We will have some data that is seperable, but not linearably seperable.   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x1r = 2*np.random.random((200,1))-1
x2r = 2*np.random.random((200,1))-1

x3r = x1r*x1r+x2r*x2r

yr = np.sqrt(x1r*x1r+x2r*x2r) &amp;lt; .5

mask = yr==0
plt.figure(figsize=(15,7))
plt.subplot(1,2,1)
plt.plot(x1r[mask],x2r[mask],&amp;#39;ro&amp;#39;)
plt.plot(x1r[~mask],x2r[~mask],&amp;#39;bo&amp;#39;)
plt.subplot(1,2,2)
plt.plot(x1r[mask],x3r[mask],&amp;#39;ro&amp;#39;)
plt.plot(x1r[~mask],x3r[~mask],&amp;#39;bo&amp;#39;)
plt.axhline(y=0.25)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D3/output_24_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;By transforming the data into a third dimention we take a seperable data and make in seperable by a hyperplane.  How we can train an SVM on this data, and find the decision boundary.  Two common kernals to fit data two is a gaussian kernal and a polynomial kernal.  This allow for making non-linear decision surfaces.  Lets first look at the RBF kernel.&lt;/p&gt;
&lt;h2&gt;RBF Kernel&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def plot_surface(kernel,C=1,degree=3,gamma=1,*args):
    pipeline = Pipeline([(&amp;#39;scaler&amp;#39;, StandardScaler()),
                    (&amp;#39;svc&amp;#39;, SVC(kernel=kernel,C=C,degree=degree,gamma=1,*args))])
    pipeline.fit(x,y)
    svc_rbf = pipeline.named_steps[&amp;#39;svc&amp;#39;]


    mask = y==1
    xx,yy = np.meshgrid(np.linspace(-5,5,100),np.linspace(-5,5,100))
    Z = pipeline.predict(np.c_[xx.ravel(),yy.ravel()])
    zz = Z.reshape(xx.shape)


    plt.figure(figsize=(14,8))
    plt.pcolormesh(xx,yy,zz,cmap=&amp;#39;BrBG&amp;#39;,alpha=0.3)
    plt.plot(x[mask,0],x[mask,1],color=&amp;#39;seagreen&amp;#39;,marker=&amp;#39;o&amp;#39;, markersize=10,lw=0,label=&amp;#39;1\&amp;#39;s&amp;#39;)
    plt.plot(x[~mask,0],x[~mask,1],color=&amp;#39;burlywood&amp;#39;,marker=&amp;#39;o&amp;#39;,markersize=10,lw=0,label=&amp;#39;0\&amp;#39;s&amp;#39;)
    plt.legend()
    plt.xlim([-5,5])
    plt.ylim([-5,5])
    plt.title(&amp;quot;SVM with &amp;quot; + kernel + &amp;quot; Kernel, C = &amp;quot;+str(C))
    plt.show()

plot_surface(&amp;#39;rbf&amp;#39;)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D3/output_26_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;The decision surface of this SVM is clearly not linear in the data, but it is linear in a hyperspace the data is projected into.   We can look at how the accuracy changes as we turn the model.  As well as how the deciion surfaces changes.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;cv_score = []
Cs = np.logspace(-3, 1, 100)
for c in Cs:
    pipeline = Pipeline([(&amp;#39;scaler&amp;#39;, StandardScaler()),
                    (&amp;#39;svc&amp;#39;, SVC(kernel=&amp;#39;rbf&amp;#39;, C=c))])
    cv_score.append(cross_val_score(pipeline, x, y, scoring=&amp;#39;accuracy&amp;#39;, cv=10).mean())

plt.figure(figsize=(14,8))
plt.plot(Cs,cv_score,lw=2,color=&amp;#39;seagreen&amp;#39;)
plt.xlabel(&amp;quot;Tuning Paramter&amp;quot;)
plt.ylabel(&amp;quot;Accuracy&amp;quot;)
plt.xscale(&amp;quot;log&amp;quot;)
plt.ylim([0.89,.95])
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D3/output_28_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plot_surface(&amp;#39;rbf&amp;#39;,C=100)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D3/output_29_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plot_surface(&amp;#39;rbf&amp;#39;,C=1000)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D3/output_30_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We can see that as we increase the turning parameter, which is lower the regulization, we get very curvy decision surfaces.&lt;/p&gt;
&lt;h2&gt;Polynomial&lt;/h2&gt;
&lt;p&gt;The polynomial kernal allows for some curvature to the decision surface, but usally less than that fit by the RBF kernel.   We can see a degree polynomial curve below.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plot_surface(&amp;#39;poly&amp;#39;)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D3/output_32_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We can look at the surface as we change the turning parameter and the degree of the kernel.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plot_surface(&amp;#39;rbf&amp;#39;,C=100,degree=3)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D3/output_34_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plot_surface(&amp;#39;rbf&amp;#39;,C=1,degree=5)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D3/output_35_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We see that the hypersurface changes its form adn has more curvature as we increase the size of these parameters.  &lt;/p&gt;
&lt;h2&gt;Grid Search&lt;/h2&gt;
&lt;p&gt;Ideally we will want to find the best model to fit the data we are given.  This is difficult to do by hand, so we can use a grid search strategy to find the best model on our training data.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.grid_search&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;GridSearchCV&lt;/span&gt;
&lt;span class="n"&gt;parameters&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;svc__degree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;svc__C&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)}&lt;/span&gt;
&lt;span class="n"&gt;pipeline&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Pipeline&lt;/span&gt;&lt;span class="p"&gt;([(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;scaler&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;StandardScaler&lt;/span&gt;&lt;span class="p"&gt;()),&lt;/span&gt;
                    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;svc&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;SVC&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;poly&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))])&lt;/span&gt;
&lt;span class="n"&gt;clf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GridSearchCV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pipeline&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;parameters&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;scoring&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Best Accuracy:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_score_&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Best Parameters:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_params_&lt;/span&gt;

&lt;span class="n"&gt;Best&lt;/span&gt; &lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.94&lt;/span&gt;
&lt;span class="n"&gt;Best&lt;/span&gt; &lt;span class="n"&gt;Parameters&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;svc__degree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;svc__C&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.058570208180566671&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;



&lt;span class="n"&gt;plot_surface&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;poly&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_params_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;svc__C&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;degree&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_params_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;svc__degree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D3/output_38_0.png" /&gt;&lt;/p&gt;
&lt;h2&gt;Multi-Classification&lt;/h2&gt;
&lt;p&gt;We can also use SVM's, and other classifiers, with datesets that have multiple classifications.   An example is the digits dataset that has hand written digits as images and we are attempting to classify them.&lt;/p&gt;
&lt;p&gt;The two methods is 1 vs all, which makes a classifier for each classification.  Then each data point is scored by each classifier.  The highest scored predictor is then classified as a positive example in that classifier.
In 1 vs 1, a classifier is made for each pair of data, and then there is a vote.  The classification with the most votes win.   We will be using both of these with a SVM on the digit data.&lt;/p&gt;
&lt;p&gt;Because we are going to be using linear kernals, there is a optimize algorithm in sklearn that we will be using.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.multiclass&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;OneVsRestClassifier&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;OneVsOneClassifier&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;load_digits&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.svm&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LinearSVC&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cross_validation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;recall_score&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;precision_score&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_digits&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;images&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;images&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1797&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;LinVsAll&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;OneVsRestClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;LinearSVC&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;LinVsOne&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;OneVsOneClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;LinearSVC&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;imshow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;images&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Greys&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D3/output_40_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;The data are 8x8 pixle images of numbers that are hand written.  There are 10 classifications available in tis dataset.  We will train both multiclassification methods on the dataset and check the test accuracy.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x_train, x_test, y_train, y_test = train_test_split(images,data.target)

LinVsAll.fit(x_train,y_train)
y_pred = LinVsAll.predict(x_test)

print &amp;quot;One Vs All&amp;quot;
print &amp;quot;Accuracy: &amp;quot;, accuracy_score(y_test,y_pred)
print &amp;quot;Recall: &amp;quot;, recall_score(y_test,y_pred,average=&amp;#39;weighted&amp;#39;)
print &amp;quot;Precision: &amp;quot;, precision_score(y_test,y_pred,average=&amp;#39;weighted&amp;#39;)


print &amp;quot;&amp;quot;
print &amp;quot;One Vs One&amp;quot;
LinVsOne.fit(x_train,y_train)
y_pred = LinVsOne.predict(x_test)

print &amp;quot;Accuracy: &amp;quot;, accuracy_score(y_test,y_pred)
print &amp;quot;Recall: &amp;quot;, recall_score(y_test,y_pred,average=&amp;#39;weighted&amp;#39;)
print &amp;quot;Precision: &amp;quot;, precision_score(y_test,y_pred,average=&amp;#39;weighted&amp;#39;)

One Vs All
Accuracy:  0.942222222222
Recall:  0.942222222222
Precision:  0.942982349293

One Vs One
Accuracy:  0.975555555556
Recall:  0.975555555556
Precision:  0.976581128748
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In this case we have the One vs One method being more accurate.  I suspect that we find some values of 7,9, and 4 that are pretty similar, and the voting helps seperate them while the best score does not. &lt;/p&gt;
&lt;h2&gt;Real World Data&lt;/h2&gt;
&lt;p&gt;We have some biological data that we are asked to predict if a given sample comes from stool or tissue.  This problem is interesting to me because the data is not structured in a way for us to answer it.  We have to restructure the data set!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;df_b = pd.read_csv(&amp;#39;data/bio.csv&amp;#39;).drop(&amp;#39;Group&amp;#39;,axis=1)
df_b.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Taxon&lt;/th&gt;
      &lt;th&gt;Patient&lt;/th&gt;
      &lt;th&gt;Tissue&lt;/th&gt;
      &lt;th&gt;Stool&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Firmicutes&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;136&lt;/td&gt;
      &lt;td&gt;4182&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Firmicutes&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1174&lt;/td&gt;
      &lt;td&gt;703&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Firmicutes&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;408&lt;/td&gt;
      &lt;td&gt;3946&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Firmicutes&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;831&lt;/td&gt;
      &lt;td&gt;8605&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;Firmicutes&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;693&lt;/td&gt;
      &lt;td&gt;50&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;df_b = df_b.pivot(&amp;#39;Patient&amp;#39;,&amp;#39;Taxon&amp;#39;)
df_b
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th colspan="5" halign="left"&gt;Tissue&lt;/th&gt;
      &lt;th colspan="5" halign="left"&gt;Stool&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Taxon&lt;/th&gt;
      &lt;th&gt;Actinobacteria&lt;/th&gt;
      &lt;th&gt;Bacteroidetes&lt;/th&gt;
      &lt;th&gt;Firmicutes&lt;/th&gt;
      &lt;th&gt;Other&lt;/th&gt;
      &lt;th&gt;Proteobacteria&lt;/th&gt;
      &lt;th&gt;Actinobacteria&lt;/th&gt;
      &lt;th&gt;Bacteroidetes&lt;/th&gt;
      &lt;th&gt;Firmicutes&lt;/th&gt;
      &lt;th&gt;Other&lt;/th&gt;
      &lt;th&gt;Proteobacteria&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Patient&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1590&lt;/td&gt;
      &lt;td&gt;67&lt;/td&gt;
      &lt;td&gt;136&lt;/td&gt;
      &lt;td&gt;195&lt;/td&gt;
      &lt;td&gt;2469&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;4182&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;1821&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1174&lt;/td&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;839&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;703&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;661&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;259&lt;/td&gt;
      &lt;td&gt;85&lt;/td&gt;
      &lt;td&gt;408&lt;/td&gt;
      &lt;td&gt;316&lt;/td&gt;
      &lt;td&gt;4414&lt;/td&gt;
      &lt;td&gt;300&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;3946&lt;/td&gt;
      &lt;td&gt;43&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;568&lt;/td&gt;
      &lt;td&gt;143&lt;/td&gt;
      &lt;td&gt;831&lt;/td&gt;
      &lt;td&gt;202&lt;/td&gt;
      &lt;td&gt;12044&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;8605&lt;/td&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;83&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;1102&lt;/td&gt;
      &lt;td&gt;678&lt;/td&gt;
      &lt;td&gt;693&lt;/td&gt;
      &lt;td&gt;116&lt;/td&gt;
      &lt;td&gt;2310&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;50&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;td&gt;678&lt;/td&gt;
      &lt;td&gt;4829&lt;/td&gt;
      &lt;td&gt;718&lt;/td&gt;
      &lt;td&gt;527&lt;/td&gt;
      &lt;td&gt;3053&lt;/td&gt;
      &lt;td&gt;377&lt;/td&gt;
      &lt;td&gt;209&lt;/td&gt;
      &lt;td&gt;717&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;547&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;td&gt;260&lt;/td&gt;
      &lt;td&gt;74&lt;/td&gt;
      &lt;td&gt;173&lt;/td&gt;
      &lt;td&gt;357&lt;/td&gt;
      &lt;td&gt;395&lt;/td&gt;
      &lt;td&gt;58&lt;/td&gt;
      &lt;td&gt;651&lt;/td&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;2174&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;8&lt;/th&gt;
      &lt;td&gt;424&lt;/td&gt;
      &lt;td&gt;169&lt;/td&gt;
      &lt;td&gt;228&lt;/td&gt;
      &lt;td&gt;106&lt;/td&gt;
      &lt;td&gt;2651&lt;/td&gt;
      &lt;td&gt;233&lt;/td&gt;
      &lt;td&gt;254&lt;/td&gt;
      &lt;td&gt;80&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;767&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;9&lt;/th&gt;
      &lt;td&gt;548&lt;/td&gt;
      &lt;td&gt;106&lt;/td&gt;
      &lt;td&gt;162&lt;/td&gt;
      &lt;td&gt;67&lt;/td&gt;
      &lt;td&gt;1195&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;3196&lt;/td&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;76&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10&lt;/th&gt;
      &lt;td&gt;201&lt;/td&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;372&lt;/td&gt;
      &lt;td&gt;203&lt;/td&gt;
      &lt;td&gt;6857&lt;/td&gt;
      &lt;td&gt;83&lt;/td&gt;
      &lt;td&gt;381&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;795&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;11&lt;/th&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;4255&lt;/td&gt;
      &lt;td&gt;392&lt;/td&gt;
      &lt;td&gt;483&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;359&lt;/td&gt;
      &lt;td&gt;4361&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;666&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12&lt;/th&gt;
      &lt;td&gt;109&lt;/td&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;107&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;2950&lt;/td&gt;
      &lt;td&gt;59&lt;/td&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;1667&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;3994&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;13&lt;/th&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;2473&lt;/td&gt;
      &lt;td&gt;96&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;1541&lt;/td&gt;
      &lt;td&gt;183&lt;/td&gt;
      &lt;td&gt;2314&lt;/td&gt;
      &lt;td&gt;223&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;816&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;14&lt;/th&gt;
      &lt;td&gt;310&lt;/td&gt;
      &lt;td&gt;102&lt;/td&gt;
      &lt;td&gt;281&lt;/td&gt;
      &lt;td&gt;305&lt;/td&gt;
      &lt;td&gt;1307&lt;/td&gt;
      &lt;td&gt;204&lt;/td&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;2377&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;53&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;df_b = df_b.stack(level=0)
df_b
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Taxon&lt;/th&gt;
      &lt;th&gt;Actinobacteria&lt;/th&gt;
      &lt;th&gt;Bacteroidetes&lt;/th&gt;
      &lt;th&gt;Firmicutes&lt;/th&gt;
      &lt;th&gt;Other&lt;/th&gt;
      &lt;th&gt;Proteobacteria&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Patient&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th rowspan="2" valign="top"&gt;1&lt;/th&gt;
      &lt;th&gt;Tissue&lt;/th&gt;
      &lt;td&gt;1590&lt;/td&gt;
      &lt;td&gt;67&lt;/td&gt;
      &lt;td&gt;136&lt;/td&gt;
      &lt;td&gt;195&lt;/td&gt;
      &lt;td&gt;2469&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Stool&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;4182&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;1821&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan="2" valign="top"&gt;2&lt;/th&gt;
      &lt;th&gt;Tissue&lt;/th&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1174&lt;/td&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;839&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Stool&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;703&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;661&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan="2" valign="top"&gt;3&lt;/th&gt;
      &lt;th&gt;Tissue&lt;/th&gt;
      &lt;td&gt;259&lt;/td&gt;
      &lt;td&gt;85&lt;/td&gt;
      &lt;td&gt;408&lt;/td&gt;
      &lt;td&gt;316&lt;/td&gt;
      &lt;td&gt;4414&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Stool&lt;/th&gt;
      &lt;td&gt;300&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;3946&lt;/td&gt;
      &lt;td&gt;43&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan="2" valign="top"&gt;4&lt;/th&gt;
      &lt;th&gt;Tissue&lt;/th&gt;
      &lt;td&gt;568&lt;/td&gt;
      &lt;td&gt;143&lt;/td&gt;
      &lt;td&gt;831&lt;/td&gt;
      &lt;td&gt;202&lt;/td&gt;
      &lt;td&gt;12044&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Stool&lt;/th&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;8605&lt;/td&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;83&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan="2" valign="top"&gt;5&lt;/th&gt;
      &lt;th&gt;Tissue&lt;/th&gt;
      &lt;td&gt;1102&lt;/td&gt;
      &lt;td&gt;678&lt;/td&gt;
      &lt;td&gt;693&lt;/td&gt;
      &lt;td&gt;116&lt;/td&gt;
      &lt;td&gt;2310&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Stool&lt;/th&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;50&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan="2" valign="top"&gt;6&lt;/th&gt;
      &lt;th&gt;Tissue&lt;/th&gt;
      &lt;td&gt;678&lt;/td&gt;
      &lt;td&gt;4829&lt;/td&gt;
      &lt;td&gt;718&lt;/td&gt;
      &lt;td&gt;527&lt;/td&gt;
      &lt;td&gt;3053&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Stool&lt;/th&gt;
      &lt;td&gt;377&lt;/td&gt;
      &lt;td&gt;209&lt;/td&gt;
      &lt;td&gt;717&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;547&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan="2" valign="top"&gt;7&lt;/th&gt;
      &lt;th&gt;Tissue&lt;/th&gt;
      &lt;td&gt;260&lt;/td&gt;
      &lt;td&gt;74&lt;/td&gt;
      &lt;td&gt;173&lt;/td&gt;
      &lt;td&gt;357&lt;/td&gt;
      &lt;td&gt;395&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Stool&lt;/th&gt;
      &lt;td&gt;58&lt;/td&gt;
      &lt;td&gt;651&lt;/td&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;2174&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan="2" valign="top"&gt;8&lt;/th&gt;
      &lt;th&gt;Tissue&lt;/th&gt;
      &lt;td&gt;424&lt;/td&gt;
      &lt;td&gt;169&lt;/td&gt;
      &lt;td&gt;228&lt;/td&gt;
      &lt;td&gt;106&lt;/td&gt;
      &lt;td&gt;2651&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Stool&lt;/th&gt;
      &lt;td&gt;233&lt;/td&gt;
      &lt;td&gt;254&lt;/td&gt;
      &lt;td&gt;80&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;767&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan="2" valign="top"&gt;9&lt;/th&gt;
      &lt;th&gt;Tissue&lt;/th&gt;
      &lt;td&gt;548&lt;/td&gt;
      &lt;td&gt;106&lt;/td&gt;
      &lt;td&gt;162&lt;/td&gt;
      &lt;td&gt;67&lt;/td&gt;
      &lt;td&gt;1195&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Stool&lt;/th&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;3196&lt;/td&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;76&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan="2" valign="top"&gt;10&lt;/th&gt;
      &lt;th&gt;Tissue&lt;/th&gt;
      &lt;td&gt;201&lt;/td&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;372&lt;/td&gt;
      &lt;td&gt;203&lt;/td&gt;
      &lt;td&gt;6857&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Stool&lt;/th&gt;
      &lt;td&gt;83&lt;/td&gt;
      &lt;td&gt;381&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;795&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan="2" valign="top"&gt;11&lt;/th&gt;
      &lt;th&gt;Tissue&lt;/th&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;4255&lt;/td&gt;
      &lt;td&gt;392&lt;/td&gt;
      &lt;td&gt;483&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Stool&lt;/th&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;359&lt;/td&gt;
      &lt;td&gt;4361&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;666&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan="2" valign="top"&gt;12&lt;/th&gt;
      &lt;th&gt;Tissue&lt;/th&gt;
      &lt;td&gt;109&lt;/td&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;107&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;2950&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Stool&lt;/th&gt;
      &lt;td&gt;59&lt;/td&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;1667&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;3994&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan="2" valign="top"&gt;13&lt;/th&gt;
      &lt;th&gt;Tissue&lt;/th&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;2473&lt;/td&gt;
      &lt;td&gt;96&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;1541&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Stool&lt;/th&gt;
      &lt;td&gt;183&lt;/td&gt;
      &lt;td&gt;2314&lt;/td&gt;
      &lt;td&gt;223&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;816&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan="2" valign="top"&gt;14&lt;/th&gt;
      &lt;th&gt;Tissue&lt;/th&gt;
      &lt;td&gt;310&lt;/td&gt;
      &lt;td&gt;102&lt;/td&gt;
      &lt;td&gt;281&lt;/td&gt;
      &lt;td&gt;305&lt;/td&gt;
      &lt;td&gt;1307&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Stool&lt;/th&gt;
      &lt;td&gt;204&lt;/td&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;2377&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;53&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;df_b = df_b.reset_index()
df_b
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;Taxon&lt;/th&gt;
      &lt;th&gt;Patient&lt;/th&gt;
      &lt;th&gt;level_1&lt;/th&gt;
      &lt;th&gt;Actinobacteria&lt;/th&gt;
      &lt;th&gt;Bacteroidetes&lt;/th&gt;
      &lt;th&gt;Firmicutes&lt;/th&gt;
      &lt;th&gt;Other&lt;/th&gt;
      &lt;th&gt;Proteobacteria&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;1590&lt;/td&gt;
      &lt;td&gt;67&lt;/td&gt;
      &lt;td&gt;136&lt;/td&gt;
      &lt;td&gt;195&lt;/td&gt;
      &lt;td&gt;2469&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;4182&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;1821&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1174&lt;/td&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;839&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;703&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;661&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;259&lt;/td&gt;
      &lt;td&gt;85&lt;/td&gt;
      &lt;td&gt;408&lt;/td&gt;
      &lt;td&gt;316&lt;/td&gt;
      &lt;td&gt;4414&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;300&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;3946&lt;/td&gt;
      &lt;td&gt;43&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;568&lt;/td&gt;
      &lt;td&gt;143&lt;/td&gt;
      &lt;td&gt;831&lt;/td&gt;
      &lt;td&gt;202&lt;/td&gt;
      &lt;td&gt;12044&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;8605&lt;/td&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;83&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;8&lt;/th&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;1102&lt;/td&gt;
      &lt;td&gt;678&lt;/td&gt;
      &lt;td&gt;693&lt;/td&gt;
      &lt;td&gt;116&lt;/td&gt;
      &lt;td&gt;2310&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;9&lt;/th&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;50&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10&lt;/th&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;678&lt;/td&gt;
      &lt;td&gt;4829&lt;/td&gt;
      &lt;td&gt;718&lt;/td&gt;
      &lt;td&gt;527&lt;/td&gt;
      &lt;td&gt;3053&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;11&lt;/th&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;377&lt;/td&gt;
      &lt;td&gt;209&lt;/td&gt;
      &lt;td&gt;717&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;547&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12&lt;/th&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;260&lt;/td&gt;
      &lt;td&gt;74&lt;/td&gt;
      &lt;td&gt;173&lt;/td&gt;
      &lt;td&gt;357&lt;/td&gt;
      &lt;td&gt;395&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;13&lt;/th&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;58&lt;/td&gt;
      &lt;td&gt;651&lt;/td&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;2174&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;14&lt;/th&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;424&lt;/td&gt;
      &lt;td&gt;169&lt;/td&gt;
      &lt;td&gt;228&lt;/td&gt;
      &lt;td&gt;106&lt;/td&gt;
      &lt;td&gt;2651&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;15&lt;/th&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;233&lt;/td&gt;
      &lt;td&gt;254&lt;/td&gt;
      &lt;td&gt;80&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;767&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;16&lt;/th&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;548&lt;/td&gt;
      &lt;td&gt;106&lt;/td&gt;
      &lt;td&gt;162&lt;/td&gt;
      &lt;td&gt;67&lt;/td&gt;
      &lt;td&gt;1195&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;17&lt;/th&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;3196&lt;/td&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;76&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;18&lt;/th&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;201&lt;/td&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;372&lt;/td&gt;
      &lt;td&gt;203&lt;/td&gt;
      &lt;td&gt;6857&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;19&lt;/th&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;83&lt;/td&gt;
      &lt;td&gt;381&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;795&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;20&lt;/th&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;4255&lt;/td&gt;
      &lt;td&gt;392&lt;/td&gt;
      &lt;td&gt;483&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;21&lt;/th&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;359&lt;/td&gt;
      &lt;td&gt;4361&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;666&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;22&lt;/th&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;109&lt;/td&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;107&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;2950&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;23&lt;/th&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;59&lt;/td&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;1667&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;3994&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;24&lt;/th&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;2473&lt;/td&gt;
      &lt;td&gt;96&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;1541&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;25&lt;/th&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;183&lt;/td&gt;
      &lt;td&gt;2314&lt;/td&gt;
      &lt;td&gt;223&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;816&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;26&lt;/th&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;310&lt;/td&gt;
      &lt;td&gt;102&lt;/td&gt;
      &lt;td&gt;281&lt;/td&gt;
      &lt;td&gt;305&lt;/td&gt;
      &lt;td&gt;1307&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;27&lt;/th&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;204&lt;/td&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;2377&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;53&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;df_b[&amp;#39;Location&amp;#39;] = np.where(df_b.level_1 == &amp;#39;Tissue&amp;#39;,1,0)
df_b
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;Taxon&lt;/th&gt;
      &lt;th&gt;Patient&lt;/th&gt;
      &lt;th&gt;level_1&lt;/th&gt;
      &lt;th&gt;Actinobacteria&lt;/th&gt;
      &lt;th&gt;Bacteroidetes&lt;/th&gt;
      &lt;th&gt;Firmicutes&lt;/th&gt;
      &lt;th&gt;Other&lt;/th&gt;
      &lt;th&gt;Proteobacteria&lt;/th&gt;
      &lt;th&gt;Location&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;1590&lt;/td&gt;
      &lt;td&gt;67&lt;/td&gt;
      &lt;td&gt;136&lt;/td&gt;
      &lt;td&gt;195&lt;/td&gt;
      &lt;td&gt;2469&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;4182&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;1821&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1174&lt;/td&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;839&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;703&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;661&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;259&lt;/td&gt;
      &lt;td&gt;85&lt;/td&gt;
      &lt;td&gt;408&lt;/td&gt;
      &lt;td&gt;316&lt;/td&gt;
      &lt;td&gt;4414&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;300&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;3946&lt;/td&gt;
      &lt;td&gt;43&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;568&lt;/td&gt;
      &lt;td&gt;143&lt;/td&gt;
      &lt;td&gt;831&lt;/td&gt;
      &lt;td&gt;202&lt;/td&gt;
      &lt;td&gt;12044&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;8605&lt;/td&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;83&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;8&lt;/th&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;1102&lt;/td&gt;
      &lt;td&gt;678&lt;/td&gt;
      &lt;td&gt;693&lt;/td&gt;
      &lt;td&gt;116&lt;/td&gt;
      &lt;td&gt;2310&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;9&lt;/th&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;50&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10&lt;/th&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;678&lt;/td&gt;
      &lt;td&gt;4829&lt;/td&gt;
      &lt;td&gt;718&lt;/td&gt;
      &lt;td&gt;527&lt;/td&gt;
      &lt;td&gt;3053&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;11&lt;/th&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;377&lt;/td&gt;
      &lt;td&gt;209&lt;/td&gt;
      &lt;td&gt;717&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;547&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12&lt;/th&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;260&lt;/td&gt;
      &lt;td&gt;74&lt;/td&gt;
      &lt;td&gt;173&lt;/td&gt;
      &lt;td&gt;357&lt;/td&gt;
      &lt;td&gt;395&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;13&lt;/th&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;58&lt;/td&gt;
      &lt;td&gt;651&lt;/td&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;2174&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;14&lt;/th&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;424&lt;/td&gt;
      &lt;td&gt;169&lt;/td&gt;
      &lt;td&gt;228&lt;/td&gt;
      &lt;td&gt;106&lt;/td&gt;
      &lt;td&gt;2651&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;15&lt;/th&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;233&lt;/td&gt;
      &lt;td&gt;254&lt;/td&gt;
      &lt;td&gt;80&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;767&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;16&lt;/th&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;548&lt;/td&gt;
      &lt;td&gt;106&lt;/td&gt;
      &lt;td&gt;162&lt;/td&gt;
      &lt;td&gt;67&lt;/td&gt;
      &lt;td&gt;1195&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;17&lt;/th&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;3196&lt;/td&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;76&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;18&lt;/th&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;201&lt;/td&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;372&lt;/td&gt;
      &lt;td&gt;203&lt;/td&gt;
      &lt;td&gt;6857&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;19&lt;/th&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;83&lt;/td&gt;
      &lt;td&gt;381&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;795&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;20&lt;/th&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;4255&lt;/td&gt;
      &lt;td&gt;392&lt;/td&gt;
      &lt;td&gt;483&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;21&lt;/th&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;359&lt;/td&gt;
      &lt;td&gt;4361&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;666&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;22&lt;/th&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;109&lt;/td&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;107&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;2950&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;23&lt;/th&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;59&lt;/td&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;1667&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;3994&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;24&lt;/th&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;2473&lt;/td&gt;
      &lt;td&gt;96&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;1541&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;25&lt;/th&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;183&lt;/td&gt;
      &lt;td&gt;2314&lt;/td&gt;
      &lt;td&gt;223&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;816&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;26&lt;/th&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;Tissue&lt;/td&gt;
      &lt;td&gt;310&lt;/td&gt;
      &lt;td&gt;102&lt;/td&gt;
      &lt;td&gt;281&lt;/td&gt;
      &lt;td&gt;305&lt;/td&gt;
      &lt;td&gt;1307&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;27&lt;/th&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;Stool&lt;/td&gt;
      &lt;td&gt;204&lt;/td&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;2377&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;53&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;df_b = df_b.drop([&amp;#39;level_1&amp;#39;, &amp;#39;Patient&amp;#39;], axis=1)
df_b
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;Taxon&lt;/th&gt;
      &lt;th&gt;Actinobacteria&lt;/th&gt;
      &lt;th&gt;Bacteroidetes&lt;/th&gt;
      &lt;th&gt;Firmicutes&lt;/th&gt;
      &lt;th&gt;Other&lt;/th&gt;
      &lt;th&gt;Proteobacteria&lt;/th&gt;
      &lt;th&gt;Location&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1590&lt;/td&gt;
      &lt;td&gt;67&lt;/td&gt;
      &lt;td&gt;136&lt;/td&gt;
      &lt;td&gt;195&lt;/td&gt;
      &lt;td&gt;2469&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;4182&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;1821&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1174&lt;/td&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;839&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;703&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;661&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;259&lt;/td&gt;
      &lt;td&gt;85&lt;/td&gt;
      &lt;td&gt;408&lt;/td&gt;
      &lt;td&gt;316&lt;/td&gt;
      &lt;td&gt;4414&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;300&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;3946&lt;/td&gt;
      &lt;td&gt;43&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;td&gt;568&lt;/td&gt;
      &lt;td&gt;143&lt;/td&gt;
      &lt;td&gt;831&lt;/td&gt;
      &lt;td&gt;202&lt;/td&gt;
      &lt;td&gt;12044&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;8605&lt;/td&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;83&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;8&lt;/th&gt;
      &lt;td&gt;1102&lt;/td&gt;
      &lt;td&gt;678&lt;/td&gt;
      &lt;td&gt;693&lt;/td&gt;
      &lt;td&gt;116&lt;/td&gt;
      &lt;td&gt;2310&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;9&lt;/th&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;50&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10&lt;/th&gt;
      &lt;td&gt;678&lt;/td&gt;
      &lt;td&gt;4829&lt;/td&gt;
      &lt;td&gt;718&lt;/td&gt;
      &lt;td&gt;527&lt;/td&gt;
      &lt;td&gt;3053&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;11&lt;/th&gt;
      &lt;td&gt;377&lt;/td&gt;
      &lt;td&gt;209&lt;/td&gt;
      &lt;td&gt;717&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;547&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12&lt;/th&gt;
      &lt;td&gt;260&lt;/td&gt;
      &lt;td&gt;74&lt;/td&gt;
      &lt;td&gt;173&lt;/td&gt;
      &lt;td&gt;357&lt;/td&gt;
      &lt;td&gt;395&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;13&lt;/th&gt;
      &lt;td&gt;58&lt;/td&gt;
      &lt;td&gt;651&lt;/td&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;2174&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;14&lt;/th&gt;
      &lt;td&gt;424&lt;/td&gt;
      &lt;td&gt;169&lt;/td&gt;
      &lt;td&gt;228&lt;/td&gt;
      &lt;td&gt;106&lt;/td&gt;
      &lt;td&gt;2651&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;15&lt;/th&gt;
      &lt;td&gt;233&lt;/td&gt;
      &lt;td&gt;254&lt;/td&gt;
      &lt;td&gt;80&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;767&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;16&lt;/th&gt;
      &lt;td&gt;548&lt;/td&gt;
      &lt;td&gt;106&lt;/td&gt;
      &lt;td&gt;162&lt;/td&gt;
      &lt;td&gt;67&lt;/td&gt;
      &lt;td&gt;1195&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;17&lt;/th&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;3196&lt;/td&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;76&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;18&lt;/th&gt;
      &lt;td&gt;201&lt;/td&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;372&lt;/td&gt;
      &lt;td&gt;203&lt;/td&gt;
      &lt;td&gt;6857&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;19&lt;/th&gt;
      &lt;td&gt;83&lt;/td&gt;
      &lt;td&gt;381&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;795&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;20&lt;/th&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;4255&lt;/td&gt;
      &lt;td&gt;392&lt;/td&gt;
      &lt;td&gt;483&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;21&lt;/th&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;359&lt;/td&gt;
      &lt;td&gt;4361&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;666&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;22&lt;/th&gt;
      &lt;td&gt;109&lt;/td&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;107&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;2950&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;23&lt;/th&gt;
      &lt;td&gt;59&lt;/td&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;1667&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;3994&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;24&lt;/th&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;2473&lt;/td&gt;
      &lt;td&gt;96&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;1541&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;25&lt;/th&gt;
      &lt;td&gt;183&lt;/td&gt;
      &lt;td&gt;2314&lt;/td&gt;
      &lt;td&gt;223&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;816&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;26&lt;/th&gt;
      &lt;td&gt;310&lt;/td&gt;
      &lt;td&gt;102&lt;/td&gt;
      &lt;td&gt;281&lt;/td&gt;
      &lt;td&gt;305&lt;/td&gt;
      &lt;td&gt;1307&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;27&lt;/th&gt;
      &lt;td&gt;204&lt;/td&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;2377&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;53&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;And now we have our data!!!!  We can split into a train test set and see how it performs.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;y = df_b[&amp;#39;Location&amp;#39;].values
x = df_b.drop(&amp;#39;Location&amp;#39;, axis=1).values
x_train, x_test, y_train,y_test = train_test_split(x,y,test_size=.2)
svc_lin = LinearSVC()
parameters = {&amp;#39;C&amp;#39;:np.logspace(-3,3,1000)}
clf = GridSearchCV(svc_lin, parameters, scoring=&amp;#39;accuracy&amp;#39;, cv=10)
clf.fit(x_train,y_train)
print &amp;quot;Best Accuracy:&amp;quot;, clf.best_score_
print &amp;quot;Test Accuracy:&amp;quot;, accuracy_score(y_test,clf.best_estimator_.predict(x_test))

Best Accuracy: 0.863636363636
Test Accuracy: 0.166666666667
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Our linear SVC did not generalize to the test set at all.  Lets try a different model!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;svc_lin = SVC(kernel=&amp;#39;rbf&amp;#39;)
parameters = {&amp;#39;C&amp;#39;:np.logspace(-3,3,100),&amp;#39;gamma&amp;#39;:np.logspace(-8,2,11)}
clf = GridSearchCV(svc_lin, parameters, scoring=&amp;#39;accuracy&amp;#39;, cv=10)
clf.fit(x_train,y_train)
print &amp;quot;Best Accuracy:&amp;quot;, clf.best_score_
print &amp;quot;Test Accuracy:&amp;quot;, accuracy_score(y_test,clf.best_estimator_.predict(x_test))

Best Accuracy: 0.818181818182
Test Accuracy: 0.666666666667
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The RBF kernal generalized much better to the test set.  We are doing better then guessing, but I am wondering if a logistic regressor will do better.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;lin = LogisticRegression()
parameters = {&amp;#39;C&amp;#39;:np.logspace(-3,3,1000)}
clf = GridSearchCV(lin, parameters, scoring=&amp;#39;accuracy&amp;#39;, cv=10)
clf.fit(x_train,y_train)
print &amp;quot;Best Accuracy:&amp;quot;, clf.best_score_
print &amp;quot;Test Accuracy:&amp;quot;, accuracy_score(y_test,clf.best_estimator_.predict(x_test))

Best Accuracy: 0.818181818182
Test Accuracy: 0.333333333333
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is not the best model by far.   Before we come to a close, we will see if the SVC does better at predict than a random forest.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.ensemble&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;
&lt;span class="n"&gt;rf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;parameters&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;n_estimators&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:[&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;]}&lt;/span&gt;
&lt;span class="n"&gt;clf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GridSearchCV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;parameters&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;scoring&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Best Accuracy:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_score_&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Test Accuracy:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_estimator_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;Best&lt;/span&gt; &lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.818181818182&lt;/span&gt;
&lt;span class="n"&gt;Test&lt;/span&gt; &lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.833333333333&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And as expected, the random forest goes for the best generalization.   Of course, that what ensemble methods are suppose to do.  We're suppose to learn about them in depth tomorrow.  Until then....&lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="SVM"></category><category term="support vector machines"></category></entry><entry><title>Galvanize - Week 04 - Day 2</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-04-02/" rel="alternate"></link><updated>2015-06-23T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-23:galvanize/galvanize-data-science-04-02/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 4 - Day 2&lt;/h2&gt;
&lt;p&gt;Today's quiz a an online interview questions that involves picking a random value from a stream in order 1 memory use. 
After that was a lecture on Bootstrap Aggregate (Bagging) ML methods, focused on decisions trees, then the random forest algorithm.   We implemented a random forest using our decision trees we made from yesterday.&lt;/p&gt;
&lt;h2&gt;Random Forest Class&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;DecisionTree&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DecisionTree&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;RandomForest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;A Random Forest class&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_trees&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_features&lt;/span&gt;&lt;span class="p"&gt;,):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;           num_trees:  number of trees to create in the forest:&lt;/span&gt;
&lt;span class="sd"&gt;        num_features:  the number of features to consider when choosing the&lt;/span&gt;
&lt;span class="sd"&gt;                           best split for each node of the decision trees&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_trees&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;num_trees&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_features&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;num_features&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;forest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        X:  two dimensional numpy array representing feature matrix&lt;/span&gt;
&lt;span class="sd"&gt;                for test data&lt;/span&gt;
&lt;span class="sd"&gt;        y:  numpy array representing labels for test data&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;forest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;build_forest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_trees&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_features&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;build_forest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_trees&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_features&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        Return a list of num_trees DecisionTrees.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="n"&gt;forest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="n"&gt;size_feature&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;floor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_features&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;num_features&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
            &lt;span class="n"&gt;size_feature&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;num_features&lt;/span&gt;

        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_trees&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

            &lt;span class="c"&gt;#features = np.random.choice(range(len(X[0,:])),size=size_feature,replace=False)&lt;/span&gt;
            &lt;span class="n"&gt;dt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DecisionTree&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_features&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;num_features&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;indexes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="kp"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;dt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;indexes&lt;/span&gt;&lt;span class="p"&gt;,:],&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;indexes&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="n"&gt;forest&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dt&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;forest&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        Return a numpy array of the labels predicted for the given test data.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;forest&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;forest&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
            &lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;hstack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;forest&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

        &lt;span class="n"&gt;final_predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;return_counts&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;final_predictions&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;final_predictions&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        Return the accuracy of the Random Forest for the given test data and&lt;/span&gt;
&lt;span class="sd"&gt;        labels.&lt;/span&gt;

&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="n"&gt;prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prediction&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Checking Our Random Forest&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cross_validation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;DecisionTree&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DecisionTree&lt;/span&gt;

&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;../data/playgolf.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Result&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;
&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;dt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DecisionTree&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;dt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;predicted_y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;dt&lt;/span&gt;

&lt;span class="mi"&gt;0&lt;/span&gt;
  &lt;span class="o"&gt;|-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;overcast&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="n"&gt;Play&lt;/span&gt;
  &lt;span class="o"&gt;|-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;no&lt;/span&gt; &lt;span class="n"&gt;overcast&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="mi"&gt;1&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;71&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="n"&gt;Play&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;71&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="mi"&gt;2&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="n"&gt;Play&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="n"&gt;Don&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;t Play&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Our Decision tree is still functioning.  Since the random forest depends on that I wanted to just show that it functions.  The idea is that if we have a weak classifier we can use it a large number of them to vote on a decisions and find, on average, a better answer.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;RandomForest&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RandomForest&lt;/span&gt;

&lt;span class="n"&gt;rf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomForest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_trees&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;rf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y_predict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;rf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;score:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;y_predict&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;


&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Play&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Play&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Play&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Play&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Play&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Play&amp;#39;&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Don&amp;#39;t Play&amp;quot;&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Don&amp;#39;t Play&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The random forest, unsurprisingly, does not do very well on the golf data set.  It is very small, and the rules are complicated.   Lets try it on some congress data.&lt;/p&gt;
&lt;h2&gt;Comparision with Sklearn&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;congress&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;../data/congressional_voting.csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;header&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;congress&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;congress&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;republican&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;democrat&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;n&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;?&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;congress&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;congress&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;
&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;test_size&lt;/span&gt;&lt;span class="o"&gt;=.&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;cv_score&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.&lt;/span&gt;
&lt;span class="n"&gt;skcv_score&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cross_validation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;KFold&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.ensemble&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;

&lt;span class="n"&gt;kf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;KFold&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;n_folds&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;train_index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_index&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;kf&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;rf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomForest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_trees&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;skrf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;max_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;rf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;train_index&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;train_index&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;skrf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;train_index&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;train_index&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;cv_score&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;rf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;test_index&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;test_index&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;10.&lt;/span&gt;
    &lt;span class="n"&gt;skcv_score&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;skrf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;test_index&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;test_index&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;10.&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;                       CV Accuracy    Test Accuracy&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;My RF Scores:         &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cv_score&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;rf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;My Sklearn RF Scores: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;skcv_score&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;skrf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;


                       &lt;span class="n"&gt;CV&lt;/span&gt; &lt;span class="n"&gt;Accuracy&lt;/span&gt;    &lt;span class="n"&gt;Test&lt;/span&gt; &lt;span class="n"&gt;Accuracy&lt;/span&gt;
&lt;span class="n"&gt;My&lt;/span&gt; &lt;span class="n"&gt;RF&lt;/span&gt; &lt;span class="n"&gt;Scores&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;          &lt;span class="mf"&gt;0.958441558442&lt;/span&gt; &lt;span class="mf"&gt;0.94495412844&lt;/span&gt;
&lt;span class="n"&gt;My&lt;/span&gt; &lt;span class="n"&gt;Sklearn&lt;/span&gt; &lt;span class="n"&gt;RF&lt;/span&gt; &lt;span class="n"&gt;Scores&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.958658008658&lt;/span&gt; &lt;span class="mf"&gt;0.95871559633&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Sklearn's random forest classifier and my random forest implementation give similar results in cross validation and on the test set.  On small datasets, it works in similar time.   &lt;/p&gt;
&lt;h2&gt;Afternoon&lt;/h2&gt;
&lt;p&gt;The afternoon paired sprint involved using and exploring sklearn's random forest classifier on a cell phone plan dataset attempting to predict churn.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cross_validation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.ensemble&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.neighbors&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;KNeighborsClassifier&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.tree&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DecisionTreeClassifier&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;roc_curve&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;precision_score&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;recall_score&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;confusion_matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;../data/churn.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;State&lt;/th&gt;
      &lt;th&gt;Account Length&lt;/th&gt;
      &lt;th&gt;Area Code&lt;/th&gt;
      &lt;th&gt;Phone&lt;/th&gt;
      &lt;th&gt;Int'l Plan&lt;/th&gt;
      &lt;th&gt;VMail Plan&lt;/th&gt;
      &lt;th&gt;VMail Message&lt;/th&gt;
      &lt;th&gt;Day Mins&lt;/th&gt;
      &lt;th&gt;Day Calls&lt;/th&gt;
      &lt;th&gt;Day Charge&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;Eve Calls&lt;/th&gt;
      &lt;th&gt;Eve Charge&lt;/th&gt;
      &lt;th&gt;Night Mins&lt;/th&gt;
      &lt;th&gt;Night Calls&lt;/th&gt;
      &lt;th&gt;Night Charge&lt;/th&gt;
      &lt;th&gt;Intl Mins&lt;/th&gt;
      &lt;th&gt;Intl Calls&lt;/th&gt;
      &lt;th&gt;Intl Charge&lt;/th&gt;
      &lt;th&gt;CustServ Calls&lt;/th&gt;
      &lt;th&gt;Churn?&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;KS&lt;/td&gt;
      &lt;td&gt;128&lt;/td&gt;
      &lt;td&gt;415&lt;/td&gt;
      &lt;td&gt;382-4657&lt;/td&gt;
      &lt;td&gt;no&lt;/td&gt;
      &lt;td&gt;yes&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;265.1&lt;/td&gt;
      &lt;td&gt;110&lt;/td&gt;
      &lt;td&gt;45.07&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;99&lt;/td&gt;
      &lt;td&gt;16.78&lt;/td&gt;
      &lt;td&gt;244.7&lt;/td&gt;
      &lt;td&gt;91&lt;/td&gt;
      &lt;td&gt;11.01&lt;/td&gt;
      &lt;td&gt;10.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;2.70&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;False.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;OH&lt;/td&gt;
      &lt;td&gt;107&lt;/td&gt;
      &lt;td&gt;415&lt;/td&gt;
      &lt;td&gt;371-7191&lt;/td&gt;
      &lt;td&gt;no&lt;/td&gt;
      &lt;td&gt;yes&lt;/td&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;161.6&lt;/td&gt;
      &lt;td&gt;123&lt;/td&gt;
      &lt;td&gt;27.47&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;103&lt;/td&gt;
      &lt;td&gt;16.62&lt;/td&gt;
      &lt;td&gt;254.4&lt;/td&gt;
      &lt;td&gt;103&lt;/td&gt;
      &lt;td&gt;11.45&lt;/td&gt;
      &lt;td&gt;13.7&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;3.70&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;False.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;NJ&lt;/td&gt;
      &lt;td&gt;137&lt;/td&gt;
      &lt;td&gt;415&lt;/td&gt;
      &lt;td&gt;358-1921&lt;/td&gt;
      &lt;td&gt;no&lt;/td&gt;
      &lt;td&gt;no&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;243.4&lt;/td&gt;
      &lt;td&gt;114&lt;/td&gt;
      &lt;td&gt;41.38&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;110&lt;/td&gt;
      &lt;td&gt;10.30&lt;/td&gt;
      &lt;td&gt;162.6&lt;/td&gt;
      &lt;td&gt;104&lt;/td&gt;
      &lt;td&gt;7.32&lt;/td&gt;
      &lt;td&gt;12.2&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;3.29&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;False.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;OH&lt;/td&gt;
      &lt;td&gt;84&lt;/td&gt;
      &lt;td&gt;408&lt;/td&gt;
      &lt;td&gt;375-9999&lt;/td&gt;
      &lt;td&gt;yes&lt;/td&gt;
      &lt;td&gt;no&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;299.4&lt;/td&gt;
      &lt;td&gt;71&lt;/td&gt;
      &lt;td&gt;50.90&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;88&lt;/td&gt;
      &lt;td&gt;5.26&lt;/td&gt;
      &lt;td&gt;196.9&lt;/td&gt;
      &lt;td&gt;89&lt;/td&gt;
      &lt;td&gt;8.86&lt;/td&gt;
      &lt;td&gt;6.6&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;1.78&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;False.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;OK&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;415&lt;/td&gt;
      &lt;td&gt;330-6626&lt;/td&gt;
      &lt;td&gt;yes&lt;/td&gt;
      &lt;td&gt;no&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;166.7&lt;/td&gt;
      &lt;td&gt;113&lt;/td&gt;
      &lt;td&gt;28.34&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;122&lt;/td&gt;
      &lt;td&gt;12.61&lt;/td&gt;
      &lt;td&gt;186.9&lt;/td&gt;
      &lt;td&gt;121&lt;/td&gt;
      &lt;td&gt;8.41&lt;/td&gt;
      &lt;td&gt;10.1&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;2.73&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;False.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 21 columns&lt;/p&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;for i in df.columns:
    print i, df[i].nunique()

State 51
Account Length 212
Area Code 3
Phone 3333
Int&amp;#39;l Plan 2
VMail Plan 2
VMail Message 46
Day Mins 1667
Day Calls 119
Day Charge 1667
Eve Mins 1611
Eve Calls 123
Eve Charge 1440
Night Mins 1591
Night Calls 120
Night Charge 933
Intl Mins 162
Intl Calls 21
Intl Charge 162
CustServ Calls 10
Churn? 2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We are going to clean up the data a little.   Replace boolean type values with 1 or 0, and drop some information that will not work with the classifier. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;df[&amp;#39;Int\&amp;#39;l Plan&amp;#39;]=np.where(df[&amp;#39;Int\&amp;#39;l Plan&amp;#39;]==&amp;#39;yes&amp;#39;,1,0)
df[&amp;#39;VMail Plan&amp;#39;]=np.where(df[&amp;#39;VMail Plan&amp;#39;]==&amp;#39;yes&amp;#39;,1,0)
df[&amp;#39;Churn?&amp;#39;]=np.where(df[&amp;#39;Churn?&amp;#39;]==&amp;#39;True.&amp;#39;,1,0)
df = df[[u&amp;#39;Account Length&amp;#39;, u&amp;#39;Int\&amp;#39;l Plan&amp;#39;, u&amp;#39;VMail Plan&amp;#39;, u&amp;#39;VMail Message&amp;#39;, u&amp;#39;Day Mins&amp;#39;, u&amp;#39;Day Calls&amp;#39;, u&amp;#39;Day Charge&amp;#39;, u&amp;#39;Eve Mins&amp;#39;, u&amp;#39;Eve Calls&amp;#39;, u&amp;#39;Eve Charge&amp;#39;, u&amp;#39;Night Mins&amp;#39;, u&amp;#39;Night Calls&amp;#39;, u&amp;#39;Night Charge&amp;#39;, u&amp;#39;Intl Mins&amp;#39;, u&amp;#39;Intl Calls&amp;#39;, u&amp;#39;Intl Charge&amp;#39;, u&amp;#39;CustServ Calls&amp;#39;, u&amp;#39;Churn?&amp;#39;]]
df.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Account Length&lt;/th&gt;
      &lt;th&gt;Int'l Plan&lt;/th&gt;
      &lt;th&gt;VMail Plan&lt;/th&gt;
      &lt;th&gt;VMail Message&lt;/th&gt;
      &lt;th&gt;Day Mins&lt;/th&gt;
      &lt;th&gt;Day Calls&lt;/th&gt;
      &lt;th&gt;Day Charge&lt;/th&gt;
      &lt;th&gt;Eve Mins&lt;/th&gt;
      &lt;th&gt;Eve Calls&lt;/th&gt;
      &lt;th&gt;Eve Charge&lt;/th&gt;
      &lt;th&gt;Night Mins&lt;/th&gt;
      &lt;th&gt;Night Calls&lt;/th&gt;
      &lt;th&gt;Night Charge&lt;/th&gt;
      &lt;th&gt;Intl Mins&lt;/th&gt;
      &lt;th&gt;Intl Calls&lt;/th&gt;
      &lt;th&gt;Intl Charge&lt;/th&gt;
      &lt;th&gt;CustServ Calls&lt;/th&gt;
      &lt;th&gt;Churn?&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;128&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;265.1&lt;/td&gt;
      &lt;td&gt;110&lt;/td&gt;
      &lt;td&gt;45.07&lt;/td&gt;
      &lt;td&gt;197.4&lt;/td&gt;
      &lt;td&gt;99&lt;/td&gt;
      &lt;td&gt;16.78&lt;/td&gt;
      &lt;td&gt;244.7&lt;/td&gt;
      &lt;td&gt;91&lt;/td&gt;
      &lt;td&gt;11.01&lt;/td&gt;
      &lt;td&gt;10.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;2.70&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;107&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;161.6&lt;/td&gt;
      &lt;td&gt;123&lt;/td&gt;
      &lt;td&gt;27.47&lt;/td&gt;
      &lt;td&gt;195.5&lt;/td&gt;
      &lt;td&gt;103&lt;/td&gt;
      &lt;td&gt;16.62&lt;/td&gt;
      &lt;td&gt;254.4&lt;/td&gt;
      &lt;td&gt;103&lt;/td&gt;
      &lt;td&gt;11.45&lt;/td&gt;
      &lt;td&gt;13.7&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;3.70&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;137&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;243.4&lt;/td&gt;
      &lt;td&gt;114&lt;/td&gt;
      &lt;td&gt;41.38&lt;/td&gt;
      &lt;td&gt;121.2&lt;/td&gt;
      &lt;td&gt;110&lt;/td&gt;
      &lt;td&gt;10.30&lt;/td&gt;
      &lt;td&gt;162.6&lt;/td&gt;
      &lt;td&gt;104&lt;/td&gt;
      &lt;td&gt;7.32&lt;/td&gt;
      &lt;td&gt;12.2&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;3.29&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;84&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;299.4&lt;/td&gt;
      &lt;td&gt;71&lt;/td&gt;
      &lt;td&gt;50.90&lt;/td&gt;
      &lt;td&gt;61.9&lt;/td&gt;
      &lt;td&gt;88&lt;/td&gt;
      &lt;td&gt;5.26&lt;/td&gt;
      &lt;td&gt;196.9&lt;/td&gt;
      &lt;td&gt;89&lt;/td&gt;
      &lt;td&gt;8.86&lt;/td&gt;
      &lt;td&gt;6.6&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;1.78&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;166.7&lt;/td&gt;
      &lt;td&gt;113&lt;/td&gt;
      &lt;td&gt;28.34&lt;/td&gt;
      &lt;td&gt;148.3&lt;/td&gt;
      &lt;td&gt;122&lt;/td&gt;
      &lt;td&gt;12.61&lt;/td&gt;
      &lt;td&gt;186.9&lt;/td&gt;
      &lt;td&gt;121&lt;/td&gt;
      &lt;td&gt;8.41&lt;/td&gt;
      &lt;td&gt;10.1&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;2.73&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;df.info()

&amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;
Int64Index: 3333 entries, 0 to 3332
Data columns (total 18 columns):
Account Length    3333 non-null int64
Int&amp;#39;l Plan        3333 non-null int64
VMail Plan        3333 non-null int64
VMail Message     3333 non-null int64
Day Mins          3333 non-null float64
Day Calls         3333 non-null int64
Day Charge        3333 non-null float64
Eve Mins          3333 non-null float64
Eve Calls         3333 non-null int64
Eve Charge        3333 non-null float64
Night Mins        3333 non-null float64
Night Calls       3333 non-null int64
Night Charge      3333 non-null float64
Intl Mins         3333 non-null float64
Intl Calls        3333 non-null int64
Intl Charge       3333 non-null float64
CustServ Calls    3333 non-null int64
Churn?            3333 non-null int64
dtypes: float64(8), int64(10)
memory usage: 494.7 KB
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So now we have a clean dataset with only ints and floats. Lets prepare our test and training&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;y = df[&amp;#39;Churn?&amp;#39;].values
x = df.drop(&amp;#39;Churn?&amp;#39;,axis=1).values
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = .3)
model = RandomForestClassifier()
model.fit(x_train, y_train)
y_predict = model.predict(x_test)
print &amp;quot;Base Accuracy: &amp;quot;, model.score(x_test,y_test)
print &amp;quot;Guessing No Churn:&amp;quot;, np.sum(y_test==0).astype(float)/len(y_test)

Base Accuracy:  0.939
Guessing No Churn: 0.862
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The random forest is giving a better than guessing result!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;print confusion_matrix(y_test, model.predict(x_test))

[[853   9]
 [ 52  86]]



print &amp;quot;Recall: &amp;quot;, recall_score(y_test,y_predict)
print &amp;quot;Precision: &amp;quot;, precision_score(y_test,y_predict)

Recall:  0.623188405797
Precision:  0.905263157895
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The model is having the worst problem predicting that people who do churn will churn.   Only ~60% of those that churn were predicted to do so.  There is room for imporovement in the model here.&lt;/p&gt;
&lt;p&gt;Sklearn's random forest classifiery has an out of bag error estimate as well as a estimator of feature importance.  We are going to use these next.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;model_oob = RandomForestClassifier(oob_score=True)
model_oob.fit(x_train, y_train)
oob_score = model_oob.score(x_test, y_test)
print &amp;#39;Accuracy (old/new): &amp;#39;, model.score(x_test,y_test), oob_score

print &amp;quot;OBB Estimate: &amp;quot;, model_oob.oob_score_

y_predict_oob = model_oob.predict(x_test)

print &amp;#39;Precision (old, new)&amp;#39;, precision_score(y_test, y_predict), precision_score(y_test, y_predict_oob)
print &amp;#39;Recall (old, new)&amp;#39;, recall_score(y_test, y_predict), recall_score(y_test, y_predict_oob)

Accuracy (old/new):  0.939 0.943
OBB Estimate:  0.921560222889
Precision (old, new) 0.905263157895 0.917525773196
Recall (old, new) 0.623188405797 0.644927536232
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The difference between the old and new model is not statistically significant.  They are just the natural variation in this model.   The OBB estimate is very close to the accuracy on the test set.  That is promissing.  Lets see if we can find the most important features:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;features = model.feature_importances_
print df.columns[model.feature_importances_ &amp;gt;= sorted(features)[-5]]
features = model_oob.feature_importances_
print df.columns[model_oob.feature_importances_ &amp;gt;= sorted(features)[-5]]

Index([u&amp;#39;Int&amp;#39;l Plan&amp;#39;, u&amp;#39;Day Mins&amp;#39;, u&amp;#39;Day Charge&amp;#39;, u&amp;#39;Eve Charge&amp;#39;, u&amp;#39;CustServ Calls&amp;#39;], dtype=&amp;#39;object&amp;#39;)
Index([u&amp;#39;Int&amp;#39;l Plan&amp;#39;, u&amp;#39;Day Mins&amp;#39;, u&amp;#39;Day Charge&amp;#39;, u&amp;#39;Eve Charge&amp;#39;, u&amp;#39;CustServ Calls&amp;#39;], dtype=&amp;#39;object&amp;#39;)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can see that the two models share 4 out of 5 of the same most important features.   They differ on Eve. Charge and Int'l Plan.  &lt;/p&gt;
&lt;p&gt;Before we start selecting featuers, we want to make sure that we are seeing the best model. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def tree_accuracy(num_trees):    
    model = RandomForestClassifier(oob_score=True, n_estimators=num_trees)
    model.fit(x_train, y_train)
    accuracy = model.score(x_test, y_test)
    return accuracy

treevalues1 = range(1, 1000, 100)
values1 = []
for v in treevalues1:
    values1.append(tree_accuracy(v))

treevalues2 = range(1, 200, 10)
values2 = []
for v in treevalues2:
    values2.append(tree_accuracy(v))
plt.figure(figsize=(14,8))
plt.subplot(1,2,1)
plt.plot(treevalues1, values1,lw=2,color=&amp;#39;seagreen&amp;#39;)
plt.subplot(1,2,2)
plt.plot(treevalues2, values2,lw=2,color=&amp;#39;steelblue&amp;#39;)
plt.xlabel(&amp;#39;Number of Trees&amp;#39;)
plt.ylabel(&amp;#39;accuracy&amp;#39;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D2/output_23_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We can see after about 50 estimators the accuracy does not significantly improve.   We also see if there is a limit on the number of features to consider at each node.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def tree_accuracy(num_features, num_trees=50):    
    model = RandomForestClassifier(oob_score=True, n_estimators=num_trees, max_features=num_features)
    model.fit(x_train, y_train)
    accuracy = model.score(x_test, y_test)
    return accuracy

treevalues1 = range(1, 17, 1)
values1 = []
for v in treevalues1:
    values1.append(tree_accuracy(v))

plt.figure(figsize=(14,8))
plt.plot(treevalues1, values1,lw=2,color=&amp;#39;seagreen&amp;#39;)

plt.xlabel(&amp;#39;Number of Features&amp;#39;)
plt.ylabel(&amp;#39;accuracy&amp;#39;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D2/output_25_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We can consider 4 features for each node and about 5 estimators while improving the results.&lt;/p&gt;
&lt;p&gt;I am wondering how this compares to other models we have covered.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure(figsize=(14,8))
for model in [LogisticRegression(),DecisionTreeClassifier(),KNeighborsClassifier(),RandomForestClassifier(n_estimators=50,max_features=5)]:
    model.fit(x_train,y_train)
    print &amp;quot;MODEL: &amp;quot;, model.__class__.__name__
    y_pred = model.predict(x_test)
    y_prob = model.predict_proba(x_test)[:,1]
    print &amp;quot;Accuracy&amp;quot;, accuracy_score(y_pred,y_test)
    print &amp;quot;Recall&amp;quot;, recall_score(y_pred,y_test)
    print &amp;quot;Precision&amp;quot;, precision_score(y_pred,y_test)
    print &amp;quot;&amp;quot;
    fpr,trp,thres = roc_curve(y_test,y_prob)
    plt.plot(fpr,trp,label=model.__class__.__name__)
plt.xlabel(&amp;quot;False Positive Rate&amp;quot;)
plt.ylabel(&amp;quot;True Positive Rate&amp;quot;)
plt.legend(loc=4)
plt.show()

MODEL:  LogisticRegression
Accuracy 0.872
Recall 0.647058823529
Precision 0.159420289855

MODEL:  DecisionTreeClassifier
Accuracy 0.907
Recall 0.659574468085
Precision 0.673913043478

MODEL:  KNeighborsClassifier
Accuracy 0.886
Recall 0.714285714286
Precision 0.289855072464

MODEL:  RandomForestClassifier
Accuracy 0.96
Recall 0.929824561404
Precision 0.768115942029
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D2/output_27_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;The random forest out performs the other models.   We have a relativley high true positve for a small false positive rate.   If we wanted to avoid false positive predictions of churn, the random forest can be turned to have a tre positive rate between 70 and 80%.   &lt;/p&gt;
&lt;p&gt;Now lets try to find the most important features in the data set.  We are going through each tree in our model and getting the feature importance of that model.  We then will average over all the importance estimates.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;collections&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;defaultdict&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;itertools&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;izip&lt;/span&gt;


&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;defaultdict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;tree&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;estimators_&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;findex&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tree&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;feature_importances_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ordered_features&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;findex&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;values&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tree&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;feature_importances_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;findex&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;izip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;ordered_features&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;features&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;feature_means&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;feature_stds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iteritems&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;vals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vals&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;std&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vals&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;feature_means&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;feature_stds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;feature_means&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;feature_means&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;indexes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;feature_means&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;feature_means&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;feature_means&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;indexes&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;feature_stds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;feature_stds&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="n"&gt;indexes&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;999&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;features&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="n"&gt;indexes&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;ind&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  &lt;span class="c"&gt;# the x locations for the groups&lt;/span&gt;
&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.55&lt;/span&gt;       &lt;span class="c"&gt;# the width of the bars&lt;/span&gt;

&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;feature_means&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;yerr&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;feature_stds&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Mean Importance&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Feature Importance&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xticks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ind&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xticklabels&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;rotation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;45&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D2/output_29_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;So we see that the most important features, on average, are day charge, day mins, custserv calls, int'l plan, eve charge, and int'l calls. &lt;/p&gt;
&lt;p&gt;Lets retrain the dataset on this subseted data.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;df2 = df[[u&amp;#39;Int\&amp;#39;l Plan&amp;#39;, u&amp;#39;Day Mins&amp;#39;, u&amp;#39;Day Charge&amp;#39;, u&amp;#39;Eve Mins&amp;#39;, u&amp;#39;Eve Charge&amp;#39;, u&amp;#39;CustServ Calls&amp;#39;]]
x = df2.values
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Int'l Plan&lt;/th&gt;
      &lt;th&gt;Day Mins&lt;/th&gt;
      &lt;th&gt;Day Charge&lt;/th&gt;
      &lt;th&gt;Eve Mins&lt;/th&gt;
      &lt;th&gt;Eve Charge&lt;/th&gt;
      &lt;th&gt;CustServ Calls&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;265.1&lt;/td&gt;
      &lt;td&gt;45.07&lt;/td&gt;
      &lt;td&gt;197.4&lt;/td&gt;
      &lt;td&gt;16.78&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;161.6&lt;/td&gt;
      &lt;td&gt;27.47&lt;/td&gt;
      &lt;td&gt;195.5&lt;/td&gt;
      &lt;td&gt;16.62&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;243.4&lt;/td&gt;
      &lt;td&gt;41.38&lt;/td&gt;
      &lt;td&gt;121.2&lt;/td&gt;
      &lt;td&gt;10.30&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;299.4&lt;/td&gt;
      &lt;td&gt;50.90&lt;/td&gt;
      &lt;td&gt;61.9&lt;/td&gt;
      &lt;td&gt;5.26&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;166.7&lt;/td&gt;
      &lt;td&gt;28.34&lt;/td&gt;
      &lt;td&gt;148.3&lt;/td&gt;
      &lt;td&gt;12.61&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = .3)
model = RandomForestClassifier(n_estimators=100,max_features=5)
model.fit(x_train, y_train)
y_predict = model.predict(x_test)
print &amp;quot;Base Accuracy: &amp;quot;, model.score(x_test,y_test)
print &amp;quot;Guessing No Churn:&amp;quot;, np.sum(y_test==0).astype(float)/len(y_test)
print &amp;quot;Recall: &amp;quot;, recall_score(y_test,y_predict)
print &amp;quot;Precision: &amp;quot;, precision_score(y_test,y_predict)
print confusion_matrix(y_test, model.predict(x_test))

Base Accuracy:  0.944
Guessing No Churn: 0.857
Recall:  0.671328671329
Precision:  0.914285714286
[[848   9]
 [ 47  96]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The similar model gives similar results as the more complicated model, lending credence to the idea these are the most influencial factors.   If a cell phone company wants to reduce churn then they need to deal with the number of mins and charges for customer plans.   This is where they will reduce churn.&lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="Random Forests"></category><category term="sklearn"></category></entry><entry><title>Galvanize - Week 04 - Day 1</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-04-01/" rel="alternate"></link><updated>2015-06-02T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-22:galvanize/galvanize-data-science-04-01/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 4 - Day 1&lt;/h2&gt;
&lt;p&gt;Our quiz involved creating an SQL table that will determine churn for an fake web adervertising data.  Then with this new table, and a table of predictions, we had to come up with SQL queries that would calculate accuracy, precision, recall, and specificity.  &lt;/p&gt;
&lt;h3&gt;Tables&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;advertisers
    id
    name
    city
    state
    business_type

campaigns
    advertiser_id
    campaign_id
    start_date
    duration
    daily_budget

predicted_churn
    advertiser_id
    churn
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Table Query&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;CREATE TABLE churn 
AS (SELECT a.id, 
        a.name, 
        a.city, 
        a.state, 
        a.business_type, 
        (DATEDIFF(day,
            GETDATE(),
            c.start_date)
            +c.duration &amp;gt; 14) AS churn
    FROM advertisers a 
    JOIN (SELECT c.* 
            FROM campaigns c 
            JOIN (SELECT advertiser_id, 
                    MAX(start_date) as last_campaign_date 
                    GROUPBY advertiser_id) cc 
            ON c.advertiser_id = cc.advertiser
            AND c.start_date = cc.last_campaign_date) c
    ON a.id = c.advertiser_id
    );
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Metric Query&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;SELECT CAST((TP+TN) AS FLOAT)/(TP+TN+FP+FN) as accuracy,
            CAST(TP AS FLOAT)/(TP+FN) as recall,
            CAST(TP AS FLOAT)/(TP+FP) as precision,
            CAST(TN AS FLOAT)/(TN+FP) as specificity
FROM (SELECT COUNT( CASE WHERE c.churn=1 AND pc.churn=1
                          THEN 1 ELSE 0) as TP,
             COUNT( CASE WHERE c.churn=1 AND pc.churn=0
                          THEN 1 ELSE 0) as FN,
             COUNT( CASE WHERE c.churn=0 AND pc.churn=1
                          THEN 1 ELSE 0) as FP,
             COUNT( CASE WHERE c.churn=0 AND pc.churn=0
                          THEN 1 ELSE 0) as TN,
      FROM churn c JOIN predicted_churn)
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;k Nearest Neighbors&lt;/h2&gt;
&lt;p&gt;Our morning individual sprit was to implement a kNN class that can take differnt similarity functions as a measure of nearest.  For good for bad, mine was by var the tursted solution, but that is because I perfer to think interms of matrix operations.  Because of my use of numpy, mine was also the fastest!&lt;/p&gt;
&lt;p&gt;We will start with loading some data.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;make_classification&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;load_iris&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;make_classification&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_redundant&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_informative&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="n"&gt;n_clusters_per_class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;class_sep&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;euclidean_distance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;arr&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - row: 1d numpy array k x 1&lt;/span&gt;
&lt;span class="sd"&gt;            - arr: 2d numpy array m x n&lt;/span&gt;
&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - 1d numpy array m x 1&lt;/span&gt;

&lt;span class="sd"&gt;        Calculates the euclidean distance of row from each row in arr.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;power&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;arr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;euclidean_distance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;arr&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - row: 1d numpy array k x 1&lt;/span&gt;
&lt;span class="sd"&gt;            - arr: 2d numpy array m x n&lt;/span&gt;
&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - 1d numpy array m x 1&lt;/span&gt;

&lt;span class="sd"&gt;        Calculates the euclidean distance of row from each row in arr.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;power&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;arr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cosine_distance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;arr&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - row: 1d numpy array k x 1&lt;/span&gt;
&lt;span class="sd"&gt;            - arr: 2d numpy array m x n&lt;/span&gt;
&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - 1d numpy array m x 1&lt;/span&gt;

&lt;span class="sd"&gt;        Calculates the cosign similarity of row from each row in arr.&lt;/span&gt;
&lt;span class="sd"&gt;        cosign similarity = 1 - a.dot(b)/(|a||b|)&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;arr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linalg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;norm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linalg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;norm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;KNN&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;similarity&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - k: int &amp;gt; 0&lt;/span&gt;
&lt;span class="sd"&gt;            - similarity: function(1d numpy array,2d numpy array) returns 1d numpy array&lt;/span&gt;
&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - None&lt;/span&gt;

&lt;span class="sd"&gt;        Instantiates the KNN class&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similarity&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;similarity&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - X: 2d numpy array&lt;/span&gt;
&lt;span class="sd"&gt;            - y: 1d numpy array of labels&lt;/span&gt;
&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - None&lt;/span&gt;

&lt;span class="sd"&gt;        Stores training data&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - X: 2d numpy array&lt;/span&gt;
&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - 1d numpy array&lt;/span&gt;

&lt;span class="sd"&gt;        Calculate the distances of each row in X from each row in the training data.  &lt;/span&gt;
&lt;span class="sd"&gt;        Returns the max vote from k nearest points.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="n"&gt;distances&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;apply_along_axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similarity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;apply_along_axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;bincount&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)[:&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;]])),&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;distances&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;

&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - numpy float&lt;/span&gt;

&lt;span class="sd"&gt;        Accurcy of kNN on training data&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;


&lt;span class="n"&gt;knn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;KNN&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;euclidean_distance&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;knn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;knn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;knn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;




&lt;span class="mf"&gt;1.0&lt;/span&gt;




&lt;span class="n"&gt;knn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;KNN&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;cosine_distance&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;knn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;knn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;knn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;




&lt;span class="mf"&gt;1.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;kNN on Iris Data&lt;/h2&gt;
&lt;p&gt;I will apply my KNN class on the Iris dataset from sklearn, and compare my results to the sklearn results.  I will do this for both my metrics of euclidean and cosign.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.colors&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ListedColormap&lt;/span&gt;
&lt;span class="n"&gt;cmap_light&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ListedColormap&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;#FFAAAA&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;#AAFFAA&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;#AAAAFF&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;cmap_bold&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ListedColormap&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;#FF0000&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;#00FF00&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;#0000FF&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="n"&gt;n_neighbors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;iris&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_iris&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;XI&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;iris&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; 
&lt;span class="n"&gt;yI&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;iris&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;func&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;euclidean_distance&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cosine_distance&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
    &lt;span class="n"&gt;knn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;KNN&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_neighbors&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;knn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;XI&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;yI&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;h&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;
    &lt;span class="n"&gt;x_min&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_max&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;XI&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;XI&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;y_min&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_max&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;XI&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;XI&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;yy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;meshgrid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_min&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_max&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_min&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_max&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;Z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;knn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()])&lt;/span&gt;
    &lt;span class="n"&gt;Z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Z&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pcolormesh&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Z&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cmap_light&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;XI&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;XI&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;yI&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cmap_bold&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Bryan &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot; KNN 3-Class classification (k = &lt;/span&gt;&lt;span class="si"&gt;%i&lt;/span&gt;&lt;span class="s"&gt;)&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_neighbors&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;


    &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.neighbors&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;KNeighborsClassifier&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;sKNN&lt;/span&gt;
    &lt;span class="n"&gt;sknn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sKNN&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_neighbors&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;n_neighbors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sknn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;XI&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;yI&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;h&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;
    &lt;span class="n"&gt;x_min&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_max&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;XI&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;XI&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;y_min&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_max&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;XI&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;XI&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;yy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;meshgrid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_min&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_max&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_min&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_max&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;Z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sknn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()])&lt;/span&gt;
    &lt;span class="n"&gt;Z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Z&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pcolormesh&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Z&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cmap_light&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;XI&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;XI&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;yI&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cmap_bold&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Sklearn KNN 3-Class classification (k = &lt;/span&gt;&lt;span class="si"&gt;%i&lt;/span&gt;&lt;span class="s"&gt;)&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_neighbors&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D1/output_7_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D1/output_7_1.png" /&gt;&lt;/p&gt;
&lt;h2&gt;Best K&lt;/h2&gt;
&lt;p&gt;We can use cross validation to try to find the best K to optimize for a metric.  Because the Iris data set has 3 labels, we can not use precision or recall.   We can use accuracy.   With a 20 Fold Cross Validation, we can estimate the accuracy for different K values.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;recall_score&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;precision_score&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cross_validation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;KFold&lt;/span&gt;
&lt;span class="n"&gt;mean_accuracy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;mean_precision&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;mean_recall&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;k_range&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;k_range&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;kf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;KFold&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;yI&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;n_folds&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;knn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;KNN&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;euclidean_distance&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;accuracy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="n"&gt;precision&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="n"&gt;recall&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;train_index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_index&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;kf&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;XI&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;train_index&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;XI&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;test_index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;yI&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;train_index&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;yI&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;test_index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;knn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;knn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;yI&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;precision&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;precision_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="n"&gt;recall&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;recall_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;mean_accuracy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;yI&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;mean_precision&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;precision&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
        &lt;span class="n"&gt;mean_recall&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;recall&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k_range&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;mean_accuracy&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Accuracy&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;yI&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k_range&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;mean_precision&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Precision&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k_range&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;mean_recall&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Recall&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW04D1/output_9_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;It seems like any k &amp;gt; 5 and k &amp;lt; 50 will do well this data set.  Really this should be done on a hold out set for a final estimate of the model.&lt;/p&gt;
&lt;h2&gt;Recusion&lt;/h2&gt;
&lt;p&gt;We had an optional assignment to work on Recursive methods to preare for our afternoon spring involving decision trees.  We had to make trees and print trees using the following tree class.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="n"&gt;TreeNode&lt;/span&gt;(&lt;span class="n"&gt;object&lt;/span&gt;):
    &lt;span class="n"&gt;def&lt;/span&gt; &lt;span class="n"&gt;__init__&lt;/span&gt;(&lt;span class="k"&gt;self&lt;/span&gt;, &lt;span class="nb"&gt;value&lt;/span&gt;, &lt;span class="n"&gt;left&lt;/span&gt;=&lt;span class="n"&gt;None&lt;/span&gt;, &lt;span class="n"&gt;right&lt;/span&gt;=&lt;span class="n"&gt;None&lt;/span&gt;):
        &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="nb"&gt;value&lt;/span&gt; = &lt;span class="nb"&gt;value&lt;/span&gt;
        &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;left&lt;/span&gt; = &lt;span class="n"&gt;left&lt;/span&gt;
        &lt;span class="k"&gt;self&lt;/span&gt;.&lt;span class="n"&gt;right&lt;/span&gt; = &lt;span class="n"&gt;right&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The print method I developed was just to us a "|_" style to represent branches of the tree.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def print_all(tree,level=1):
    response = &amp;quot;|_&amp;quot; + str(tree.value)
    if tree.left != None:
        response += &amp;#39;\n&amp;#39; +  &amp;quot; &amp;quot;*2*level +print_all(tree.left,level+1)
    if tree.right != None:
        response += &amp;quot;\n&amp;quot; +  &amp;quot; &amp;quot;*2*level +print_all(tree.right,level+1)
    return response

Tree = TreeNode(10,TreeNode(5,TreeNode(4),TreeNode(5)),TreeNode(10))
print print_all(Tree)

|_10
  |_5
    |_4
    |_5
  |_10
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We were asked to also find a method to find a value of a tree by summing.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def sum_tree(root):
    if root.left == None:
        if root.right==None:
            return root.value
        else:
            return root.value+sum_tree(root.right)
    elif root.right == None:
        return root.value + sum_tree(root.left)
    else:
        return sum_tree(root.left) + sum_tree(root.right) + root.value

sum_tree(Tree)




34
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We were also asked to come up with a pay to construct a tree that would give all possible out comes of n coin flips:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def build_coinflip_tree(n,root=TreeNode(&amp;quot;&amp;quot;)):
    if n == 0:
        return root
    root.left = build_coinflip_tree(n-1,root=TreeNode(&amp;quot;H&amp;quot;))
    root.right = build_coinflip_tree(n-1,root=TreeNode(&amp;quot;T&amp;quot;))
    return root

print print_all(build_coinflip_tree(3))

|_
  |_H
    |_H
      |_H
      |_T
    |_T
      |_H
      |_T
  |_T
    |_H
      |_H
      |_T
    |_T
      |_H
      |_T
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Decision Trees&lt;/h2&gt;
&lt;p&gt;The afternoon paired spring involved creating and appending pythong classes to implement a Decision tree with pre and post purning.   We started with the simple golf dataset.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;DecisionTree&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DecisionTree&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;../data/playgolf.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Outlook&lt;/th&gt;
      &lt;th&gt;Temperature&lt;/th&gt;
      &lt;th&gt;Humidity&lt;/th&gt;
      &lt;th&gt;Windy&lt;/th&gt;
      &lt;th&gt;Result&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;sunny&lt;/td&gt;
      &lt;td&gt;85&lt;/td&gt;
      &lt;td&gt;85&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;Don't Play&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;sunny&lt;/td&gt;
      &lt;td&gt;80&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
      &lt;td&gt;Don't Play&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;overcast&lt;/td&gt;
      &lt;td&gt;83&lt;/td&gt;
      &lt;td&gt;78&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;Play&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;rain&lt;/td&gt;
      &lt;td&gt;70&lt;/td&gt;
      &lt;td&gt;96&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;Play&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;rain&lt;/td&gt;
      &lt;td&gt;68&lt;/td&gt;
      &lt;td&gt;80&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;Play&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;rain&lt;/td&gt;
      &lt;td&gt;65&lt;/td&gt;
      &lt;td&gt;70&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
      &lt;td&gt;Don't Play&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;td&gt;overcast&lt;/td&gt;
      &lt;td&gt;64&lt;/td&gt;
      &lt;td&gt;65&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
      &lt;td&gt;Play&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;td&gt;sunny&lt;/td&gt;
      &lt;td&gt;72&lt;/td&gt;
      &lt;td&gt;95&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;Don't Play&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;8&lt;/th&gt;
      &lt;td&gt;sunny&lt;/td&gt;
      &lt;td&gt;69&lt;/td&gt;
      &lt;td&gt;70&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;Play&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;9&lt;/th&gt;
      &lt;td&gt;rain&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;80&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;Play&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10&lt;/th&gt;
      &lt;td&gt;sunny&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;70&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
      &lt;td&gt;Play&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;11&lt;/th&gt;
      &lt;td&gt;overcast&lt;/td&gt;
      &lt;td&gt;72&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
      &lt;td&gt;Play&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12&lt;/th&gt;
      &lt;td&gt;overcast&lt;/td&gt;
      &lt;td&gt;81&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;Play&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;13&lt;/th&gt;
      &lt;td&gt;rain&lt;/td&gt;
      &lt;td&gt;71&lt;/td&gt;
      &lt;td&gt;80&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
      &lt;td&gt;Don't Play&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;First we will show the results of the Decision Tree we made:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;y = df.Result.values
x = df.drop(&amp;#39;Result&amp;#39;,axis=1).values
dt = DecisionTree()
dt.fit(x, y,df.drop(&amp;#39;Result&amp;#39;,axis=1).columns)
print dt

Outlook
  |-&amp;gt; overcast:
  |     Play
  |-&amp;gt; no overcast:
  |     Temperature
  |     |-&amp;gt; &amp;lt; 80:
  |     |     Temperature
  |     |     |-&amp;gt; &amp;lt; 75:
  |     |     |     Temperature
  |     |     |     |-&amp;gt; &amp;lt; 71:
  |     |     |     |     Temperature
  |     |     |     |     |-&amp;gt; &amp;lt; 68:
  |     |     |     |     |     Don&amp;#39;t Play
  |     |     |     |     |-&amp;gt; &amp;gt;= 68:
  |     |     |     |     |     Play
  |     |     |     |-&amp;gt; &amp;gt;= 71:
  |     |     |     |     Don&amp;#39;t Play
  |     |     |-&amp;gt; &amp;gt;= 75:
  |     |     |     Play
  |     |-&amp;gt; &amp;gt;= 80:
  |     |     Don&amp;#39;t Play
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can see the decision tree can split on the same variable multiple times, and we can change the spliting criteria.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;dt = DecisionTree(impurity_criterion=&amp;#39;gini&amp;#39;)
dt.fit(x, y,df.drop(&amp;#39;Result&amp;#39;,axis=1).columns)
print dt

Outlook
  |-&amp;gt; overcast:
  |     Play
  |-&amp;gt; no overcast:
  |     Temperature
  |     |-&amp;gt; &amp;lt; 80:
  |     |     Temperature
  |     |     |-&amp;gt; &amp;lt; 68:
  |     |     |     Don&amp;#39;t Play
  |     |     |-&amp;gt; &amp;gt;= 68:
  |     |     |     Temperature
  |     |     |     |-&amp;gt; &amp;lt; 71:
  |     |     |     |     Play
  |     |     |     |-&amp;gt; &amp;gt;= 71:
  |     |     |     |     Temperature
  |     |     |     |     |-&amp;gt; &amp;lt; 75:
  |     |     |     |     |     Don&amp;#39;t Play
  |     |     |     |     |-&amp;gt; &amp;gt;= 75:
  |     |     |     |     |     Play
  |     |-&amp;gt; &amp;gt;= 80:
  |     |     Don&amp;#39;t Play



dt = DecisionTree(depth=2)
dt.fit(x, y,df.drop(&amp;#39;Result&amp;#39;,axis=1).columns)
print dt

Outlook
  |-&amp;gt; overcast:
  |     Play
  |-&amp;gt; no overcast:
  |     Temperature
  |     |-&amp;gt; &amp;lt; 80:
  |     |     Play
  |     |-&amp;gt; &amp;gt;= 80:
  |     |     Don&amp;#39;t Play



dt = DecisionTree(leaf_size=7)
dt.fit(x, y,df.drop(&amp;#39;Result&amp;#39;,axis=1).columns)
print dt

Outlook
  |-&amp;gt; overcast:
  |     Play
  |-&amp;gt; no overcast:
  |     Temperature
  |     |-&amp;gt; &amp;lt; 80:
  |     |     Temperature
  |     |     |-&amp;gt; &amp;lt; 75:
  |     |     |     Play
  |     |     |-&amp;gt; &amp;gt;= 75:
  |     |     |     Play
  |     |-&amp;gt; &amp;gt;= 80:
  |     |     Don&amp;#39;t Play
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Post Pruning&lt;/h2&gt;
&lt;p&gt;We also implementing a post pruning procedure that takes a test set of data and labels, then prunes the tree to non decrease accuracy while reducing the size of the tree.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cross_validation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;
&lt;span class="n"&gt;iris&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_iris&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;iris&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;iris&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;
&lt;span class="n"&gt;X_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;X_tst&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_tst&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;test_size&lt;/span&gt;&lt;span class="o"&gt;=.&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;dt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_trn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_trn&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;dt&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Accuracy On Test Set:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_tst&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;y_tst&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;dt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;prune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_tst&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_tst&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;dt&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Accuracy On Test Set:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_tst&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;y_tst&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="mi"&gt;2&lt;/span&gt;
  &lt;span class="o"&gt;|-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mf"&gt;3.5&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;
  &lt;span class="o"&gt;|-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mf"&gt;3.5&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="mi"&gt;3&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mf"&gt;1.8&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="mi"&gt;2&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mf"&gt;5.6&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="mi"&gt;1&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mf"&gt;5.6&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="mi"&gt;2&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.8&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="mi"&gt;2&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mf"&gt;4.9&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="mi"&gt;1&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mf"&gt;4.9&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt; &lt;span class="n"&gt;On&lt;/span&gt; &lt;span class="n"&gt;Test&lt;/span&gt; &lt;span class="n"&gt;Set&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.906666666667&lt;/span&gt;
&lt;span class="mi"&gt;2&lt;/span&gt;
  &lt;span class="o"&gt;|-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mf"&gt;3.5&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;
  &lt;span class="o"&gt;|-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mf"&gt;3.5&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="mi"&gt;3&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mf"&gt;1.8&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="mi"&gt;1&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.8&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;     &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt; &lt;span class="n"&gt;On&lt;/span&gt; &lt;span class="n"&gt;Test&lt;/span&gt; &lt;span class="n"&gt;Set&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.92&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Decision Tree Code&lt;/h2&gt;
&lt;p&gt;The decision tree class is built on a TreeNode class, similar to the recusion part of the lesson.   We altered the original to allow tracking of parent nodes for up and down tree transversals.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;collections&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;TreeNode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;    A node class for a decision tree.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;  &lt;span class="c"&gt;# (int)    index of feature to split on&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;  &lt;span class="c"&gt;# value of the feature to split on&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;categorical&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;  &lt;span class="c"&gt;# (bool) whether or not node is split on&lt;/span&gt;
                                 &lt;span class="c"&gt;# categorial feature&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;    &lt;span class="c"&gt;# (string) name of feature (or name of class in the&lt;/span&gt;
                            &lt;span class="c"&gt;#          case of a list)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;    &lt;span class="c"&gt;# (TreeNode) left child&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;right&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;   &lt;span class="c"&gt;# (TreeNode) right child&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;leaf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;   &lt;span class="c"&gt;# (bool)   true if node is a leaf, false otherwise&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;classes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;  &lt;span class="c"&gt;# (Counter) only necessary for leaf node:&lt;/span&gt;
                                  &lt;span class="c"&gt;#           key is class name and value is&lt;/span&gt;
                                  &lt;span class="c"&gt;#           count of the count of data points&lt;/span&gt;
                                  &lt;span class="c"&gt;#           that terminate at this leaf&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;predict_one&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - x: 1d numpy array (single data point)&lt;/span&gt;
&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - y: predicted label&lt;/span&gt;

&lt;span class="sd"&gt;        Return the predicted label for a single data point.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;leaf&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;
        &lt;span class="n"&gt;col_value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;categorical&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;col_value&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="c"&gt;### REPLACE WITH YOUR CODE&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_one&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_one&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;col_value&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="c"&gt;### REPLACE WITH YOUR CODE&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_one&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_one&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;prune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;parent&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - X_test: 2d np array&lt;/span&gt;
&lt;span class="sd"&gt;            - y_test: 1d np array&lt;/span&gt;
&lt;span class="sd"&gt;            - parent: Boolean&lt;/span&gt;
&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;

&lt;span class="sd"&gt;        Prunes node if both children are leaves.  &lt;/span&gt;
&lt;span class="sd"&gt;        If not, call prune on children.&lt;/span&gt;
&lt;span class="sd"&gt;        If prune successful, call prune on parent node. &lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;parent&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;

        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;leaf&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;categorical&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;

            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;leaf&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;leaf&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                
                &lt;span class="n"&gt;leftX&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;,:]&lt;/span&gt;
                &lt;span class="n"&gt;rightX&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;,:]&lt;/span&gt;
                &lt;span class="n"&gt;lefty&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="n"&gt;righty&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;leftX&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;left_y_pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply_along_axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_one&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;leftX&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;left_y_pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([])&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rightX&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;right_y_pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply_along_axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_one&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;rightX&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;right_y_pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([])&lt;/span&gt;
                &lt;span class="n"&gt;accuracy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;left_y_pred&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;lefty&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;right_y_pred&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;righty&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

                &lt;span class="n"&gt;new_counter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;classes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
                &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;classes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;new_counter&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;classes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

                &lt;span class="n"&gt;most_common&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new_counter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_common&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

                &lt;span class="n"&gt;node_acc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;most_common&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;node_acc&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
                    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;right&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
                    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;leaf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;
                    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;classes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new_counter&lt;/span&gt;
                    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;most_common&lt;/span&gt;
                    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parent&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;prune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;parent&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;leaf&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;prune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;,:],&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;right&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;leaf&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;

                    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;prune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;,:],&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;



    &lt;span class="c"&gt;# This is for visualizing your tree. You don&amp;#39;t need to look into this code.&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;as_string&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;prefix&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - level: int (amount to indent)&lt;/span&gt;
&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - prefix: str (to start the line with)&lt;/span&gt;

&lt;span class="sd"&gt;        Return a string representation of the tree rooted at this node.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;prefix&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;indent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;  |   &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;level&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;  |-&amp;gt; &amp;quot;&lt;/span&gt;
            &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;indent&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;prefix&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;indent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;  |   &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;level&lt;/span&gt;
        &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;indent&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;  &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;leaf&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;categorical&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;left_key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;right_key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;no &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;left_key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;lt; &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;right_key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;gt;= &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_string&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;level&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;left_key&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_string&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;level&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;right_key&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__repr__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_string&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;



&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;math&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;DecisionTree&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;    A decision tree class.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;leaf_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stop_percentage&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;error_threshold&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;impurity_criterion&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;entropy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        Initialize an empty DecisionTree.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;  &lt;span class="c"&gt;# root Node&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;feature_names&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;  &lt;span class="c"&gt;# string names of features (for interpreting&lt;/span&gt;
                                   &lt;span class="c"&gt;# the tree)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;categorical&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;  &lt;span class="c"&gt;# Boolean array of whether variable is&lt;/span&gt;
                                 &lt;span class="c"&gt;# categorical (or continuous)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;impurity_criterion&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_entropy&lt;/span&gt; \
                                  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;impurity_criterion&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;entropy&amp;#39;&lt;/span&gt; \
                                  &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_gini&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;leaf_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;leaf_size&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;leaf_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;leaf_size&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;leaf_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1e10&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stop_percentage&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;stop_percentage&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stop_percentage&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;stop_percentage&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stop_percentage&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;error_threshold&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;error_threshold&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;error_threshold&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;error_threshold&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;error_threshold&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - X: 2d numpy array&lt;/span&gt;
&lt;span class="sd"&gt;            - y: 1d numpy array&lt;/span&gt;
&lt;span class="sd"&gt;            - feature_names: numpy array of strings&lt;/span&gt;
&lt;span class="sd"&gt;        OUTPUT: None&lt;/span&gt;

&lt;span class="sd"&gt;        Build the decision tree.&lt;/span&gt;
&lt;span class="sd"&gt;        X is a 2 dimensional array with each column being a feature and each&lt;/span&gt;
&lt;span class="sd"&gt;        row a data point.&lt;/span&gt;
&lt;span class="sd"&gt;        y is a 1 dimensional array with each value being the corresponding&lt;/span&gt;
&lt;span class="sd"&gt;        label.&lt;/span&gt;
&lt;span class="sd"&gt;        feature_names is an optional list containing the names of each of the&lt;/span&gt;
&lt;span class="sd"&gt;        features.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;feature_names&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;feature_names&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;feature_names&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;feature_names&lt;/span&gt;

        &lt;span class="c"&gt;# Create True/False array of whether the variable is categorical&lt;/span&gt;
        &lt;span class="n"&gt;is_categorical&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; \
                                   &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;bool&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; \
                                   &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;unicode&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;categorical&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vectorize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;is_categorical&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_build_tree&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_build_tree&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;counter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - X: 2d numpy array&lt;/span&gt;
&lt;span class="sd"&gt;            - y: 1d numpy array&lt;/span&gt;
&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - TreeNode&lt;/span&gt;

&lt;span class="sd"&gt;        Recursively build the decision tree. Return the root node.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

        &lt;span class="n"&gt;node&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TreeNode&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;splits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_choose_split_index&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;return_counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;counter&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stop_percentage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;leaf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;
            &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;classes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;classes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_common&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;X1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;splits&lt;/span&gt;
            &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;
            &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;
            &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;categorical&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;categorical&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

            &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_build_tree&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;counter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;counter&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;node&lt;/span&gt;

            &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;right&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_build_tree&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;counter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;counter&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;node&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;node&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_entropy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - y: 1d numpy array&lt;/span&gt;
&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - float&lt;/span&gt;

&lt;span class="sd"&gt;        Return the entropy of the array y.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;return_counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_gini&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - y: 1d numpy array&lt;/span&gt;
&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - float&lt;/span&gt;

&lt;span class="sd"&gt;        Return the gini impurity of the array y.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;return_counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;power&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_make_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;split_index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;split_value&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - X: 2d numpy array&lt;/span&gt;
&lt;span class="sd"&gt;            - y: 1d numpy array&lt;/span&gt;
&lt;span class="sd"&gt;            - split_index: int (index of feature)&lt;/span&gt;
&lt;span class="sd"&gt;            - split_value: int/float/bool/str (value of feature)&lt;/span&gt;
&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - X1: 2d numpy array (feature matrix for subset 1)&lt;/span&gt;
&lt;span class="sd"&gt;            - y1: 1d numpy array (labels for subset 1)&lt;/span&gt;
&lt;span class="sd"&gt;            - X2: 2d numpy array (feature matrix for subset 2)&lt;/span&gt;
&lt;span class="sd"&gt;            - y2: 1d numpy array (labels for subset 2)&lt;/span&gt;

&lt;span class="sd"&gt;        Return the two subsets of the dataset achieved by the given feature and&lt;/span&gt;
&lt;span class="sd"&gt;        value to split on.&lt;/span&gt;

&lt;span class="sd"&gt;        Call the method like this:&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;gt;&amp;gt;&amp;gt; X1, y1, X2, y2 = self._make_split(X, y, split_index, split_value)&lt;/span&gt;

&lt;span class="sd"&gt;        X1, y1 is a subset of the data.&lt;/span&gt;
&lt;span class="sd"&gt;        X2, y2 is the other subset of the data.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;categorical&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;split_index&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
            &lt;span class="n"&gt;condition&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="n"&gt;split_index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;split_value&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;condition&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="n"&gt;split_index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;split_value&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;condition&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,:],&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;condition&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;condition&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,:],&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;condition&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_information_gain&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - y: 1d numpy array&lt;/span&gt;
&lt;span class="sd"&gt;            - y1: 1d numpy array (labels for subset 1)&lt;/span&gt;
&lt;span class="sd"&gt;            - y2: 1d numpy array (labels for subset 2)&lt;/span&gt;
&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - float&lt;/span&gt;

&lt;span class="sd"&gt;        Return the information gain of making the given split.&lt;/span&gt;

&lt;span class="sd"&gt;        Use self.impurity_criterion(y) rather than calling _entropy or _gini&lt;/span&gt;
&lt;span class="sd"&gt;        directly.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;impurity_criterion&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;impurity_criterion&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; \
                &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;impurity_criterion&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_choose_split_index&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - X: 2d numpy array&lt;/span&gt;
&lt;span class="sd"&gt;            - y: 1d numpy array&lt;/span&gt;
&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - index: int (index of feature)&lt;/span&gt;
&lt;span class="sd"&gt;            - value: int/float/bool/str (value of feature)&lt;/span&gt;
&lt;span class="sd"&gt;            - splits: (2d array, 1d array, 2d array, 1d array)&lt;/span&gt;

&lt;span class="sd"&gt;        Determine which feature and value to split on. Return the index and&lt;/span&gt;
&lt;span class="sd"&gt;        value of the optimal split along with the split of the dataset.&lt;/span&gt;

&lt;span class="sd"&gt;        Return None, None, None if there is no split which improves information&lt;/span&gt;
&lt;span class="sd"&gt;        gain.&lt;/span&gt;

&lt;span class="sd"&gt;        Call the method like this:&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;gt;&amp;gt;&amp;gt; index, value, splits = self._choose_split_index(X, y)&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;gt;&amp;gt;&amp;gt; X1, y1, X2, y2 = splits&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;leaf_size&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;leaf_size&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;

        &lt;span class="n"&gt;index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="n"&gt;max_gain&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1e10&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;xrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])):&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;split_value&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
                &lt;span class="n"&gt;X1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_make_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;split_value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;gain&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_information_gain&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;gain&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;max_gain&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;max_gain&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gain&lt;/span&gt;
                    &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;split_value&lt;/span&gt;
                    &lt;span class="n"&gt;index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;

        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;max_gain&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;error_threshold&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_make_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        INPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - X: 2d numpy array&lt;/span&gt;
&lt;span class="sd"&gt;        OUTPUT:&lt;/span&gt;
&lt;span class="sd"&gt;            - y: 1d numpy array&lt;/span&gt;

&lt;span class="sd"&gt;        Return an array of predictions for the feature matrix X.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply_along_axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_one&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;arr&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;prune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;prune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__str__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        Return string representation of the Decision Tree.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="kNN"></category><category term="K Nearest Neighbors"></category><category term="Decision Trees"></category></entry><entry><title>Galvanize - Week 03 - Day 5</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-03-05/" rel="alternate"></link><updated>2015-06-19T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-19:galvanize/galvanize-data-science-03-05/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 3 - Day 5&lt;/h2&gt;
&lt;p&gt;Today we had our checkin survey as a quiz, then we had a lecture on gradient decent.  We covered examples using linear and logistic regression.  The assignment was an all day paired sprint. &lt;/p&gt;
&lt;h2&gt;Gradient Descent&lt;/h2&gt;
&lt;p&gt;We will be implementing logistic regression using the gradient descent algorithm.  The goal in to include regulation and stocastic gradient decent.  We will start by testing it on data that will allow for simple solutions.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;scipy.optimize&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;op&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;genfromtxt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data/testdata.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;delimiter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;xp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,:]&lt;/span&gt;
&lt;span class="n"&gt;xn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,:]&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xp&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;xp&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;go&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Positive&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xn&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;xn&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ro&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Negative&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;First Feature&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Second Feature&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D5/output_1_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;This data set is very nice because the positive and negative examples are linearly separable.   I'll have to remember this dataset when I try to implement support vector machines.  I can guess the sigmoid function that will fit this data.&lt;/p&gt;
&lt;p&gt;$$y = \frac{1}{1+e^{-2x_1}}$$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x  = np.linspace(-6,8,100)
y1 = 1/(1+np.exp(-2.*(x)))
plt.plot(X[:,0],y,&amp;#39;ro&amp;#39;)
plt.plot(x,y1,&amp;#39;b-&amp;#39;)
plt.ylim([-0.1,1.1])
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D5/output_3_0.png" /&gt;&lt;/p&gt;
&lt;h2&gt;Cost function&lt;/h2&gt;
&lt;p&gt;In order to be able to evaluate if our gradient descent algorithm is working correctly, we will need to be able to calculate the cost.  The cost function we will be using is the &lt;em&gt;log likelihood&lt;/em&gt;. Our goal will be to &lt;em&gt;maximize&lt;/em&gt; this value, so we will actually be implementing gradient &lt;em&gt;ascent&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;$$ \mathcal{l}(\Theta) = Log(\mathcal{L}(\Theta))= \Sigma_{i} ( \ y_i  \ log( \ h(x_i|\Theta) \ ) + (1-y_i) \ log( \ 1-h(x_i|\Theta) \ ) \ )$$&lt;/p&gt;
&lt;p&gt;where the hypothesis fucntion is &lt;/p&gt;
&lt;p&gt;$$ h(x|\Theta) = \frac{1}{1 \ + \ e^{\Theta x}} $$&lt;/p&gt;
&lt;p&gt;We will be using the gradient ascent potion of using &lt;/p&gt;
&lt;p&gt;$$\Theta_i = \Theta_i + \alpha \frac{\partial}{\partial\Theta_i} \mathcal{l}(\Theta)$$&lt;/p&gt;
&lt;p&gt;Where alpha is the learning rate for the update.   We can show that &lt;/p&gt;
&lt;p&gt;$$\frac{\partial}{\partial\Theta_i} \mathcal{l}(\Theta) = \Sigma_{i} ( \ y_i \ - \ h(x_i|\Theta) \ ) \ x_j $$&lt;/p&gt;
&lt;p&gt;We also implimented feature scaling, the options to fit the intercept, and Ridge (l2) penalizations.  This is done by subtracking a term from the cost function.&lt;/p&gt;
&lt;p&gt;$$ \mathcal{l}(\Theta) = Log(\mathcal{L}(\Theta))= \Sigma_{i} ( \ y_i  \ log( \ h(x_i|\Theta) \ ) + (1-y_i) \ log( \ 1-h(x_i|\Theta) \ ) \ ) - \lambda \Theta^2$$&lt;/p&gt;
&lt;p&gt;This changes the update function to&lt;/p&gt;
&lt;p&gt;$$\frac{\partial}{\partial\theta_i} \mathcal{l}(\Theta) = \Sigma_{i} ( \ y_i \ - \ h(x_i|\Theta) \ ) \ x_j - 2 \ \lambda \theta_i$$&lt;/p&gt;
&lt;p&gt;The larger the parameter lambda, the stronger the pull for the coefficients to be zero.&lt;/p&gt;
&lt;p&gt;The last method we implmeneted was a stocastic gradient decent. Where we shuffled the data and take a set for each data point.  We then reshuffle the data and take another stuff.   This, in practice, is faster than hill climbing.   We did not implement this with regularization.   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kr"&gt;class&lt;/span&gt; &lt;span class="nx"&gt;regression_function&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;

    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;fit_intercept&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;scale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;lamb&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;tol&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="nx"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;x&lt;/span&gt;
        &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;y&lt;/span&gt;
        &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;lamb&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;lamb&lt;/span&gt;
        &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;shape&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;shape&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;theta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,:&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;scale&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;scale&lt;/span&gt;
        &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;fit_intercept&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;fit_intercept&lt;/span&gt;
        &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;tol&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;tol&lt;/span&gt;
        &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x_mean&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;axis&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x_std&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;std&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nx"&gt;scale&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    
            &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x_mean&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x_std&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nx"&gt;fit_intercept&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
            &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;add_intercept&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;row_hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;row&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;row&lt;/span&gt;&lt;span class="p"&gt;,:&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;


    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;X&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nx"&gt;X&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nx"&gt;None&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;X&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;X&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;thresh&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nx"&gt;X&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nx"&gt;None&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="nx"&gt;thresh&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kr"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;scale&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
                &lt;span class="nx"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;X&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x_mean&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x_std&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;fit_intercept&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
                &lt;span class="nx"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;add_intercept&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="nx"&gt;thresh&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kr"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;log_likelihood&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="nx"&gt;llh&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;lamb&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;T&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;llh&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="cp"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;

    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;log_likelihood_gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;T&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;hypothesis&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;lamb&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;theta&lt;/span&gt;


    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;stoch_log_likelihood_gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;row&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="nx"&gt;xt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;row&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;T&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;xt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;row&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;row_hypothesis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;row&lt;/span&gt;&lt;span class="p"&gt;)).&lt;/span&gt;&lt;span class="nx"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;gradient_ascent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="nx"&gt;lik_diff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
        &lt;span class="nx"&gt;previous_likelihood&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log_likelihood&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="nx"&gt;lik_diff&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;tol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
            &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;theta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;theta&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nx"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log_likelihood_gradient&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="nx"&gt;temp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log_likelihood&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="nx"&gt;lik_diff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;temp&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nx"&gt;previous_likelihood&lt;/span&gt;
            &lt;span class="nx"&gt;previous_likelihood&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;temp&lt;/span&gt;

    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;stoch_gradient_ascent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="nx"&gt;lik_diff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
        &lt;span class="nx"&gt;previous_likelihood&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log_likelihood&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="nx"&gt;rows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;shuffle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="k"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;,:&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;
        &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="k"&gt;rows&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;

        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="nx"&gt;lik_diff&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;tol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nx"&gt;i&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="nx"&gt;xrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
                &lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;STOCK LIKI:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;stoch_log_likelihood_gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Shapes:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;stoch_log_likelihood_gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;shape&lt;/span&gt;
                &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;theta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;theta&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nx"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;stoch_log_likelihood_gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="nx"&gt;temp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log_likelihood&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="nx"&gt;Sprint&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;TEMP:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;temp&lt;/span&gt;
            &lt;span class="nx"&gt;lik_diff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;temp&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nx"&gt;previous_likelihood&lt;/span&gt;
            &lt;span class="nx"&gt;previous_likelihood&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;temp&lt;/span&gt;

            &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;shuffle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="k"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;,:&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;
            &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="k"&gt;rows&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;

    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;add_intercept&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;X&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nx"&gt;X&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="nx"&gt;None&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
            &lt;span class="nx"&gt;ones&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,:&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="nx"&gt;ones&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="p"&gt;:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt;
            &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;ones&lt;/span&gt;
            &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;theta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,:&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
            &lt;span class="nx"&gt;ones&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;X&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;X&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,:&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="nx"&gt;ones&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="p"&gt;:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;X&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;ones&lt;/span&gt;


    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;get_coeff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;scale&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;fit_intercept&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;T&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;hstack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x_std&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;T&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;x_std&lt;/span&gt; 
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;T&lt;/span&gt;




&lt;span class="nx"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;regression_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;delta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="nx"&gt;t1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;3.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;3.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;delta&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;t2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;3.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;3.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;delta&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;T1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;T2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;meshgrid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;t1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;t2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;Z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;T1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;x1&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="nx"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;t1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nx"&gt;j&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;y1&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="nx"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;t2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;theta&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;x1&lt;/span&gt;
        &lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;theta&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;y1&lt;/span&gt;
        &lt;span class="nx"&gt;Z&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;j&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log_likelihood&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;CS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;contour&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;T1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;T2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;Z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;clabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;CS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;inline&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;First Feature&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Second Feature&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Controur of Log Likelihood&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;




&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nx"&gt;matplotlib&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;text&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Text&lt;/span&gt; &lt;span class="nx"&gt;at&lt;/span&gt; &lt;span class="mh"&gt;0x10a552c50&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D5/output_6_1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.pcolor(Z)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D5/output_7_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;These plots are showing how seperable the data is.   We could fit this data with a number of logisitic function perfectly.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x  = np.linspace(-6,8,100)
y1 = 1/(1+np.exp(-2.*(x)))
y2 = 1/(1+np.exp(-10.*(x)))
y3 = 1/(1+np.exp(-100.*(x)))
plt.plot(X[:,0],y,&amp;#39;ro&amp;#39;)
plt.plot(x,y1,&amp;#39;b-&amp;#39;)
plt.plot(x,y2,&amp;#39;b-&amp;#39;)
plt.plot(x,y3,&amp;#39;b-&amp;#39;)
plt.ylim([-0.1,1.1])
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D5/output_9_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;So for any logistic function with a postive constant with a first feature will fit the data we have.  &lt;/p&gt;
&lt;h2&gt;Compare to Sklearn&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;regression_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gradient_ascent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.00001&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;theta&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Accuracy: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="p"&gt;[[&lt;/span&gt; &lt;span class="mf"&gt;0.01688462&lt;/span&gt;  &lt;span class="mf"&gt;1.27894634&lt;/span&gt;  &lt;span class="mf"&gt;0.00995178&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;1.0&lt;/span&gt;



&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;

&lt;span class="n"&gt;lin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fit_intercept&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;lin&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;lin&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intercept_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lin&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coef_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lin&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="mf"&gt;0.04652751&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt; &lt;span class="mf"&gt;1.2318561&lt;/span&gt;   &lt;span class="mf"&gt;0.02251709&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;


&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Library&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Python&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;2.7&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;packages&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sklearn&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;utils&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;validation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;449&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;DataConversionWarning&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;vector&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="n"&gt;was&lt;/span&gt; &lt;span class="n"&gt;passed&lt;/span&gt; &lt;span class="n"&gt;when&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt; &lt;span class="n"&gt;was&lt;/span&gt; &lt;span class="n"&gt;expected&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Please&lt;/span&gt; &lt;span class="n"&gt;change&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;example&lt;/span&gt; &lt;span class="n"&gt;using&lt;/span&gt; &lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
  &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;column_or_1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;warn&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This give similar results to sklearn.   The sklearn package does seem to be faster, but I also believe it is using a c package called liblinear for its optimization, while we are doing it in pure python.&lt;/p&gt;
&lt;h2&gt;Checking Scaling&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nx"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;regression_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;fit_intercept&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;scale&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;gradient_ascent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.0001&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;get_coeff&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Accuracy: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;predictions&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="kr"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="err"&gt;[&lt;/span&gt; &lt;span class="mf"&gt;0.17710665&lt;/span&gt;  &lt;span class="mf"&gt;1.17554584&lt;/span&gt;  &lt;span class="mf"&gt;0.05796619&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nx"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;1.0&lt;/span&gt;



&lt;span class="nx"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;regression_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;fit_intercept&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;scale&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;gradient_ascent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.00001&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;get_coeff&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Accuracy: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;predictions&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="kr"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log_likelihood&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="err"&gt;[&lt;/span&gt; &lt;span class="mf"&gt;0.01688462&lt;/span&gt;  &lt;span class="mf"&gt;1.27894634&lt;/span&gt;  &lt;span class="mf"&gt;0.00995178&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nx"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;1.0&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.227847971687&lt;/span&gt;



&lt;span class="nx"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;regression_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;fit_intercept&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;scale&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;gradient_ascent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.00001&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;get_coeff&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Accuracy: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;predictions&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="kr"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="err"&gt;[&lt;/span&gt; &lt;span class="mf"&gt;0.09595542&lt;/span&gt;  &lt;span class="mf"&gt;0.92911705&lt;/span&gt;  &lt;span class="mf"&gt;0.0366225&lt;/span&gt; &lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nx"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;1.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Graduate Student Data&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;genfromtxt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data/grad.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;skiprows&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;delimiter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;yg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;xg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;span class="n"&gt;rg&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;regression_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xg&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;yg&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;fit_intercept&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;scale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;tol&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-6&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;rg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gradient_ascent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.000001&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;rg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_coeff&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;rg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.84699307&lt;/span&gt;  &lt;span class="mf"&gt;0.00229446&lt;/span&gt;  &lt;span class="mf"&gt;0.76299305&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.54843734&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;





&lt;span class="mf"&gt;0.70499999999999996&lt;/span&gt;




&lt;span class="n"&gt;log&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xg&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;yg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hstack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intercept_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coef_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xg&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;yg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.18847876&lt;/span&gt;  &lt;span class="mf"&gt;0.00191577&lt;/span&gt;  &lt;span class="mf"&gt;0.21564289&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.59842009&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="mf"&gt;0.715&lt;/span&gt;


&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Library&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Python&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;2.7&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;packages&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sklearn&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;utils&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;validation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;449&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;DataConversionWarning&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;vector&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="n"&gt;was&lt;/span&gt; &lt;span class="n"&gt;passed&lt;/span&gt; &lt;span class="n"&gt;when&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt; &lt;span class="n"&gt;was&lt;/span&gt; &lt;span class="n"&gt;expected&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Please&lt;/span&gt; &lt;span class="n"&gt;change&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;example&lt;/span&gt; &lt;span class="n"&gt;using&lt;/span&gt; &lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
  &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;column_or_1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;warn&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Regularization&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nx"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;regression_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;fit_intercept&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;scale&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;lamb&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;gradient_ascent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.00001&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;get_coeff&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Accuracy: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;predictions&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="kr"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="err"&gt;[&lt;/span&gt; &lt;span class="mf"&gt;0.09595542&lt;/span&gt;  &lt;span class="mf"&gt;0.92911705&lt;/span&gt;  &lt;span class="mf"&gt;0.0366225&lt;/span&gt; &lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nx"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;1.0&lt;/span&gt;



&lt;span class="nx"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;regression_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;fit_intercept&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;scale&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;lamb&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;gradient_ascent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.00001&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;get_coeff&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Accuracy: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;predictions&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="kr"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="err"&gt;[&lt;/span&gt; &lt;span class="mf"&gt;0.02568882&lt;/span&gt;  &lt;span class="mf"&gt;0.53308379&lt;/span&gt;  &lt;span class="mf"&gt;0.01324245&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nx"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;1.0&lt;/span&gt;



&lt;span class="nx"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;regression_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;fit_intercept&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;scale&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;lamb&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;gradient_ascent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.00001&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;get_coeff&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Accuracy: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;predictions&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="kr"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="err"&gt;[&lt;/span&gt; &lt;span class="mf"&gt;0.00178464&lt;/span&gt;  &lt;span class="mf"&gt;0.22617375&lt;/span&gt;  &lt;span class="mf"&gt;0.00074595&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nx"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;1.0&lt;/span&gt;



&lt;span class="nx"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;regression_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;fit_intercept&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;scale&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;lamb&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;gradient_ascent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.00001&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;get_coeff&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Accuracy: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;predictions&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="kr"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="err"&gt;[&lt;/span&gt;  &lt;span class="mf"&gt;3.04588371e-06&lt;/span&gt;   &lt;span class="mf"&gt;4.27234980e-02&lt;/span&gt;  &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;8.65650480e-04&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nx"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;1.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Stochastic Gradient Descent&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;regression_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;fit_intercept&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;scale&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lamb&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tol&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1e-5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;print&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log_likelihood&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nf"&gt;%timeit&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stoch_gradient_ascent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;print&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log_likelihood&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;print&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_coeff&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;69.314718056&lt;/span&gt;
&lt;span class="n"&gt;The&lt;/span&gt; &lt;span class="n"&gt;slowest&lt;/span&gt; &lt;span class="n"&gt;run&lt;/span&gt; &lt;span class="n"&gt;took&lt;/span&gt; &lt;span class="mf"&gt;68.69&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt; &lt;span class="n"&gt;longer&lt;/span&gt; &lt;span class="n"&gt;than&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;fastest&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="n"&gt;This&lt;/span&gt; &lt;span class="n"&gt;could&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="n"&gt;that&lt;/span&gt; &lt;span class="n"&gt;an&lt;/span&gt; &lt;span class="n"&gt;intermediate&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;being&lt;/span&gt; &lt;span class="n"&gt;cached&lt;/span&gt; 
&lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;2.29&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.000261667070057&lt;/span&gt;
&lt;span class="p"&gt;[[&lt;/span&gt; &lt;span class="mf"&gt;1.40603903&lt;/span&gt;  &lt;span class="mf"&gt;2.90379792&lt;/span&gt;  &lt;span class="mf"&gt;0.22544191&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;



&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;regression_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;fit_intercept&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;scale&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lamb&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tol&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1e-5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;print&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log_likelihood&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nf"&gt;%timeit&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gradient_ascent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1e-1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;print&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log_likelihood&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;print&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_coeff&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;69.314718056&lt;/span&gt;
&lt;span class="n"&gt;The&lt;/span&gt; &lt;span class="n"&gt;slowest&lt;/span&gt; &lt;span class="n"&gt;run&lt;/span&gt; &lt;span class="n"&gt;took&lt;/span&gt; &lt;span class="mf"&gt;1034.52&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt; &lt;span class="n"&gt;longer&lt;/span&gt; &lt;span class="n"&gt;than&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;fastest&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="n"&gt;This&lt;/span&gt; &lt;span class="n"&gt;could&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="n"&gt;that&lt;/span&gt; &lt;span class="n"&gt;an&lt;/span&gt; &lt;span class="n"&gt;intermediate&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;being&lt;/span&gt; &lt;span class="n"&gt;cached&lt;/span&gt; 
&lt;span class="mi"&gt;10000&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;129&lt;/span&gt; &lt;span class="err"&gt;µ&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.000393662821043&lt;/span&gt;
&lt;span class="p"&gt;[[&lt;/span&gt; &lt;span class="mf"&gt;1.31662671&lt;/span&gt;  &lt;span class="mf"&gt;2.79854521&lt;/span&gt;  &lt;span class="mf"&gt;0.25109632&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Newton's Method for a single variable&lt;/h2&gt;
&lt;p&gt;We were told to use newton's method for root finding on the following function:&lt;/p&gt;
&lt;p&gt;$$f(x) = 6 \ x^2 + 3 \ x - 10$$&lt;/p&gt;
&lt;p&gt;This function has two roots: -1.565 and 1.0650.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;math&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;df&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mf"&gt;0.00001&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.00001&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.00002&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;newton_roots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;tolerance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1e-3&lt;/span&gt;
    &lt;span class="n"&gt;xo&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="n"&gt;toll&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fabs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;toll&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;tolerance&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;xo&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;xo&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xo&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;xo&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;toll&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xo&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mf"&gt;1e6&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;xo&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;collections&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;

&lt;span class="n"&gt;cnt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;round&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;newton_roots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;cnt&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;cnt&lt;/span&gt;

&lt;span class="n"&gt;Counter&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mf"&gt;1.065&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;54&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.565&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;46&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can see that we get the two roots about equal number of times.  &lt;/p&gt;</summary><category term="data-science"></category><category term="gradient decent"></category><category term="stocastic gradient decent"></category><category term="logistic regression"></category></entry><entry><title>Galvanize - Week 03 - Day 4</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-03-04/" rel="alternate"></link><updated>2015-06-18T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-18:galvanize/galvanize-data-science-03-04/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 3 - Day 4&lt;/h2&gt;
&lt;p&gt;Today we had a 2 hour assessment on everything we covered.  There were programming style problem and 1 math style problems.  The topics were on everything we have covered up to now.  &lt;/p&gt;
&lt;h2&gt;Afternoon&lt;/h2&gt;
&lt;p&gt;The lectures today were on Logistic Regresion, Odds, and ROC Curves.   &lt;/p&gt;
&lt;h2&gt;ROC Curve&lt;/h2&gt;
&lt;p&gt;We were told that one of the best ways to evaluate how a classifier performs is an &lt;a href="http://en.wikipedia.org/wiki/Receiver_operating_characteristic"&gt;ROC curve&lt;/a&gt;.   They display the change in the false and true positive rates as paramters in the model change.  In the case of logistic regression, its the threshold use to classify a data point based on the predicted probability. &lt;/p&gt;
&lt;p&gt;Recall that the &lt;em&gt;true positive rate&lt;/em&gt; is&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; number of true positives     number correctly predicted positive
-------------------------- = -------------------------------------
 number of positive cases           number of positive cases
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and the &lt;em&gt;false positive rate&lt;/em&gt; is&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; number of false positives     number incorrectly predicted positive
--------------------------- = ---------------------------------------
  number of negative cases           number of negative cases
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;make_classification&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cross_validation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;__future__&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;division&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;roc_curve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;thresholds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;TPR&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="n"&gt;FPR&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;thresh&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;thresholds&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="n"&gt;thresh&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;TPR&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;FPR&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;TPR&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TPR&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;FPR&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;FPR&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;TPR&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;FPR&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;thresholds&lt;/span&gt;


&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;make_classification&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_redundant&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_informative&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="n"&gt;n_clusters_per_class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;probabilities&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_proba&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;)[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;tpr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fpr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;thresholds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;roc_curve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;probabilities&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fpr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tpr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;seagreen&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;False Positive Rate (1 - Specificity)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;True Positive Rate (Sensitivity, Recall)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;ROC plot of fake data&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D4/output_1_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;roc_curve&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;roc&lt;/span&gt;
&lt;span class="n"&gt;fpr1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;tpr1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;threshs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;roc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;probabilities&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fpr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tpr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;seagreen&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;linestyle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;--&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;marker&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;o&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Bryans ROC&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fpr1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tpr1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;indianred&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Sklearn ROC&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;False Positive Rate (1 - Specificity)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;True Positive Rate (Sensitivity, Recall)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;ROC plot of fake data&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D4/output_2_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;The results between the two curves is negligable on a fake dataset.  We are now going to do this with FICO data.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data/loanf.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Interest.Rate&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;FICO.Score&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Loan.Length&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Loan.Amount&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;


&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cross_validation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.calibration&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;CalibratedClassifierCV&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LogisticRegressionCV&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;roc_auc_score&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;recall_score&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;precision_score&lt;/span&gt;

&lt;span class="n"&gt;a_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;a_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;cal&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CalibratedClassifierCV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;isotonic&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cal&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;probs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cal&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_proba&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a_test&lt;/span&gt;&lt;span class="p"&gt;)[:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;tpr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fpr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;thresholds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;roc_curve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;probs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fpr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tpr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;seagreen&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;False Positive Rate (1 - Specificity)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;True Positive Rate (Sensitivity, Recall)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;ROC plot of Loan Data&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;AUC: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;roc_auc_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cal&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a_test&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;b_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Accuracy: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cal&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a_test&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;b_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Recall: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;recall_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cal&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a_test&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;b_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Precision: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;precision_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cal&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a_test&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;b_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D4/output_5_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; AUC:  0.763176276353
Accuracy:  0.769333333333
Recall:  0.744094488189
Precision:  0.636363636364
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The the model is not a great model, but it does start off identifying 3 out of 4 true positives and has 6 our of 10 of those predicted to be positive actually being positive.  &lt;/p&gt;
&lt;h2&gt;Graduate School Admissions&lt;/h2&gt;
&lt;p&gt;The data we will be using net is admission data on Grad school acceptances.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;admit&lt;/code&gt;: whether or not the applicant was admitted to grad. school&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gpa&lt;/code&gt;: undergraduate GPA&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GRE&lt;/code&gt;: score of GRE test&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rank&lt;/code&gt;: prestige of undergraduate school (1 is highest prestige, ala Harvard)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We will use the GPA, GRE, and rank of the applicants to try to predict whether or not they will be accepted into graduate school.&lt;/p&gt;
&lt;p&gt;Before we get to predictions, we should do some data exploration.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Load in the dataset into pandas: &lt;code&gt;data/grad.csv&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;grad = pd.read_csv('data/grad.csv')
grad.head()&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;admit&lt;/th&gt;
      &lt;th&gt;gre&lt;/th&gt;
      &lt;th&gt;gpa&lt;/th&gt;
      &lt;th&gt;rank&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;380&lt;/td&gt;
      &lt;td&gt;3.61&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;660&lt;/td&gt;
      &lt;td&gt;3.67&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;800&lt;/td&gt;
      &lt;td&gt;4.00&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;640&lt;/td&gt;
      &lt;td&gt;3.19&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;520&lt;/td&gt;
      &lt;td&gt;2.93&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;grad.info()

&amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;
Int64Index: 400 entries, 0 to 399
Data columns (total 4 columns):
admit    400 non-null int64
gre      400 non-null int64
gpa      400 non-null float64
rank     400 non-null int64
dtypes: float64(1), int64(3)
memory usage: 15.6 KB



grad.describe()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;admit&lt;/th&gt;
      &lt;th&gt;gre&lt;/th&gt;
      &lt;th&gt;gpa&lt;/th&gt;
      &lt;th&gt;rank&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;count&lt;/th&gt;
      &lt;td&gt;400.000000&lt;/td&gt;
      &lt;td&gt;400.000000&lt;/td&gt;
      &lt;td&gt;400.000000&lt;/td&gt;
      &lt;td&gt;400.00000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;mean&lt;/th&gt;
      &lt;td&gt;0.317500&lt;/td&gt;
      &lt;td&gt;587.700000&lt;/td&gt;
      &lt;td&gt;3.389900&lt;/td&gt;
      &lt;td&gt;2.48500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;std&lt;/th&gt;
      &lt;td&gt;0.466087&lt;/td&gt;
      &lt;td&gt;115.516536&lt;/td&gt;
      &lt;td&gt;0.380567&lt;/td&gt;
      &lt;td&gt;0.94446&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;min&lt;/th&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;220.000000&lt;/td&gt;
      &lt;td&gt;2.260000&lt;/td&gt;
      &lt;td&gt;1.00000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;25%&lt;/th&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;520.000000&lt;/td&gt;
      &lt;td&gt;3.130000&lt;/td&gt;
      &lt;td&gt;2.00000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;50%&lt;/th&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;580.000000&lt;/td&gt;
      &lt;td&gt;3.395000&lt;/td&gt;
      &lt;td&gt;2.00000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;75%&lt;/th&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;660.000000&lt;/td&gt;
      &lt;td&gt;3.670000&lt;/td&gt;
      &lt;td&gt;3.00000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;max&lt;/th&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;800.000000&lt;/td&gt;
      &lt;td&gt;4.000000&lt;/td&gt;
      &lt;td&gt;4.00000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;temp = pd.crosstab(grad[&amp;#39;admit&amp;#39;],grad[&amp;#39;rank&amp;#39;])
temp
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;rank&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;th&gt;4&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;admit&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;97&lt;/td&gt;
      &lt;td&gt;93&lt;/td&gt;
      &lt;td&gt;55&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;54&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;temp.transpose().plot(kind=&amp;#39;bar&amp;#39;)




&amp;lt;matplotlib.axes._subplots.AxesSubplot at 0x10a7a8a90&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D4/output_11_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;We see that if a person is applying to grad school from a rank 1 school, they are more likely than not to be accepeted.   We also see that this ratio drops as the rank of the current school is lower.   We also see that most of the dat is from ranke 2 and rank 3 scores.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;(temp/temp.sum()).transpose().plot(kind=&amp;#39;bar&amp;#39;)




&amp;lt;matplotlib.axes._subplots.AxesSubplot at 0x10f591a50&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D4/output_13_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;Looking at the rations instead of hte counts highlight that change.   There is an increase in chances of getting accepted if the person is coming from a better school.   &lt;/p&gt;
&lt;p&gt;Lets look at the GRE and GPA distributions.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;grad.gre.hist()




&amp;lt;matplotlib.axes._subplots.AxesSubplot at 0x10f854990&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D4/output_15_1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;grad.gpa.hist()




&amp;lt;matplotlib.axes._subplots.AxesSubplot at 0x10f8f2a10&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D4/output_16_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;Both of these are skewed left, but we do have a cut off on the GPA not being above 4.  We see a spike there, and this is commonly seen in any data with arbitary cutoffs.   If there was no max GPA, we would expenct that some people would have 5's,6's, and so on.  They might be rare, but they are there.  The cap compresses all these overacheivers to 4.0.  &lt;/p&gt;
&lt;h2&gt;Fitting Grad School Admissions&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;statsmodels.api&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sm&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;statsmodels.discrete.discrete_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Logit&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;grad&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;admit&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;grad&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gre&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gpa&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;rank&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Logit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;Optimization&lt;/span&gt; &lt;span class="n"&gt;terminated&lt;/span&gt; &lt;span class="n"&gt;successfully&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
         &lt;span class="n"&gt;Current&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.574302&lt;/span&gt;
         &lt;span class="n"&gt;Iterations&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;table class="simpletable"&gt;
&lt;caption&gt;Logit Regression Results&lt;/caption&gt;
&lt;tr&gt;
  &lt;th&gt;Dep. Variable:&lt;/th&gt;       &lt;td&gt;admit&lt;/td&gt;      &lt;th&gt;  No. Observations:  &lt;/th&gt;  &lt;td&gt;   400&lt;/td&gt;  
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Model:&lt;/th&gt;               &lt;td&gt;Logit&lt;/td&gt;      &lt;th&gt;  Df Residuals:      &lt;/th&gt;  &lt;td&gt;   396&lt;/td&gt;  
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Method:&lt;/th&gt;               &lt;td&gt;MLE&lt;/td&gt;       &lt;th&gt;  Df Model:          &lt;/th&gt;  &lt;td&gt;     3&lt;/td&gt;  
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Date:&lt;/th&gt;          &lt;td&gt;Fri, 19 Jun 2015&lt;/td&gt; &lt;th&gt;  Pseudo R-squ.:     &lt;/th&gt;  &lt;td&gt;0.08107&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Time:&lt;/th&gt;              &lt;td&gt;07:23:59&lt;/td&gt;     &lt;th&gt;  Log-Likelihood:    &lt;/th&gt; &lt;td&gt; -229.72&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;converged:&lt;/th&gt;           &lt;td&gt;True&lt;/td&gt;       &lt;th&gt;  LL-Null:           &lt;/th&gt; &lt;td&gt; -249.99&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt; &lt;/th&gt;                      &lt;td&gt; &lt;/td&gt;        &lt;th&gt;  LLR p-value:       &lt;/th&gt; &lt;td&gt;8.207e-09&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
    &lt;td&gt;&lt;/td&gt;       &lt;th&gt;coef&lt;/th&gt;     &lt;th&gt;std err&lt;/th&gt;      &lt;th&gt;z&lt;/th&gt;      &lt;th&gt;P&gt;|z|&lt;/th&gt; &lt;th&gt;[95.0% Conf. Int.]&lt;/th&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;const&lt;/th&gt; &lt;td&gt;   -3.4495&lt;/td&gt; &lt;td&gt;    1.133&lt;/td&gt; &lt;td&gt;   -3.045&lt;/td&gt; &lt;td&gt; 0.002&lt;/td&gt; &lt;td&gt;   -5.670    -1.229&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;gre&lt;/th&gt;   &lt;td&gt;    0.0023&lt;/td&gt; &lt;td&gt;    0.001&lt;/td&gt; &lt;td&gt;    2.101&lt;/td&gt; &lt;td&gt; 0.036&lt;/td&gt; &lt;td&gt;    0.000     0.004&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;gpa&lt;/th&gt;   &lt;td&gt;    0.7770&lt;/td&gt; &lt;td&gt;    0.327&lt;/td&gt; &lt;td&gt;    2.373&lt;/td&gt; &lt;td&gt; 0.018&lt;/td&gt; &lt;td&gt;    0.135     1.419&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;rank&lt;/th&gt;  &lt;td&gt;   -0.5600&lt;/td&gt; &lt;td&gt;    0.127&lt;/td&gt; &lt;td&gt;   -4.405&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;   -0.809    -0.311&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;We see that the model is not very good.  The Pseudo R-square, which as to do with the deviance or negative log likelihood, is very low.  The coefficients are interested in that they do predict more likely admision for higher gre, higher gpa, and better schools.   &lt;/p&gt;
&lt;p&gt;I think I want to plot the over of the predictions to show how poor the model is.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;xp = X.values[(y.values==1)[:,0],:]
yp = model.fittedvalues.values[(y.values==1)[:,0]]
xn = X.values[(y.values==0)[:,0],:]
yn = model.fittedvalues.values[(y.values==0)[:,0]]
zp = xp.dot(model.params.values)
zn = xn.dot(model.params.values)
plt.figure(figsize=(14,5))
plt.subplot(1,2,1)
plt.plot(zp,np.exp(yp)/(1+np.exp(yp)),&amp;#39;go&amp;#39;,alpha=0.5)
plt.xlabel(&amp;quot;Logodds for Datapoint&amp;quot;)
plt.ylabel(&amp;quot;Prob for Student Admited&amp;quot;)
plt.subplot(1,2,2)
plt.plot(zn,np.exp(yn)/(1+np.exp(yn)),&amp;#39;ro&amp;#39;,alpha=0.5)
plt.xlabel(&amp;quot;Logodds for Datapoint&amp;quot;)
plt.ylabel(&amp;quot;Prob for Student Not Admited&amp;quot;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D4/output_20_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;This model does not do a great job of predicting admissions, but we can attemp to use Sklearn's machinery to get a better fit, and also measure the model metrics simply.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LogisticRegressionCV&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;roc_auc_score&lt;/span&gt;


&lt;span class="n"&gt;a_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;a_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;grad&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gre&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gpa&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;rank&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;grad&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;admit&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;lin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;cal1&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;CalibratedClassifierCV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lin&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;isotonic&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cal1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;b_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;lin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LogisticRegressionCV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;scoring&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;lin&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;b_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;probs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cal1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_proba&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a_test&lt;/span&gt;&lt;span class="p"&gt;)[:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;tpr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fpr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;thresholds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;roc_curve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;probs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fpr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tpr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;seagreen&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;False Positive Rate (1 - Specificity)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;True Positive Rate (Sensitivity, Recall)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;ROC plot of College Data&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;AUC: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;roc_auc_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cal1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a_test&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;b_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Accuracy: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cal1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a_test&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;b_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Recall: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;recall_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cal1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a_test&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;b_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Precision: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;precision_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cal1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a_test&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;b_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D4/output_22_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;AUC&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.613445378151&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.666666666667&lt;/span&gt;
&lt;span class="n"&gt;Recall&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.485714285714&lt;/span&gt;
&lt;span class="n"&gt;Precision&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.435897435897&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The area under the ROC curve is not far from 0.5 (random guessing).  The model only predicts 50% of the students admitted to college of being admitted, and only 43% of those predicted to be admitted were actually admitted.   I do not think the College Board will be breaking down our doors for this model.&lt;/p&gt;
&lt;p&gt;In one way we treated the Rank as a continuous variable, and could try treating it like a categorical variable instead.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;grad1 = pd.get_dummies(grad, columns=[&amp;#39;rank&amp;#39;])
a_train, a_test, b_train, b_test = train_test_split(grad1.drop([&amp;#39;admit&amp;#39;,&amp;#39;rank_4&amp;#39;],axis=1).values, grad1.admit.values, test_size=0.30, random_state=42)

lin = LogisticRegression()
cal2=CalibratedClassifierCV(lin, method=&amp;#39;isotonic&amp;#39;, cv=20)
cal2.fit(a_train,b_train)

probs = cal2.predict_proba(a_test)[:,1]
tpr1, fpr1, thresholds1 = roc_curve(probs, b_test)

plt.plot(fpr, tpr,color=&amp;#39;seagreen&amp;#39;,alpha=0.8,lw=3,label=&amp;quot;Original&amp;quot;)
plt.plot(fpr1, tpr1,color=&amp;#39;indianred&amp;#39;,alpha=0.8,lw=3,label=&amp;quot;With Rank Categories&amp;quot;)
plt.xlabel(&amp;quot;False Positive Rate (1 - Specificity)&amp;quot;)
plt.ylabel(&amp;quot;True Positive Rate (Sensitivity, Recall)&amp;quot;)
plt.title(&amp;quot;ROC plot of College Data&amp;quot;)
plt.xlim([0,1])
plt.ylim([0,1])
plt.legend(loc=4)
plt.show()
print &amp;quot;AUC: &amp;quot;, roc_auc_score(cal2.predict(a_test),b_test)
print &amp;quot;Accuracy: &amp;quot;, accuracy_score(cal2.predict(a_test),b_test)
print &amp;quot;Recall: &amp;quot;, recall_score(cal2.predict(a_test),b_test)
print &amp;quot;Precision: &amp;quot;, precision_score(cal2.predict(a_test),b_test)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D4/output_24_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;AUC&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.640625&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.691666666667&lt;/span&gt;
&lt;span class="n"&gt;Recall&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.53125&lt;/span&gt;
&lt;span class="n"&gt;Precision&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.435897435897&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We could have an initial pass where we want a TPR &amp;gt; 60% and FPR &amp;lt; 40.  We can find the thresholds for these values.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;thresholds[(tpr &amp;gt; 0.6)&amp;amp;(fpr &amp;lt; 0.4)]




array([ 0.24242424,  0.25252525,  0.26262626])
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Beta coefficients as Odds Ratio&lt;/h2&gt;
&lt;p&gt;One thing that is often lost when talking about logistic regression is the idea of the odds ratio, or rather the probabilistic interpretation of the model. For this next part we will get hands on with the odds ratio.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;&lt;em&gt;odds ratio&lt;/em&gt;&lt;/strong&gt; is defined as the product of the exponential of each coefficient.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="images/odds_ratio.png" /&gt;&lt;/p&gt;
&lt;p&gt;This is the odds of being admitted over not being admitted.&lt;/p&gt;
&lt;p&gt;It tells you how much a one unit increase of a feature corresponds to the odds of being admitted to grad school. And in doing so the coefficients of the logistic regression can be interpreted similarly to the coefficients of linear regression.&lt;/p&gt;
&lt;p&gt;From our model we can look at the beta coefficients (Intercept,GRE, GPA, Rank)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;beta = cal1.calibrated_classifiers_[-1].__dict__[&amp;#39;base_estimator&amp;#39;].coef_[0,:]
print beta
beta = np.hstack((cal1.calibrated_classifiers_[-1].__dict__[&amp;#39;base_estimator&amp;#39;].intercept_[0],beta))
beta

[ 0.00084169  0.36208945 -0.54024057]





array([ -1.19927209e+00,   8.41691796e-04,   3.62089453e-01,
        -5.40240569e-01])
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The odd ratios for each beta is given by:&lt;/p&gt;
&lt;p&gt;$$\mbox{odds ratio} = e^{\beta_i}$$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;np.exp(beta)




array([ 0.30141353,  1.00084205,  1.43632742,  0.58260808])
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This means that the base line odd ration of getting into grad school is 0.3.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Increasing your gre by 1 point increases your odds by 1.0008.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Increasing your gpa by 1 point increases your ods by 1.435.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Decreasing your rank of college 1 unit decreases your odds by 0.582.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We can also ask how much change would result in doubling the odds ratio:&lt;/p&gt;
&lt;p&gt;$$x_i = \frac{ln(2)}{\beta_i}$$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;np.log(2)/beta




array([ -5.77973244e-01,   8.23516617e+02,   1.91429818e+00,
        -1.28303430e+00])
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Increasing my GRE by 824 doubles my odds ration.  Increasing my GPA by 1.91 doubles the odds ratio, and increasing the ranking by 1.28 doubles the odds ratio.  &lt;/p&gt;
&lt;h2&gt;Predicted Probabilities&lt;/h2&gt;
&lt;p&gt;Now let's actually play with our data to verify what we calculated above with the Odds Ratio.  We can look, on average, how the rank changes the odds.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;g = grad.groupby(&amp;#39;rank&amp;#39;).mean().reset_index().drop(&amp;#39;admit&amp;#39;,axis=1)
g
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;rank&lt;/th&gt;
      &lt;th&gt;gre&lt;/th&gt;
      &lt;th&gt;gpa&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;611.803279&lt;/td&gt;
      &lt;td&gt;3.453115&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;596.026490&lt;/td&gt;
      &lt;td&gt;3.361656&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;574.876033&lt;/td&gt;
      &lt;td&gt;3.432893&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;570.149254&lt;/td&gt;
      &lt;td&gt;3.318358&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;p_g = cal1.predict_proba(g[[&amp;#39;gre&amp;#39;,&amp;#39;gpa&amp;#39;,&amp;#39;rank&amp;#39;]].values)[:,1]
p_g




array([ 0.68469485,  0.3519206 ,  0.17594864,  0.05175475])
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can use this to calculate the odds rations for each rank&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;odds_g = p_g/(1-p_g)
final = np.vstack((np.arange(1,5),np.vstack((p_g,odds_g))))
final




array([[ 1.        ,  2.        ,  3.        ,  4.        ],
       [ 0.68469485,  0.3519206 ,  0.17594864,  0.05175475],
       [ 2.1715308 ,  0.54302082,  0.21351659,  0.0545795 ]])




predicted_odds = np.hstack((np.array(2.1715408),(odds_g*0.583)[:3]))
predicted_odds




array([ 2.1715408 ,  1.26600246,  0.31658114,  0.12448017])
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The odds to drop, but they do not match the vlaues we have from the average predictions.  We can make a graph of the log odds and find the slope:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pd.DataFrame({&amp;quot;logodds&amp;quot;:np.log(odds_g),&amp;quot;rank&amp;quot;:range(1,5)}).set_index(&amp;#39;rank&amp;#39;).plot(kind=&amp;#39;bar&amp;#39;)
print -1.7/3,beta[3]

-0.566666666667 -0.540240569018
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D4/output_41_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;In this case the slop of the logodds and the fitted coefficient match up very close.  Lets do this for the GRE and GPA&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LinearRegression&lt;/span&gt;
&lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;grad&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;groupby&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gre&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset_index&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;drop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;admit&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;p_g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cal1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_proba&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gre&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gpa&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;rank&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;)[:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;odds_g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;p_g&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;p_g&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gpa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;odds_g&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;go&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;linear&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LinearRegression&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;linear&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gre&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;26&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;odds_g&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;26&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;linear&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coef_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;beta&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="mf"&gt;0.00138822870627&lt;/span&gt; &lt;span class="mf"&gt;0.000841691795892&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D4/output_43_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;They are the same scale, but differ by a factor 1.5.   This makes sense because we have a few clear outliers in the data.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LinearRegression&lt;/span&gt;
&lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;grad&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;groupby&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gpa&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset_index&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;drop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;admit&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;p_g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cal1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_proba&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gre&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gpa&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;rank&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;)[:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;odds_g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;p_g&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;p_g&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gpa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;odds_g&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;go&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;linear&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LinearRegression&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c"&gt;#linear.fit(g.gpa.values,odds_g)&lt;/span&gt;
&lt;span class="n"&gt;linear&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gpa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;132&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;odds_g&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;132&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;linear&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coef_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;beta&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="mf"&gt;0.506303444619&lt;/span&gt; &lt;span class="mf"&gt;0.362089452847&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D4/output_45_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;This is also close, and the same order of magnitude.  But we have some clear outliers that need to be address in with this model.   The fact tha the coefficients of the model have a interpretation in terms of odds is great.  It adds a hook to reality in this abstraction. &lt;/p&gt;
&lt;h2&gt;MOOCS&lt;/h2&gt;
&lt;p&gt;This is the future!  No one goes to physical schools any more and MOOCs rule the world.&lt;/p&gt;
&lt;p&gt;Harvard and MIT have &lt;a href="http://newsoffice.mit.edu/2014/mit-and-harvard-release-de-identified-learning-data-open-online-courses"&gt;released&lt;/a&gt; a great dataset around engagement statistics for their MOOC courses. One of the biggest issues with MOOCs is engagement. We will try to predict the probability of 'engagement' of a student given all the other columns.  We will define engagement here as either: &lt;code&gt;explored == 1 OR certified == 1&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;mooc = pd.read_csv(&amp;#39;data/mooc.csv&amp;#39;)
mooc[&amp;#39;engagement&amp;#39;] = mooc[&amp;#39;explored&amp;#39;]+mooc[&amp;#39;certified&amp;#39;]
mooc[&amp;#39;engagement&amp;#39;] = np.where(mooc.engagement &amp;gt; 0,1,0)
mooc.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;course_id&lt;/th&gt;
      &lt;th&gt;userid_DI&lt;/th&gt;
      &lt;th&gt;registered&lt;/th&gt;
      &lt;th&gt;viewed&lt;/th&gt;
      &lt;th&gt;explored&lt;/th&gt;
      &lt;th&gt;certified&lt;/th&gt;
      &lt;th&gt;final_cc_cname_DI&lt;/th&gt;
      &lt;th&gt;LoE_DI&lt;/th&gt;
      &lt;th&gt;YoB&lt;/th&gt;
      &lt;th&gt;gender&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;start_time_DI&lt;/th&gt;
      &lt;th&gt;last_event_DI&lt;/th&gt;
      &lt;th&gt;nevents&lt;/th&gt;
      &lt;th&gt;ndays_act&lt;/th&gt;
      &lt;th&gt;nplay_video&lt;/th&gt;
      &lt;th&gt;nchapters&lt;/th&gt;
      &lt;th&gt;nforum_posts&lt;/th&gt;
      &lt;th&gt;roles&lt;/th&gt;
      &lt;th&gt;incomplete_flag&lt;/th&gt;
      &lt;th&gt;engagement&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;HarvardX/CB22x/2013_Spring&lt;/td&gt;
      &lt;td&gt;MHxPC130442623&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;United States&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;2012-12-19&lt;/td&gt;
      &lt;td&gt;2013-11-17&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;HarvardX/CS50x/2012&lt;/td&gt;
      &lt;td&gt;MHxPC130442623&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;United States&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;2012-10-15&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;HarvardX/CB22x/2013_Spring&lt;/td&gt;
      &lt;td&gt;MHxPC130275857&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;United States&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;2013-02-08&lt;/td&gt;
      &lt;td&gt;2013-11-17&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;HarvardX/CS50x/2012&lt;/td&gt;
      &lt;td&gt;MHxPC130275857&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;United States&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;2012-09-17&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;HarvardX/ER22x/2013_Spring&lt;/td&gt;
      &lt;td&gt;MHxPC130275857&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;United States&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;2012-12-19&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 21 columns&lt;/p&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;mg = mooc.groupby(&amp;#39;course_id&amp;#39;)[&amp;#39;course_id&amp;#39;,&amp;#39;viewed&amp;#39;,&amp;#39;explored&amp;#39;,&amp;#39;certified&amp;#39;,&amp;#39;engagement&amp;#39;].mean()
mg = mg.sort([&amp;#39;engagement&amp;#39;])
mg
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;viewed&lt;/th&gt;
      &lt;th&gt;explored&lt;/th&gt;
      &lt;th&gt;certified&lt;/th&gt;
      &lt;th&gt;engagement&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;course_id&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;HarvardX/CB22x/2013_Spring&lt;/th&gt;
      &lt;td&gt;0.543764&lt;/td&gt;
      &lt;td&gt;0.018232&lt;/td&gt;
      &lt;td&gt;0.012799&lt;/td&gt;
      &lt;td&gt;0.018299&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;MITx/3.091x/2013_Spring&lt;/th&gt;
      &lt;td&gt;0.960906&lt;/td&gt;
      &lt;td&gt;0.023457&lt;/td&gt;
      &lt;td&gt;0.022479&lt;/td&gt;
      &lt;td&gt;0.028506&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;HarvardX/PH278x/2013_Spring&lt;/th&gt;
      &lt;td&gt;0.379173&lt;/td&gt;
      &lt;td&gt;0.030049&lt;/td&gt;
      &lt;td&gt;0.017954&lt;/td&gt;
      &lt;td&gt;0.031867&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;MITx/6.002x/2013_Spring&lt;/th&gt;
      &lt;td&gt;0.480549&lt;/td&gt;
      &lt;td&gt;0.040612&lt;/td&gt;
      &lt;td&gt;0.026670&lt;/td&gt;
      &lt;td&gt;0.041511&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;MITx/8.MReV/2013_Summer&lt;/th&gt;
      &lt;td&gt;0.708663&lt;/td&gt;
      &lt;td&gt;0.039675&lt;/td&gt;
      &lt;td&gt;0.031339&lt;/td&gt;
      &lt;td&gt;0.042841&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;MITx/6.00x/2013_Spring&lt;/th&gt;
      &lt;td&gt;0.944850&lt;/td&gt;
      &lt;td&gt;0.046678&lt;/td&gt;
      &lt;td&gt;0.021710&lt;/td&gt;
      &lt;td&gt;0.046695&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;MITx/8.02x/2013_Spring&lt;/th&gt;
      &lt;td&gt;0.669447&lt;/td&gt;
      &lt;td&gt;0.058039&lt;/td&gt;
      &lt;td&gt;0.026475&lt;/td&gt;
      &lt;td&gt;0.058071&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;MITx/3.091x/2012_Fall&lt;/th&gt;
      &lt;td&gt;0.493352&lt;/td&gt;
      &lt;td&gt;0.063032&lt;/td&gt;
      &lt;td&gt;0.044460&lt;/td&gt;
      &lt;td&gt;0.063032&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;MITx/6.00x/2012_Fall&lt;/th&gt;
      &lt;td&gt;0.620716&lt;/td&gt;
      &lt;td&gt;0.062685&lt;/td&gt;
      &lt;td&gt;0.037119&lt;/td&gt;
      &lt;td&gt;0.063074&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;HarvardX/CS50x/2012&lt;/th&gt;
      &lt;td&gt;0.625430&lt;/td&gt;
      &lt;td&gt;0.064986&lt;/td&gt;
      &lt;td&gt;0.007588&lt;/td&gt;
      &lt;td&gt;0.065016&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;HarvardX/ER22x/2013_Spring&lt;/th&gt;
      &lt;td&gt;0.560238&lt;/td&gt;
      &lt;td&gt;0.061527&lt;/td&gt;
      &lt;td&gt;0.040867&lt;/td&gt;
      &lt;td&gt;0.069435&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;MITx/6.002x/2012_Fall&lt;/th&gt;
      &lt;td&gt;0.637549&lt;/td&gt;
      &lt;td&gt;0.073951&lt;/td&gt;
      &lt;td&gt;0.042881&lt;/td&gt;
      &lt;td&gt;0.074343&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;MITx/7.00x/2013_Spring&lt;/th&gt;
      &lt;td&gt;0.622686&lt;/td&gt;
      &lt;td&gt;0.073826&lt;/td&gt;
      &lt;td&gt;0.039174&lt;/td&gt;
      &lt;td&gt;0.074825&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;MITx/2.01x/2013_Spring&lt;/th&gt;
      &lt;td&gt;0.682436&lt;/td&gt;
      &lt;td&gt;0.098853&lt;/td&gt;
      &lt;td&gt;0.043601&lt;/td&gt;
      &lt;td&gt;0.099029&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;HarvardX/PH207x/2012_Fall&lt;/th&gt;
      &lt;td&gt;0.583742&lt;/td&gt;
      &lt;td&gt;0.104155&lt;/td&gt;
      &lt;td&gt;0.044287&lt;/td&gt;
      &lt;td&gt;0.104179&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;MITx/14.73x/2013_Spring&lt;/th&gt;
      &lt;td&gt;0.588016&lt;/td&gt;
      &lt;td&gt;0.105310&lt;/td&gt;
      &lt;td&gt;0.074812&lt;/td&gt;
      &lt;td&gt;0.105633&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The goal is to attempt to predict engagement for a user based on data they do not have before they start the course.   This is only self-reported information like the Highest Level of Education, Year of Birth, Gender, and when the course started.   We can also attemp to predict it including the course id, but this will not generalize to other courses.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;m1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mooc&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;LoE_DI&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;YoB&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;gender&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;start_time_DI&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;engagement&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;


&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;m1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LoE_DI&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]:&lt;/span&gt;
    &lt;span class="n"&gt;m1&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nan&lt;/span&gt;
    &lt;span class="n"&gt;m1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;m1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LoE_DI&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;m1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Library&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Python&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;2.7&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;packages&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;IPython&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;__main__&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;SettingWithCopyWarning&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; 
&lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="n"&gt;trying&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;be&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;copy&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="nb"&gt;slice&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;a&lt;/span&gt; &lt;span class="nn"&gt;DataFrame.&lt;/span&gt;
&lt;span class="n"&gt;Try&lt;/span&gt; &lt;span class="n"&gt;using&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;row_indexer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;col_indexer&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="n"&gt;instead&lt;/span&gt;

&lt;span class="n"&gt;See&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;caveats&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;documentation&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pydata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;org&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;docs&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;stable&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;indexing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="c"&gt;#indexing-view-versus-copy&lt;/span&gt;
  &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;IPython.kernel.zmq&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;kernelapp&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;app&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;LoE_DI&lt;/th&gt;
      &lt;th&gt;YoB&lt;/th&gt;
      &lt;th&gt;gender&lt;/th&gt;
      &lt;th&gt;start_time_DI&lt;/th&gt;
      &lt;th&gt;engagement&lt;/th&gt;
      &lt;th&gt;Secondary&lt;/th&gt;
      &lt;th&gt;Bachelor's&lt;/th&gt;
      &lt;th&gt;Master's&lt;/th&gt;
      &lt;th&gt;Doctorate&lt;/th&gt;
      &lt;th&gt;Less than Secondary&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2012-12-19&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2012-10-15&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2013-02-08&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2012-09-17&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2012-12-19&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;m1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gender&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]:&lt;/span&gt;
    &lt;span class="n"&gt;m1&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nan&lt;/span&gt;
    &lt;span class="n"&gt;m1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;m1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gender&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;m1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Library&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Python&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;2.7&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;packages&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;IPython&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;__main__&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;SettingWithCopyWarning&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; 
&lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="n"&gt;trying&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;be&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;copy&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="nb"&gt;slice&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;a&lt;/span&gt; &lt;span class="nn"&gt;DataFrame.&lt;/span&gt;
&lt;span class="n"&gt;Try&lt;/span&gt; &lt;span class="n"&gt;using&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;row_indexer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;col_indexer&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="n"&gt;instead&lt;/span&gt;

&lt;span class="n"&gt;See&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;caveats&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;documentation&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pydata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;org&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;docs&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;stable&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;indexing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="c"&gt;#indexing-view-versus-copy&lt;/span&gt;
  &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;IPython.kernel.zmq&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;kernelapp&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;app&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;LoE_DI&lt;/th&gt;
      &lt;th&gt;YoB&lt;/th&gt;
      &lt;th&gt;gender&lt;/th&gt;
      &lt;th&gt;start_time_DI&lt;/th&gt;
      &lt;th&gt;engagement&lt;/th&gt;
      &lt;th&gt;Secondary&lt;/th&gt;
      &lt;th&gt;Bachelor's&lt;/th&gt;
      &lt;th&gt;Master's&lt;/th&gt;
      &lt;th&gt;Doctorate&lt;/th&gt;
      &lt;th&gt;Less than Secondary&lt;/th&gt;
      &lt;th&gt;m&lt;/th&gt;
      &lt;th&gt;f&lt;/th&gt;
      &lt;th&gt;o&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2012-12-19&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2012-10-15&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2013-02-08&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2012-09-17&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2012-12-19&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;m1 = m1.drop([&amp;#39;LoE_DI&amp;#39;,&amp;#39;gender&amp;#39;],axis=1)
m1.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;YoB&lt;/th&gt;
      &lt;th&gt;start_time_DI&lt;/th&gt;
      &lt;th&gt;engagement&lt;/th&gt;
      &lt;th&gt;Secondary&lt;/th&gt;
      &lt;th&gt;Bachelor's&lt;/th&gt;
      &lt;th&gt;Master's&lt;/th&gt;
      &lt;th&gt;Doctorate&lt;/th&gt;
      &lt;th&gt;Less than Secondary&lt;/th&gt;
      &lt;th&gt;m&lt;/th&gt;
      &lt;th&gt;f&lt;/th&gt;
      &lt;th&gt;o&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2012-12-19&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2012-10-15&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2013-02-08&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2012-09-17&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2012-12-19&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;m1.YoB = pd.cut(m1.YoB,[0,1960,1970,1980,1990,2000,2010,2020])
for x in m1.YoB.unique()[1:]:
    m1[x] = np.nan
    m1.loc[:,x] = np.where(m1.YoB==x,1,0)
m1.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;YoB&lt;/th&gt;
      &lt;th&gt;start_time_DI&lt;/th&gt;
      &lt;th&gt;engagement&lt;/th&gt;
      &lt;th&gt;Secondary&lt;/th&gt;
      &lt;th&gt;Bachelor's&lt;/th&gt;
      &lt;th&gt;Master's&lt;/th&gt;
      &lt;th&gt;Doctorate&lt;/th&gt;
      &lt;th&gt;Less than Secondary&lt;/th&gt;
      &lt;th&gt;m&lt;/th&gt;
      &lt;th&gt;f&lt;/th&gt;
      &lt;th&gt;o&lt;/th&gt;
      &lt;th&gt;(2010, 2020]&lt;/th&gt;
      &lt;th&gt;(1980, 1990]&lt;/th&gt;
      &lt;th&gt;(1960, 1970]&lt;/th&gt;
      &lt;th&gt;(1970, 1980]&lt;/th&gt;
      &lt;th&gt;(1990, 2000]&lt;/th&gt;
      &lt;th&gt;(0, 1960]&lt;/th&gt;
      &lt;th&gt;(2000, 2010]&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2012-12-19&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2012-10-15&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2013-02-08&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2012-09-17&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2012-12-19&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;m1 = m1.drop(&amp;#39;YoB&amp;#39;,axis=1)
m1.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;start_time_DI&lt;/th&gt;
      &lt;th&gt;engagement&lt;/th&gt;
      &lt;th&gt;Secondary&lt;/th&gt;
      &lt;th&gt;Bachelor's&lt;/th&gt;
      &lt;th&gt;Master's&lt;/th&gt;
      &lt;th&gt;Doctorate&lt;/th&gt;
      &lt;th&gt;Less than Secondary&lt;/th&gt;
      &lt;th&gt;m&lt;/th&gt;
      &lt;th&gt;f&lt;/th&gt;
      &lt;th&gt;o&lt;/th&gt;
      &lt;th&gt;(2010, 2020]&lt;/th&gt;
      &lt;th&gt;(1980, 1990]&lt;/th&gt;
      &lt;th&gt;(1960, 1970]&lt;/th&gt;
      &lt;th&gt;(1970, 1980]&lt;/th&gt;
      &lt;th&gt;(1990, 2000]&lt;/th&gt;
      &lt;th&gt;(0, 1960]&lt;/th&gt;
      &lt;th&gt;(2000, 2010]&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;2012-12-19&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2012-10-15&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;2013-02-08&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;2012-09-17&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;2012-12-19&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;m1 = m1.drop([&amp;#39;start_time_DI&amp;#39;],axis=1)
m1.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;engagement&lt;/th&gt;
      &lt;th&gt;Secondary&lt;/th&gt;
      &lt;th&gt;Bachelor's&lt;/th&gt;
      &lt;th&gt;Master's&lt;/th&gt;
      &lt;th&gt;Doctorate&lt;/th&gt;
      &lt;th&gt;Less than Secondary&lt;/th&gt;
      &lt;th&gt;m&lt;/th&gt;
      &lt;th&gt;f&lt;/th&gt;
      &lt;th&gt;o&lt;/th&gt;
      &lt;th&gt;(2010, 2020]&lt;/th&gt;
      &lt;th&gt;(1980, 1990]&lt;/th&gt;
      &lt;th&gt;(1960, 1970]&lt;/th&gt;
      &lt;th&gt;(1970, 1980]&lt;/th&gt;
      &lt;th&gt;(1990, 2000]&lt;/th&gt;
      &lt;th&gt;(0, 1960]&lt;/th&gt;
      &lt;th&gt;(2000, 2010]&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;m1.info()

&amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;
Int64Index: 641138 entries, 0 to 641137
Data columns (total 16 columns):
engagement             641138 non-null int64
Secondary              641138 non-null int64
Bachelor&amp;#39;s             641138 non-null int64
Master&amp;#39;s               641138 non-null int64
Doctorate              641138 non-null int64
Less than Secondary    641138 non-null int64
m                      641138 non-null int64
f                      641138 non-null int64
o                      641138 non-null int64
(2010, 2020]           641138 non-null int64
(1980, 1990]           641138 non-null int64
(1960, 1970]           641138 non-null int64
(1970, 1980]           641138 non-null int64
(1990, 2000]           641138 non-null int64
(0, 1960]              641138 non-null int64
(2000, 2010]           641138 non-null int64
dtypes: int64(16)
memory usage: 83.2 MB



y = m1.engagement.values
x = m1.drop(&amp;#39;engagement&amp;#39;,axis=1).values
print y.shape,x.shape

(641138,) (641138, 15)



from sklearn.metrics import confusion_matrix

a_train, a_test, b_train, b_test = train_test_split(x,y,test_size=0.50)

mlog = LogisticRegressionCV(cv=20)
mlog.fit(a_train,b_train)

probs = mlog.predict_proba(a_test)[:,1]
tpr1, fpr1, thresholds1 = roc_curve(probs, b_test)

plt.plot(fpr, tpr,color=&amp;#39;seagreen&amp;#39;,alpha=0.8,lw=3)
plt.xlabel(&amp;quot;False Positive Rate (1 - Specificity)&amp;quot;)
plt.ylabel(&amp;quot;True Positive Rate (Sensitivity, Recall)&amp;quot;)
plt.title(&amp;quot;MOOC&amp;quot;)
plt.xlim([0,1])
plt.ylim([0,1])
plt.legend(loc=4)
plt.show()
print &amp;quot;Recall: &amp;quot;, precision_score(mlog.predict(a_test),b_test)
print &amp;quot;Precision: &amp;quot;, recall_score(mlog.predict(a_test),b_test)
print &amp;quot;Accuracy: &amp;quot;, accuracy_score(mlog.predict(a_test),b_test)
confusion_matrix(mlog.predict(a_test),b_test)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D4/output_60_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Recall&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.0&lt;/span&gt;
&lt;span class="n"&gt;Precision&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.0&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.937143017572&lt;/span&gt;





&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="o"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;300419&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;20150&lt;/span&gt;&lt;span class="o"&gt;],&lt;/span&gt;
       &lt;span class="o"&gt;[&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;      &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This model, unsurpisingly, predicts no engagement because engagement is so rare.  This is a know problem with logistic regresion.   To avoid this we can drop duplicates and refit the data.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;m2 = m1.drop_duplicates()
y = m2.engagement.values
x = m2.drop(&amp;#39;engagement&amp;#39;,axis=1).values
print y.shape,x.shape

(163,) (163, 15)



a_train, a_test, b_train, b_test = train_test_split(x,y,test_size=0.50)

mlog = LogisticRegressionCV(cv=20)
mlog.fit(a_train,b_train)

probs = mlog.predict_proba(a_test)[:,1]
tpr1, fpr1, thresholds1 = roc_curve(probs, b_test)

plt.plot(fpr, tpr,color=&amp;#39;seagreen&amp;#39;,alpha=0.8,lw=3)
plt.xlabel(&amp;quot;False Positive Rate (1 - Specificity)&amp;quot;)
plt.ylabel(&amp;quot;True Positive Rate (Sensitivity, Recall)&amp;quot;)
plt.title(&amp;quot;MOOC&amp;quot;)
plt.xlim([0,1])
plt.ylim([0,1])
plt.legend(loc=4)
plt.show()
print &amp;quot;Recall: &amp;quot;, precision_score(mlog.predict(a_test),b_test)
print &amp;quot;Precision: &amp;quot;, recall_score(mlog.predict(a_test),b_test)
print &amp;quot;Accuracy: &amp;quot;, accuracy_score(mlog.predict(a_test),b_test)
confusion_matrix(mlog.predict(a_test),b_test)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D4/output_63_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Recall&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.121951219512&lt;/span&gt;
&lt;span class="n"&gt;Precision&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.277777777778&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.40243902439&lt;/span&gt;





&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="o"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;36&lt;/span&gt;&lt;span class="o"&gt;],&lt;/span&gt;
       &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;]])&lt;/span&gt;




&lt;span class="n"&gt;probs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mlog&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;predict_proba&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;m1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;drop&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;engagement&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;).&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;)[:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;predict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mlog&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;predict&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;m1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;drop&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;engagement&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;).&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tpr1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fpr1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;thresholds1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;roc_curve&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;probs&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;m1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;engagement&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;values&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;plot&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fpr&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tpr&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;seagreen&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;xlabel&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;False Positive Rate (1 - Specificity)&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;ylabel&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;True Positive Rate (Sensitivity, Recall)&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;title&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;MOOC&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;xlim&lt;/span&gt;&lt;span class="o"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;ylim&lt;/span&gt;&lt;span class="o"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;legend&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;show&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Recall: &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;precision_score&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="n"&gt;m1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;engagement&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;values&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Precision: &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;recall_score&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="n"&gt;m1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;engagement&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;values&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Accuracy: &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="n"&gt;m1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;engagement&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;values&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;confusion_matrix&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="n"&gt;m1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;engagement&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;values&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D4/output_64_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Recall&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.136417673866&lt;/span&gt;
&lt;span class="n"&gt;Precision&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.0649505324104&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.821936930895&lt;/span&gt;





&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="o"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;521467&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;34868&lt;/span&gt;&lt;span class="o"&gt;],&lt;/span&gt;
       &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;79295&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;   &lt;span class="mi"&gt;5508&lt;/span&gt;&lt;span class="o"&gt;]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I do not think the model is any better.   Ad at this point I think based on this data we are not able to predict engagement by self-reported features&lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="Lasso Regresion"></category><category term="Ridge Regression"></category><category term="Regularization"></category></entry><entry><title>Galvanize - Week 03 - Day 3</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-03-03/" rel="alternate"></link><updated>2015-06-17T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-17:galvanize/galvanize-data-science-03-03/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 3 - Day 3&lt;/h2&gt;
&lt;p&gt;Today we had a miniquiz on cleaning data.  Identify missing values, incorrect format, and outliers.   It was a straight forward assignment.   I was struck with there is no clear end to data cleaning without a purpose.   It would be nice ot set a stoping criteria or variable specification so there are clear evaluation criteria.  Obviously with raw data the data has to be explored, and these criteria does not exist.   &lt;/p&gt;
&lt;h2&gt;Morning: One-fold Cross Validation&lt;/h2&gt;
&lt;p&gt;This morning we started using cross validation on the boston data set from sklearn.  The goal is not to make the best model, but just work through th eprocess of using cross validation. &lt;/p&gt;
&lt;p&gt;Descriptions for each column in &lt;code&gt;features&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Attribute Information (in order):
    - CRIM     per capita crime rate by town
    - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.
    - INDUS    proportion of non-retail business acres per town
    - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)
    - NOX      nitric oxides concentration (parts per 10 million)
    - RM       average number of rooms per dwelling
    - AGE      proportion of owner-occupied units built prior to 1940
    - DIS      weighted distances to five Boston employment centres
    - RAD      index of accessibility to radial highways
    - TAX      full-value property-tax rate per $10,000
    - PTRATIO  pupil-teacher ratio by town
    - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town
    - LSTAT    % lower status of the population
    - MEDV     Median value of owner-occupied homes in $1000's&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;scipy.stats&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sc&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pandas.tools.plotting&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;scatter_matrix&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LinearRegression&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cross_validation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;KFold&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cross_validation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cross_validation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;cross_val_score&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;load_boston&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;mean_squared_error&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;StandardScaler&lt;/span&gt;
&lt;span class="n"&gt;boston&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_boston&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;features&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;boston&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;
&lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;boston&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="c"&gt;# housing price&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We are using the train, test split to make a training set of 70% of the data and a test set of 30% of the data.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;train_feature, test_feature, train_target, test_target = train_test_split(features, target, test_size=0.3)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We are going to use sklearn's LinearRegresion on this data set.  There are likely issues with multicolinearity, but we will skip that for now.   We will train the data on the training set, and test it on the testing set.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;linear = LinearRegression()
linear.fit(train_feature, train_target)
# You can call predict to get the predicted values for training and test
train_predicted = linear.predict(train_feature)
test_predicted = linear.predict(test_feature)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I wrote a mean square function to compare to sklearn's function.   I expect the test set to have larger value then the training set because the model was not trained on the test set.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def MSE(x1,x2):
    return np.sum(np.power(x2-x1,2))/len(x1)
print &amp;quot;Train MSE: &amp;quot;, MSE(train_predicted,train_target),mean_squared_error(train_predicted,train_target)
print &amp;quot;Test MSE: &amp;quot;, MSE(test_predicted,test_target), mean_squared_error(test_predicted,test_target)


Train MSE:  21.1395296142 21.1395296142
Test MSE:  24.6555052851 24.6555052851
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;K-fold Cross Validation&lt;/h2&gt;
&lt;p&gt;In K-fold cross validation the data is split into &lt;strong&gt;k&lt;/strong&gt; groups. One group
out of the k groups will be the test set, the rest (&lt;strong&gt;k-1&lt;/strong&gt;) groups will
be the training set. In the next iteration, another group will be the test set,
and the rest will be the training set. The process repeats for k iterations (k-fold).
In each fold, a metric for accuracy (MSE in this case) will be calculated and
an overall average of that metric will be calculated over k-folds.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;To do this we need to manage randomly sampling &lt;strong&gt;k&lt;/strong&gt; folds.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Properly combining those &lt;strong&gt;k&lt;/strong&gt; folds into a test and training set on
   your &lt;strong&gt;on the training dataset&lt;/strong&gt;. Outside of the k-fold, there should be
   another set which will be referred to as the &lt;strong&gt;hold-out set&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Train your model on your constructed training set and evaluate on the given test set&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Repeat steps &lt;strong&gt;2&lt;/strong&gt; and &lt;strong&gt;3&lt;/strong&gt; &lt;em&gt;k&lt;/em&gt; times.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Average your results of your error metric.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compare the MSE for your test set in Part 1. and your K-fold cross validated error in &lt;code&gt;4.&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;indexes = np.arange(len(train_feature))
indexes2 = indexes.copy()
linear = LinearRegression()
count = len(indexes)
mse = []
k = 10.
for i in range(int(k)):
    choices = np.random.choice(indexes2,int(count/k),replace=False)
    indexes2 = np.setdiff1d(indexes2,choices)
    train_index = np.setdiff1d(indexes,choices)
    linear.fit(train_feature[train_index], train_target[train_index])
    test_predicted = linear.predict(train_feature[choices])
    mse.append(mean_squared_error(train_target[choices],test_predicted))&lt;/p&gt;
&lt;p&gt;print "Avg MSE: ",sum(mse)/k&lt;/p&gt;
&lt;p&gt;Avg MSE:  23.9048376671&lt;/p&gt;
&lt;p&gt;def scorer(model,X,y):
    return mean_squared_error(y,model.predict(X))&lt;/p&gt;
&lt;p&gt;cross_val_score(LinearRegression(),train_feature,train_target,scoring=scorer,cv=10).mean()&lt;/p&gt;
&lt;p&gt;24.72849552718905&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I made my own k-fold validation and compared it to the sklearn method.  There is an obviously efficiency in code.  I did my own wrapper for the scoring because the string method sometimes returned negative values.   &lt;/p&gt;
&lt;p&gt;We can look at the comparison between traiing and cross validaton as we increase the sample size.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sample_sizes = np.arange(10,350,10)
train_mse = []
cross_mse = []
for size in sample_sizes:
    linear = LinearRegression()

    linear.fit(train_feature[:size],train_target[:size])
    train_predicted = linear.predict(train_feature[:size])
    train_mse.append(mean_squared_error(train_predicted[:size],train_target[:size]))
    cross_mse.append(cross_val_score(linear,train_feature[:size],train_target[:size],scoring=scorer,cv=5).mean())

print len(sample_sizes),len(train_mse)
plt.figure(figsize=(10,8))
plt.plot(sample_sizes,train_mse,color=&amp;#39;seagreen&amp;#39;,lw=2,alpha=0.8,label=&amp;#39;Train Set MSE&amp;#39;)
plt.plot(sample_sizes,cross_mse,color=&amp;#39;steelblue&amp;#39;,lw=2,alpha=0.8,label=&amp;#39;CV Set MSE&amp;#39;)
plt.legend()
plt.xlabel(&amp;quot;Sample Size&amp;quot;)
plt.ylabel(&amp;quot;MSE&amp;quot;)
plt.ylim([0,100])
plt.show()

34 34
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D3/output_13_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;In this case we see that the two values start to converge, but the CV is higher.  This make sense because it is hold out values to test on.   It should be a better approximation to applying it to a test set. &lt;/p&gt;
&lt;p&gt;We can look at the difference between the test and training sets as we increase the training size.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sample_sizes = np.arange(10,350,10)
test_mse = []
train_mse = []
for size in sample_sizes:
    linear = LinearRegression()
    linear.fit(train_feature[:size],train_target[:size])
    train_predicted = linear.predict(train_feature)
    test_predicted = linear.predict(test_feature)
    train_mse.append(mean_squared_error(train_predicted,train_target))
    test_mse.append(mean_squared_error(test_predicted,test_target))

plt.figure(figsize=(10,8))
plt.plot(sample_sizes,train_mse,color=&amp;#39;seagreen&amp;#39;,lw=2,alpha=0.8,label=&amp;#39;Train Set MSE&amp;#39;)
plt.plot(sample_sizes,test_mse,color=&amp;#39;steelblue&amp;#39;,lw=2,alpha=0.8,label=&amp;#39;Test Set MSE&amp;#39;)
plt.legend()
plt.xlabel(&amp;quot;Sample Size&amp;quot;)
plt.ylabel(&amp;quot;MSE&amp;quot;)
plt.ylim([0,100])
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D3/output_15_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;test_mse = []
train_mse = []
num_feat = range(1,len(train_feature[0,:]))
for i in num_feat:
    linear = LinearRegression()
    linear.fit(train_feature[:,:i],train_target)
    train_predicted = linear.predict(train_feature[:,:i])
    test_predicted = linear.predict(test_feature[:,:i])
    train_mse.append(mean_squared_error(train_predicted,train_target))
    test_mse.append(mean_squared_error(test_predicted,test_target))

plt.figure(figsize=(10,8))
plt.plot(num_feat,train_mse,color=&amp;#39;seagreen&amp;#39;,lw=2,alpha=0.8,label=&amp;#39;Train Set MSE&amp;#39;)
plt.plot(num_feat,test_mse,color=&amp;#39;steelblue&amp;#39;,lw=2,alpha=0.8,label=&amp;#39;Test Set MSE&amp;#39;)
plt.legend()
plt.xlabel(&amp;quot;Number Features&amp;quot;)
plt.ylabel(&amp;quot;MSE&amp;quot;)
plt.ylim([0,100])
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D3/output_16_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;As we increase features and data, our results on the training set go down and the test set values, in this case, look to converge.   &lt;/p&gt;
&lt;h2&gt;Stepwise Regression&lt;/h2&gt;
&lt;p&gt;While stepwise regression has its many &lt;a href="http://andrewgelman.com/2014/06/02/hate-stepwise-regression/"&gt;critics&lt;/a&gt;, it is a useful exercise to introduce the concept of feature selection in the context of linear regression. This extra credit exercise has two components of different difficulties. First, use the &lt;code&gt;scikit-learn&lt;/code&gt; reverse feature elimation (a greedy feature elimination algorithm) to implement something similar to sequential backward selection. The second, more difficult part is implementing sequential forward selection.&lt;/p&gt;
&lt;p&gt;We generate a random dataset that has 100 features, but only 5 of them influence the response variable.  We can use sklearn's RFE to fit and attempt to rank the features.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;make_friedman1&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;make_friedman1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.feature_selection&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RFE&lt;/span&gt;
&lt;span class="n"&gt;linear&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LinearRegression&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;rfe&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RFE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;linear&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;rfe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;rfe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ranking_&lt;/span&gt;




&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;  &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;71&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;47&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;36&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;94&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;61&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;39&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="mi"&gt;58&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;75&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;98&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;79&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;41&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;78&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;54&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;76&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;86&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;55&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;43&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="mi"&gt;29&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;66&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;35&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;68&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;37&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;92&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;51&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;89&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;46&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;82&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;83&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;96&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;77&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;31&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;72&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;90&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;62&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;67&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;59&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;73&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;85&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="mi"&gt;91&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;88&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;26&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;56&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;33&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;53&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;38&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="mi"&gt;48&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;84&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;34&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;93&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;23&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;27&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;63&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;70&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="mi"&gt;44&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;45&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;97&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;87&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;60&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;57&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;49&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;95&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;81&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;99&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;74&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;65&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;69&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We are going to loop through these variables and use them as a fit.   We want to see if a there is a point where adding more features will not improve the model.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;linear = LinearRegression()
rsq = []
for i in range(2,50):
    linear.fit(X[:,rfe.ranking_ &amp;lt; i],y)
    rsq.append(linear.score(X[:,rfe.ranking_ &amp;lt; i],y))
plt.plot(range(2,50),rsq,lw=3,color=&amp;#39;seagreen&amp;#39;,alpha=0.5,label=&amp;#39;R-Square&amp;#39;)
plt.xlabel(&amp;quot;Number of Variables&amp;quot;)
plt.ylabel(&amp;#39;R-Squared&amp;#39;)
plt.ylim([0,1])
plt.axvline(x=5,linestyle=&amp;#39;--&amp;#39;,color=&amp;#39;gray&amp;#39;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D3/output_21_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;Instead of using RFE to do backward selection, we can create a class that implements sequential forward selection, which involves starting with no variables in the model, testing the addition of each variable using a chosen model comparison criterion, adding the variable (if any) that improves the model the most, and repeating this process until none improves the model.&lt;/p&gt;
&lt;h4&gt;Reference&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://onlinecourses.science.psu.edu/stat501/node/88"&gt;Stepwise Regression Procedure&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;class ForwardRegression:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def __init__(self,X,y):
    self.nFeatures = X.shape[1]
    self.nRow = X.shape[0]
    self.X = X
    self.y = y
    self.linear = LinearRegression()
    self.scores = []
    self.best_features = []
    self.best_model = False

def next_best(self):
    if not self.best_model:
        max_rsq = 0
        best_index = -1
        for i in range(self.nFeatures):
            if i not in self.best_features:
                self.linear.fit(self.X[:,(self.best_features+[i])],self.y)
                score = self.linear.score(self.X[:,(self.best_features+[i])],self.y)
                if score &amp;gt; max_rsq:
                    max_rsq = score
                    best_index = i
        if best_index != -1:
            if len(self.scores) &amp;gt; 1:
                if (max_rsq-self.scores[-1])/self.scores[-1] &amp;gt; 0.01:
                    self.best_features.append(best_index)
                    self.scores.append(max_rsq)
                else:
                    self.best_model = True

            else:
                self.best_features.append(best_index)
                self.scores.append(max_rsq)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;fr = ForwardRegression(X,y)
for i in range(5):
    fr.next_best()
print fr.scores
print fr.best_features
print fr.best_model&lt;/p&gt;
&lt;p&gt;[0.32517954427506357, 0.49706338477081047, 0.64962046580083821, 0.74271747755945094]
[3, 1, 0, 4]
True&lt;/p&gt;
&lt;p&gt;rfe.ranking_&lt;/p&gt;
&lt;p&gt;array([  3,   2,  71,   1,   4,  47,  22,  36,  94,  61,  14,  39,  24,
        58,  20,  75,  98,  79,  41,  32,  78,  54,  76,  86,  55,  43,
        29,  66,  35,  68,  37,   8,  92,  51,  13,  89,  46,  82,  83,
        30,  96,  77,  31,  72,  90,  62,  67,  59,  73,  15,  11,  85,
        91,  17,  88,  26,  56,  28,  33,  53,  18,  10,   7,   6,  38,
        48,  50,  19,  84,  34,  93,  23,  27,  63,  70,  16,  12, 100,
        44,  80,  45,  97,  87,   9,  21,   5,  52,  60,  57,  49,  25,
        40,  95,  81,  42,  99,  74,  65,  69,  64])&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This matches with the previous result for this example.&lt;/p&gt;
&lt;h2&gt;Afternoon - Lasso and Ridge Regresson&lt;/h2&gt;
&lt;p&gt;The goal fo this exercise is to get a feel for the shrinkage that these models do for coefficients.   We will start with the Ridge Regression in sklearn on the diabetes dataset.  We did a basic fit to start. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;load_diabetes&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LinearRegression&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Lasso&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Ridge&lt;/span&gt;

&lt;span class="n"&gt;diabetes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_diabetes&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;diabetes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;diabetes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;XT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;diabetes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;span class="n"&gt;yT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;diabetes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;span class="n"&gt;fit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Ridge&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;normalize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;MSE: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mean_squared_error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;MSE&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;4251.12234379&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we will look at how the parameters change as we increasee alpha.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;StandardScaler&lt;/span&gt;

&lt;span class="n"&gt;scaler&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;StandardScaler&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;alphas&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;alphas&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;alphas&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;X_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;scaler&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;fit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Ridge&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;normalize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coef_&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;param&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;alphas&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;param&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D3/output_28_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;Given a large enough alpha/lambda, the coefficients go to zero   This is a property of the model, and we want to try to use this paramter to find the best model.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;k = X.shape[1]
alphas = np.logspace(-3,0,1000)
mse_train = []
mse_test = []
for i,a in enumerate(alphas):
    X_data = scaler.fit_transform(X)
    fit = Ridge(alpha=a, normalize=True).fit(X_data, y)
    mse_train.append(mean_squared_error(y,fit.predict(X_data)))
    mse_test.append(mean_squared_error(yT,fit.predict(scaler.transform(XT))))
plt.figure(figsize=(14,6))
plt.plot(alphas, mse_train)
plt.plot(alphas, mse_test,color=&amp;#39;green&amp;#39;)
plt.show()


print &amp;quot;Best Alpha: &amp;quot;, alphas[mse_test.index(min(mse_test))]
alpha_ridge = alphas[mse_test.index(min(mse_test))]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D3/output_30_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Best Alpha:  0.252582002696
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we are going to do the same for Lasso Regresion&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;k = X.shape[1]
alphas = np.logspace(-2, 2)
params = np.zeros((len(alphas), k))
for i,a in enumerate(alphas):
    X_data = scaler.fit_transform(X)
    fit = Lasso(alpha=a, normalize=True).fit(X_data, y)
    params[i] = fit.coef_

plt.figure(figsize=(14,6))
for param in params.T:
    plt.plot(alphas, param)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D3/output_32_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;The Lasso drops the paramters to zero much more quickly than the Ridge Method.  This is because of the absolut value in the prior.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;k = X.shape[1]
alphas = np.logspace(-3,0,1000)
mse_train = []
mse_test = []
for i,a in enumerate(alphas):
    X_data = scaler.fit_transform(X)
    fit = Lasso(alpha=a, normalize=True).fit(X_data, y)
    mse_train.append(mean_squared_error(y,fit.predict(X_data)))
    mse_test.append(mean_squared_error(yT,fit.predict(scaler.transform(XT))))
plt.figure(figsize=(14,6))
plt.plot(alphas, mse_train)
plt.plot(alphas, mse_test,color=&amp;#39;green&amp;#39;)
plt.show()

print &amp;quot;Best Alpha: &amp;quot;, alphas[mse_test.index(min(mse_test))]
alpha_lasso = alphas[mse_test.index(min(mse_test))]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D3/output_34_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Best Alpha:  0.286059553518
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We are going to compare the 3 models.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;ridge = Ridge(alpha=alpha_ridge)
ridge.fit(X_data,y)

lasso = Lasso(alpha=alpha_lasso)
lasso.fit(X_data,y)

ols = LinearRegression()
ols.fit(X_data,y)

print &amp;quot;Ridge MSE:&amp;quot;,mean_squared_error(yT,ridge.predict(scaler.transform(XT)))
print &amp;quot;Lasso MSE:&amp;quot;,mean_squared_error(yT,lasso.predict(scaler.transform(XT)))
print &amp;quot;OLS MSE:&amp;quot;,mean_squared_error(yT,ols.predict(scaler.transform(XT)))
print &amp;quot; &amp;quot;
print &amp;quot;Ridge,Lasso,OLS&amp;quot; 
for i in range(len(ridge.coef_)):
    print round(ridge.coef_[i],2),round(lasso.coef_[i],2),round(ols.coef_[i],2)

Ridge MSE: 3184.60043415
Lasso MSE: 3160.04592755
OLS MSE: 3190.98282981

Ridge,Lasso,OLS
-3.28 -2.95 -3.29
-17.46 -17.04 -17.51
20.52 20.39 20.55
14.68 14.28 14.7
2.45 -0.0 3.85
-15.54 -12.27 -16.78
-12.38 -11.89 -13.07
5.94 4.43 5.84
26.36 27.43 25.93
4.47 4.34 4.44
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The Lasso model on the lower MSE on the test set, and also dropped one of the variables in the model.   Over all its coefficients are lower, and this is consistent with what we saw in the previous plots.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;r2_score&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Ridge MSE:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;r2_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;yT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;ridge&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scaler&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;XT&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Lasso MSE:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;r2_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;yT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lasso&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scaler&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;XT&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;OLS MSE:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;r2_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;yT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;ols&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scaler&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;XT&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

&lt;span class="n"&gt;Ridge&lt;/span&gt; &lt;span class="n"&gt;MSE&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.473709418009&lt;/span&gt;
&lt;span class="n"&gt;Lasso&lt;/span&gt; &lt;span class="n"&gt;MSE&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.477767322867&lt;/span&gt;
&lt;span class="n"&gt;OLS&lt;/span&gt; &lt;span class="n"&gt;MSE&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.472654656259&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It is clear that this is far from the final story...&lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="Lasso Regresion"></category><category term="Ridge Regression"></category><category term="Regularization"></category></entry><entry><title>Galvanize - Week 03 - Day 2</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-03-02/" rel="alternate"></link><updated>2015-06-16T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-16:galvanize/galvanize-data-science-03-02/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 3 - Day 2&lt;/h2&gt;
&lt;p&gt;Today we did more linear regression, and started evaluating applying linear models to regression problems.   It was a combination of informative and frustration because I learned a lot, but did not develope an intuition for the process.   I suppsoe that will come with time.  &lt;/p&gt;
&lt;h2&gt;Mini-Quiz&lt;/h2&gt;
&lt;p&gt;Today's miniquiz took all of 5 minutes.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Write a python function to find the value in a list that's closest to a given value.&lt;/p&gt;
&lt;p&gt;e.g. &lt;code&gt;closest([10, 17, 2, 29, 16], 14&lt;/code&gt; should return 16.&lt;/p&gt;
&lt;p&gt;a = [10,17,2,29,16]
import math
def closest(array,val):
    diff = [math.fabs(x-val) for x in array]
    index = diff.index(min(diff))
    return array[index]&lt;/p&gt;
&lt;p&gt;closest(a,14)&lt;/p&gt;
&lt;p&gt;16&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Instead let's start with a numpy array. How can we do the same thing in one line using numpy magic.&lt;/p&gt;
&lt;p&gt;import numpy as np&lt;/p&gt;
&lt;p&gt;a = np.array(a)
a[np.abs(a-14).argmin()]&lt;/p&gt;
&lt;p&gt;16&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;My favorite numpy trick is &lt;a href="http://docs.scipy.org/doc/numpy/user/basics.indexing.html#boolean-or-mask-index-arrays"&gt;masking&lt;/a&gt;. Say you have a feature matrix &lt;code&gt;X&lt;/code&gt; (2d numpy array) and with labels &lt;code&gt;y&lt;/code&gt; (1d numpy array). I would like to get a feature matrix of only the positive cases, i.e. get the rows from &lt;code&gt;X&lt;/code&gt; where &lt;code&gt;y&lt;/code&gt; is positive.&lt;/p&gt;
&lt;p&gt;How can you do this in one line?&lt;/p&gt;
&lt;p&gt;Create example &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; to verify your code.&lt;/p&gt;
&lt;p&gt;x = np.random.rand(100,10)
y = np.random.randint(2,size=(100,))&lt;/p&gt;
&lt;p&gt;print x.shape, x[y&amp;gt;0,:].shape&lt;/p&gt;
&lt;p&gt;(100, 10) (47, 10)&lt;/p&gt;
&lt;p&gt;print set(y[y&amp;gt;0].tolist())&lt;/p&gt;
&lt;p&gt;set([1])&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Morning - Regression&lt;/h2&gt;
&lt;p&gt;The linear regression model makes a number of assumptions about the data, including &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Homoscedasticity of residuals&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Normal distribution of residuals&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lack of multicollinearity among features&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Independence of the observations (For example, independence assumption violated if data is a time series)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Since the results of the regression model depend on these statistical assumptions, the 
results of the regression model are only correct if our assumptions hold (at least approximately).&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;This morning we will be exploring two datasets: &lt;code&gt;prestige&lt;/code&gt; and &lt;code&gt;ccard&lt;/code&gt;. Below is a description of the 2 datasets.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;prestige&lt;/code&gt; &lt;em&gt;(From yesterday afternoon)&lt;/em&gt;&lt;ul&gt;
&lt;li&gt;Prediction of the prestige of a job&lt;/li&gt;
&lt;li&gt;Dependent variable: &lt;code&gt;prestige&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Independent variables: &lt;code&gt;income&lt;/code&gt;, &lt;code&gt;education&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Code to load data set into dataframe:&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;python
  import statsmodels.api as sm
  prestige = sm.datasets.get_rdataset("Duncan", "car", cache=True).data&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ccard&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;Prediction of the average credit card expenditure&lt;/li&gt;
&lt;li&gt;Dependent variable: &lt;code&gt;AVGEXP&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Independent variables: &lt;code&gt;AGE&lt;/code&gt;, &lt;code&gt;INCOME&lt;/code&gt;, &lt;code&gt;INCOMESQ&lt;/code&gt; (&lt;code&gt;INCOME^2&lt;/code&gt;), &lt;code&gt;OWNRENT&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Code to load data set into dataframe:&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;python
  credit_card = sm.datasets.ccard.load_pandas().data&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Prestige Regression&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;scipy.stats&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sc&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;statsmodels.api&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sm&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pandas.tools.plotting&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;scatter_matrix&lt;/span&gt;
&lt;span class="n"&gt;prestige&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_rdataset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Duncan&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;car&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cache&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;
&lt;span class="n"&gt;credit_card&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ccard&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_pandas&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;


&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;scatter_matrix&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prestige&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="kp"&gt;diagonal&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;kde&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Figure&lt;/span&gt; &lt;span class="n"&gt;at&lt;/span&gt; &lt;span class="mh"&gt;0x106186450&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_9_1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure()
prestige.boxplot()
plt.show()

/Library/Python/2.7/site-packages/pandas/tools/plotting.py:2633: FutureWarning: 
The default value for &amp;#39;return_type&amp;#39; will change to &amp;#39;axes&amp;#39; in a future release.
 To use the future behavior now, set return_type=&amp;#39;axes&amp;#39;.
 To keep the previous behavior and silence this warning, set return_type=&amp;#39;dict&amp;#39;.
  warnings.warn(msg, FutureWarning)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_10_1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;y = prestige[[&amp;#39;prestige&amp;#39;]]
x = sm.add_constant(prestige[[&amp;#39;income&amp;#39;,&amp;#39;education&amp;#39;]])
model1 = sm.OLS(y,x).fit()
model1.summary()
&lt;/pre&gt;&lt;/div&gt;


&lt;table class="simpletable"&gt;
&lt;caption&gt;OLS Regression Results&lt;/caption&gt;
&lt;tr&gt;
  &lt;th&gt;Dep. Variable:&lt;/th&gt;        &lt;td&gt;prestige&lt;/td&gt;     &lt;th&gt;  R-squared:         &lt;/th&gt; &lt;td&gt;   0.828&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Model:&lt;/th&gt;                   &lt;td&gt;OLS&lt;/td&gt;       &lt;th&gt;  Adj. R-squared:    &lt;/th&gt; &lt;td&gt;   0.820&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Method:&lt;/th&gt;             &lt;td&gt;Least Squares&lt;/td&gt;  &lt;th&gt;  F-statistic:       &lt;/th&gt; &lt;td&gt;   101.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Date:&lt;/th&gt;             &lt;td&gt;Wed, 17 Jun 2015&lt;/td&gt; &lt;th&gt;  Prob (F-statistic):&lt;/th&gt; &lt;td&gt;8.65e-17&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Time:&lt;/th&gt;                 &lt;td&gt;07:50:23&lt;/td&gt;     &lt;th&gt;  Log-Likelihood:    &lt;/th&gt; &lt;td&gt; -178.98&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;No. Observations:&lt;/th&gt;      &lt;td&gt;    45&lt;/td&gt;      &lt;th&gt;  AIC:               &lt;/th&gt; &lt;td&gt;   364.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Df Residuals:&lt;/th&gt;          &lt;td&gt;    42&lt;/td&gt;      &lt;th&gt;  BIC:               &lt;/th&gt; &lt;td&gt;   369.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Df Model:&lt;/th&gt;              &lt;td&gt;     2&lt;/td&gt;      &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;   
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Covariance Type:&lt;/th&gt;      &lt;td&gt;nonrobust&lt;/td&gt;    &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;   
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
      &lt;td&gt;&lt;/td&gt;         &lt;th&gt;coef&lt;/th&gt;     &lt;th&gt;std err&lt;/th&gt;      &lt;th&gt;t&lt;/th&gt;      &lt;th&gt;P&gt;|t|&lt;/th&gt; &lt;th&gt;[95.0% Conf. Int.]&lt;/th&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;const&lt;/th&gt;     &lt;td&gt;   -6.0647&lt;/td&gt; &lt;td&gt;    4.272&lt;/td&gt; &lt;td&gt;   -1.420&lt;/td&gt; &lt;td&gt; 0.163&lt;/td&gt; &lt;td&gt;  -14.686     2.556&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;income&lt;/th&gt;    &lt;td&gt;    0.5987&lt;/td&gt; &lt;td&gt;    0.120&lt;/td&gt; &lt;td&gt;    5.003&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;    0.357     0.840&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;education&lt;/th&gt; &lt;td&gt;    0.5458&lt;/td&gt; &lt;td&gt;    0.098&lt;/td&gt; &lt;td&gt;    5.555&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;    0.348     0.744&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
  &lt;th&gt;Omnibus:&lt;/th&gt;       &lt;td&gt; 1.279&lt;/td&gt; &lt;th&gt;  Durbin-Watson:     &lt;/th&gt; &lt;td&gt;   1.458&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Prob(Omnibus):&lt;/th&gt; &lt;td&gt; 0.528&lt;/td&gt; &lt;th&gt;  Jarque-Bera (JB):  &lt;/th&gt; &lt;td&gt;   0.520&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Skew:&lt;/th&gt;          &lt;td&gt; 0.155&lt;/td&gt; &lt;th&gt;  Prob(JB):          &lt;/th&gt; &lt;td&gt;   0.771&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Kurtosis:&lt;/th&gt;      &lt;td&gt; 3.426&lt;/td&gt; &lt;th&gt;  Cond. No.          &lt;/th&gt; &lt;td&gt;    163.&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;So far we have looked at the data distributions, and the scatter matrix shows relationships between prestige and both income and education.  We have some covariance between income and educations, that could affect the assumption of linear regression that the variables in the model are independant.   We can look at a studentized resid plot and a QQ plot to examine the model.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def stud_plot(model):
    stud = model.resid/model.resid.std()
    fitv = model.fittedvalues
    plt.figure(figsize=(10,4))
    plt.plot(fitv,stud,marker=&amp;#39;o&amp;#39;,lw=0,color=&amp;#39;steelblue&amp;#39;,alpha=0.8)
    plt.axhline(2,color=&amp;#39;gray&amp;#39;,linestyle=&amp;#39;--&amp;#39;,)
    plt.axhline(-2,color=&amp;#39;gray&amp;#39;,linestyle=&amp;#39;--&amp;#39;)
    plt.xlabel(&amp;quot;Fitted Values&amp;quot;)
    plt.ylabel(&amp;quot;Studentized Residual&amp;quot;)
    plt.ylim([-5,5])
    plt.show()

def qq_plot(model):
    plt.figure(figsize=(10,4))
    stud = model.resid/model.resid.std()
    sc.probplot(model.resid,plot=plt)
    plt.title(&amp;quot;QQ Plot&amp;quot;)
    plt.show()

stud_plot(model1)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_13_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;qq_plot(model1)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_14_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We see se have two outliers from the studentized plot, those that are more than 2 standard deviation from the fit.   The QQ-plot shows a fairly normal distributions of the residuals, suggesting the fit is okay.  We can also see if we have any points with high leverage.&lt;/p&gt;
&lt;p&gt;$$\hat{y} = X \dot \beta = X (X^T \ X)^{-1} \ X^T \ y = H \ y$$&lt;/p&gt;
&lt;p&gt;$$ H = X (X^T \ X)^{-1} \ X^T $$  &lt;/p&gt;
&lt;p&gt;The diagonals of the hat matrix (H) are considered to be estimates of leverage of each point.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def get_H(X):
    H = X.dot( np.linalg.inv(X.transpose().dot(X)).dot(X.transpose()) )
    return H.diagonal()

def lev_plot(model,X):
    h = get_H(X)
    stud = model.resid/model.resid.std()
    plt.figure(figsize=(10,5))
    plt.plot(h,stud,marker=&amp;#39;o&amp;#39;,lw=0,color=&amp;#39;steelblue&amp;#39;,alpha=0.8)
    plt.xlabel(&amp;quot;H Leverage&amp;quot;)
    plt.ylabel(&amp;quot;Studentized Residual&amp;quot;)
    plt.ylim([-5,5])
    plt.show()

lev_plot(model1,x.values)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_17_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We can see that we have 3 points that are leveraging the results, and one of them is an outlier.&lt;/p&gt;
&lt;p&gt;Now we have the question - what do we do with the outliers and the high leverage points?  I think we will stick wih removing all the high leverage points.  We before we do lets look that these three points.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x[get_H(x.values)&amp;gt;0.15]
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;const&lt;/th&gt;
      &lt;th&gt;income&lt;/th&gt;
      &lt;th&gt;education&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;minister&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;84&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;conductor&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;76&lt;/td&gt;
      &lt;td&gt;34&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;RR.engineer&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;81&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;y[get_H(x.values)&amp;gt;=0.15]
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;prestige&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;minister&lt;/th&gt;
      &lt;td&gt;87&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;conductor&lt;/th&gt;
      &lt;td&gt;38&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;RR.engineer&lt;/th&gt;
      &lt;td&gt;67&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;We see the engineer and conductor have higher income, but lower eduation, while the minister has lower education and higher income.   To decide what we do with these values we really need to know the purpose of the model.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;hp = get_H(x.values)
model2 = sm.OLS(y[hp&amp;lt;0.15],x[hp&amp;lt;0.15]).fit()
model2.summary()
&lt;/pre&gt;&lt;/div&gt;


&lt;table class="simpletable"&gt;
&lt;caption&gt;OLS Regression Results&lt;/caption&gt;
&lt;tr&gt;
  &lt;th&gt;Dep. Variable:&lt;/th&gt;        &lt;td&gt;prestige&lt;/td&gt;     &lt;th&gt;  R-squared:         &lt;/th&gt; &lt;td&gt;   0.876&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Model:&lt;/th&gt;                   &lt;td&gt;OLS&lt;/td&gt;       &lt;th&gt;  Adj. R-squared:    &lt;/th&gt; &lt;td&gt;   0.870&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Method:&lt;/th&gt;             &lt;td&gt;Least Squares&lt;/td&gt;  &lt;th&gt;  F-statistic:       &lt;/th&gt; &lt;td&gt;   138.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Date:&lt;/th&gt;             &lt;td&gt;Wed, 17 Jun 2015&lt;/td&gt; &lt;th&gt;  Prob (F-statistic):&lt;/th&gt; &lt;td&gt;2.02e-18&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Time:&lt;/th&gt;                 &lt;td&gt;07:50:23&lt;/td&gt;     &lt;th&gt;  Log-Likelihood:    &lt;/th&gt; &lt;td&gt; -160.59&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;No. Observations:&lt;/th&gt;      &lt;td&gt;    42&lt;/td&gt;      &lt;th&gt;  AIC:               &lt;/th&gt; &lt;td&gt;   327.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Df Residuals:&lt;/th&gt;          &lt;td&gt;    39&lt;/td&gt;      &lt;th&gt;  BIC:               &lt;/th&gt; &lt;td&gt;   332.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Df Model:&lt;/th&gt;              &lt;td&gt;     2&lt;/td&gt;      &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;   
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Covariance Type:&lt;/th&gt;      &lt;td&gt;nonrobust&lt;/td&gt;    &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;   
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
      &lt;td&gt;&lt;/td&gt;         &lt;th&gt;coef&lt;/th&gt;     &lt;th&gt;std err&lt;/th&gt;      &lt;th&gt;t&lt;/th&gt;      &lt;th&gt;P&gt;|t|&lt;/th&gt; &lt;th&gt;[95.0% Conf. Int.]&lt;/th&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;const&lt;/th&gt;     &lt;td&gt;   -6.3174&lt;/td&gt; &lt;td&gt;    3.680&lt;/td&gt; &lt;td&gt;   -1.717&lt;/td&gt; &lt;td&gt; 0.094&lt;/td&gt; &lt;td&gt;  -13.760     1.125&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;income&lt;/th&gt;    &lt;td&gt;    0.9307&lt;/td&gt; &lt;td&gt;    0.154&lt;/td&gt; &lt;td&gt;    6.053&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;    0.620     1.242&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;education&lt;/th&gt; &lt;td&gt;    0.2846&lt;/td&gt; &lt;td&gt;    0.121&lt;/td&gt; &lt;td&gt;    2.345&lt;/td&gt; &lt;td&gt; 0.024&lt;/td&gt; &lt;td&gt;    0.039     0.530&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
  &lt;th&gt;Omnibus:&lt;/th&gt;       &lt;td&gt; 3.811&lt;/td&gt; &lt;th&gt;  Durbin-Watson:     &lt;/th&gt; &lt;td&gt;   1.468&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Prob(Omnibus):&lt;/th&gt; &lt;td&gt; 0.149&lt;/td&gt; &lt;th&gt;  Jarque-Bera (JB):  &lt;/th&gt; &lt;td&gt;   2.802&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Skew:&lt;/th&gt;          &lt;td&gt;-0.614&lt;/td&gt; &lt;th&gt;  Prob(JB):          &lt;/th&gt; &lt;td&gt;   0.246&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Kurtosis:&lt;/th&gt;      &lt;td&gt; 3.303&lt;/td&gt; &lt;th&gt;  Cond. No.          &lt;/th&gt; &lt;td&gt;    158.&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Removing 3 of the 45 data points slightly improved the R-squared value, but dramatically changed the model.   The coefficients were initialy (0.5987,0.5458).  The new model coefficient is (0.9407,2846).  The minister must have been pulling the fit down because they have high prestigue but low income.  Removing them changed the model.   Few people become ministers, so it could be a better model without including them. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;stud_plot(model2)
qq_plot(model2)
lev_plot(model2,x[get_H(x.values)&amp;lt;0.15].values)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_24_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_24_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_24_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;The leverage plot does not show a few points dominating the fit, buter there are a few outliers in the fit.   The QQ plot shows some signs of the erros not being normal.   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;print &amp;quot;Model 1 RSE: &amp;quot;, np.sqrt(np.sum(np.power(y.values.reshape(1,45)-model1.predict(x),2))/(45-2-1))
print &amp;quot;Model 2 RSE: &amp;quot;, np.sqrt(np.sum(np.power(y.values.reshape(1,45)-model2.predict(x),2))/(45-2-1))

Model 1 RSE:  13.3690283982
Model 2 RSE:  14.6713753944
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;On the entire dataset, the first model does a better job fitting the entire dataset then the second model.  The second model fits the subsetted data better.   On these vlaues we have&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;print &amp;quot;Model 1 RSE: &amp;quot;, np.sqrt(np.sum(np.power(y[hp&amp;lt;0.15].values.reshape(1,42)-model1.predict(x[hp&amp;lt;0.15]),2))/(42-2-1))
print &amp;quot;Model 2 RSE: &amp;quot;, np.sqrt(np.sum(np.power(y[hp&amp;lt;0.15].values.reshape(1,42)-model2.predict(x[hp&amp;lt;0.15]),2))/(42-2-1))

Model 1 RSE:  12.2166311202
Model 2 RSE:  11.492268427
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;On the subsetted data, the second model does do better.   If this model was unleashed into the wild we would need to identify outliers and attempt to decide what to do with them&lt;/p&gt;
&lt;h2&gt;Credit Analysis&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure(figsize=(10,10))
scatter_matrix(credit_card,diagonal=&amp;#39;kde&amp;#39;,alpha=0.5,figsize=(14,14))
plt.show()


&amp;lt;matplotlib.figure.Figure at 0x10a815250&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_30_1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;credit_card.corr()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;AVGEXP&lt;/th&gt;
      &lt;th&gt;AGE&lt;/th&gt;
      &lt;th&gt;INCOME&lt;/th&gt;
      &lt;th&gt;INCOMESQ&lt;/th&gt;
      &lt;th&gt;OWNRENT&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;AVGEXP&lt;/th&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.168367&lt;/td&gt;
      &lt;td&gt;0.443135&lt;/td&gt;
      &lt;td&gt;0.372679&lt;/td&gt;
      &lt;td&gt;0.243342&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;AGE&lt;/th&gt;
      &lt;td&gt;0.168367&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.385108&lt;/td&gt;
      &lt;td&gt;0.316498&lt;/td&gt;
      &lt;td&gt;0.438236&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;INCOME&lt;/th&gt;
      &lt;td&gt;0.443135&lt;/td&gt;
      &lt;td&gt;0.385108&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.964707&lt;/td&gt;
      &lt;td&gt;0.473079&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;INCOMESQ&lt;/th&gt;
      &lt;td&gt;0.372679&lt;/td&gt;
      &lt;td&gt;0.316498&lt;/td&gt;
      &lt;td&gt;0.964707&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.434500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;OWNRENT&lt;/th&gt;
      &lt;td&gt;0.243342&lt;/td&gt;
      &lt;td&gt;0.438236&lt;/td&gt;
      &lt;td&gt;0.473079&lt;/td&gt;
      &lt;td&gt;0.434500&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;credit_card.corr(method=&amp;#39;spearman&amp;#39;)
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;AVGEXP&lt;/th&gt;
      &lt;th&gt;AGE&lt;/th&gt;
      &lt;th&gt;INCOME&lt;/th&gt;
      &lt;th&gt;INCOMESQ&lt;/th&gt;
      &lt;th&gt;OWNRENT&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;AVGEXP&lt;/th&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.182947&lt;/td&gt;
      &lt;td&gt;0.533556&lt;/td&gt;
      &lt;td&gt;0.533556&lt;/td&gt;
      &lt;td&gt;0.340274&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;AGE&lt;/th&gt;
      &lt;td&gt;0.182947&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.444940&lt;/td&gt;
      &lt;td&gt;0.444940&lt;/td&gt;
      &lt;td&gt;0.434660&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;INCOME&lt;/th&gt;
      &lt;td&gt;0.533556&lt;/td&gt;
      &lt;td&gt;0.444940&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.410097&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;INCOMESQ&lt;/th&gt;
      &lt;td&gt;0.533556&lt;/td&gt;
      &lt;td&gt;0.444940&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.410097&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;OWNRENT&lt;/th&gt;
      &lt;td&gt;0.340274&lt;/td&gt;
      &lt;td&gt;0.434660&lt;/td&gt;
      &lt;td&gt;0.410097&lt;/td&gt;
      &lt;td&gt;0.410097&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The scatter matrix shows that therre are some variations in between the average expense and age, income, and income squaree.  Obviously income and income squared are related.   The spearmann correlations show that age and income are ordered together, but that ordering does not seem to be a linear relationship because of the significant increason from pearson to spearman.  This could affect our modeling.   &lt;/p&gt;
&lt;p&gt;We'll do a basic fit and see what we are starting with.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;yc = credit_card[[&amp;#39;AVGEXP&amp;#39;]]
xc = sm.add_constant(credit_card[[&amp;#39;INCOME&amp;#39;,&amp;#39;INCOMESQ&amp;#39;,&amp;#39;AGE&amp;#39;,&amp;quot;OWNRENT&amp;quot;]])
model3 = sm.OLS(yc,xc).fit()
model3.summary()
&lt;/pre&gt;&lt;/div&gt;


&lt;table class="simpletable"&gt;
&lt;caption&gt;OLS Regression Results&lt;/caption&gt;
&lt;tr&gt;
  &lt;th&gt;Dep. Variable:&lt;/th&gt;         &lt;td&gt;AVGEXP&lt;/td&gt;      &lt;th&gt;  R-squared:         &lt;/th&gt; &lt;td&gt;   0.244&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Model:&lt;/th&gt;                   &lt;td&gt;OLS&lt;/td&gt;       &lt;th&gt;  Adj. R-squared:    &lt;/th&gt; &lt;td&gt;   0.198&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Method:&lt;/th&gt;             &lt;td&gt;Least Squares&lt;/td&gt;  &lt;th&gt;  F-statistic:       &lt;/th&gt; &lt;td&gt;   5.394&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Date:&lt;/th&gt;             &lt;td&gt;Wed, 17 Jun 2015&lt;/td&gt; &lt;th&gt;  Prob (F-statistic):&lt;/th&gt; &lt;td&gt;0.000795&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Time:&lt;/th&gt;                 &lt;td&gt;08:06:50&lt;/td&gt;     &lt;th&gt;  Log-Likelihood:    &lt;/th&gt; &lt;td&gt; -506.49&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;No. Observations:&lt;/th&gt;      &lt;td&gt;    72&lt;/td&gt;      &lt;th&gt;  AIC:               &lt;/th&gt; &lt;td&gt;   1023.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Df Residuals:&lt;/th&gt;          &lt;td&gt;    67&lt;/td&gt;      &lt;th&gt;  BIC:               &lt;/th&gt; &lt;td&gt;   1034.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Df Model:&lt;/th&gt;              &lt;td&gt;     4&lt;/td&gt;      &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;   
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Covariance Type:&lt;/th&gt;      &lt;td&gt;nonrobust&lt;/td&gt;    &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;   
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
      &lt;td&gt;&lt;/td&gt;        &lt;th&gt;coef&lt;/th&gt;     &lt;th&gt;std err&lt;/th&gt;      &lt;th&gt;t&lt;/th&gt;      &lt;th&gt;P&gt;|t|&lt;/th&gt; &lt;th&gt;[95.0% Conf. Int.]&lt;/th&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;const&lt;/th&gt;    &lt;td&gt; -237.1465&lt;/td&gt; &lt;td&gt;  199.352&lt;/td&gt; &lt;td&gt;   -1.190&lt;/td&gt; &lt;td&gt; 0.238&lt;/td&gt; &lt;td&gt; -635.054   160.761&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;INCOME&lt;/th&gt;   &lt;td&gt;  234.3470&lt;/td&gt; &lt;td&gt;   80.366&lt;/td&gt; &lt;td&gt;    2.916&lt;/td&gt; &lt;td&gt; 0.005&lt;/td&gt; &lt;td&gt;   73.936   394.758&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;INCOMESQ&lt;/th&gt; &lt;td&gt;  -14.9968&lt;/td&gt; &lt;td&gt;    7.469&lt;/td&gt; &lt;td&gt;   -2.008&lt;/td&gt; &lt;td&gt; 0.049&lt;/td&gt; &lt;td&gt;  -29.906    -0.088&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;AGE&lt;/th&gt;      &lt;td&gt;   -3.0818&lt;/td&gt; &lt;td&gt;    5.515&lt;/td&gt; &lt;td&gt;   -0.559&lt;/td&gt; &lt;td&gt; 0.578&lt;/td&gt; &lt;td&gt;  -14.089     7.926&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;OWNRENT&lt;/th&gt;  &lt;td&gt;   27.9409&lt;/td&gt; &lt;td&gt;   82.922&lt;/td&gt; &lt;td&gt;    0.337&lt;/td&gt; &lt;td&gt; 0.737&lt;/td&gt; &lt;td&gt; -137.573   193.455&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
  &lt;th&gt;Omnibus:&lt;/th&gt;       &lt;td&gt;69.024&lt;/td&gt; &lt;th&gt;  Durbin-Watson:     &lt;/th&gt; &lt;td&gt;   1.640&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Prob(Omnibus):&lt;/th&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;th&gt;  Jarque-Bera (JB):  &lt;/th&gt; &lt;td&gt; 497.349&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Skew:&lt;/th&gt;          &lt;td&gt; 2.844&lt;/td&gt; &lt;th&gt;  Prob(JB):          &lt;/th&gt; &lt;td&gt;1.00e-108&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Kurtosis:&lt;/th&gt;      &lt;td&gt;14.551&lt;/td&gt; &lt;th&gt;  Cond. No.          &lt;/th&gt; &lt;td&gt;    227.&lt;/td&gt; 
&lt;/tr&gt;
&lt;/table&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;stud_plot(model3)
qq_plot(model3)
lev_plot(model3,xc.values)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_35_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_35_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_35_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;Our inital linear model is not a strong fit, age and own/rent are not significantly involved in the model, the residuals are not normally distributed, and there are outliers and high leverage points.   We clearly need to do something with this model.  The variances does not look constant.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;statsmodels.stats.diagnostic&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;HetGoldfeldQuandt&lt;/span&gt;
&lt;span class="n"&gt;HGQ&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;HetGoldfeldQuandt&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;HGQ&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;yc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;xc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;




&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.3799238831599079&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.18743313399026834&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;increasing&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;




&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;equal_var&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fittedvalues&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fittedvalues&lt;/span&gt;
    &lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;resid&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;resid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;
    &lt;span class="n"&gt;half&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fittedvalues&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;sc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;levene&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;half&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;half&lt;/span&gt;&lt;span class="p"&gt;:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="n"&gt;equal_var&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;




&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;7.6983153917314482&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.0070815962364431974&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We see that th HetGoldfeldQuandt test shows the variance of the data is not significantly increasing with fitted values, but the levene test shows that there is not equal variance between the lower half and the upper half of the results.   If true, we need to have a fundamentally different model.  We could try a power law relationship.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;model4 = sm.OLS(np.log(yc+1),xc).fit()
model4.summary()
&lt;/pre&gt;&lt;/div&gt;


&lt;table class="simpletable"&gt;
&lt;caption&gt;OLS Regression Results&lt;/caption&gt;
&lt;tr&gt;
  &lt;th&gt;Dep. Variable:&lt;/th&gt;         &lt;td&gt;AVGEXP&lt;/td&gt;      &lt;th&gt;  R-squared:         &lt;/th&gt; &lt;td&gt;   0.282&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Model:&lt;/th&gt;                   &lt;td&gt;OLS&lt;/td&gt;       &lt;th&gt;  Adj. R-squared:    &lt;/th&gt; &lt;td&gt;   0.239&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Method:&lt;/th&gt;             &lt;td&gt;Least Squares&lt;/td&gt;  &lt;th&gt;  F-statistic:       &lt;/th&gt; &lt;td&gt;   6.576&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Date:&lt;/th&gt;             &lt;td&gt;Wed, 17 Jun 2015&lt;/td&gt; &lt;th&gt;  Prob (F-statistic):&lt;/th&gt; &lt;td&gt;0.000159&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Time:&lt;/th&gt;                 &lt;td&gt;08:01:19&lt;/td&gt;     &lt;th&gt;  Log-Likelihood:    &lt;/th&gt; &lt;td&gt; -97.129&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;No. Observations:&lt;/th&gt;      &lt;td&gt;    72&lt;/td&gt;      &lt;th&gt;  AIC:               &lt;/th&gt; &lt;td&gt;   204.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Df Residuals:&lt;/th&gt;          &lt;td&gt;    67&lt;/td&gt;      &lt;th&gt;  BIC:               &lt;/th&gt; &lt;td&gt;   215.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Df Model:&lt;/th&gt;              &lt;td&gt;     4&lt;/td&gt;      &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;   
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Covariance Type:&lt;/th&gt;      &lt;td&gt;nonrobust&lt;/td&gt;    &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;   
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
      &lt;td&gt;&lt;/td&gt;        &lt;th&gt;coef&lt;/th&gt;     &lt;th&gt;std err&lt;/th&gt;      &lt;th&gt;t&lt;/th&gt;      &lt;th&gt;P&gt;|t|&lt;/th&gt; &lt;th&gt;[95.0% Conf. Int.]&lt;/th&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;const&lt;/th&gt;    &lt;td&gt;    3.6758&lt;/td&gt; &lt;td&gt;    0.677&lt;/td&gt; &lt;td&gt;    5.432&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;    2.325     5.027&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;INCOME&lt;/th&gt;   &lt;td&gt;    0.7680&lt;/td&gt; &lt;td&gt;    0.273&lt;/td&gt; &lt;td&gt;    2.815&lt;/td&gt; &lt;td&gt; 0.006&lt;/td&gt; &lt;td&gt;    0.223     1.313&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;INCOMESQ&lt;/th&gt; &lt;td&gt;   -0.0463&lt;/td&gt; &lt;td&gt;    0.025&lt;/td&gt; &lt;td&gt;   -1.826&lt;/td&gt; &lt;td&gt; 0.072&lt;/td&gt; &lt;td&gt;   -0.097     0.004&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;AGE&lt;/th&gt;      &lt;td&gt;   -0.0238&lt;/td&gt; &lt;td&gt;    0.019&lt;/td&gt; &lt;td&gt;   -1.273&lt;/td&gt; &lt;td&gt; 0.207&lt;/td&gt; &lt;td&gt;   -0.061     0.014&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;OWNRENT&lt;/th&gt;  &lt;td&gt;    0.3307&lt;/td&gt; &lt;td&gt;    0.281&lt;/td&gt; &lt;td&gt;    1.175&lt;/td&gt; &lt;td&gt; 0.244&lt;/td&gt; &lt;td&gt;   -0.231     0.893&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
  &lt;th&gt;Omnibus:&lt;/th&gt;       &lt;td&gt; 5.638&lt;/td&gt; &lt;th&gt;  Durbin-Watson:     &lt;/th&gt; &lt;td&gt;   1.902&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Prob(Omnibus):&lt;/th&gt; &lt;td&gt; 0.060&lt;/td&gt; &lt;th&gt;  Jarque-Bera (JB):  &lt;/th&gt; &lt;td&gt;   4.883&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Skew:&lt;/th&gt;          &lt;td&gt;-0.511&lt;/td&gt; &lt;th&gt;  Prob(JB):          &lt;/th&gt; &lt;td&gt;  0.0870&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Kurtosis:&lt;/th&gt;      &lt;td&gt; 3.764&lt;/td&gt; &lt;th&gt;  Cond. No.          &lt;/th&gt; &lt;td&gt;    227.&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;stud_plot(model4)
qq_plot(model4)
lev_plot(model4,xc.values)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_41_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_41_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_41_2.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;HGQ = HetGoldfeldQuandt()
print HGQ.run(np.log(yc+1),xc)
print equal_var(model4)

(0.54047445064175459, 0.95411861481885185, &amp;#39;increasing&amp;#39;)
(0.0049114588257328637, 0.94432837966256522)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Both tests show that the variance appears to be constant with this fit.   The exponential model seems to be an improvement from this perspective.   We can look at the variance indication factor to see if there are any variables we should not be including.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def print_vif(x):
    for i,col in enumerate(x.columns):
        print col, vif(x.values,i)
print_vif(xc)

const 35.2892427253
INCOME 16.3339165879
INCOMESQ 15.21011121
AGE 1.3624340126
OWNRENT 1.43105661679
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In this case the income and income square obviously predict each other, but the other variables appear to be independant.   Maybe this is the case for an interaction term in our model.  Owners and renters probably have different credit habits.  We also saw spearman correlation between age and income.  The improvement of this model will have to be explored after we cover interaction terms&lt;/p&gt;
&lt;h2&gt;Afternoon&lt;/h2&gt;
&lt;p&gt;In the afternoon we were given a new data set and told to perform a regression fit on the data.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;balance = pd.read_csv(&amp;#39;../linear-regression/data/balance.csv&amp;#39;)
balance.info()

&amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;
Int64Index: 400 entries, 0 to 399
Data columns (total 12 columns):
Unnamed: 0    400 non-null int64
Income        400 non-null float64
Limit         400 non-null int64
Rating        400 non-null int64
Cards         400 non-null int64
Age           400 non-null int64
Education     400 non-null int64
Gender        400 non-null object
Student       400 non-null object
Married       400 non-null object
Ethnicity     400 non-null object
Balance       400 non-null int64
dtypes: float64(1), int64(7), object(4)
memory usage: 40.6+ KB



balance.head(10)
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Unnamed: 0&lt;/th&gt;
      &lt;th&gt;Income&lt;/th&gt;
      &lt;th&gt;Limit&lt;/th&gt;
      &lt;th&gt;Rating&lt;/th&gt;
      &lt;th&gt;Cards&lt;/th&gt;
      &lt;th&gt;Age&lt;/th&gt;
      &lt;th&gt;Education&lt;/th&gt;
      &lt;th&gt;Gender&lt;/th&gt;
      &lt;th&gt;Student&lt;/th&gt;
      &lt;th&gt;Married&lt;/th&gt;
      &lt;th&gt;Ethnicity&lt;/th&gt;
      &lt;th&gt;Balance&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;14.891&lt;/td&gt;
      &lt;td&gt;3606&lt;/td&gt;
      &lt;td&gt;283&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;34&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;Male&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;Caucasian&lt;/td&gt;
      &lt;td&gt;333&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;106.025&lt;/td&gt;
      &lt;td&gt;6645&lt;/td&gt;
      &lt;td&gt;483&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;82&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;Female&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;Asian&lt;/td&gt;
      &lt;td&gt;903&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;104.593&lt;/td&gt;
      &lt;td&gt;7075&lt;/td&gt;
      &lt;td&gt;514&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;71&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;Male&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;Asian&lt;/td&gt;
      &lt;td&gt;580&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;148.924&lt;/td&gt;
      &lt;td&gt;9504&lt;/td&gt;
      &lt;td&gt;681&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;36&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;Female&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;Asian&lt;/td&gt;
      &lt;td&gt;964&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;55.882&lt;/td&gt;
      &lt;td&gt;4897&lt;/td&gt;
      &lt;td&gt;357&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;68&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;Male&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;Caucasian&lt;/td&gt;
      &lt;td&gt;331&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;80.180&lt;/td&gt;
      &lt;td&gt;8047&lt;/td&gt;
      &lt;td&gt;569&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;77&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;Male&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;Caucasian&lt;/td&gt;
      &lt;td&gt;1151&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;20.996&lt;/td&gt;
      &lt;td&gt;3388&lt;/td&gt;
      &lt;td&gt;259&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;37&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;Female&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;African American&lt;/td&gt;
      &lt;td&gt;203&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;71.408&lt;/td&gt;
      &lt;td&gt;7114&lt;/td&gt;
      &lt;td&gt;512&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;87&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;Male&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;Asian&lt;/td&gt;
      &lt;td&gt;872&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;8&lt;/th&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;15.125&lt;/td&gt;
      &lt;td&gt;3300&lt;/td&gt;
      &lt;td&gt;266&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;66&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;Female&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;Caucasian&lt;/td&gt;
      &lt;td&gt;279&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;9&lt;/th&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;71.061&lt;/td&gt;
      &lt;td&gt;6819&lt;/td&gt;
      &lt;td&gt;491&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;41&lt;/td&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;Female&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;African American&lt;/td&gt;
      &lt;td&gt;1350&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;scatter_matrix(balance,diagonal=&amp;#39;kde&amp;#39;,figsize=(14,14))
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_48_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;In order to do regression we need to remove the categorical variables and replace them with variables that are zero or one.  With Ethnicity we need to decided ona  baseline, which we decided on african american (alphabetical order).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;balance = balance.drop(&amp;quot;Unnamed: 0&amp;quot;,axis=1)
balance.Gender = balance.Gender.str.strip()
balance.Gender = np.where(balance.Gender==&amp;#39;Male&amp;#39;,1,0)
balance.Student = np.where(balance.Student==&amp;#39;Yes&amp;#39;,1,0)
balance.Married = np.where(balance.Married==&amp;#39;Yes&amp;#39;,1,0)
balance[&amp;#39;Caucasian&amp;#39;] = np.where(balance.Ethnicity==&amp;#39;Caucasian&amp;#39;,1,0)
balance[&amp;#39;Asian&amp;#39;] = np.where(balance.Ethnicity==&amp;#39;Asian&amp;#39;,1,0)
balance = balance.drop(&amp;#39;Ethnicity&amp;#39;,axis=1)
balance.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Income&lt;/th&gt;
      &lt;th&gt;Limit&lt;/th&gt;
      &lt;th&gt;Rating&lt;/th&gt;
      &lt;th&gt;Cards&lt;/th&gt;
      &lt;th&gt;Age&lt;/th&gt;
      &lt;th&gt;Education&lt;/th&gt;
      &lt;th&gt;Gender&lt;/th&gt;
      &lt;th&gt;Student&lt;/th&gt;
      &lt;th&gt;Married&lt;/th&gt;
      &lt;th&gt;Balance&lt;/th&gt;
      &lt;th&gt;Caucasian&lt;/th&gt;
      &lt;th&gt;Asian&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;14.891&lt;/td&gt;
      &lt;td&gt;3606&lt;/td&gt;
      &lt;td&gt;283&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;34&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;333&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;106.025&lt;/td&gt;
      &lt;td&gt;6645&lt;/td&gt;
      &lt;td&gt;483&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;82&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;903&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;104.593&lt;/td&gt;
      &lt;td&gt;7075&lt;/td&gt;
      &lt;td&gt;514&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;71&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;580&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;148.924&lt;/td&gt;
      &lt;td&gt;9504&lt;/td&gt;
      &lt;td&gt;681&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;36&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;964&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;55.882&lt;/td&gt;
      &lt;td&gt;4897&lt;/td&gt;
      &lt;td&gt;357&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;68&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;331&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;yb = balance[[&amp;#39;Balance&amp;#39;]]
xb = sm.add_constant(balance.drop([&amp;#39;Balance&amp;#39;],axis=1))
modelb1 = sm.OLS(yb,xb).fit()
modelb1.summary()
&lt;/pre&gt;&lt;/div&gt;


&lt;table class="simpletable"&gt;
&lt;caption&gt;OLS Regression Results&lt;/caption&gt;
&lt;tr&gt;
  &lt;th&gt;Dep. Variable:&lt;/th&gt;         &lt;td&gt;Balance&lt;/td&gt;     &lt;th&gt;  R-squared:         &lt;/th&gt; &lt;td&gt;   0.955&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Model:&lt;/th&gt;                   &lt;td&gt;OLS&lt;/td&gt;       &lt;th&gt;  Adj. R-squared:    &lt;/th&gt; &lt;td&gt;   0.954&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Method:&lt;/th&gt;             &lt;td&gt;Least Squares&lt;/td&gt;  &lt;th&gt;  F-statistic:       &lt;/th&gt; &lt;td&gt;   750.3&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Date:&lt;/th&gt;             &lt;td&gt;Wed, 17 Jun 2015&lt;/td&gt; &lt;th&gt;  Prob (F-statistic):&lt;/th&gt; &lt;td&gt;1.11e-253&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Time:&lt;/th&gt;                 &lt;td&gt;08:33:39&lt;/td&gt;     &lt;th&gt;  Log-Likelihood:    &lt;/th&gt; &lt;td&gt; -2398.7&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;No. Observations:&lt;/th&gt;      &lt;td&gt;   400&lt;/td&gt;      &lt;th&gt;  AIC:               &lt;/th&gt; &lt;td&gt;   4821.&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Df Residuals:&lt;/th&gt;          &lt;td&gt;   388&lt;/td&gt;      &lt;th&gt;  BIC:               &lt;/th&gt; &lt;td&gt;   4869.&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Df Model:&lt;/th&gt;              &lt;td&gt;    11&lt;/td&gt;      &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;    
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Covariance Type:&lt;/th&gt;      &lt;td&gt;nonrobust&lt;/td&gt;    &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;    
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
      &lt;td&gt;&lt;/td&gt;         &lt;th&gt;coef&lt;/th&gt;     &lt;th&gt;std err&lt;/th&gt;      &lt;th&gt;t&lt;/th&gt;      &lt;th&gt;P&gt;|t|&lt;/th&gt; &lt;th&gt;[95.0% Conf. Int.]&lt;/th&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;const&lt;/th&gt;     &lt;td&gt; -489.8611&lt;/td&gt; &lt;td&gt;   35.801&lt;/td&gt; &lt;td&gt;  -13.683&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt; -560.250  -419.473&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Income&lt;/th&gt;    &lt;td&gt;   -7.8031&lt;/td&gt; &lt;td&gt;    0.234&lt;/td&gt; &lt;td&gt;  -33.314&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;   -8.264    -7.343&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Limit&lt;/th&gt;     &lt;td&gt;    0.1909&lt;/td&gt; &lt;td&gt;    0.033&lt;/td&gt; &lt;td&gt;    5.824&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;    0.126     0.255&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Rating&lt;/th&gt;    &lt;td&gt;    1.1365&lt;/td&gt; &lt;td&gt;    0.491&lt;/td&gt; &lt;td&gt;    2.315&lt;/td&gt; &lt;td&gt; 0.021&lt;/td&gt; &lt;td&gt;    0.171     2.102&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Cards&lt;/th&gt;     &lt;td&gt;   17.7245&lt;/td&gt; &lt;td&gt;    4.341&lt;/td&gt; &lt;td&gt;    4.083&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;    9.190    26.259&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Age&lt;/th&gt;       &lt;td&gt;   -0.6139&lt;/td&gt; &lt;td&gt;    0.294&lt;/td&gt; &lt;td&gt;   -2.088&lt;/td&gt; &lt;td&gt; 0.037&lt;/td&gt; &lt;td&gt;   -1.192    -0.036&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Education&lt;/th&gt; &lt;td&gt;   -1.0989&lt;/td&gt; &lt;td&gt;    1.598&lt;/td&gt; &lt;td&gt;   -0.688&lt;/td&gt; &lt;td&gt; 0.492&lt;/td&gt; &lt;td&gt;   -4.241     2.043&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Gender&lt;/th&gt;    &lt;td&gt;   10.6532&lt;/td&gt; &lt;td&gt;    9.914&lt;/td&gt; &lt;td&gt;    1.075&lt;/td&gt; &lt;td&gt; 0.283&lt;/td&gt; &lt;td&gt;   -8.839    30.145&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Student&lt;/th&gt;   &lt;td&gt;  425.7474&lt;/td&gt; &lt;td&gt;   16.723&lt;/td&gt; &lt;td&gt;   25.459&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;  392.869   458.626&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Married&lt;/th&gt;   &lt;td&gt;   -8.5339&lt;/td&gt; &lt;td&gt;   10.363&lt;/td&gt; &lt;td&gt;   -0.824&lt;/td&gt; &lt;td&gt; 0.411&lt;/td&gt; &lt;td&gt;  -28.908    11.841&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Caucasian&lt;/th&gt; &lt;td&gt;   10.1070&lt;/td&gt; &lt;td&gt;   12.210&lt;/td&gt; &lt;td&gt;    0.828&lt;/td&gt; &lt;td&gt; 0.408&lt;/td&gt; &lt;td&gt;  -13.899    34.113&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Asian&lt;/th&gt;     &lt;td&gt;   16.8042&lt;/td&gt; &lt;td&gt;   14.119&lt;/td&gt; &lt;td&gt;    1.190&lt;/td&gt; &lt;td&gt; 0.235&lt;/td&gt; &lt;td&gt;  -10.955    44.564&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
  &lt;th&gt;Omnibus:&lt;/th&gt;       &lt;td&gt;34.899&lt;/td&gt; &lt;th&gt;  Durbin-Watson:     &lt;/th&gt; &lt;td&gt;   1.968&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Prob(Omnibus):&lt;/th&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;th&gt;  Jarque-Bera (JB):  &lt;/th&gt; &lt;td&gt;  41.766&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Skew:&lt;/th&gt;          &lt;td&gt; 0.782&lt;/td&gt; &lt;th&gt;  Prob(JB):          &lt;/th&gt; &lt;td&gt;8.52e-10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Kurtosis:&lt;/th&gt;      &lt;td&gt; 3.241&lt;/td&gt; &lt;th&gt;  Cond. No.          &lt;/th&gt; &lt;td&gt;3.87e+04&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;stud_plot(modelb1)
qq_plot(modelb1)
lev_plot(modelb1,xb.values)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_52_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_52_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_52_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;We have some very strange behavor with our model.   I am currious what is happening here.  Lets start by looking at the data points where we have the strang line on the studentized plot.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;balance[modelb1.fittedvalues &amp;lt; 100].describe()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Income&lt;/th&gt;
      &lt;th&gt;Limit&lt;/th&gt;
      &lt;th&gt;Rating&lt;/th&gt;
      &lt;th&gt;Cards&lt;/th&gt;
      &lt;th&gt;Age&lt;/th&gt;
      &lt;th&gt;Education&lt;/th&gt;
      &lt;th&gt;Gender&lt;/th&gt;
      &lt;th&gt;Student&lt;/th&gt;
      &lt;th&gt;Married&lt;/th&gt;
      &lt;th&gt;Balance&lt;/th&gt;
      &lt;th&gt;Caucasian&lt;/th&gt;
      &lt;th&gt;Asian&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;count&lt;/th&gt;
      &lt;td&gt;81.000000&lt;/td&gt;
      &lt;td&gt;81.000000&lt;/td&gt;
      &lt;td&gt;81.000000&lt;/td&gt;
      &lt;td&gt;81.000000&lt;/td&gt;
      &lt;td&gt;81.000000&lt;/td&gt;
      &lt;td&gt;81.000000&lt;/td&gt;
      &lt;td&gt;81.000000&lt;/td&gt;
      &lt;td&gt;81.000000&lt;/td&gt;
      &lt;td&gt;81.000000&lt;/td&gt;
      &lt;td&gt;81&lt;/td&gt;
      &lt;td&gt;81.000000&lt;/td&gt;
      &lt;td&gt;81.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;mean&lt;/th&gt;
      &lt;td&gt;28.950296&lt;/td&gt;
      &lt;td&gt;2078.024691&lt;/td&gt;
      &lt;td&gt;177.074074&lt;/td&gt;
      &lt;td&gt;2.753086&lt;/td&gt;
      &lt;td&gt;55.679012&lt;/td&gt;
      &lt;td&gt;13.419753&lt;/td&gt;
      &lt;td&gt;0.530864&lt;/td&gt;
      &lt;td&gt;0.012346&lt;/td&gt;
      &lt;td&gt;0.592593&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.481481&lt;/td&gt;
      &lt;td&gt;0.308642&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;std&lt;/th&gt;
      &lt;td&gt;15.648895&lt;/td&gt;
      &lt;td&gt;736.739048&lt;/td&gt;
      &lt;td&gt;47.463085&lt;/td&gt;
      &lt;td&gt;1.145981&lt;/td&gt;
      &lt;td&gt;17.237914&lt;/td&gt;
      &lt;td&gt;2.801179&lt;/td&gt;
      &lt;td&gt;0.502156&lt;/td&gt;
      &lt;td&gt;0.111111&lt;/td&gt;
      &lt;td&gt;0.494413&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.502770&lt;/td&gt;
      &lt;td&gt;0.464811&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;min&lt;/th&gt;
      &lt;td&gt;10.726000&lt;/td&gt;
      &lt;td&gt;855.000000&lt;/td&gt;
      &lt;td&gt;93.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;24.000000&lt;/td&gt;
      &lt;td&gt;6.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;25%&lt;/th&gt;
      &lt;td&gt;18.036000&lt;/td&gt;
      &lt;td&gt;1501.000000&lt;/td&gt;
      &lt;td&gt;142.000000&lt;/td&gt;
      &lt;td&gt;2.000000&lt;/td&gt;
      &lt;td&gt;40.000000&lt;/td&gt;
      &lt;td&gt;11.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;50%&lt;/th&gt;
      &lt;td&gt;27.039000&lt;/td&gt;
      &lt;td&gt;2047.000000&lt;/td&gt;
      &lt;td&gt;173.000000&lt;/td&gt;
      &lt;td&gt;3.000000&lt;/td&gt;
      &lt;td&gt;57.000000&lt;/td&gt;
      &lt;td&gt;14.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;75%&lt;/th&gt;
      &lt;td&gt;34.772000&lt;/td&gt;
      &lt;td&gt;2529.000000&lt;/td&gt;
      &lt;td&gt;199.000000&lt;/td&gt;
      &lt;td&gt;3.000000&lt;/td&gt;
      &lt;td&gt;70.000000&lt;/td&gt;
      &lt;td&gt;15.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;max&lt;/th&gt;
      &lt;td&gt;92.112000&lt;/td&gt;
      &lt;td&gt;4612.000000&lt;/td&gt;
      &lt;td&gt;344.000000&lt;/td&gt;
      &lt;td&gt;6.000000&lt;/td&gt;
      &lt;td&gt;84.000000&lt;/td&gt;
      &lt;td&gt;19.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;balance[modelb1.fittedvalues &amp;gt; 100].describe()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Income&lt;/th&gt;
      &lt;th&gt;Limit&lt;/th&gt;
      &lt;th&gt;Rating&lt;/th&gt;
      &lt;th&gt;Cards&lt;/th&gt;
      &lt;th&gt;Age&lt;/th&gt;
      &lt;th&gt;Education&lt;/th&gt;
      &lt;th&gt;Gender&lt;/th&gt;
      &lt;th&gt;Student&lt;/th&gt;
      &lt;th&gt;Married&lt;/th&gt;
      &lt;th&gt;Balance&lt;/th&gt;
      &lt;th&gt;Caucasian&lt;/th&gt;
      &lt;th&gt;Asian&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;count&lt;/th&gt;
      &lt;td&gt;319.000000&lt;/td&gt;
      &lt;td&gt;319.000000&lt;/td&gt;
      &lt;td&gt;319.000000&lt;/td&gt;
      &lt;td&gt;319.000000&lt;/td&gt;
      &lt;td&gt;319.000000&lt;/td&gt;
      &lt;td&gt;319.000000&lt;/td&gt;
      &lt;td&gt;319.000000&lt;/td&gt;
      &lt;td&gt;319.000000&lt;/td&gt;
      &lt;td&gt;319.000000&lt;/td&gt;
      &lt;td&gt;319.000000&lt;/td&gt;
      &lt;td&gt;319.000000&lt;/td&gt;
      &lt;td&gt;319.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;mean&lt;/th&gt;
      &lt;td&gt;49.349781&lt;/td&gt;
      &lt;td&gt;5410.407524&lt;/td&gt;
      &lt;td&gt;400.103448&lt;/td&gt;
      &lt;td&gt;3.009404&lt;/td&gt;
      &lt;td&gt;55.664577&lt;/td&gt;
      &lt;td&gt;13.457680&lt;/td&gt;
      &lt;td&gt;0.470219&lt;/td&gt;
      &lt;td&gt;0.122257&lt;/td&gt;
      &lt;td&gt;0.617555&lt;/td&gt;
      &lt;td&gt;652.056426&lt;/td&gt;
      &lt;td&gt;0.501567&lt;/td&gt;
      &lt;td&gt;0.241379&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;std&lt;/th&gt;
      &lt;td&gt;37.582144&lt;/td&gt;
      &lt;td&gt;2071.839874&lt;/td&gt;
      &lt;td&gt;139.162472&lt;/td&gt;
      &lt;td&gt;1.419730&lt;/td&gt;
      &lt;td&gt;17.279892&lt;/td&gt;
      &lt;td&gt;3.206312&lt;/td&gt;
      &lt;td&gt;0.499896&lt;/td&gt;
      &lt;td&gt;0.328097&lt;/td&gt;
      &lt;td&gt;0.486748&lt;/td&gt;
      &lt;td&gt;422.907364&lt;/td&gt;
      &lt;td&gt;0.500783&lt;/td&gt;
      &lt;td&gt;0.428592&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;min&lt;/th&gt;
      &lt;td&gt;10.354000&lt;/td&gt;
      &lt;td&gt;1160.000000&lt;/td&gt;
      &lt;td&gt;126.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;23.000000&lt;/td&gt;
      &lt;td&gt;5.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;25%&lt;/th&gt;
      &lt;td&gt;23.022500&lt;/td&gt;
      &lt;td&gt;3907.000000&lt;/td&gt;
      &lt;td&gt;298.000000&lt;/td&gt;
      &lt;td&gt;2.000000&lt;/td&gt;
      &lt;td&gt;42.500000&lt;/td&gt;
      &lt;td&gt;11.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;305.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;50%&lt;/th&gt;
      &lt;td&gt;36.508000&lt;/td&gt;
      &lt;td&gt;5110.000000&lt;/td&gt;
      &lt;td&gt;377.000000&lt;/td&gt;
      &lt;td&gt;3.000000&lt;/td&gt;
      &lt;td&gt;56.000000&lt;/td&gt;
      &lt;td&gt;14.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;607.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;75%&lt;/th&gt;
      &lt;td&gt;62.848500&lt;/td&gt;
      &lt;td&gt;6408.000000&lt;/td&gt;
      &lt;td&gt;467.000000&lt;/td&gt;
      &lt;td&gt;4.000000&lt;/td&gt;
      &lt;td&gt;69.000000&lt;/td&gt;
      &lt;td&gt;16.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;950.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;max&lt;/th&gt;
      &lt;td&gt;186.634000&lt;/td&gt;
      &lt;td&gt;13913.000000&lt;/td&gt;
      &lt;td&gt;982.000000&lt;/td&gt;
      &lt;td&gt;9.000000&lt;/td&gt;
      &lt;td&gt;98.000000&lt;/td&gt;
      &lt;td&gt;20.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;1999.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;balance.describe()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Income&lt;/th&gt;
      &lt;th&gt;Limit&lt;/th&gt;
      &lt;th&gt;Rating&lt;/th&gt;
      &lt;th&gt;Cards&lt;/th&gt;
      &lt;th&gt;Age&lt;/th&gt;
      &lt;th&gt;Education&lt;/th&gt;
      &lt;th&gt;Gender&lt;/th&gt;
      &lt;th&gt;Student&lt;/th&gt;
      &lt;th&gt;Married&lt;/th&gt;
      &lt;th&gt;Balance&lt;/th&gt;
      &lt;th&gt;Caucasian&lt;/th&gt;
      &lt;th&gt;Asian&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;count&lt;/th&gt;
      &lt;td&gt;400.000000&lt;/td&gt;
      &lt;td&gt;400.000000&lt;/td&gt;
      &lt;td&gt;400.000000&lt;/td&gt;
      &lt;td&gt;400.000000&lt;/td&gt;
      &lt;td&gt;400.000000&lt;/td&gt;
      &lt;td&gt;400.000000&lt;/td&gt;
      &lt;td&gt;400.000000&lt;/td&gt;
      &lt;td&gt;400.000000&lt;/td&gt;
      &lt;td&gt;400.00000&lt;/td&gt;
      &lt;td&gt;400.000000&lt;/td&gt;
      &lt;td&gt;400.00000&lt;/td&gt;
      &lt;td&gt;400.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;mean&lt;/th&gt;
      &lt;td&gt;45.218885&lt;/td&gt;
      &lt;td&gt;4735.600000&lt;/td&gt;
      &lt;td&gt;354.940000&lt;/td&gt;
      &lt;td&gt;2.957500&lt;/td&gt;
      &lt;td&gt;55.667500&lt;/td&gt;
      &lt;td&gt;13.450000&lt;/td&gt;
      &lt;td&gt;0.482500&lt;/td&gt;
      &lt;td&gt;0.100000&lt;/td&gt;
      &lt;td&gt;0.61250&lt;/td&gt;
      &lt;td&gt;520.015000&lt;/td&gt;
      &lt;td&gt;0.49750&lt;/td&gt;
      &lt;td&gt;0.255000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;std&lt;/th&gt;
      &lt;td&gt;35.244273&lt;/td&gt;
      &lt;td&gt;2308.198848&lt;/td&gt;
      &lt;td&gt;154.724143&lt;/td&gt;
      &lt;td&gt;1.371275&lt;/td&gt;
      &lt;td&gt;17.249807&lt;/td&gt;
      &lt;td&gt;3.125207&lt;/td&gt;
      &lt;td&gt;0.500319&lt;/td&gt;
      &lt;td&gt;0.300376&lt;/td&gt;
      &lt;td&gt;0.48779&lt;/td&gt;
      &lt;td&gt;459.758877&lt;/td&gt;
      &lt;td&gt;0.50062&lt;/td&gt;
      &lt;td&gt;0.436407&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;min&lt;/th&gt;
      &lt;td&gt;10.354000&lt;/td&gt;
      &lt;td&gt;855.000000&lt;/td&gt;
      &lt;td&gt;93.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;23.000000&lt;/td&gt;
      &lt;td&gt;5.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.00000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.00000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;25%&lt;/th&gt;
      &lt;td&gt;21.007250&lt;/td&gt;
      &lt;td&gt;3088.000000&lt;/td&gt;
      &lt;td&gt;247.250000&lt;/td&gt;
      &lt;td&gt;2.000000&lt;/td&gt;
      &lt;td&gt;41.750000&lt;/td&gt;
      &lt;td&gt;11.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.00000&lt;/td&gt;
      &lt;td&gt;68.750000&lt;/td&gt;
      &lt;td&gt;0.00000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;50%&lt;/th&gt;
      &lt;td&gt;33.115500&lt;/td&gt;
      &lt;td&gt;4622.500000&lt;/td&gt;
      &lt;td&gt;344.000000&lt;/td&gt;
      &lt;td&gt;3.000000&lt;/td&gt;
      &lt;td&gt;56.000000&lt;/td&gt;
      &lt;td&gt;14.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;1.00000&lt;/td&gt;
      &lt;td&gt;459.500000&lt;/td&gt;
      &lt;td&gt;0.00000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;75%&lt;/th&gt;
      &lt;td&gt;57.470750&lt;/td&gt;
      &lt;td&gt;5872.750000&lt;/td&gt;
      &lt;td&gt;437.250000&lt;/td&gt;
      &lt;td&gt;4.000000&lt;/td&gt;
      &lt;td&gt;70.000000&lt;/td&gt;
      &lt;td&gt;16.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;1.00000&lt;/td&gt;
      &lt;td&gt;863.000000&lt;/td&gt;
      &lt;td&gt;1.00000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;max&lt;/th&gt;
      &lt;td&gt;186.634000&lt;/td&gt;
      &lt;td&gt;13913.000000&lt;/td&gt;
      &lt;td&gt;982.000000&lt;/td&gt;
      &lt;td&gt;9.000000&lt;/td&gt;
      &lt;td&gt;98.000000&lt;/td&gt;
      &lt;td&gt;20.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;1.00000&lt;/td&gt;
      &lt;td&gt;1999.000000&lt;/td&gt;
      &lt;td&gt;1.00000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;We see that relative to the averages, the trouble points looked to be people with no balance.  If we do a fit without balance, just to check, I am curreous if we get a good model.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;modelb2 = sm.OLS(yb[yb.values&amp;gt;0],xb[yb.values&amp;gt;0]).fit()
modelb2.summary()
&lt;/pre&gt;&lt;/div&gt;


&lt;table class="simpletable"&gt;
&lt;caption&gt;OLS Regression Results&lt;/caption&gt;
&lt;tr&gt;
  &lt;th&gt;Dep. Variable:&lt;/th&gt;         &lt;td&gt;Balance&lt;/td&gt;     &lt;th&gt;  R-squared:         &lt;/th&gt; &lt;td&gt;   0.999&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Model:&lt;/th&gt;                   &lt;td&gt;OLS&lt;/td&gt;       &lt;th&gt;  Adj. R-squared:    &lt;/th&gt; &lt;td&gt;   0.999&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Method:&lt;/th&gt;             &lt;td&gt;Least Squares&lt;/td&gt;  &lt;th&gt;  F-statistic:       &lt;/th&gt; &lt;td&gt;4.366e+04&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Date:&lt;/th&gt;             &lt;td&gt;Wed, 17 Jun 2015&lt;/td&gt; &lt;th&gt;  Prob (F-statistic):&lt;/th&gt;  &lt;td&gt;  0.00&lt;/td&gt;  
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Time:&lt;/th&gt;                 &lt;td&gt;08:44:21&lt;/td&gt;     &lt;th&gt;  Log-Likelihood:    &lt;/th&gt; &lt;td&gt; -1162.5&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;No. Observations:&lt;/th&gt;      &lt;td&gt;   310&lt;/td&gt;      &lt;th&gt;  AIC:               &lt;/th&gt; &lt;td&gt;   2349.&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Df Residuals:&lt;/th&gt;          &lt;td&gt;   298&lt;/td&gt;      &lt;th&gt;  BIC:               &lt;/th&gt; &lt;td&gt;   2394.&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Df Model:&lt;/th&gt;              &lt;td&gt;    11&lt;/td&gt;      &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;    
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Covariance Type:&lt;/th&gt;      &lt;td&gt;nonrobust&lt;/td&gt;    &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;    
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
      &lt;td&gt;&lt;/td&gt;         &lt;th&gt;coef&lt;/th&gt;     &lt;th&gt;std err&lt;/th&gt;      &lt;th&gt;t&lt;/th&gt;      &lt;th&gt;P&gt;|t|&lt;/th&gt; &lt;th&gt;[95.0% Conf. Int.]&lt;/th&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;const&lt;/th&gt;     &lt;td&gt; -696.6745&lt;/td&gt; &lt;td&gt;    4.406&lt;/td&gt; &lt;td&gt; -158.103&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt; -705.346  -688.003&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Income&lt;/th&gt;    &lt;td&gt;   -9.9916&lt;/td&gt; &lt;td&gt;    0.029&lt;/td&gt; &lt;td&gt; -339.458&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;  -10.050    -9.934&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Limit&lt;/th&gt;     &lt;td&gt;    0.3360&lt;/td&gt; &lt;td&gt;    0.004&lt;/td&gt; &lt;td&gt;   84.135&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;    0.328     0.344&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Rating&lt;/th&gt;    &lt;td&gt;   -0.1433&lt;/td&gt; &lt;td&gt;    0.059&lt;/td&gt; &lt;td&gt;   -2.428&lt;/td&gt; &lt;td&gt; 0.016&lt;/td&gt; &lt;td&gt;   -0.259    -0.027&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Cards&lt;/th&gt;     &lt;td&gt;   25.4764&lt;/td&gt; &lt;td&gt;    0.500&lt;/td&gt; &lt;td&gt;   50.962&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;   24.493    26.460&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Age&lt;/th&gt;       &lt;td&gt;   -1.0029&lt;/td&gt; &lt;td&gt;    0.036&lt;/td&gt; &lt;td&gt;  -28.215&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;   -1.073    -0.933&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Education&lt;/th&gt; &lt;td&gt;   -0.0080&lt;/td&gt; &lt;td&gt;    0.189&lt;/td&gt; &lt;td&gt;   -0.042&lt;/td&gt; &lt;td&gt; 0.966&lt;/td&gt; &lt;td&gt;   -0.381     0.365&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Gender&lt;/th&gt;    &lt;td&gt;   -0.2332&lt;/td&gt; &lt;td&gt;    1.200&lt;/td&gt; &lt;td&gt;   -0.194&lt;/td&gt; &lt;td&gt; 0.846&lt;/td&gt; &lt;td&gt;   -2.596     2.129&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Student&lt;/th&gt;   &lt;td&gt;  500.8310&lt;/td&gt; &lt;td&gt;    1.880&lt;/td&gt; &lt;td&gt;  266.464&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;  497.132   504.530&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Married&lt;/th&gt;   &lt;td&gt;   -2.0625&lt;/td&gt; &lt;td&gt;    1.261&lt;/td&gt; &lt;td&gt;   -1.636&lt;/td&gt; &lt;td&gt; 0.103&lt;/td&gt; &lt;td&gt;   -4.543     0.418&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Caucasian&lt;/th&gt; &lt;td&gt;   -0.0700&lt;/td&gt; &lt;td&gt;    1.467&lt;/td&gt; &lt;td&gt;   -0.048&lt;/td&gt; &lt;td&gt; 0.962&lt;/td&gt; &lt;td&gt;   -2.956     2.816&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Asian&lt;/th&gt;     &lt;td&gt;   -1.3785&lt;/td&gt; &lt;td&gt;    1.731&lt;/td&gt; &lt;td&gt;   -0.796&lt;/td&gt; &lt;td&gt; 0.426&lt;/td&gt; &lt;td&gt;   -4.784     2.027&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
  &lt;th&gt;Omnibus:&lt;/th&gt;       &lt;td&gt; 3.799&lt;/td&gt; &lt;th&gt;  Durbin-Watson:     &lt;/th&gt; &lt;td&gt;   2.067&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Prob(Omnibus):&lt;/th&gt; &lt;td&gt; 0.150&lt;/td&gt; &lt;th&gt;  Jarque-Bera (JB):  &lt;/th&gt; &lt;td&gt;   3.766&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Skew:&lt;/th&gt;          &lt;td&gt;-0.269&lt;/td&gt; &lt;th&gt;  Prob(JB):          &lt;/th&gt; &lt;td&gt;   0.152&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Kurtosis:&lt;/th&gt;      &lt;td&gt; 2.963&lt;/td&gt; &lt;th&gt;  Cond. No.          &lt;/th&gt; &lt;td&gt;4.37e+04&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;stud_plot(modelb2)
qq_plot(modelb2)
lev_plot(modelb2,xb[yb.values&amp;gt;0].values)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_59_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_59_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_59_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;So we have a great fit where the variance is constant, the residuals are normally distributed, and there are no high leverage points if we fit the data with removing the zero-balance points.   People with zero balance, however, are in the data.   Our regression does not make valid predictions for people with zero balnce.  &lt;/p&gt;
&lt;p&gt;This seems like a two step process:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Classify if the person is likely to have zero balance.&lt;/li&gt;
&lt;li&gt;If they do predict zero, otherwise predict the regression model.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Another solution would be to cut on credit rating.  One model for those above 350 credit rating, and another model for those with less than 350 credit rating.  This is because in the zero balance group, the max credit rating was 344.  Some of the issues is that we not know if this is a general cutoff, but lets try it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;modelb3 = sm.OLS(yb[xb.Rating &amp;gt; 350],xb[xb.Rating &amp;gt; 350]).fit()
modelb3.summary()
&lt;/pre&gt;&lt;/div&gt;


&lt;table class="simpletable"&gt;
&lt;caption&gt;OLS Regression Results&lt;/caption&gt;
&lt;tr&gt;
  &lt;th&gt;Dep. Variable:&lt;/th&gt;         &lt;td&gt;Balance&lt;/td&gt;     &lt;th&gt;  R-squared:         &lt;/th&gt; &lt;td&gt;   0.999&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Model:&lt;/th&gt;                   &lt;td&gt;OLS&lt;/td&gt;       &lt;th&gt;  Adj. R-squared:    &lt;/th&gt; &lt;td&gt;   0.999&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Method:&lt;/th&gt;             &lt;td&gt;Least Squares&lt;/td&gt;  &lt;th&gt;  F-statistic:       &lt;/th&gt; &lt;td&gt;1.854e+04&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Date:&lt;/th&gt;             &lt;td&gt;Wed, 17 Jun 2015&lt;/td&gt; &lt;th&gt;  Prob (F-statistic):&lt;/th&gt; &lt;td&gt;1.07e-273&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Time:&lt;/th&gt;                 &lt;td&gt;09:06:41&lt;/td&gt;     &lt;th&gt;  Log-Likelihood:    &lt;/th&gt; &lt;td&gt; -741.54&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;No. Observations:&lt;/th&gt;      &lt;td&gt;   196&lt;/td&gt;      &lt;th&gt;  AIC:               &lt;/th&gt; &lt;td&gt;   1507.&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Df Residuals:&lt;/th&gt;          &lt;td&gt;   184&lt;/td&gt;      &lt;th&gt;  BIC:               &lt;/th&gt; &lt;td&gt;   1546.&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Df Model:&lt;/th&gt;              &lt;td&gt;    11&lt;/td&gt;      &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;    
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Covariance Type:&lt;/th&gt;      &lt;td&gt;nonrobust&lt;/td&gt;    &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;    
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
      &lt;td&gt;&lt;/td&gt;         &lt;th&gt;coef&lt;/th&gt;     &lt;th&gt;std err&lt;/th&gt;      &lt;th&gt;t&lt;/th&gt;      &lt;th&gt;P&gt;|t|&lt;/th&gt; &lt;th&gt;[95.0% Conf. Int.]&lt;/th&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;const&lt;/th&gt;     &lt;td&gt; -691.8364&lt;/td&gt; &lt;td&gt;    6.766&lt;/td&gt; &lt;td&gt; -102.258&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt; -705.184  -678.488&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Income&lt;/th&gt;    &lt;td&gt;   -9.9829&lt;/td&gt; &lt;td&gt;    0.037&lt;/td&gt; &lt;td&gt; -271.846&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;  -10.055    -9.910&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Limit&lt;/th&gt;     &lt;td&gt;    0.3346&lt;/td&gt; &lt;td&gt;    0.005&lt;/td&gt; &lt;td&gt;   65.301&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;    0.325     0.345&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Rating&lt;/th&gt;    &lt;td&gt;   -0.1283&lt;/td&gt; &lt;td&gt;    0.076&lt;/td&gt; &lt;td&gt;   -1.698&lt;/td&gt; &lt;td&gt; 0.091&lt;/td&gt; &lt;td&gt;   -0.277     0.021&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Cards&lt;/th&gt;     &lt;td&gt;   25.3670&lt;/td&gt; &lt;td&gt;    0.660&lt;/td&gt; &lt;td&gt;   38.407&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;   24.064    26.670&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Age&lt;/th&gt;       &lt;td&gt;   -1.0321&lt;/td&gt; &lt;td&gt;    0.048&lt;/td&gt; &lt;td&gt;  -21.524&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;   -1.127    -0.938&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Education&lt;/th&gt; &lt;td&gt;   -0.0099&lt;/td&gt; &lt;td&gt;    0.252&lt;/td&gt; &lt;td&gt;   -0.039&lt;/td&gt; &lt;td&gt; 0.969&lt;/td&gt; &lt;td&gt;   -0.507     0.487&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Gender&lt;/th&gt;    &lt;td&gt;   -1.5948&lt;/td&gt; &lt;td&gt;    1.597&lt;/td&gt; &lt;td&gt;   -0.998&lt;/td&gt; &lt;td&gt; 0.319&lt;/td&gt; &lt;td&gt;   -4.746     1.557&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Student&lt;/th&gt;   &lt;td&gt;  501.4411&lt;/td&gt; &lt;td&gt;    2.587&lt;/td&gt; &lt;td&gt;  193.814&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;  496.337   506.546&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Married&lt;/th&gt;   &lt;td&gt;   -2.5047&lt;/td&gt; &lt;td&gt;    1.725&lt;/td&gt; &lt;td&gt;   -1.452&lt;/td&gt; &lt;td&gt; 0.148&lt;/td&gt; &lt;td&gt;   -5.907     0.898&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Caucasian&lt;/th&gt; &lt;td&gt;    0.1485&lt;/td&gt; &lt;td&gt;    1.961&lt;/td&gt; &lt;td&gt;    0.076&lt;/td&gt; &lt;td&gt; 0.940&lt;/td&gt; &lt;td&gt;   -3.721     4.018&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Asian&lt;/th&gt;     &lt;td&gt;   -2.5407&lt;/td&gt; &lt;td&gt;    2.280&lt;/td&gt; &lt;td&gt;   -1.115&lt;/td&gt; &lt;td&gt; 0.266&lt;/td&gt; &lt;td&gt;   -7.038     1.957&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
  &lt;th&gt;Omnibus:&lt;/th&gt;       &lt;td&gt; 5.399&lt;/td&gt; &lt;th&gt;  Durbin-Watson:     &lt;/th&gt; &lt;td&gt;   2.016&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Prob(Omnibus):&lt;/th&gt; &lt;td&gt; 0.067&lt;/td&gt; &lt;th&gt;  Jarque-Bera (JB):  &lt;/th&gt; &lt;td&gt;   5.524&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Skew:&lt;/th&gt;          &lt;td&gt;-0.404&lt;/td&gt; &lt;th&gt;  Prob(JB):          &lt;/th&gt; &lt;td&gt;  0.0632&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Kurtosis:&lt;/th&gt;      &lt;td&gt; 2.842&lt;/td&gt; &lt;th&gt;  Cond. No.          &lt;/th&gt; &lt;td&gt;5.92e+04&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;modelb4 = sm.OLS(yb[xb.Rating &amp;lt;= 350],xb[xb.Rating &amp;lt;= 350]).fit()
modelb4.summary()
&lt;/pre&gt;&lt;/div&gt;


&lt;table class="simpletable"&gt;
&lt;caption&gt;OLS Regression Results&lt;/caption&gt;
&lt;tr&gt;
  &lt;th&gt;Dep. Variable:&lt;/th&gt;         &lt;td&gt;Balance&lt;/td&gt;     &lt;th&gt;  R-squared:         &lt;/th&gt; &lt;td&gt;   0.851&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Model:&lt;/th&gt;                   &lt;td&gt;OLS&lt;/td&gt;       &lt;th&gt;  Adj. R-squared:    &lt;/th&gt; &lt;td&gt;   0.842&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Method:&lt;/th&gt;             &lt;td&gt;Least Squares&lt;/td&gt;  &lt;th&gt;  F-statistic:       &lt;/th&gt; &lt;td&gt;   99.66&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Date:&lt;/th&gt;             &lt;td&gt;Wed, 17 Jun 2015&lt;/td&gt; &lt;th&gt;  Prob (F-statistic):&lt;/th&gt; &lt;td&gt;3.80e-73&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Time:&lt;/th&gt;                 &lt;td&gt;09:07:02&lt;/td&gt;     &lt;th&gt;  Log-Likelihood:    &lt;/th&gt; &lt;td&gt; -1197.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;No. Observations:&lt;/th&gt;      &lt;td&gt;   204&lt;/td&gt;      &lt;th&gt;  AIC:               &lt;/th&gt; &lt;td&gt;   2420.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Df Residuals:&lt;/th&gt;          &lt;td&gt;   192&lt;/td&gt;      &lt;th&gt;  BIC:               &lt;/th&gt; &lt;td&gt;   2459.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Df Model:&lt;/th&gt;              &lt;td&gt;    11&lt;/td&gt;      &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;   
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Covariance Type:&lt;/th&gt;      &lt;td&gt;nonrobust&lt;/td&gt;    &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;   
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
      &lt;td&gt;&lt;/td&gt;         &lt;th&gt;coef&lt;/th&gt;     &lt;th&gt;std err&lt;/th&gt;      &lt;th&gt;t&lt;/th&gt;      &lt;th&gt;P&gt;|t|&lt;/th&gt; &lt;th&gt;[95.0% Conf. Int.]&lt;/th&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;const&lt;/th&gt;     &lt;td&gt; -218.3506&lt;/td&gt; &lt;td&gt;   47.949&lt;/td&gt; &lt;td&gt;   -4.554&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt; -312.924  -123.777&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Income&lt;/th&gt;    &lt;td&gt;   -7.1002&lt;/td&gt; &lt;td&gt;    0.446&lt;/td&gt; &lt;td&gt;  -15.913&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;   -7.980    -6.220&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Limit&lt;/th&gt;     &lt;td&gt;    0.1523&lt;/td&gt; &lt;td&gt;    0.043&lt;/td&gt; &lt;td&gt;    3.563&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;    0.068     0.237&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Rating&lt;/th&gt;    &lt;td&gt;    0.4791&lt;/td&gt; &lt;td&gt;    0.654&lt;/td&gt; &lt;td&gt;    0.732&lt;/td&gt; &lt;td&gt; 0.465&lt;/td&gt; &lt;td&gt;   -0.811     1.769&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Cards&lt;/th&gt;     &lt;td&gt;   13.9981&lt;/td&gt; &lt;td&gt;    5.762&lt;/td&gt; &lt;td&gt;    2.430&lt;/td&gt; &lt;td&gt; 0.016&lt;/td&gt; &lt;td&gt;    2.634    25.362&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Age&lt;/th&gt;       &lt;td&gt;   -0.6226&lt;/td&gt; &lt;td&gt;    0.368&lt;/td&gt; &lt;td&gt;   -1.691&lt;/td&gt; &lt;td&gt; 0.092&lt;/td&gt; &lt;td&gt;   -1.349     0.104&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Education&lt;/th&gt; &lt;td&gt;   -2.7730&lt;/td&gt; &lt;td&gt;    2.072&lt;/td&gt; &lt;td&gt;   -1.338&lt;/td&gt; &lt;td&gt; 0.182&lt;/td&gt; &lt;td&gt;   -6.859     1.313&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Gender&lt;/th&gt;    &lt;td&gt;   25.9813&lt;/td&gt; &lt;td&gt;   12.584&lt;/td&gt; &lt;td&gt;    2.065&lt;/td&gt; &lt;td&gt; 0.040&lt;/td&gt; &lt;td&gt;    1.161    50.801&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Student&lt;/th&gt;   &lt;td&gt;  339.5260&lt;/td&gt; &lt;td&gt;   22.216&lt;/td&gt; &lt;td&gt;   15.283&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;  295.707   383.345&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Married&lt;/th&gt;   &lt;td&gt;   -8.2622&lt;/td&gt; &lt;td&gt;   12.799&lt;/td&gt; &lt;td&gt;   -0.646&lt;/td&gt; &lt;td&gt; 0.519&lt;/td&gt; &lt;td&gt;  -33.507    16.983&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Caucasian&lt;/th&gt; &lt;td&gt;   22.5267&lt;/td&gt; &lt;td&gt;   15.427&lt;/td&gt; &lt;td&gt;    1.460&lt;/td&gt; &lt;td&gt; 0.146&lt;/td&gt; &lt;td&gt;   -7.901    52.955&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Asian&lt;/th&gt;     &lt;td&gt;   14.5170&lt;/td&gt; &lt;td&gt;   17.628&lt;/td&gt; &lt;td&gt;    0.824&lt;/td&gt; &lt;td&gt; 0.411&lt;/td&gt; &lt;td&gt;  -20.252    49.286&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
  &lt;th&gt;Omnibus:&lt;/th&gt;       &lt;td&gt; 3.153&lt;/td&gt; &lt;th&gt;  Durbin-Watson:     &lt;/th&gt; &lt;td&gt;   1.919&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Prob(Omnibus):&lt;/th&gt; &lt;td&gt; 0.207&lt;/td&gt; &lt;th&gt;  Jarque-Bera (JB):  &lt;/th&gt; &lt;td&gt;   2.562&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Skew:&lt;/th&gt;          &lt;td&gt; 0.155&lt;/td&gt; &lt;th&gt;  Prob(JB):          &lt;/th&gt; &lt;td&gt;   0.278&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Kurtosis:&lt;/th&gt;      &lt;td&gt; 2.547&lt;/td&gt; &lt;th&gt;  Cond. No.          &lt;/th&gt; &lt;td&gt;2.49e+04&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;stud_plot(modelb3)
qq_plot(modelb3)
lev_plot(modelb3,xb[xb.Rating&amp;gt;350].values)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_63_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_63_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_63_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;The model for above 350 Credit Rating looks good.  Lets check below 350.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;stud_plot(modelb4)
qq_plot(modelb4)
lev_plot(modelb4,xb[xb.Rating&amp;lt;=350].values)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_65_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_65_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D2/output_65_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;We have the same issue before.   We must made a cut to make a good prediction, then removed the values from the data that were causing issues without knowing the balance.   This can be useful in practice, but i find it a little unstatisfying.   For now we will stop with this exploration.  &lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="regression"></category></entry><entry><title>Galvanize - Week 03 - Day 1</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-03-01/" rel="alternate"></link><updated>2015-06-15T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-15:galvanize/galvanize-data-science-03-01/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 3 - Day 1&lt;/h2&gt;
&lt;p&gt;Today we had the first quiz I did not finish.  I attempted to do algebra in latex, and made a sign mistake and had difficulty traking my mistake.   &lt;/p&gt;
&lt;p&gt;The morning involved using numpy to solve some linear algrebra based problems.  The afternoon had to do with exploratory data analysis and linear regression.   &lt;/p&gt;
&lt;h2&gt;Miniquiz&lt;/h2&gt;
&lt;p&gt;Probability Practice&lt;/p&gt;
&lt;p&gt;Let's say we play a game where I keep flipping a coin until I get heads. If the first time I get heads is on the nth coin, then I pay you 2n-1 dollars. How much would you pay me to play this game for us to break even in the long term? Show your work.&lt;/p&gt;
&lt;p&gt;P(n) = p^(n-1)*(1-p)&lt;/p&gt;
&lt;p&gt;$$E(V) = \Sigma_{i=1}^{\infty} p^{n-1} \ (1-p) \ (2n-1) $$&lt;/p&gt;
&lt;p&gt;$$E(V) = \Sigma_{i=1}^{\infty} (2n-1) (p^{n-1} - p^n) $$&lt;/p&gt;
&lt;p&gt;$$E(V) = \Sigma{i=1}^{\infty} 2 \ n \ p^{n-1} - \Sigma{i=1}^{\infty} 2 \ n \ p^{n} - \Sigma{i=1}^{\infty} p^{n-1} + \Sigma{i=1}^{\infty} p^{n} $$&lt;/p&gt;
&lt;p&gt;$$E(V) = 2 + \Sigma{i=1}^{\infty} 2 \ (n+1)\ p^{n} - \Sigma{i=1}^{\infty} 2 \ n \ p^{n} - 1 - \Sigma{i=1}^{\infty} p^{n} + \Sigma{i=1}^{\infty} p^{n} $$&lt;/p&gt;
&lt;p&gt;$$E(V) = 1 + \Sigma_{i=1}^{\infty} 2 p^{n} $$&lt;/p&gt;
&lt;p&gt;$$E(V) = 1 + \frac{2 \ p }{1-p}$$&lt;/p&gt;
&lt;p&gt;Write a program to simulate the game and verify that your answer is correct.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;expect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;val&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;val&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;val&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;an&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;simulation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;pays&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="n"&gt;pays&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;append&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;pays&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pays&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;pays&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;expect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;an&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;simulation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;



&lt;span class="mf"&gt;1.22222222222&lt;/span&gt; &lt;span class="mf"&gt;1.22222222222&lt;/span&gt; &lt;span class="mf"&gt;1.2154&lt;/span&gt;
&lt;span class="mf"&gt;1.46575342466&lt;/span&gt; &lt;span class="mf"&gt;1.46575342466&lt;/span&gt; &lt;span class="mf"&gt;1.4702&lt;/span&gt;
&lt;span class="mf"&gt;1.76923076923&lt;/span&gt; &lt;span class="mf"&gt;1.76923076923&lt;/span&gt; &lt;span class="mf"&gt;1.7798&lt;/span&gt;
&lt;span class="mf"&gt;2.15789473684&lt;/span&gt; &lt;span class="mf"&gt;2.15789473684&lt;/span&gt; &lt;span class="mf"&gt;2.1384&lt;/span&gt;
&lt;span class="mf"&gt;2.67346938776&lt;/span&gt; &lt;span class="mf"&gt;2.67346938776&lt;/span&gt; &lt;span class="mf"&gt;2.6592&lt;/span&gt;
&lt;span class="mf"&gt;3.39024390244&lt;/span&gt; &lt;span class="mf"&gt;3.39024390244&lt;/span&gt; &lt;span class="mf"&gt;3.3546&lt;/span&gt;
&lt;span class="mf"&gt;4.45454545455&lt;/span&gt; &lt;span class="mf"&gt;4.45454545455&lt;/span&gt; &lt;span class="mf"&gt;4.3904&lt;/span&gt;
&lt;span class="mf"&gt;6.2&lt;/span&gt; &lt;span class="mf"&gt;6.2&lt;/span&gt; &lt;span class="mf"&gt;6.186&lt;/span&gt;
&lt;span class="mf"&gt;9.58823529412&lt;/span&gt; &lt;span class="mf"&gt;9.58823529412&lt;/span&gt; &lt;span class="mf"&gt;9.6414&lt;/span&gt;
&lt;span class="mf"&gt;19.0&lt;/span&gt; &lt;span class="mf"&gt;19.0&lt;/span&gt; &lt;span class="mf"&gt;19.1224&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Linear Algebra Practice:&lt;/h2&gt;
&lt;p&gt;The stochastic matrix is central to the Markov process. It is a sqaure matrix specifying that probabilities of going from one state to the other such that every column of the matrix sums to 1.  The probability of entering a certain state depends only on the last state occupied and the stochastic matrix, not on any earlier states&lt;/p&gt;
&lt;p&gt;Suppose that the 2004 &lt;strong&gt;state of land use&lt;/strong&gt; in a city of 60 mi^2 of built-up
area is&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;In 2004:

C (Commercially Used): 25%
I (Industrially Used): 20%
R (Residentially Used): 55%
&lt;/pre&gt;&lt;/div&gt;


&lt;ol&gt;
&lt;li&gt;Find the &lt;strong&gt;state of land use&lt;/strong&gt; in &lt;strong&gt;2009&lt;/strong&gt; and &lt;strong&gt;2014&lt;/strong&gt;,
   assuming that the transition probabilities for 5-year intervals are given
   by the matrix &lt;strong&gt;A&lt;/strong&gt; and remain practically the same over the time considered.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;div align="center"&gt;
      &lt;img src="images/transition_matix_A.png"&gt;
   &lt;/div&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;A_5&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;0.7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="n"&gt;A_10&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;A_5&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;A_5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;A_10&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;2004: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.55&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;2009: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;A_5&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.55&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;2014: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;A_10&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.55&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;

&lt;span class="mi"&gt;2004&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="mf"&gt;0.25&lt;/span&gt;  &lt;span class="mf"&gt;0.2&lt;/span&gt;   &lt;span class="mf"&gt;0.55&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="mi"&gt;2009&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="mf"&gt;0.195&lt;/span&gt;  &lt;span class="mf"&gt;0.34&lt;/span&gt;   &lt;span class="mf"&gt;0.465&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="mi"&gt;2014&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="mf"&gt;0.1705&lt;/span&gt;  &lt;span class="mf"&gt;0.438&lt;/span&gt;   &lt;span class="mf"&gt;0.3915&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Part 1.2&lt;/h3&gt;
&lt;p&gt;This following question uses the &lt;code&gt;iris&lt;/code&gt; dataset. Load the data in with the following code.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;
&lt;span class="c"&gt;# The 1st column is sepal length and the 2nd column is sepal width&lt;/span&gt;
&lt;span class="n"&gt;sepalLength_sepalWidth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_iris&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Make a scatter plot of sepal width vs sepal length&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compute the mean vector (column-wise) of the data matrix. The &lt;code&gt;shape&lt;/code&gt;
   of the mean vector should be &lt;code&gt;(1, 2)&lt;/code&gt; and plot it.&lt;/p&gt;
&lt;p&gt;%matplotlib inline
from sklearn import datasets
import matplotlib.pyplot as plt&lt;/p&gt;
&lt;p&gt;sepalLength_sepalWidth = datasets.load_iris().data[:, :2]
plt.plot(sepalLength_sepalWidth[:,0],sepalLength_sepalWidth[:,1],linewidth=0,marker='o',color='steelblue',alpha=0.25,label="Data")
plt.xlabel('Sepal Length')
plt.ylabel('Sepal Width')
plt.plot(sepalLength_sepalWidth[:,0].mean(),sepalLength_sepalWidth[:,1].mean(),'x',
         markeredgewidth=10,markersize=20,color='indianred',label='Mean',alpha=0.5)
print "Shape: ",sepalLength_sepalWidth.shape&lt;/p&gt;
&lt;p&gt;Shape:  (150, 2)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D1/output_5_1.png" /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Write a function (&lt;code&gt;euclidean_dist&lt;/code&gt;) to calculate the euclidean distance
   between two &lt;strong&gt;column vectors (not row vector)&lt;/strong&gt;. Your function should check
   if the vectors are column vectors and the shape of the two vectors are the same .&lt;/p&gt;
&lt;p&gt;def euclidean_dist(c1,c2):
    if c2.shape==c1.shape and c1.shape[1]==1:
        return np.sqrt(np.sum(np.power(c1-c2,2)))
    return None&lt;/p&gt;
&lt;p&gt;a = np.ones((10,1))
b = np.zeros((10,1))
euclidean_dist(a,b)==np.sqrt(10)&lt;/p&gt;
&lt;p&gt;True&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Write a function (&lt;code&gt;cosine_sim&lt;/code&gt;) to calculate the cosine similarity_between 
   two &lt;strong&gt;column vectors (not row vector)&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;def cosine_sim(c1,c2):
    if c2.shape==c1.shape and c1.shape[1]==1:
        result = c1.transpose().dot(c2)/(np.linalg.norm(c1)*np.linalg.norm(c2))
        return result[0,0]
    return None&lt;/p&gt;
&lt;p&gt;a = np.array([1,0]).reshape(2,1)
b = np.array([0,1]).reshape(2,1)
print cosine_sim(a,b)==0
a = np.array([1,0]).reshape(2,1)
b = np.array([1,1]).reshape(2,1)
print cosine_sim(a,b) == 1/np.sqrt(2)&lt;/p&gt;
&lt;p&gt;True
True&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Write a function that would loop through all the data points in a given matrix and 
   calculate the given distance metric between each of the data point and the mean
   vector. Use the function to compute Euclidean Distance and Cosine Similarity between each of
   the data points and the mean of the data points. You should be able to call the function
   in this manner:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Plot histograms of the euclidean distances and cosine similarities.&lt;/p&gt;
&lt;p&gt;def compute_dist(data,func):
    means = data.mean(axis=0).transpose().reshape(data.shape[1],1)
    dists = []
    for i in range(data.shape[0]):
        dists.append(func(data[i,:].reshape(data.shape[1],1),means))
    dists = np.array(dists)
    dists = dists.reshape(data.shape[0],1)
    return dists&lt;/p&gt;
&lt;p&gt;values = compute_dist(sepalLength_sepalWidth,euclidean_dist)
plt.hist(values[:,0],color='steelblue',alpha=0.5,edgecolor='black',linewidth=0.1)
plt.xlabel('Euclidean Distance From Mean')
plt.ylabel('Count')
plt.show()
values = compute_dist(sepalLength_sepalWidth,cosine_sim)
plt.hist(values[:,0],color='steelblue',alpha=0.5,linewidth=0.1)
plt.xlabel('Cosign Similarity From Mean')
plt.ylabel('Count')
plt.show()&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D1/output_11_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D1/output_11_1.png" /&gt;&lt;/p&gt;
&lt;h2&gt;Extra Credit: Implementing the PageRank Algorithm&lt;/h2&gt;
&lt;p&gt;The &lt;a href="http://en.wikipedia.org/wiki/PageRank"&gt;Page Rank Algorithm&lt;/a&gt; is used by Google
Search (in their early days) to rank websites in their search engine in terms 
of the importance of webpages. 
&lt;a href="http://books.google.com/books/p/princeton?id=5o_K4rri1CsC&amp;amp;printsec=frontcover&amp;amp;source=gbs_ViewAPI&amp;amp;hl=en#v=onepage&amp;amp;q&amp;amp;f=false"&gt;More about PageRank&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We will implement PageRank on this simple network of websites.&lt;/p&gt;
&lt;p&gt;&lt;div align="center"&gt;
    &lt;img src="images/pageweb.png"&gt;
   &lt;/div&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;In the above image:&lt;/strong&gt;
   - Each node is a web page
   - Each directed edge corresponds to one page referencing the other
   - These web pages correspond to the states our Markov chain can be in
   - Assume that the model of our chain is that of a random surfer/walker.&lt;/p&gt;
&lt;p&gt;In this model, we transition from one web page (state) to the next with
equal probability (to begin).  Or rather we randomly pick an outgoing edge
from our current state.  Before we can do any sort of calculation we need to
know how we will move on this Markov Chain.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;PR = np.array([[0,1,0,0,0],[0.5,0,0.5,0,0],[0.333333,0.333333,0,0,0.333333],[1.,0,0,0,0],[0,0.3333333,0.3333333,0.3333333,0]]).transpose()
PR




array([[ 0.       ,  0.5      ,  0.333333 ,  1.       ,  0.       ],
       [ 1.       ,  0.       ,  0.333333 ,  0.       ,  0.3333333],
       [ 0.       ,  0.5      ,  0.       ,  0.       ,  0.3333333],
       [ 0.       ,  0.       ,  0.       ,  0.       ,  0.3333333],
       [ 0.       ,  0.       ,  0.333333 ,  0.       ,  0.       ]])
&lt;/pre&gt;&lt;/div&gt;


&lt;ol&gt;
&lt;li&gt;Now that we have a transition matrix, the next step is to iterate on this
   from one page to the next (like someone blindly navigating the internet) and
   see where we end up. The probability distribution for our random surfer can
   be described in this matrix notation as well (or vector rather).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Initialize a vector for the probability of where our random surfer is.
   It will be a vector with length equal to the number of pages.
   Initialize it to be equally probable to start on any page
   (i.e. you start randomly in a state on the chain).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;start = np.array([0.2,0.2,0.2,0.2,0.2]).reshape(5,1)
start




array([[ 0.2],
       [ 0.2],
       [ 0.2],
       [ 0.2],
       [ 0.2]])
&lt;/pre&gt;&lt;/div&gt;


&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;To take a step on the chain, simply matrix multiple our user vector by the
   transition matrix.
   After one iteration, what is the most likely location for your random surfer?&lt;/p&gt;
&lt;p&gt;step1 = PR.dot(start)
step1&lt;/p&gt;
&lt;p&gt;array([[ 0.3666666 ],
       [ 0.33333326],
       [ 0.16666666],
       [ 0.06666666],
       [ 0.0666666 ]])&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Plot how the probabilities change.
   Iterate the matrix through the first ten steps.
   At each step create a bar plot of the surfers probability vector.&lt;/p&gt;
&lt;p&gt;steps = start.copy()
plt.figure(figsize=(15,8))
for i in range(10):
    steps = PR.dot(steps)
    ax = plt.subplot(2,5,i+1)
    plt.bar(np.arange(5),steps[:,0],color='steelblue',alpha=0.5,linewidth=0.1)
    ax.set_xticklabels (('A', 'B', 'C', 'D', 'E') )
    plt.title(str(i+1) + " Steps")
plt.show()
print "Final Distribution: ",steps&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D1/output_19_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Final Distribution:  [[ 0.29401788]
 [ 0.38811497]
 [ 0.22055748]
 [ 0.02429332]
 [ 0.07301416]]
&lt;/pre&gt;&lt;/div&gt;


&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;This time to compute the stationary distribution, we can use numpy's
   matrix operations. Using the function for calculating &lt;a href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.eig.html"&gt;eigenvectors&lt;/a&gt; compute the
   stationary distibution (page rank).  Is it the same as what you found
   from above?  What is it's eigenvalue?&lt;/p&gt;
&lt;p&gt;values,Vectors = np.linalg.eig(PR)
values&lt;/p&gt;
&lt;p&gt;array([ 0.99999977+0.j        , -0.64800046+0.27072373j,
       -0.64800046-0.27072373j,  0.14800058+0.30123034j,
        0.14800058-0.30123034j])&lt;/p&gt;
&lt;p&gt;solution = np.real(Vectors[:,0]/np.sum(Vectors[:,0]))
solution.reshape(5,1)&lt;/p&gt;
&lt;p&gt;array([[ 0.29268293],
       [ 0.39024392],
       [ 0.21951223],
       [ 0.02439023],
       [ 0.07317069]])&lt;/p&gt;
&lt;p&gt;import pandas as pd
df = pd.DataFrame(columns=["A","B","C","D","E"])
steps = start.copy()
for i in range(20):
    df.loc[i] = steps[:,0].transpose()
    steps = PR.dot(steps)&lt;/p&gt;
&lt;p&gt;df.plot()
plt.legend(bbox_to_anchor=(0.08,1),ncol=5, loc=3, borderaxespad=0.)
print "Final Distribution: "
steps&lt;/p&gt;
&lt;p&gt;Final Distribution: &lt;/p&gt;
&lt;p&gt;array([[ 0.29265924],
       [ 0.39030474],
       [ 0.21945581],
       [ 0.02438301],
       [ 0.07319274]])&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D1/output_23_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;We can see that the stationary state is found in 6 states.   The vector produced by this method matches the eigenvectors found by numpy linear algrebra library&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;PR.dot(steps)




array([[ 0.29268725],
       [ 0.39020868],
       [ 0.21954995],
       [ 0.02439758],
       [ 0.07315186]])
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Exploratory Data Analysis (EDA)&lt;/h2&gt;
&lt;p&gt;Exploratory data analysis is a first crucial step to building predictive models from your data. EDA allows you
to confirm or invalidate some of the assumptions you are making about your data and understand relationships between your variables.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;In this scenario, you are a data scientist at &lt;a href="http://www.bayareabikeshare.com/"&gt;Bay Area Bike Share&lt;/a&gt;. Your task
is to provide insights on bike user activity and behavior to the products team. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Load the file &lt;code&gt;data/201402_trip_data.csv&lt;/code&gt; into a dataframe.&lt;/p&gt;
&lt;p&gt;import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as scs
import statsmodels.api as sm
from pandas.tools.plotting import scatter_matrix
%matplotlib inline&lt;/p&gt;
&lt;p&gt;df = pd.read_csv('data/201402_trip_data.csv')&lt;/p&gt;
&lt;p&gt;df['start_date'] = pd.to_datetime(df.start_date)
df['end_date'] = pd.to_datetime(df.end_date)
df['month'] = df.start_date.dt.month
df['dayofweek'] = df.start_date.dt.dayofweek
df['date'] = df.start_date.dt.date
df['hour'] = df.start_date.dt.hour&lt;/p&gt;
&lt;p&gt;df.info()&lt;/p&gt;
&lt;p&gt;&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 144015 entries, 0 to 144014
Data columns (total 15 columns):
trip_id              144015 non-null int64
duration             144015 non-null int64
start_date           144015 non-null datetime64[ns]
start_station        144015 non-null object
start_terminal       144015 non-null int64
end_date             144015 non-null datetime64[ns]
end_station          144015 non-null object
end_terminal         144015 non-null int64
bike_#               144015 non-null int64
subscription_type    144015 non-null object
zip_code             137885 non-null object
month                144015 non-null int64
dayofweek            144015 non-null int64
date                 144015 non-null object
hour                 144015 non-null int64
dtypes: datetime64&lt;a href="2"&gt;ns&lt;/a&gt;, int64(8), object(5)
memory usage: 17.6+ MB&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Group the bike rides by &lt;code&gt;month&lt;/code&gt; and count the number of users per month. Plot the number of users for each month. 
   What do you observe? Provide a likely explanation to your observation. Real life data can often be messy/incomplete
   and cursory EDA is often able to reveal that.&lt;/p&gt;
&lt;p&gt;m = df.groupby('month')
a = m.trip_id.count().tolist()
a = a[2:]+a[:2]
fig,ax = plt.subplots()
plt.bar(range(7),a,color='steelblue',alpha=0.5)
ax.set_xticklabels(('Aug','Sep','Oct',"Nov","Dec",'Jan','Feb'))
plt.show()&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D1/output_30_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We see that we do not have data for the entire month of august, so it is not fair to evaluate it to the other months.  We see that there is a slowdown in december, and febuary has less days.   It might make more sense to look at the daily usage rates. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Plot the daily user count from September to December. Mark the &lt;code&gt;mean&lt;/code&gt; and &lt;code&gt;mean +/- 1.5 * Standard Deviation&lt;/code&gt; as 
   horizontal lines on the plot. This would help you identify the outliers in your data. Describe your observations. &lt;/p&gt;
&lt;p&gt;duc = df[df.month.isin([9, 10, 11, 12])].groupby('date')
counts = duc.trip_id.count().reset_index().set_index('date')
counts.columns = ['Count']
high = counts.mean()+1.5&lt;em&gt;counts.std()
low = counts.mean()-1.5&lt;/em&gt;counts.std()
counts.plot(color='steelblue',lw=2,alpha=.75)
plt.axhline(high.values,color='black',linestyle='--')
plt.axhline(low.values,color='black',linestyle='--')
plt.xticks(rotation=30)
plt.ylabel('Daily User Count')
plt.show()&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D1/output_33_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;The dashed black lines are the 'outlier' boundaries.   Though these are not the traditional definition of an outlire, we see points outside of these bounds.  The issues is that we have seasonal variation.  The low months pull down the average making high months look like possible outliers.   I do not believe we see any outlires in this data set, and won't believe it until I understand the cyclical nature of the data.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Plot the distribution of the daily user counts for all months as a histogram. Fit a 
   &lt;a href="http://glowingpython.blogspot.com/2012/08/kernel-density-estimation-with-scipy.html"&gt;KDE&lt;/a&gt; to the histogram.
   What is the distribution and explain why the distribution might be shaped as such. &lt;/p&gt;
&lt;p&gt;duc = df.groupby('date')
counts = duc.trip_id.count()
counts.hist(alpha=.5, linewidth=0, bins=20, normed=True)&lt;/p&gt;
&lt;p&gt;kde = scs.gaussian_kde(counts)
s = np.linspace(counts.min(), counts.max(), 100)
plt.plot(s, kde(s), color='indianred', lw=3)&lt;/p&gt;
&lt;p&gt;[&lt;matplotlib.lines.Line2D at 0x11123e610&gt;]&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D1/output_36_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;This looks like we could have two different contributers to daily user counts.   One that has a mean of around 1000, and another with a mean around 400.   The combination of the two sources could produce a double peaked distribution like this.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure(figsize=(14,8))
ax = plt.gca()
df[&amp;#39;weekend&amp;#39;] = df.dayofweek.isin([5,6])
duc_we = df[df[&amp;#39;weekend&amp;#39;]].groupby(&amp;#39;date&amp;#39;)
duc_wd = df[~df[&amp;#39;weekend&amp;#39;]].groupby(&amp;#39;date&amp;#39;)
counts_we = duc_we.trip_id.count().reset_index().set_index(&amp;#39;date&amp;#39;)
counts_wd = duc_wd.trip_id.count().reset_index().set_index(&amp;#39;date&amp;#39;)
counts_we.hist(alpha=.7, linewidth=0, bins=20, normed=True, color=&amp;#39;burlywood&amp;#39;,ax=ax)
counts_wd.hist(alpha=.7, linewidth=0, bins=20, normed=True, color=&amp;#39;seagreen&amp;#39;,ax=ax)

kde_we = scs.gaussian_kde(counts_we.values[:,0])
kde_wd = scs.gaussian_kde(counts_wd.values[:,0])
plt.plot(s, kde_we(s), color=&amp;#39;goldenrod&amp;#39;, lw=3, label=&amp;#39;Weekend&amp;#39;)
plt.plot(s, kde_wd(s), color=&amp;#39;forestgreen&amp;#39;, lw=3, label=&amp;#39;Weekday&amp;#39;)
plt.xlabel(&amp;#39;Number of Daily Users&amp;#39;)
plt.ylabel(&amp;#39;Probability Density&amp;#39;)
plt.title(&amp;#39;Weekend vs Weekday Daily User Count&amp;#39;)
plt.legend()
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D1/output_38_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We can see that from this distirbution that the weekend users seem to be around 400, and the weekday user counts seem to be peaked around 1000.  The combintation of the two distributions produces the initial histogram we looked at&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Now we are going to explore hourly trends of user activity. Group the bike rides by &lt;code&gt;date&lt;/code&gt; and &lt;code&gt;hour&lt;/code&gt; and count 
   the number of rides in the given hour on the given date. Make a 
   &lt;a href="http://blog.bharatbhole.com/creating-boxplots-with-matplotlib/"&gt;boxplot&lt;/a&gt; of the hours in the day &lt;strong&gt;(x)&lt;/strong&gt; against
   the number of users &lt;strong&gt;(y)&lt;/strong&gt; in that given hour. &lt;/p&gt;
&lt;p&gt;plt.figure(figsize=(14,8))
ax=plt.gca()
huc = df.groupby(['date','hour'])
huc_vals = huc.trip_id.count().unstack()
huc_vals.fillna(0.0,inplace=True)
huc_vals.plot(kind='box',ax=ax)
plt.xlabel('Hour of Day')
plt.ylabel('Hourly User Count')
plt.show()&lt;/p&gt;
&lt;p&gt;huc.trip_id.count().reset_index().boxplot('trip_id',by='hour')
plt.show()&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D1/output_41_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D1/output_41_1.png" /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Replot the boxplot from above after binning your data into weekday and weekend. Describe the differences you observe between hour user activity between weekday and weekend? &lt;/p&gt;
&lt;p&gt;plt.figure(figsize=(14,6))
ax=plt.subplot(1,2,1)
huc = df[df.weekend].groupby(['date','hour'])
huc_vals = huc.trip_id.count().unstack()
huc_vals.fillna(0.0,inplace=True)
huc_vals.plot(kind='box',ax=ax)
plt.xlabel('Hour of Day')
plt.ylabel('Weekend Hourly User Count')
plt.title('Weekend Hourly User Counts')&lt;/p&gt;
&lt;p&gt;ax=plt.subplot(1,2,2)
huc = df[~df.weekend].groupby(['date','hour'])
huc_vals = huc.trip_id.count().unstack()
huc_vals.fillna(0.0,inplace=True)
huc_vals.plot(kind='box',ax=ax)
plt.xlabel('Hour of Day')
plt.ylabel('Weekday Hourly User Count')
plt.title('Weekday Hourly User Counts')
plt.show()&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D1/output_43_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;Weekend users center in daylight hours and peak shortly after lunch.   Weekday users seem to be commuters, using the bikes before and after work hours, with a similar proportion of users using the bikes around lunchtime as weekend users.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;There are two types of bike users (specified by column &lt;code&gt;Subscription Type&lt;/code&gt;: &lt;code&gt;Subscriber&lt;/code&gt; and &lt;code&gt;Customer&lt;/code&gt;. Given this
   information and the weekend and weekday categorization, plot and inspect the user activity trends. Suppose the 
   product team wants to run a promotional campaign, what are you suggestions in terms of who the promotion should 
   apply to and when it should apply for the campaign to be effective?&lt;/p&gt;
&lt;p&gt;plt.figure(figsize=(14,12))
ax=plt.subplot(2,2,1)
huc = df[(df.weekend)&amp;amp;(df.subscription_type=='Customer')].groupby(['date','hour'])
huc_vals = huc.trip_id.count().unstack()
huc_vals.fillna(0.0,inplace=True)
huc_vals.plot(kind='box',ax=ax)
plt.xlabel('Hour of Day')
plt.ylabel('Weekend Hourly User Count')
plt.ylim([0,150])
plt.title('Customer Weekend Hourly User Counts')&lt;/p&gt;
&lt;p&gt;ax=plt.subplot(2,2,2)
huc = df[(~df.weekend)&amp;amp;(df.subscription_type=='Customer')].groupby(['date','hour'])
huc_vals = huc.trip_id.count().unstack()
huc_vals.fillna(0.0,inplace=True)
huc_vals.plot(kind='box',ax=ax)
plt.xlabel('Hour of Day')
plt.ylabel('Weekday Hourly User Count')
plt.ylim([0,150])
plt.title('Customer Weekday Hourly User Counts')&lt;/p&gt;
&lt;p&gt;ax=plt.subplot(2,2,3)
huc = df[(df.weekend)&amp;amp;(df.subscription_type=='Subscriber')].groupby(['date','hour'])
huc_vals = huc.trip_id.count().unstack()
huc_vals.fillna(0.0,inplace=True)
huc_vals.plot(kind='box',ax=ax)
plt.xlabel('Hour of Day')
plt.ylabel('Weekend Hourly User Count')
plt.ylim([0,150])
plt.title('Subscriber Weekend Hourly User Counts')&lt;/p&gt;
&lt;p&gt;ax=plt.subplot(2,2,4)
huc = df[(~df.weekend)&amp;amp;(df.subscription_type=='Subscriber')].groupby(['date','hour'])
huc_vals = huc.trip_id.count().unstack()
huc_vals.fillna(0.0,inplace=True)
huc_vals.plot(kind='box',ax=ax)
plt.xlabel('Hour of Day')
plt.ylabel('Weekday Hourly User Count')
plt.ylim([0,150])
plt.title('Subscriber Weekday Hourly User Counts')&lt;/p&gt;
&lt;p&gt;plt.show()&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D1/output_46_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;It seems that subscribers are mostly commuters, and responsible for the weekday double peek.  Because there seems to be a large number of bikes not be used on the weekends, or during lunch periods, a promotion targeting customers during non-peak times could help bring in more revenue.  &lt;/p&gt;
&lt;h2&gt;Linear Regression&lt;/h2&gt;
&lt;p&gt;Linear regression is an approach to modeling the relationship between a continuous dependent (&lt;strong&gt;y&lt;/strong&gt;) variable and 
one or more continuous independent (&lt;strong&gt;x&lt;/strong&gt;) variables. Here you will be introduced to fitting the model and interpreting
the results before we dive more into the details of linear regression tomorrow.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;We will be using the &lt;code&gt;prestige&lt;/code&gt; data in &lt;code&gt;statsmodels&lt;/code&gt;. &lt;code&gt;statsmodels&lt;/code&gt; is the de facto library for performing regression tasks in Python. Load the data with the follow code.&lt;/p&gt;
&lt;p&gt;import statsmodels.api as sm
prestige = sm.datasets.get_rdataset("Duncan", "car", cache=True).data
y = prestige['prestige']
x = prestige[['income', 'education']].astype(float)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;income&lt;/th&gt;
      &lt;th&gt;education&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;accountant&lt;/th&gt;
      &lt;td&gt;62&lt;/td&gt;
      &lt;td&gt;86&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;pilot&lt;/th&gt;
      &lt;td&gt;72&lt;/td&gt;
      &lt;td&gt;76&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;architect&lt;/th&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;92&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;author&lt;/th&gt;
      &lt;td&gt;55&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;chemist&lt;/th&gt;
      &lt;td&gt;64&lt;/td&gt;
      &lt;td&gt;86&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Explore the data by making a &lt;a href="http://pandas.pydata.org/pandas-docs/version/0.15.0/visualization.html#visualization-scatter-matrix"&gt;scatter_matrix&lt;/a&gt;
   and a &lt;a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.boxplot.html"&gt;boxplot&lt;/a&gt;
   to show the range of each of your variables.&lt;/p&gt;
&lt;p&gt;scatter_matrix(prestige[['prestige','income','education']], diagonal='kde', figsize=(10,10))
plt.show()&lt;/p&gt;
&lt;p&gt;prestige[['prestige','income','education']].boxplot()
plt.show()&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D1/output_51_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW03D1/output_51_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;It seems that the values have been normalized between 0 and 100.  It also looks that prestige is related to education and income, but so are income and education.   Since these values are not independant, we might see funny results in our fits.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The beta coefficients of a linear regression model can be calculated by solving the normal equation.
   Using numpy, write a function that solves the &lt;strong&gt;normal equation&lt;/strong&gt; (below).
   As input your function should take a matrix of features (&lt;strong&gt;x&lt;/strong&gt;) and
   a vector of target (&lt;strong&gt;y&lt;/strong&gt;). You should return a vector of beta coefficients 
   that represent the line of best fit which minimizes the residual. 
   Calculate  R&lt;sup&gt;2&lt;/sup&gt;. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;div align="center"&gt;
      &lt;img height="30" src="images/normal_equation.png"&gt;
   &lt;/div&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x = sm.add_constant(x)
x.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;const&lt;/th&gt;
      &lt;th&gt;income&lt;/th&gt;
      &lt;th&gt;education&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;accountant&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;62&lt;/td&gt;
      &lt;td&gt;86&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;pilot&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;72&lt;/td&gt;
      &lt;td&gt;76&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;architect&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;92&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;author&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;55&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;chemist&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;64&lt;/td&gt;
      &lt;td&gt;86&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;def solve_normal(matrix, vector):
    x = matrix.values
    y = vector.values
    return np.linalg.inv(x.transpose().dot(x)).dot(x.transpose()).dot(y)

betas = solve_normal(x,y)
print &amp;quot;Constant: &amp;quot;, betas[0]
print &amp;quot;Income: &amp;quot;, betas[1]
print &amp;quot;Education: &amp;quot;, betas[2]

Constant:  -6.0646629221
Income:  0.598732821529
Education:  0.545833909401



TSS = np.sum(np.power(y.values-y.values.mean(),2))
RSS = np.sum(np.power(y.values-np.dot(x.values,betas),2))
print &amp;quot;R-Squared: &amp;quot;, 1-RSS/TSS

R-Squared:  0.828173417254
&lt;/pre&gt;&lt;/div&gt;


&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Verify your results using statsmodels. Use the code below as a reference.&lt;/p&gt;
&lt;p&gt;import statsmodels.api as sm
model = sm.OLS(y, x).fit()
model.summary()&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;table class="simpletable"&gt;
&lt;caption&gt;OLS Regression Results&lt;/caption&gt;
&lt;tr&gt;
  &lt;th&gt;Dep. Variable:&lt;/th&gt;        &lt;td&gt;prestige&lt;/td&gt;     &lt;th&gt;  R-squared:         &lt;/th&gt; &lt;td&gt;   0.828&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Model:&lt;/th&gt;                   &lt;td&gt;OLS&lt;/td&gt;       &lt;th&gt;  Adj. R-squared:    &lt;/th&gt; &lt;td&gt;   0.820&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Method:&lt;/th&gt;             &lt;td&gt;Least Squares&lt;/td&gt;  &lt;th&gt;  F-statistic:       &lt;/th&gt; &lt;td&gt;   101.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Date:&lt;/th&gt;             &lt;td&gt;Tue, 16 Jun 2015&lt;/td&gt; &lt;th&gt;  Prob (F-statistic):&lt;/th&gt; &lt;td&gt;8.65e-17&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Time:&lt;/th&gt;                 &lt;td&gt;07:23:19&lt;/td&gt;     &lt;th&gt;  Log-Likelihood:    &lt;/th&gt; &lt;td&gt; -178.98&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;No. Observations:&lt;/th&gt;      &lt;td&gt;    45&lt;/td&gt;      &lt;th&gt;  AIC:               &lt;/th&gt; &lt;td&gt;   364.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Df Residuals:&lt;/th&gt;          &lt;td&gt;    42&lt;/td&gt;      &lt;th&gt;  BIC:               &lt;/th&gt; &lt;td&gt;   369.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Df Model:&lt;/th&gt;              &lt;td&gt;     2&lt;/td&gt;      &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;   
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Covariance Type:&lt;/th&gt;      &lt;td&gt;nonrobust&lt;/td&gt;    &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;   
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
      &lt;td&gt;&lt;/td&gt;         &lt;th&gt;coef&lt;/th&gt;     &lt;th&gt;std err&lt;/th&gt;      &lt;th&gt;t&lt;/th&gt;      &lt;th&gt;P&gt;|t|&lt;/th&gt; &lt;th&gt;[95.0% Conf. Int.]&lt;/th&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;const&lt;/th&gt;     &lt;td&gt;   -6.0647&lt;/td&gt; &lt;td&gt;    4.272&lt;/td&gt; &lt;td&gt;   -1.420&lt;/td&gt; &lt;td&gt; 0.163&lt;/td&gt; &lt;td&gt;  -14.686     2.556&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;income&lt;/th&gt;    &lt;td&gt;    0.5987&lt;/td&gt; &lt;td&gt;    0.120&lt;/td&gt; &lt;td&gt;    5.003&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;    0.357     0.840&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;education&lt;/th&gt; &lt;td&gt;    0.5458&lt;/td&gt; &lt;td&gt;    0.098&lt;/td&gt; &lt;td&gt;    5.555&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;    0.348     0.744&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
  &lt;th&gt;Omnibus:&lt;/th&gt;       &lt;td&gt; 1.279&lt;/td&gt; &lt;th&gt;  Durbin-Watson:     &lt;/th&gt; &lt;td&gt;   1.458&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Prob(Omnibus):&lt;/th&gt; &lt;td&gt; 0.528&lt;/td&gt; &lt;th&gt;  Jarque-Bera (JB):  &lt;/th&gt; &lt;td&gt;   0.520&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Skew:&lt;/th&gt;          &lt;td&gt; 0.155&lt;/td&gt; &lt;th&gt;  Prob(JB):          &lt;/th&gt; &lt;td&gt;   0.771&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Kurtosis:&lt;/th&gt;      &lt;td&gt; 3.426&lt;/td&gt; &lt;th&gt;  Cond. No.          &lt;/th&gt; &lt;td&gt;    163.&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;ol&gt;
&lt;li&gt;Interpret your result summary, focusing on the beta coefficents, p-values, F-statistic, and the R&lt;sup&gt;2&lt;/sup&gt;. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The results from the manual calculation match the values from statsmodels' OLS regression.   We have 82.8% of the varience is explained by the model.  The F-statistics, assuming independant variables, says our model does describe some of the behavior of the prestige.   The coefficients say that for every unit increase in income, we have a 0.5987 incraese in prestige, and for every unit increase in educaiton we have a 0.5458 increase in prestigue.  The issue with the model, highlighted by the p-value on the constant term, is that as educaiton increases, so does income.   They will increase together, somehow double increasing the prestigue.   We need a way to remove this co-linearity between income and educaiton&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x = np.random.rand(20,1)*10
y = 5*x+2+np.random.rand(20,1)*30
z = 2*x+4*y+2+np.random.rand(20,1)*40
ones = np.ones(20).reshape(20,1)

X = pd.DataFrame({&amp;#39;x&amp;#39;:x[:,0],&amp;#39;y&amp;#39;:y[:,0],&amp;#39;c&amp;#39;:ones[:,0]})
Y = pd.DataFrame({&amp;#39;z&amp;#39;:z[:,0]})
model = sm.OLS(Y, X).fit()
model.summary()
&lt;/pre&gt;&lt;/div&gt;


&lt;table class="simpletable"&gt;
&lt;caption&gt;OLS Regression Results&lt;/caption&gt;
&lt;tr&gt;
  &lt;th&gt;Dep. Variable:&lt;/th&gt;            &lt;td&gt;z&lt;/td&gt;        &lt;th&gt;  R-squared:         &lt;/th&gt; &lt;td&gt;   0.975&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Model:&lt;/th&gt;                   &lt;td&gt;OLS&lt;/td&gt;       &lt;th&gt;  Adj. R-squared:    &lt;/th&gt; &lt;td&gt;   0.972&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Method:&lt;/th&gt;             &lt;td&gt;Least Squares&lt;/td&gt;  &lt;th&gt;  F-statistic:       &lt;/th&gt; &lt;td&gt;   325.7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Date:&lt;/th&gt;             &lt;td&gt;Tue, 16 Jun 2015&lt;/td&gt; &lt;th&gt;  Prob (F-statistic):&lt;/th&gt; &lt;td&gt;2.79e-14&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Time:&lt;/th&gt;                 &lt;td&gt;07:40:32&lt;/td&gt;     &lt;th&gt;  Log-Likelihood:    &lt;/th&gt; &lt;td&gt; -78.012&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;No. Observations:&lt;/th&gt;      &lt;td&gt;    20&lt;/td&gt;      &lt;th&gt;  AIC:               &lt;/th&gt; &lt;td&gt;   162.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Df Residuals:&lt;/th&gt;          &lt;td&gt;    17&lt;/td&gt;      &lt;th&gt;  BIC:               &lt;/th&gt; &lt;td&gt;   165.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Df Model:&lt;/th&gt;              &lt;td&gt;     2&lt;/td&gt;      &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;   
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Covariance Type:&lt;/th&gt;      &lt;td&gt;nonrobust&lt;/td&gt;    &lt;th&gt;                     &lt;/th&gt;     &lt;td&gt; &lt;/td&gt;   
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
  &lt;td&gt;&lt;/td&gt;     &lt;th&gt;coef&lt;/th&gt;     &lt;th&gt;std err&lt;/th&gt;      &lt;th&gt;t&lt;/th&gt;      &lt;th&gt;P&gt;|t|&lt;/th&gt; &lt;th&gt;[95.0% Conf. Int.]&lt;/th&gt; 
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;c&lt;/th&gt; &lt;td&gt;   18.9688&lt;/td&gt; &lt;td&gt;    9.231&lt;/td&gt; &lt;td&gt;    2.055&lt;/td&gt; &lt;td&gt; 0.056&lt;/td&gt; &lt;td&gt;   -0.507    38.445&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;x&lt;/th&gt; &lt;td&gt;    2.2866&lt;/td&gt; &lt;td&gt;    2.065&lt;/td&gt; &lt;td&gt;    1.107&lt;/td&gt; &lt;td&gt; 0.284&lt;/td&gt; &lt;td&gt;   -2.071     6.644&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;y&lt;/th&gt; &lt;td&gt;    4.0274&lt;/td&gt; &lt;td&gt;    0.378&lt;/td&gt; &lt;td&gt;   10.667&lt;/td&gt; &lt;td&gt; 0.000&lt;/td&gt; &lt;td&gt;    3.231     4.824&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;table class="simpletable"&gt;
&lt;tr&gt;
  &lt;th&gt;Omnibus:&lt;/th&gt;       &lt;td&gt; 3.159&lt;/td&gt; &lt;th&gt;  Durbin-Watson:     &lt;/th&gt; &lt;td&gt;   1.527&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Prob(Omnibus):&lt;/th&gt; &lt;td&gt; 0.206&lt;/td&gt; &lt;th&gt;  Jarque-Bera (JB):  &lt;/th&gt; &lt;td&gt;   1.277&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Skew:&lt;/th&gt;          &lt;td&gt; 0.090&lt;/td&gt; &lt;th&gt;  Prob(JB):          &lt;/th&gt; &lt;td&gt;   0.528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;Kurtosis:&lt;/th&gt;      &lt;td&gt; 1.775&lt;/td&gt; &lt;th&gt;  Cond. No.          &lt;/th&gt; &lt;td&gt;    158.&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;We can see that if we take away the constant, removing a degree of freedom, the R-squared becomes larger.   I think this could be a sign that we have a covariance in the variables. &lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="EDA"></category><category term="Linear Algebra"></category></entry><entry><title>Galvanize - Week 02 - Day 5</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-02-05/" rel="alternate"></link><updated>2015-06-12T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-12:galvanize/galvanize-data-science-02-05/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 2 - Day 5&lt;/h2&gt;
&lt;p&gt;Our more quiz was a survey about our progress in the program.  The morning lecture was about the beta distribution, and its relation to A/B testing from a Bayesian perspective, and a brief introduction to the multi-arm bandit method.   &lt;/p&gt;
&lt;h2&gt;Individual Morning Sprint&lt;/h2&gt;
&lt;p&gt;This morning we had some simulated click through data for two different sites and attempted to answer question about the outcome of the two pages.  We want to find the probability of a click through on the two pages and be able to quantify how much better one site is over the other. }&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;scipy.stats&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sc&lt;/span&gt;
&lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;loadtxt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data/siteA.txt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;B&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;loadtxt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data/siteB.txt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Bayesian Analysis&lt;/h2&gt;
&lt;p&gt;We are going to start with a prior that the click through rate of both sites can be anything between 0 and 1.  This will look like the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x=np.arange(0,1.01,0.01)
y = sc.beta(a=1.,b=1.).pdf(x)

def plot_with_fill(x,y,label,color):
    lines = plt.plot(x,y,label=label,lw=2,color=color)
    plt.fill_between(x,0,y,alpha=0.2,color=color)
    plt.ylim([0,1.2*y.max()])
    plt.legend()


plot_with_fill(x,y,&amp;#39;Beta a=1,b=1&amp;#39;,&amp;#39;seagreen&amp;#39;)
plt.xlabel(&amp;quot;Probability of Click Through&amp;quot;)
plt.ylabel(&amp;quot;Probability Density&amp;quot;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_3_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;If we look at 1 value from the click through where the user does not click through, we update our believe:&lt;/p&gt;
&lt;p&gt;$$\mbox{Posterior} = \mbox{Prior} * \mbox{Likelihood}$$&lt;/p&gt;
&lt;p&gt;$$\mbox{Beta}(\alpha=1, \ \beta=2) = \mbox{Beta}(\alpha=1, \ \beta=1) \times (1 - p)$$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;b1,a1 = 1,0
y1 = sc.beta(a=1,b=1).pdf(x)
y2 = sc.beta(a=a1+1,b=b1+1).pdf(x)
plot_with_fill(x,y1,&amp;#39;Prior&amp;#39;,&amp;#39;seagreen&amp;#39;)
plot_with_fill(x,y2,&amp;#39;1 Views&amp;#39;,&amp;#39;lightsalmon&amp;#39;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_5_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;If we have 50 views, the equation would be:&lt;/p&gt;
&lt;p&gt;$$\mbox{Beta}(\alpha=1+n_{clicks}, \ \beta=1+n_{no clicks}) = \mbox{Beta}(\alpha=1, \ \beta=1) \times (1 - p)^{n_{no clicks}} \times p^{n_{clicks}}$$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;b50,a50 = np.bincount(A[:50].astype(int))
y1 = sc.beta(a=1,b=1).pdf(x)
y2 = sc.beta(a=a50+1,b=b50+1).pdf(x)
plot_with_fill(x,y1,&amp;#39;Prior&amp;#39;,&amp;#39;seagreen&amp;#39;)
plot_with_fill(x,y2,&amp;#39;50 Views&amp;#39;,&amp;#39;lightsalmon&amp;#39;)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_7_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We can imagine that we continue getting data, and our believe about the click through rate would evolve:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x=np.arange(0,1.001,0.001)
plt.figure(figsize=(15,10))
y1 = sc.beta(a=1.,b=1.).pdf(x)
plot_with_fill(x,y1,&amp;#39;Prior&amp;#39;,&amp;#39;seagreen&amp;#39;)
color_s = {&amp;#39;50&amp;#39;:&amp;#39;lightsalmon&amp;#39;,&amp;#39;100&amp;#39;:&amp;#39;aquamarine&amp;#39;,&amp;#39;200&amp;#39;:&amp;#39;turquoise&amp;#39;,&amp;#39;400&amp;#39;:&amp;#39;NavajoWhite&amp;#39;,&amp;#39;800&amp;#39;:&amp;#39;forestgreen&amp;#39;}
for count in [50,100,200,400,800]:
    bc,ac = np.bincount(A[:count].astype(int))
    y = sc.beta(a=ac,b=bc).pdf(x)
    plot_with_fill(x,y,str(count)+&amp;#39; Views&amp;#39;,color_s[str(count)])
plt.xlim([0,.2])




(0, 0.2)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_9_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;We can see that as we increase the amount of data we have, we have a more specific believe about the click through rate of site A.  &lt;strong&gt;This is different from a hypthesis test.  It does not required a fix sample size or fixed amount of time&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;We can look at the two sites for all the data.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x=np.arange(0,1.001,0.001)
plt.figure(figsize=(15,10))
bA,aA = np.bincount(A.astype(int))
bB,aB = np.bincount(B.astype(int))
y1 = sc.beta(a=float(aA),b=float(bA)).pdf(x)
y2 = sc.beta(a=float(aB),b=float(bB)).pdf(x)
plot_with_fill(x,y1,&amp;#39;A Site&amp;#39;,&amp;#39;seagreen&amp;#39;)
plot_with_fill(x,y2,&amp;#39;B Site&amp;#39;,&amp;#39;aquamarine&amp;#39;)
plt.xlim([0,.2])
plt.ylim([0,50])
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_11_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We now want to determine, given these distributions, what is the probability that site B is better than site A.  We can take random variables from both distributions and count the number of times that the random value from B is greater than the random variable from A.   We can do this 10,000 times.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;rA = sc.beta(a=aA,b=bA).rvs(size=10000)
rB = sc.beta(a=aB,b=bB).rvs(size=10000)
nLess,nMore = np.bincount((rA&amp;lt;rB).astype(int))

plt.figure()
ps = []
for i in range(1000):
    rA = sc.beta(a=aA,b=bA).rvs(size=10000)
    rB = sc.beta(a=aB,b=bB).rvs(size=10000)
    nLess,nMore = np.bincount((rA&amp;lt;rB).astype(int))
    ps.append(nMore/10000.)

plt.hist(ps,bins=15,color=&amp;#39;aquamarine&amp;#39;,alpha=0.5)
plt.show()
print &amp;quot;Mean Prob: &amp;quot;, nMore/10000.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_13_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Mean Prob:  0.9971
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Based on our current belief based on the data, the chance that sight B is better than site A is 99.7%.  &lt;/p&gt;
&lt;p&gt;We can also estimate the Bayesian equivalant of a confidence interval.&lt;/p&gt;
&lt;p&gt;This is the centeral credible region - range of the 2.5 precentile and the 97.5 percentile:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;rA = sc.beta(a=aA,b=bA).rvs(size=10000)
HDI_A = (np.percentile(rA,2.5),np.percentile(rA,97.5))
rB = sc.beta(a=aB,b=bB).rvs(size=10000)
HDI_B = (np.percentile(rB,2.5),np.percentile(rB,97.5))
print &amp;quot;Site A: &amp;quot;, HDI_A
print &amp;quot;Site B: &amp;quot;, HDI_B

Site A:  (0.05002097381711422, 0.084804921163330979)
Site B:  (0.082330727908278764, 0.12425696702783418)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;An 95% highest density interval (HDI) is the most dense interval of a posterior distribution containing X% of its mass. It is analagous to frequentist analysis's confidence intervals.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def hdi_beta(data,percent=0.95):
    bD,aD = np.bincount(data.astype(int))
    x_max = sc.beta(a=aD,b=bD).ppf(1 - percent - 1e-6)
    x_high_max = sc.beta(a=aD,b=bD).ppf(percent - 1e-6)
    vals = np.linspace(0,x_max,1000)
    p_vals = 0.95+sc.beta(a=aD,b=bD).cdf(vals)
    x_high = sc.beta(a=aD,b=bD).ppf(p_vals)
    width = x_high-vals
    low = vals[np.argmin(width)]
    high = low+width.min()
    return (low,high)

print &amp;quot;HDI A:&amp;quot;, hdi_beta(A)
print &amp;quot;HDI B:&amp;quot;, hdi_beta(B)


HDI A: (0.049391799061910255, 0.083668677250890555)
HDI B: (0.081861282294831139, 0.12374716027178045)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;These HDI are close to the central credibility region, but they are systematically lower.&lt;/p&gt;
&lt;p&gt;What is nicse about Baysina inference is we can ask what is the probability that site B is 2 percentage points better than A.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;nLess2,nMore2 = np.bincount((rB&amp;gt;(rA+0.02)).astype(int))
print &amp;quot;Probabilty B &amp;gt; A + 0.02:  &amp;quot;, nMore2/10000.

plt.figure()
plt.hist((rB-rA),bins=30,color=&amp;#39;steelblue&amp;#39;,alpha=0.4)
plt.show()

Probabilty B &amp;gt; A + 0.02:   0.881
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_19_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;In this case we can see that the difference is near zero (really 0.02), but is likely to be higher.   The probabiliy given by the simulation is 88.1%. &lt;/p&gt;
&lt;p&gt;For a sanity check we can do a hypothesis test.  We would perform a 1 sided Hypthesiss test:&lt;/p&gt;
&lt;p&gt;H0: The mean clickthrough rate is the same.&lt;br /&gt;
HA: The mean clicktrhough rate for site B is greater than site A.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;mDiff = rB.mean()-rA.mean()
se = np.sqrt(rB.var()/(len(rB)-1)+rA.var()/(len(rA)-1))
Z = mDiff/se
print mDiff,se,Z
print &amp;quot;p-value: &amp;quot;,1-sc.norm.cdf(Z)
print &amp;quot;The mean difference is statistically significant&amp;quot;


0.0363429336139 0.000138288570828 262.805041634
p-value:  0.0
The mean difference is statistically significant
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We are now told that there is a business model for this website, and it should inform our decision to implement the new site:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;* the average click on site A yields $1.00 in profit
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;the average click on site B yields $1.05 in profit  &lt;/p&gt;
&lt;p&gt;gain_per_click = (rB.sum()*1.05-rA.sum())/10000.
gain_per_click&lt;/p&gt;
&lt;p&gt;0.041471285947814275&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is an average gain of 4 cents per click increase in revenume.  Roughly 3 cents from the increase in click through rate and 1.4 cent from the increase in yield.  &lt;/p&gt;
&lt;p&gt;We are not told over what time the experiment we analysed took place over.  A site with 10 Million users per month will see an increase revenue of 400,000 dollars per month, while a site of 10,000 users per month will only see an increase of of 400 dollars per month.  The business decision of investing money and time depends on the context.  This could be a great boom for the company, or a waste of time, depending on the situation.  &lt;/p&gt;
&lt;h2&gt;Multi-arm Bandit&lt;/h2&gt;
&lt;p&gt;The multi-arm bandit approach is a method of balancing the exploration of strategies against the explortation of the best strategy.  We impleted a multi-arm bandit class with a number of strategies:  Random Choice, Max Mean, Epsilon Greedy, Soft Max, UCB1, Bayesian, and Annealing.  &lt;/p&gt;
&lt;p&gt;We have two ways to measure the success of a search strategy for now.  The regret:&lt;/p&gt;
&lt;p&gt;$$\mbox{Regret} = N \ p_{optimal} - \Sigma_{i=1}^{N} p_{i} $$&lt;/p&gt;
&lt;p&gt;And the ratio of optimal decision:&lt;/p&gt;
&lt;p&gt;$$ \frac{N_{optimal}}{N}$$&lt;/p&gt;
&lt;p&gt;The bandit class takes an array of deciion options where each value is the probability of success.  The spirit of this is examining multiple metrics at the same time: like conversion rates across multiple simulatenous tests.&lt;/p&gt;
&lt;h2&gt;Max Mean&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bandits&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Bandits&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;banditstrategy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;scipy.stats&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sc&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;prettyplotlib&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;ppl&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;bandits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Bandits&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.03&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.06&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;strat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BanditStrategy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bandits&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_choice&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;strat&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample_bandits&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ppl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;strat&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;strat&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;regrets&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Random Choice&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;steelblue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;bandits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Bandits&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.03&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.06&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;strat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BanditStrategy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bandits&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_mean&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;strat&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample_bandits&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ppl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;strat&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;strat&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;regrets&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Max Mean&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;indianred&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_26_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;The max mean, on average, performs better than a random choice.  The issue with max mean is that its very exploitive.   When there is a statisitcal fluxtuation in makes it look like a worse option is the best option, it will stick with it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure(figsize=(14,10))
for i in range(10):
    bandits = Bandits([0.05, 0.03, 0.06])
    strat = BanditStrategy(bandits, random_choice)
    strat.sample_bandits(1000)
    ppl.plot(range(strat.N),strat.percentOpt,label=&amp;#39;Random Choice&amp;#39;,color=&amp;#39;steelblue&amp;#39;,alpha=0.4,lw=3)

    bandits = Bandits([0.05, 0.03, 0.06])
    strat = BanditStrategy(bandits, max_mean)
    strat.sample_bandits(1000)
    ppl.plot(range(strat.N),strat.percentOpt,label=&amp;#39;Max Mean&amp;#39;+str(i),alpha=0.4,color=&amp;#39;indianred&amp;#39;,lw=3)

plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_28_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;This is best illustrated if we look at the percent of the time that the optimal solution is chosen.   The max-mean strategy will often find one value and stay with it.&lt;/p&gt;
&lt;p&gt;We can explore this method on three different array options:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&amp;#39;&amp;#39;&amp;#39;
One Stand Out Best = [0.1, 0.1, 0.1, 0.1, 0.9]
One Small Best = [0.1, 0.1, 0.1, 0.1, 0.12]
A clear rank = [0.1, 0.2, 0.3, 0.4, 0.5]
&amp;#39;&amp;#39;&amp;#39;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Lets look at one &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def make_multi_plots(size,func):
    values = [[0.1, 0.1, 0.1, 0.1, 0.9],[0.1, 0.1, 0.1, 0.1, 0.12],[0.1, 0.2, 0.3, 0.4, 0.5]]
    titles = [&amp;#39;One Stand Out Best&amp;#39;,&amp;#39;One Slightly Best&amp;#39;, &amp;quot;A clear rank&amp;quot;]
    for v,t in zip(values,titles): 
        plt.figure(figsize=(14,5))
        plt.subplot(1,2,1)
        for i in range(10):
            bandits = Bandits(v[:])
            strat = BanditStrategy(bandits, random_choice)
            strat.sample_bandits(size)
            ppl.plot(range(strat.N),strat.regrets,label=&amp;#39;Random Choice&amp;#39;,color=&amp;#39;steelblue&amp;#39;,alpha=0.4,lw=3)

            bandits = Bandits(v[:])
            strat = BanditStrategy(bandits, func)
            strat.sample_bandits(size)
            ppl.plot(range(strat.N),strat.regrets,label=&amp;#39;Max Mean&amp;#39;+str(i),alpha=0.4,color=&amp;#39;indianred&amp;#39;,lw=3)
        plt.title(&amp;#39;Regret - &amp;#39; + t)

        plt.subplot(1,2,2)
        for i in range(10):
            bandits = Bandits(v[:])
            strat = BanditStrategy(bandits, random_choice)
            strat.sample_bandits(size)
            ppl.plot(range(strat.N),strat.percentOpt,label=&amp;#39;Random Choice&amp;#39;,color=&amp;#39;steelblue&amp;#39;,alpha=0.4,lw=3)

            bandits = Bandits(v[:])
            strat = BanditStrategy(bandits, func)
            strat.sample_bandits(size)
            ppl.plot(range(strat.N),strat.percentOpt,label=&amp;#39;Max Mean&amp;#39;+str(i),alpha=0.4,color=&amp;#39;indianred&amp;#39;,lw=3)
        plt.title(&amp;#39;Percent Optimal - &amp;#39; + t)
        plt.show()

make_multi_plots(1000,max_mean)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_30_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_30_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_30_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;The Max-Mean appear to work well in cases where there is a single clear best option, but does not consistently find optimal results in the other options.&lt;/p&gt;
&lt;h2&gt;Epsilon Greedy&lt;/h2&gt;
&lt;p&gt;The epsilon greed strategy is a alternative to the max mean where some fraction of the time, say 10%, it will explore instead of exploit.   Well look at it for the same cases as the max mean method.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;make_multi_plots(1000,epsilon_greedy)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_32_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_32_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_32_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;This strategy has the benefit that if it does start to exploit a sub-optimal strategy, it will eventually find its way out.   This is clear in the "Slightly Best" plots where as the number of trials increase, bandits are leaving the sub-optimal strategy.  &lt;/p&gt;
&lt;h2&gt;Softmax&lt;/h2&gt;
&lt;p&gt;The soft max is another strategy that balances exploitation vs exploration by use of a parameter.   It has an anology to temperature is method of statistical mechanics.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;func = lambda x: softmax(x,tau=0.5)
make_multi_plots(1000,func)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_34_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_34_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_34_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;The tau parameter of 0.5, in this example, seems to provide random solutions.   If we reduce the size of tau to 0.005, we should get solutions close to max mean.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;func = lambda x: softmax(x,tau=0.005)
make_multi_plots(1000,func)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_36_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_36_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_36_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;Inbetween, the soft max is to reduce the initial effect of outliers, but on these arrays we get less then optimal soltuions.&lt;/p&gt;
&lt;h2&gt;UCB1&lt;/h2&gt;
&lt;p&gt;The UCB1 picks the strategy based on the number of trials and its success rate.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;make_multi_plots(1000,ucb1)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_38_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_38_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_38_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;This method worked great on one standout best, but behaved randomly on the other options&lt;/p&gt;
&lt;h2&gt;Bayesian Bandit&lt;/h2&gt;
&lt;p&gt;This method uses the ration of success and failures in a trial to pick options based on the beta distribution.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;make_multi_plots(1000,bayesian_bandit)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_40_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_40_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_40_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;This method wored well on a clear best and eventually found the optimal solution for a ranked system.  The slight best behaved randomly.&lt;/p&gt;
&lt;h2&gt;Annealing&lt;/h2&gt;
&lt;p&gt;This method is working with a softmax that starts with a 'hot' system that explores randomly and cools to a 'cold' system that exploits.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;func = lambda x:annealing(x,discount=0.90,tau=0.5)
make_multi_plots(1000,annealing)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_42_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_42_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_42_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;We can see evidence of the cooling because the random values are starting to move away from random, but we would need to see more trials to see the evenatual discovery of optimal solutions.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;color_scheme = [(227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),(188, 189, 34),(23, 190, 207)] # (219, 219, 141)]#, (]
color_scheme = [ (x/255.,y/255.,z/255.) for x,y,z in color_scheme]

func1 = lambda x: softmax(x,tau=0.5)
strategies = [max_mean,random_choice,epsilon_greedy,func1,ucb1,bayesian_bandit]

size=10000
values = [[0.1, 0.1, 0.1, 0.1, 0.9],[0.1, 0.1, 0.1, 0.1, 0.12],[0.1, 0.2, 0.3, 0.4, 0.5]]
titles = [&amp;#39;One Stand Out Best&amp;#39;,&amp;#39;One Slightly Best&amp;#39;, &amp;quot;A clear rank&amp;quot;]
for v,t in zip(values,titles): 
    plt.figure(figsize=(14,5))
    for color,func in zip(color_scheme,strategies):
        plt.subplot(1,2,1)
        bandits = Bandits(v[:])
        strat = BanditStrategy(bandits, func)
        strat.sample_bandits(size)
        ppl.plot(range(strat.N),strat.regrets,label=func.__name__,alpha=1,color=color,lw=4)
        plt.title(&amp;#39;Regret - &amp;#39; + t)
        plt.legend(loc=2)


        plt.subplot(1,2,2)
        bandits = Bandits(v[:])
        strat = BanditStrategy(bandits, func)
        strat.sample_bandits(size)
        ppl.plot(range(strat.N),strat.percentOpt,label=func.__name__,alpha=1,color=color,lw=4)
        plt.title(&amp;#39;Percent Optimal - &amp;#39; + t)

    plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_44_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_44_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D5/output_44_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;It seems that the epsilon greed strategy and bayesian bandit algorithms have the best overall performance and avoid getting stuck in non-optimal solutions.   The soft max and annealing both require turning, so they are not fairly compared.   It is nice to see that both epsilon greed and bayesian bandit solutions offer easy to implment and robust use.  &lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="ab testing"></category><category term="multi-arm bandit"></category></entry><entry><title>Galvanize - Week 02 - Day 4</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-02-04/" rel="alternate"></link><updated>2015-06-11T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-11:galvanize/galvanize-data-science-02-04/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 2 - Day 4&lt;/h2&gt;
&lt;p&gt;Our morning quiz was fun.  It was the first time that we built off a prevous quiz.  We were required to build a random variable class that used our probability mass function from the day before.   The end result was being able to simulate a random value from any distrubiton able to be defined by a PMF.  &lt;/p&gt;
&lt;p&gt;Our morning lecture was about power and sample size, as was our individual sprint.  The afternoon lecture was on Bayesian Inference, and the afternoon paired sprint was investigating evolving likelihood functions as we gained more information/data.  &lt;/p&gt;
&lt;h2&gt;Power&lt;/h2&gt;
&lt;p&gt;-Suppose you are interested in testing if on average a bottle of coke weighs 20.4 ounces. You have collected
simple random samples of 130 bottles of coke and weighed them.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;scipy.stats&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sc&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;__future__&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;division&lt;/span&gt;

&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;loadtxt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data/coke_weights.txt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;




&lt;span class="mi"&gt;130&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;State your null and alternative hypothesis.&lt;/p&gt;
&lt;p&gt;1.&lt;strong&gt;H0: The mean weight of coke bottles is 20.4 oz&lt;/strong&gt;&lt;br /&gt;
2.&lt;strong&gt;HA: The mean weight of coke bottles is different form 20.4 oz&lt;/strong&gt;     &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compute the mean and standard error of the sample. State why you are able to apply the Central
   Limit Theorem here to approximate the sample distribution to be normal.&lt;/p&gt;
&lt;p&gt;mean = data.mean()
std = data.std()
se = sc.sem(data)
print "Sample Mean: ", mean
print "Sample STD", std
print "Sample Standard Error",se
print "Sample Size: ", len(data)&lt;/p&gt;
&lt;p&gt;Sample Mean:  20.519861441
Sample STD 0.957682215104
Sample Standard Error 0.084319217426
Sample Size:  130&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;We can use the CLT on this problem because the sample size is 130, much greater than 30.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We can make a simulation of the sampling distribution of the null hypthosis, and we can make a sampling distirubiton for another believe, say the true value is the sample man.   If this is true, we can ask questions about how powerful our test is at discovering the mean coke bottle weight is not 20.4, but 20.52.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def power_graph(mu1,std1,n1,mu2,std2,n2,alpha=0.05,two_sided=True):
    x = np.array([sc.norm.rvs(loc=mu1,scale=std1,size=n1).mean() for i in range(10000)])
    y = np.array([sc.norm.rvs(loc=mu2,scale=std2,size=n2).mean() for i in range(10000)])
    plt.figure()
    plt.hist(x,normed=True,color=&amp;#39;lightseagreen&amp;#39;,edgecolor=&amp;#39;lightseagreen&amp;#39;,alpha=0.4,bins=30,label=&amp;quot;Null&amp;quot;)
    plt.hist(y,normed=True,color=&amp;#39;lightsalmon&amp;#39;,edgecolor=&amp;#39;lightsalmon&amp;#39;,alpha=0.4,bins=30,label=&amp;quot;W=20.52&amp;quot;)
    if two_sided:
        x95 = np.percentile(x,100-100*alpha/2.)
    else:
        x95 = np.percentile(x,100-100*alpha)

    plt.axvline(x95,0,10,color=&amp;#39;gray&amp;#39;,lw=2,linestyle=&amp;#39;--&amp;#39;,alpha=0.8)
    plt.legend()
    plt.show()
    print &amp;quot;Value Threshold For Significance: &amp;quot;, x95
    power = len(y[y&amp;gt;x95])/len(y)
    print &amp;quot;Power of Finding True Positive: &amp;quot;,power
    return power

power_graph(20.4,data.std(),130,data.mean(),data.std(),130)
power_graph(20.4,data.std(),130,data.mean(),data.std(),130,two_sided=False)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_6_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Value Threshold For Significance:  20.5657024198
Power of Finding True Positive:  0.2899
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_6_2.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Value Threshold For Significance:  20.5387014434
Power of Finding True Positive:  0.4037





0.4037
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;These powers are 30% for the two sided, and 42% for the onsided.   It deends if our originaly hypothesis test is a not equal or greater than.   &lt;/p&gt;
&lt;p&gt;We can also do this analytically since we are using the centeral limit.  For a two sided test, we find the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x = np.linspace(20.4-4*se,20.4+4*se,100)

y1 = sc.norm.pdf(x,loc=20.4,scale=se)
cumy1 = sc.norm.cdf(x,loc=20.4,scale=se)
y2 = sc.norm.pdf(x,loc=data.mean(),scale=se)
x975 = 20.4+1.96*se
x025 = 20.4-1.95*se
print x025,x975
plt.plot(x,y1,color=&amp;#39;indianred&amp;#39;,label=&amp;#39;Null Hypthesis&amp;#39;)
plt.plot(x,y2,color=&amp;#39;steelblue&amp;#39;,label=&amp;#39;Data&amp;#39;)
plt.fill_between(x[x&amp;gt;=x975],y2[x&amp;gt;=x975],color=&amp;#39;steelblue&amp;#39;,alpha=0.4)
plt.fill_between(x[x&amp;gt;=x975],y1[x&amp;gt;=x975],color=&amp;#39;indianred&amp;#39;,alpha=0.4)
plt.fill_between(x[x&amp;lt;=x025],y1[x&amp;lt;=x025],color=&amp;#39;indianred&amp;#39;,alpha=0.4)
plt.axvline(x975,0,10,color=&amp;#39;black&amp;#39;,lw=3,linestyle=&amp;#39;--&amp;#39;)
plt.axvline(x025,0,10,color=&amp;#39;black&amp;#39;,lw=3,linestyle=&amp;#39;--&amp;#39;)
plt.show()

20.235577526 20.5652656662
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_8_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We can see that we would not reject the null hypothesis in favor of the alternative because the peak of the blue curve is to the left of the bounding of significance.  The area under the red cuver outside of the black boundaries is 0.05, the signifcance level.   The power of detecing a signficant difference assuming the data's mean is the true value is the blue area.   In this case it is ~ 30%&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The probability of making a type II error (false negative) is called beta.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;beta = sc.norm.cdf(x975,loc=data.mean(),scale=se)-sc.norm.cdf(x025,loc=data.mean(),scale=se)
print &amp;quot;Beta (Prob of Type II Error) Assuming data value is the true value&amp;quot;, beta

Beta (Prob of Type II Error) Assuming data value is the true value 0.704503425135
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The power is always 1 minus the false negative rate:&lt;/p&gt;
&lt;p&gt;$$\mbox{Power} = 1 - \beta$$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;print &amp;quot;Power: &amp;quot;,1-beta

Power:  0.295496574865
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Statistical power is affected by a number of factors, including the &lt;strong&gt;sample size&lt;/strong&gt;, the &lt;strong&gt;effect size (difference
between the sample statistic and the statistic formulated under the null)&lt;/strong&gt;, and the &lt;strong&gt;significance level&lt;/strong&gt;. Here
we are going to explore the effect of these factors on power.&lt;/p&gt;
&lt;p&gt;If we assuming that we have a different null hypothesis, we can find the power of detecting anther effect size.  Lets stick with the sample data&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def explore_power(null_mu,sample_size,effect_size,null_standard_dev,significance_level=0.95,two_sided=True):
    if two_sided:
        critical_z = sc.norm.isf((1-significance_level)/2.)
        se = np.sqrt(null_standard_dev**2/(sample_size-1))
        x025 = null_mu-critical_z*se
        x975 = null_mu+critical_z*se
        alt_mean = null_mu+effect_size
        return (1-np.abs(sc.norm.cdf(x975,loc=alt_mean,scale=se)-sc.norm.cdf(x025,loc=alt_mean,scale=se)))*100
    else:
        critical_z = sc.norm.isf(significance_level)
        se = np.sqrt(null_standard_dev**2/(sample_size-1))
        x95 = null_mu-critical_z*se
        alt_mean = null_mu+effect_size
        return 100*(np.abs(sc.norm.cdf(x95,loc=alt_mean,scale=se)))

print explore_power(20.4,130,data.mean()-20.4,data.std())
explore_power(20.2,130,data.mean()-20.2,data.std())

29.5495708063





96.663546292685481
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The power increased when we assumed the distributions were more different.  This makes sense because the two values are father appart, and the sampling distributions have less overlap.  We can see that by calling power_graph, or calling the analyical functions because we have access to the central limit theorem.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;power_graph(20.2,data.std(),130,data.mean(),data.std(),130)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_17_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Value Threshold For Significance:  20.364830609
Power of Finding True Positive:  0.9698





0.9698




x = np.linspace(20.2-5*se,20.2+6*se,100)

y1 = sc.norm.pdf(x,loc=20.2,scale=se)
cumy1 = sc.norm.cdf(x,loc=20.2,scale=se)
y2 = sc.norm.pdf(x,loc=data.mean(),scale=se)
x975 = 20.2+1.96*se
x025 = 20.2-1.95*se
plt.plot(x,y1,color=&amp;#39;indianred&amp;#39;,label=&amp;#39;Null Hypthesis&amp;#39;)
plt.plot(x,y2,color=&amp;#39;steelblue&amp;#39;,label=&amp;#39;Data&amp;#39;)
plt.axvline(x975,0,10,color=&amp;#39;black&amp;#39;,lw=3,linestyle=&amp;#39;--&amp;#39;)
plt.axvline(x025,0,10,color=&amp;#39;black&amp;#39;,lw=3,linestyle=&amp;#39;--&amp;#39;)
plt.fill_between(x[x&amp;gt;=x975],y2[x&amp;gt;=x975],color=&amp;#39;steelblue&amp;#39;,alpha=0.4)
plt.fill_between(x[x&amp;gt;=x975],y1[x&amp;gt;=x975],color=&amp;#39;indianred&amp;#39;,alpha=0.4)
plt.fill_between(x[x&amp;lt;=x025],y1[x&amp;lt;=x025],color=&amp;#39;indianred&amp;#39;,alpha=0.4)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_18_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;This makes me wonder how the power changes with the effect size.  I image that bigger effects are easier to detect.  It makes good sense&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.plot(np.linspace(0.1,1.2,20),[explore_power(20.2,130,x,data.std()) for x in np.linspace(0.0,1.2,20)],&amp;#39;bo--&amp;#39;,
        color=&amp;#39;lightseagreen&amp;#39;,alpha=0.8,label=&amp;quot;Power&amp;quot;)
plt.ylim([0,110])
plt.xlabel(&amp;quot;Effect Size&amp;quot;)
plt.ylabel(&amp;quot;Power&amp;quot;)
plt.legend(loc=4)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_20_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;The power of a study also depends on the sample size.  As the sample size increases, the standard error decreases by the central limit theorem.   This will make two different distributions overlap less. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;power_graph(20.4,data.std(),130,data.mean(),data.std(),130)
power_graph(20.4,data.std(),1000,data.mean(),data.std(),1000)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_22_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Value Threshold For Significance:  20.5657528314
Power of Finding True Positive:  0.2857
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_22_2.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Value Threshold For Significance:  20.4590858498
Power of Finding True Positive:  0.9802





0.9802




data2 = np.loadtxt(&amp;#39;data/coke_weights_1000.txt&amp;#39;)
mean = data2.mean()
std = data2.std()
se = sc.sem(data2)
x = np.linspace(20.4-5*se,20.4+6*se,100)

y1 = sc.norm.pdf(x,loc=20.4,scale=se)
cumy1 = sc.norm.cdf(x,loc=20.4,scale=se)
y2 = sc.norm.pdf(x,loc=data2.mean(),scale=se)
x975 = 20.4+1.96*se
x025 = 20.4-1.95*se

plt.plot(x,y1,color=&amp;#39;indianred&amp;#39;,label=&amp;#39;Null Hypthesis&amp;#39;)
plt.plot(x,y2,color=&amp;#39;steelblue&amp;#39;,label=&amp;#39;Data&amp;#39;)
plt.axvline(x975,0,10,color=&amp;#39;black&amp;#39;,lw=3,linestyle=&amp;#39;--&amp;#39;)
plt.axvline(x025,0,10,color=&amp;#39;black&amp;#39;,lw=3,linestyle=&amp;#39;--&amp;#39;)
plt.fill_between(x[x&amp;gt;=x975],y2[x&amp;gt;=x975],color=&amp;#39;steelblue&amp;#39;,alpha=0.4)
plt.fill_between(x[x&amp;gt;=x975],y1[x&amp;gt;=x975],color=&amp;#39;indianred&amp;#39;,alpha=0.4)
plt.fill_between(x[x&amp;lt;=x025],y1[x&amp;lt;=x025],color=&amp;#39;indianred&amp;#39;,alpha=0.4)
plt.show()
beta = sc.norm.cdf(x975,loc=data2.mean(),scale=se)-sc.norm.cdf(x025,loc=data2.mean(),scale=se)
print &amp;quot;Beta (Prob of Type II Error) Assuming data value is the true value&amp;quot;, beta
print &amp;quot;Power:&amp;quot;,1-beta
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_23_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Beta (Prob of Type II Error) Assuming data value is the true value 0.271504963539
Power: 0.728495036461
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can also see how chaning the significance level affects the power of a study.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.plot(np.linspace(0.01,0.3,40),[explore_power(20.4,130,0.01,data.std(),significance_level=x) for x in np.linspace(0.01,0.3,40)],&amp;#39;bo--&amp;#39;,
        color=&amp;#39;lightseagreen&amp;#39;,alpha=0.6,label=&amp;quot;Power&amp;quot;)
plt.ylim([0,110])
plt.xlabel(&amp;quot;Significance Level&amp;quot;)
plt.ylabel(&amp;quot;Power&amp;quot;)
plt.legend(loc=4)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_25_0.png" /&gt;&lt;/p&gt;
&lt;h2&gt;Power Calculations for A/B testing&lt;/h2&gt;
&lt;p&gt;We continued yesterday's case study with Esty to find the power needed.  It looked like our Etsy Tuesday Landing Page experiment was under-powered.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;etsy = pd.read_csv(&amp;#39;data/experiment.csv&amp;#39;)
old_data = etsy[etsy[&amp;#39;landing_page&amp;#39;] == &amp;#39;old_page&amp;#39;][&amp;#39;converted&amp;#39;]
new_data = etsy[etsy[&amp;#39;landing_page&amp;#39;] == &amp;#39;new_page&amp;#39;][&amp;#39;converted&amp;#39;]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We will set up the following hypthesis test.&lt;/p&gt;
&lt;p&gt;X ~ p_new - p_old&lt;/p&gt;
&lt;p&gt;H0: X = 0.001
H1: X &amp;gt; 0.001&lt;/p&gt;
&lt;p&gt;We need to set up the proportions of conversions and find the standard error for this experiment.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;po = old_data.mean()
pn = new_data.mean()
p = (old_data.mean()*len(old_data)+new_data.mean()*len(new_data))/(len(old_data)+len(new_data))
se = np.sqrt(p*(1-p)/len(old_data)+p*(1-p)/len(new_data))
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can make the same plots as before and compared null to our data.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x = np.linspace(-5*se,5*se,100)

y1 = sc.norm.pdf(x,loc=0.001,scale=se)
cumy1 = sc.norm.cdf(x,loc=0.001,scale=se)
y2 = sc.norm.pdf(x,loc=(pn-po),scale=se)
x95 = 0.001+1.68*se
plt.plot(x,y1,color=&amp;#39;indianred&amp;#39;,label=&amp;#39;Null Hypthesis&amp;#39;)
plt.plot(x,y2,color=&amp;#39;steelblue&amp;#39;,label=&amp;#39;New Data&amp;#39;)
plt.axvline(x95,0,10,color=&amp;#39;black&amp;#39;,lw=3,linestyle=&amp;#39;--&amp;#39;)
plt.fill_between(x[x&amp;gt;=x95],y2[x&amp;gt;=x95],color=&amp;#39;steelblue&amp;#39;,alpha=0.4)
plt.fill_between(x[x&amp;gt;=x95],y1[x&amp;gt;=x95],color=&amp;#39;indianred&amp;#39;,alpha=0.4)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_31_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We can see our data is not statistically different of 0.001, but if we assume the data represents the true mean, we have a very weak test.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;critical_z = sc.norm.ppf(0.95)
x95 = 0.001+critical_z*se
1-sc.norm.cdf(x95,loc=(pn-po),scale=se)




0.005391084734824525
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We have a power of less than 1/2% from our data.   &lt;/p&gt;
&lt;p&gt;Increasing the sample size will weaken the power in this case, because our data is less than the null hypthesis, and we are constructing a one sided t-test.  In this case we accept the results and fail to reject the null hypthesis. &lt;/p&gt;
&lt;p&gt;We were told that Etsy decided the pilot is a plausible enough representation of the company's daily  traffic. As a result, Esty decided on a two-tailed test instead, which is as follows:&lt;/p&gt;
&lt;p&gt;```
   X ~ p_new - p_old&lt;/p&gt;
&lt;p&gt;H0: X = 0.001
   H1: X != 0.001
   ```&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x = np.linspace(-5*se,5*se,100)

y1 = sc.norm.pdf(x,loc=0.001,scale=se)
cumy1 = sc.norm.cdf(x,loc=0.001,scale=se)
y2 = sc.norm.pdf(x,loc=(pn-po),scale=se)
x025 = 0.001-1.96*se
x975 = 0.001+1.96*se
plt.plot(x,y1,color=&amp;#39;indianred&amp;#39;,label=&amp;#39;Null Hypthesis&amp;#39;)
plt.plot(x,y2,color=&amp;#39;steelblue&amp;#39;,label=&amp;#39;New Data&amp;#39;)
plt.axvline(x025,0,10,color=&amp;#39;black&amp;#39;,lw=3,linestyle=&amp;#39;--&amp;#39;)
plt.axvline(x975,0,10,color=&amp;#39;black&amp;#39;,lw=3,linestyle=&amp;#39;--&amp;#39;)
plt.fill_between(x[x&amp;gt;=x975],y2[x&amp;gt;=x975],color=&amp;#39;steelblue&amp;#39;,alpha=0.4)
plt.fill_between(x[x&amp;lt;=x025],y2[x&amp;lt;=x025],color=&amp;#39;steelblue&amp;#39;,alpha=0.4)
plt.fill_between(x[x&amp;gt;=x975],y1[x&amp;gt;=x975],color=&amp;#39;indianred&amp;#39;,alpha=0.4)
plt.fill_between(x[x&amp;lt;=x025],y1[x&amp;lt;=x025],color=&amp;#39;indianred&amp;#39;,alpha=0.4)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_36_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;print &amp;quot;2-Sided Power: &amp;quot;, sc.norm.cdf(x025,loc=(pn-po),scale=se)+(1-sc.norm.cdf(x975,loc=(pn-po),scale=se))

2-Sided Power:  0.14775925242
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Minimum Sample Size&lt;/h3&gt;
&lt;p&gt;When desigining an experiment, or conducting a test, it is important to get enough data to measure what we are looking for.  In the case of Etsy, its a 1% lift in conversions.  To try to figure out the sample size we might considered our desired false postive and false negative rates, and the Z values associated with them.&lt;/p&gt;
&lt;p&gt;$$\alpha = \mbox{False Positive Rate}, \ Z_{\alpha}$$&lt;/p&gt;
&lt;p&gt;$$\beta = \mbox{False Negative Rate}, \ Z_{\beta}$$&lt;/p&gt;
&lt;p&gt;In an experiment we will have one values, and the Z's will be related to it by the following:&lt;/p&gt;
&lt;p&gt;$$\mu_{exp} = \mbox{Experimental Result}$$&lt;/p&gt;
&lt;p&gt;$$s_{sample} = \mbox{Sampling Erroring}$$&lt;/p&gt;
&lt;p&gt;$$Z_{\alpha} = \frac{\mu_{exp} \ - \ \mu_{Null}}{s_{sample}}$$&lt;/p&gt;
&lt;p&gt;$$Z_{\beta} = \frac{\mu_{exp} \ - \ \mu_{Alternative}}{s_{sample}}$$&lt;/p&gt;
&lt;p&gt;It is worth noting that one of these Z's can be positive, while the other can be negative.  You will find equations that differ from what is done here because of that.  Taking the difference between these two equations give:&lt;/p&gt;
&lt;p&gt;$$\mbox{Effect Size} = \mu_{Alternative} - \mu_{Null}$$&lt;/p&gt;
&lt;p&gt;$$Z_{\alpha} \ - \ Z_{\beta} = \frac{\mbox{Effect Size}}{s_{sample}}$$&lt;/p&gt;
&lt;p&gt;We can use the eqauation for the sampling distribution for two sample proproption test of equal size for the sampling error.&lt;/p&gt;
&lt;p&gt;$$s_{sample} = \sqrt{\frac{ p \ (1 - p) \ 2}{n}}$$&lt;/p&gt;
&lt;p&gt;Where p is the weighted proportion of the two groups.  This gives the previous equation as.&lt;/p&gt;
&lt;p&gt;$$Z_{\alpha} \ - \ Z_{\beta} = \frac{\mbox{Effect Size}}{\sqrt{\frac{ p \ (1 - p) \ 2}{n}}}$$&lt;/p&gt;
&lt;p&gt;Squaring both sides we get:&lt;/p&gt;
&lt;p&gt;$$(Z_{\alpha} \ - \ Z_{\beta})^2 = \frac{\mbox{Effect Size}^2 \ n}{ p \ (1 - p) \ 2}$$&lt;/p&gt;
&lt;p&gt;So the needed sample size should be&lt;/p&gt;
&lt;p&gt;$$n = \frac{2 \ (Z_{\alpha} \ - \ Z_{\beta})^2 \ p \ (1-p)}{\mbox{Effect Size}^2}$$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def calc_min_sample_size(old,new,effect_size,sig=0.05,pow=0.8,one_tail=False):
    pn = new.mean()
    po = old.mean()
    no = len(old)
    nn = len(new)
    dp = pn-po
    p = ( po*no+pn*nn ) / (nn+no)
    se = np.sqrt(p*(1-p)*(1/nn+1/no))
    if one_tail:
        z_null = sc.norm.ppf((1-sig))
    else:
        z_null = sc.norm.ppf((1-sig/2))
    z_pow = sc.norm.ppf(1-pow)


    return (z_null-z_pow)**2*2*p*(1-p)/effect_size**2


calc_min_sample_size(old_data,new_data,0.001,one_tail=False)




1410314.3210247809
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So if we want a power of 80% for our Etsy experiment, meaning its likely for us to detect results that are different from a lift of 1%, we need to have 1.4 million users in each sample.  Our results are definately underpowered.&lt;/p&gt;
&lt;h2&gt;Afternoon - Bayes&lt;/h2&gt;
&lt;p&gt;We covered Bayes' Theorem and updating priors with likelihoods to produce a posterior distribution of sample paramters given data.   We started with a created class, and explore the results of these distributions given data.&lt;/p&gt;
&lt;p&gt;$$ P(Parameters \ | \ Data) = \frac{P(Data \ | \ Parameters) * P(Paramters)}{P(Data)} $$&lt;/p&gt;
&lt;p&gt;$$ \mbox{Posterior} = \frac{\mbox{Likelihood} \ \times \ \mbox{Prior}}{\mbox{Normalization}} $$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kr"&gt;class&lt;/span&gt; &lt;span class="nx"&gt;Bayes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;object&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="s1"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="s1"&gt;    INPUT:&lt;/span&gt;
&lt;span class="s1"&gt;        prior (dict): key is the value (e.g. 4-sided die),&lt;/span&gt;
&lt;span class="s1"&gt;                      value is the probability&lt;/span&gt;

&lt;span class="s1"&gt;        likelihood_func (function): takes a new piece of data and the value and&lt;/span&gt;
&lt;span class="s1"&gt;                                    outputs the likelihood of getting that data&lt;/span&gt;
&lt;span class="s1"&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;prior&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;likelihood_func&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;prior&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;prior&lt;/span&gt;
        &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;likelihood_func&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;likelihood_func&lt;/span&gt;


    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;normalize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="s1"&gt;        INPUT: None&lt;/span&gt;
&lt;span class="s1"&gt;        OUTPUT: None&lt;/span&gt;

&lt;span class="s1"&gt;        Makes the sum of the probabilities equal 1.&lt;/span&gt;
&lt;span class="s1"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="nx"&gt;total&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;prior&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;values&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nx"&gt;key&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;prior&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
            &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;prior&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;key&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;prior&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;key&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;total&lt;/span&gt;

    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="s1"&gt;        INPUT:&lt;/span&gt;
&lt;span class="s1"&gt;            data (int or str): A single observation (data point)&lt;/span&gt;

&lt;span class="s1"&gt;        OUTPUT: None&lt;/span&gt;

&lt;span class="s1"&gt;        Conduct a bayesian update. Multiply the prior by the likelihood and&lt;/span&gt;
&lt;span class="s1"&gt;        make this the new prior.&lt;/span&gt;
&lt;span class="s1"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nx"&gt;k&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;prior&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
            &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;prior&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;k&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;prior&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;k&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;likelihood_func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;normalize&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;print_distribution&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="s1"&gt;        Print the current posterior probability.&lt;/span&gt;
&lt;span class="s1"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nx"&gt;k&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="nx"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;prior&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
            &lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="nx"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;prior&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;k&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;

    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="s1"&gt;        Plot the current prior.&lt;/span&gt;
&lt;span class="s1"&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nx"&gt;color&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nx"&gt;None&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
            &lt;span class="nx"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;blue&amp;#39;&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
            &lt;span class="nx"&gt;c&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;color&lt;/span&gt;
        &lt;span class="nx"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;prior&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
        &lt;span class="nx"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;self.&lt;/span&gt;&lt;span class="nx-Member"&gt;prior&lt;/span&gt;&lt;span class="err"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;key&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nx"&gt;key&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="nx"&gt;k&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="nx"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;bar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;prior&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;&lt;span class="nx"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;c&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;label&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="nx"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;xticks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;prior&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;likelihood_dice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nx"&gt;data&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="kr"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="kr"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;likelihood_coin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;H&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="kr"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="kr"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;The problem&lt;/h3&gt;
&lt;p&gt;A box contains a 4-sided die, a 6-sided die, an 8-sided die,a 12-sided die, and a 20-sided die. A die is selected at random, and the rest are destroyed.  &lt;/p&gt;
&lt;p&gt;What is the prior?&lt;br /&gt;
&lt;strong&gt;All Dice Equally Likely&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;b = Bayes({&amp;#39;04&amp;#39;:0.2,&amp;#39;06&amp;#39;:0.2,&amp;#39;08&amp;#39;:0.2,&amp;#39;12&amp;#39;:0.2,&amp;#39;20&amp;#39;:0.2},likelihood_dice)
b.plot()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_44_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;Say I roll an 8. After one bayesian update, what is the probability that I chose each of the dice?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;b.update(8)
b.plot()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_46_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We know that we do not have a 4 or 6 sided dice, and the 8 is most likly because the 8 has a 1 in 8 chance of getting an 8, the 12 has a 1 in 12 chance of rolling and 8, and the 20 sided dice has a 1 in 20 chance of rolling an 8.&lt;/p&gt;
&lt;p&gt;Comment on the difference in the posteriors if I had rolled the die 50 times instead of 1.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;[b.update(8) for i in range(49)]&lt;/span&gt;
&lt;span class="err"&gt;b.plot()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_49_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;However unlikely it is, the posterier suggest that the post likely culperite of 50 roles all coming to 8 is an 8 sided dice.&lt;/p&gt;
&lt;p&gt;Which one of these two sets of data gives you a more certain posterior and why?
&lt;code&gt;[1, 1, 1, 3, 1, 2]&lt;/code&gt; or &lt;code&gt;[10, 10, 10, 10, 8, 8]&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;b = Bayes({&amp;#39;04&amp;#39;:0.2,&amp;#39;06&amp;#39;:0.2,&amp;#39;08&amp;#39;:0.2,&amp;#39;12&amp;#39;:0.2,&amp;#39;20&amp;#39;:0.2},likelihood_dice)
[b.update(x) for x in [1,1,1,3,1,2]]
b.plot()
plt.show()
b = Bayes({&amp;#39;04&amp;#39;:0.2,&amp;#39;06&amp;#39;:0.2,&amp;#39;08&amp;#39;:0.2,&amp;#39;12&amp;#39;:0.2,&amp;#39;20&amp;#39;:0.2},likelihood_dice)
[b.update(x) for x in [10,10,10,10,8,8]]
b.plot()
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_52_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_52_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;We are most certain in the second case becasue 3 of the dice have been ruled out, and a 1/12 per roll is much bigger than a 1/20.&lt;/p&gt;
&lt;p&gt;Say the prior of the dice is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;```
4-sided die: 8%
6-sided die: 12%
8-sided die: 16%
12-sided die: 24%
20-sided die: 40%
```
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;What are posteriors for each die after rolling the 8?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;b = Bayes({&amp;#39;04&amp;#39;:0.08,&amp;#39;06&amp;#39;:0.12,&amp;#39;08&amp;#39;:0.16,&amp;#39;12&amp;#39;:0.24,&amp;#39;20&amp;#39;:0.40},likelihood_dice)
b.update(8)
b.plot()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_55_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;The postior makes 8 sided, 12 sided, and 20 sided dice equally likely after 1 roll of an 8.  &lt;/p&gt;
&lt;p&gt;Say you keep the same prior and you roll the die 50 times and get values 1-8 every time. What would you expect of the posterior? How different do you think it would be if you'd used the uniform prior?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;b = Bayes({&amp;#39;04&amp;#39;:0.2,&amp;#39;06&amp;#39;:0.2,&amp;#39;08&amp;#39;:0.2,&amp;#39;12&amp;#39;:0.2,&amp;#39;20&amp;#39;:0.2},likelihood_dice)
[b.update(x) for x in np.random.randint(1,8,size=50)]
b.plot()
plt.show()
b = Bayes({&amp;#39;04&amp;#39;:0.08,&amp;#39;06&amp;#39;:0.12,&amp;#39;08&amp;#39;:0.16,&amp;#39;12&amp;#39;:0.24,&amp;#39;20&amp;#39;:0.40},likelihood_dice)
[b.update(x) for x in np.random.randint(1,8,size=50)]
b.plot()
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_58_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_58_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;With enough data, the difference in priors do not matter.   They converge to the same value.  &lt;/p&gt;
&lt;h2&gt;Bayes and Coin Flips&lt;/h2&gt;
&lt;p&gt;We can consider a random flip of a coin and ask what is the believe about our belief of the probability the coin resulting in heads.   Before any flip we would assume a unifor distrubiton.   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;p = np.linspace(0,0.99,100)
prior = dict()
for v in p:
    prior[str(v)] = 0.01
flips = [[&amp;#39;H&amp;#39;],[&amp;#39;T&amp;#39;],[&amp;#39;H&amp;#39;,&amp;#39;H&amp;#39;],[&amp;#39;H&amp;#39;,&amp;#39;T&amp;#39;],[&amp;#39;H&amp;#39;,&amp;#39;H&amp;#39;,&amp;#39;H&amp;#39;],[&amp;#39;T&amp;#39;,&amp;#39;H&amp;#39;,&amp;#39;T&amp;#39;],[&amp;#39;H&amp;#39;,&amp;#39;H&amp;#39;,&amp;#39;H&amp;#39;,&amp;#39;H&amp;#39;],[&amp;#39;T&amp;#39;,&amp;#39;H&amp;#39;,&amp;#39;T&amp;#39;,&amp;#39;H&amp;#39;]]

plt.figure(figsize=(15,10))
for i,f in enumerate(flips):
    plt.subplot(4,2,i+1)
    b = Bayes(prior.copy(),likelihood_coin)
    for x in f:
         b.update(x)
    b.plot(label=str(f))
    plt.legend(loc=&amp;#39;best&amp;#39;)
    plt.xticks(rotation=70,fontsize=4)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_61_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We were given a cone class, with a unknown probability.  I am going to plot the update in my posteriers after fixed number of flips to see if a Bayesian would believe this is a biased coin&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;coin&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Coin&lt;/span&gt;
&lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Coin&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;col&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;indianred&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;steelblue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;10&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;coral&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;50&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;lightseagreen&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;250&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;skyblue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;500&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;purple&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;1000&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;indianred&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Bayes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prior&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="n"&gt;likelihood_coin&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flip&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;49&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;249&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;499&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;999&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
        &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)],&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;#39; Flips&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xticks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rotation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;70&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D4/output_63_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;As we update our believes, upto 1000 flips, we see that 50 looks to be in the edge of our posterior space, but the distribution is centered around 0.53, making this the maximum likelihood value after 1000 flips.&lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="ab testing"></category><category term="statistics"></category><category term="hypothesis testing"></category></entry><entry><title>Galvanize - Week 02 - Day 3</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-02-03/" rel="alternate"></link><updated>2015-06-10T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-10:galvanize/galvanize-data-science-02-03/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 2 - Day 3&lt;/h2&gt;
&lt;p&gt;Today we had a miniquiz on making a python package that could contain an arbitrary probability mass function as a dictionary.  It had to allow new values to be set, maintain a normalized pmf, and return probabilities for values in the dictionary, None otherwise.   &lt;/p&gt;
&lt;h2&gt;Morning&lt;/h2&gt;
&lt;p&gt;The morning lecture was on Hypthesis testing and multiple testing corrections.  We reviewed the languaged, phrasing, caveots, and particulars about the frame works.  Our sprint involved investigating some questions involving multiple testing and clickthru rates&lt;/p&gt;
&lt;h2&gt;Multiple Testing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;A study attempted to measure the influence of patients' astrological signs on their risk for heart failure.
   12 groups of patients (1 group for each astrological sign) were reviewed and the incidence of heart failure in each group was recorded. For each of the 12 groups, the researchers performed a z-test comparing the incidence of heart failure in one group to the incidence among the patients of all the other groups (i.e. 12 tests). The group with the highest rate of heart failure was Pisces, which had a p-value of .026 when assessing the null hypothesis that it had the same heart failure rate as all the other groups. What is the the problem with concluding from this p-value that Pisces have a higher rate of heart failure at a significance level of 0.05? How might you correct this p-value?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;We have 12 tests, with a 5% false positive rate.  Using the Bernoulli Distribution we can see the chance of getting x number of false positive.&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;scipy.stats&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sc&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;__future__&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;division&lt;/span&gt;


&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;sc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;binom&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pmf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;indianred&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;False Positive Count&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Probability of False Positive Count&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Probability Of False Positives For 12 Tests&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Prob of 1 false postiive with 12 tests&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;binom&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pmf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Prob of 1 or More false positives with 12 test&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;sc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;binom&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pmf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;Prob&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;false&lt;/span&gt; &lt;span class="n"&gt;postiive&lt;/span&gt; &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt; &lt;span class="n"&gt;tests&lt;/span&gt; &lt;span class="mf"&gt;0.341280055366&lt;/span&gt;
&lt;span class="n"&gt;Prob&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;More&lt;/span&gt; &lt;span class="n"&gt;false&lt;/span&gt; &lt;span class="n"&gt;positives&lt;/span&gt; &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt; &lt;span class="kp"&gt;test&lt;/span&gt; &lt;span class="mf"&gt;0.459639912337&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D3/output_1_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;There is a 34% chance that one of the 12 tests will be a false positive value.  Instead, it would make more sense to chose a false positive rate such that the chance of having false positives out of 12 tests would be less than 0.05&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;p = np.linspace(0,1,10000)
cdf = 1-sc.binom.pmf(0,12,p)
plt.plot(p,cdf,label=&amp;quot;CDF of P&amp;quot;,color=&amp;#39;indianred&amp;#39;)
plt.xlabel(&amp;#39;False Positive Rate For 12 Tests&amp;#39;)
plt.ylabel(&amp;#39;Prob of 1+ False Positives&amp;#39;)
plt.fill_between(p, cdf, where=cdf&amp;lt;0.05, interpolate=True, color=&amp;#39;red&amp;#39;,alpha=0.2)
plt.show()
print &amp;quot;New Significant Level: &amp;quot;, p[cdf &amp;lt; 0.05].max()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D3/output_3_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;New Significant Level:  0.004200420042
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;In this case we would want to have a false positive rate for a single test of 0.0042.  By this criteria the p-value of 0.026 is not significant for the relation between Picese and heart failure. &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Bonferonni correct suggests taking the significant goal of an individual test and divide it by the number of tests.  This gives a value of 0.000417.  This is very close to the above results&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;print &amp;quot;Significance: &amp;quot;, 0.05/12

Significance:  0.00416666666667
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Click Through Rate&lt;/h2&gt;
&lt;p&gt;We will use hypothesis testing to analyze &lt;strong&gt;Click Through Rate (CTR)&lt;/strong&gt; on the New York Times website.
CTR is defined as the number of clicks the user make per impression that is made upon the user.
We are going to determine if there is statistically significant difference between the mean CTR for
the following groups:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Signed in users v.s. Not signed in users&lt;/li&gt;
&lt;li&gt;Male v.s. Female&lt;/li&gt;
&lt;li&gt;Each of 7 age groups against each other (7 choose 2 = 21 tests)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Because we are construction 23 hypothesis tests on this data set, we can use the Bonferroni Correction of dividing the 5% false error rate by 23 to get:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;$$\alpha_{23} = 0.00217 $$&lt;/p&gt;
&lt;p&gt;We can now load the data.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;nyt = pd.read_csv(&amp;quot;../ab-testing/data/nyt1.csv&amp;quot;)
nyt.info()

&amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;
Int64Index: 458441 entries, 0 to 458440
Data columns (total 5 columns):
Age            458441 non-null int64
Gender         458441 non-null int64
Impressions    458441 non-null int64
Clicks         458441 non-null int64
Signed_In      458441 non-null int64
dtypes: int64(5)
memory usage: 21.0 MB
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;There are not any null values in the data set, but we need to construct a click through rate for each user.   We will do this by:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Removing users without Impressions&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dividing the Clicks by Impressions&lt;/p&gt;
&lt;p&gt;nyt = nyt[nyt.Impressions!=0]
nyt['CTR'] = np.nan
nyt.CTR = nyt.Clicks.astype(float)/nyt2.Impressions.astype(float)
nyt.head()&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Age&lt;/th&gt;
      &lt;th&gt;Gender&lt;/th&gt;
      &lt;th&gt;Impressions&lt;/th&gt;
      &lt;th&gt;Clicks&lt;/th&gt;
      &lt;th&gt;Signed_In&lt;/th&gt;
      &lt;th&gt;CTR&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;36&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;49&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;47&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Now that we have the click through lets look at the distributions of variables.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;nyt2.hist(figsize=(15,8),bins=30,color=&amp;#39;indianred&amp;#39;,alpha=0.5)




array([[&amp;lt;matplotlib.axes._subplots.AxesSubplot object at 0x1088e9f10&amp;gt;,
        &amp;lt;matplotlib.axes._subplots.AxesSubplot object at 0x1088d9a50&amp;gt;],
       [&amp;lt;matplotlib.axes._subplots.AxesSubplot object at 0x108944150&amp;gt;,
        &amp;lt;matplotlib.axes._subplots.AxesSubplot object at 0x104598750&amp;gt;],
       [&amp;lt;matplotlib.axes._subplots.AxesSubplot object at 0x10882f990&amp;gt;,
        &amp;lt;matplotlib.axes._subplots.AxesSubplot object at 0x1088cafd0&amp;gt;]], dtype=object)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D3/output_11_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;The age's with zero appear to be users that are not signed in by the height of the bars in the age and signed_in graphs.   The number of total clicks is less then 50,000, and the click through rates are small are mostly zero. &lt;/p&gt;
&lt;p&gt;To answer question 1, we need to split the date between signed-in users and signed-out users.   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sign = nyt[nyt[&amp;#39;Signed_In&amp;#39;]==1]
nosign = nyt[nyt[&amp;#39;Signed_In&amp;#39;]==0]
plt.figure()
sign.hist(figsize=(15,8),bins=10,color=&amp;#39;indianred&amp;#39;,alpha=0.5)
plt.show()
plt.figure()
nosign.hist(figsize=(15,8),bins=10,color=&amp;#39;indianred&amp;#39;,alpha=0.5)
plt.show()


&amp;lt;matplotlib.figure.Figure at 0x10ed32690&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D3/output_13_1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&amp;lt;matplotlib.figure.Figure at 0x108bbc950&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D3/output_13_3.png" /&gt;&lt;/p&gt;
&lt;p&gt;We can construct a hypothesis test on the data where we have the following&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;H0: The mean click through rate between signed in users and signed-out users are the same&lt;/li&gt;
&lt;li&gt;HA: The mean click through rates between signed-in users and signed-out users aer different&lt;/li&gt;
&lt;li&gt;We requrire a p-value less than 0.00217 to rejec the Null Hypothesis in favor for the Alterative&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Do this with a Weltch's (Non Equal Variance Assigned) t-test results in the following results:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sc.ttest_ind(sign.CTR, nosign.CTR, equal_var=False)




(array(-55.37611793427461), 0.0)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The results of the test states that the test statistic to measure the difference is -55, given a p-value very close to zero, which is less than 0.00217.   In this case we can see there is a mean difference in the click through rates between the two populations.  In this case the signed-out users have a higher CTR than signed-in users.&lt;/p&gt;
&lt;p&gt;Question two has to do with the difference in click through rates between genders.   This requires that we only investigate the users that are signed in, because signed out users do not have a gender variable.   Lets look at the data and perform a Wetch's t-test.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure()
sign[sign.Gender==0].hist(figsize=(15,8),bins=10,color=&amp;#39;indianred&amp;#39;,alpha=0.5)
plt.show()
plt.figure()
sign[sign.Gender==1].hist(figsize=(15,8),bins=10,color=&amp;#39;blue&amp;#39;,alpha=0.5)
plt.show()


&amp;lt;matplotlib.figure.Figure at 0x10ed3a550&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D3/output_17_1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&amp;lt;matplotlib.figure.Figure at 0x109a90610&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D3/output_17_3.png" /&gt;&lt;/p&gt;
&lt;p&gt;A visual inspect of the data shows that men and women have similar distirubtions, with the exceptions fo the impressions distributions.  Men seem to have a wider range of impressons compared to women.  &lt;/p&gt;
&lt;p&gt;The hypthesis test we are constructing is:&lt;/p&gt;
&lt;p&gt;H0:  Signed-in Men and Women have the same mean CTR&lt;br /&gt;
HA:  Signed-in Men and Women have different mean CTR&lt;br /&gt;
&lt;em&gt;significance is 0.00217&lt;/em&gt;  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sc.ttest_ind(sign[sign.Gender==0].CTR, sign[sign.Gender==1].CTR, equal_var=False)




(array(3.2897560659373846), 0.0010028527313066396)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Our test possted a t-value of 3.29 and a p-value of 0.001, which is significant.  We reject the null in favor of the alternative, concluding that men and women have different mean click through rates.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;print &amp;quot;Click through rates (SI Men, SI Women, NOT Si)&amp;quot;,sign[sign.Gender==1].CTR.mean(),sign[sign.Gender==1].CTR.mean(),nosign.CTR.mean()

Click through rates (SI Men, SI Women, NOT Si) 0.0139185242976 0.0139185242976 0.0283549070617
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The difference in the mean CTR between men and women is significant, but not large. The difference between both groups and not-signed-in users are much more different.&lt;/p&gt;
&lt;p&gt;Now we will construct a set of hypothesis tests comparing different age groups against each other.   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sign[&amp;#39;AgeGroup&amp;#39;] = np.nan
sign.loc[:,&amp;#39;AgeGroup&amp;#39;] = pd.cut(sign.Age, [0,7, 18, 24, 34, 44, 54, 64, 1000])
df = pd.DataFrame(columns=[&amp;#39;group1&amp;#39;,&amp;#39;group2&amp;#39;,&amp;#39;meanCTR1&amp;#39;,&amp;#39;meanCTR2&amp;#39;,&amp;#39;p_value&amp;#39;,&amp;#39;mean_difference&amp;#39;])
k = 0
AG = sign.AgeGroup.unique()
for i,x in enumerate(AG):
    for j,y in enumerate(AG):
        if x != &amp;#39;(0, 7]&amp;#39; and y!=&amp;#39;(0, 7]&amp;#39; and i &amp;gt; j:
            g1 = sign[sign.AgeGroup==x].CTR
            g2 = sign[sign.AgeGroup==y].CTR
            p = sc.ttest_ind(g1,g2, equal_var=False)[1]
            diff = g1.mean()-g2.mean()
            df.loc[k] = [x,y,g1.mean(),g2.mean(),p,diff]
            k += 1

df = df[df.p_value &amp;lt; 0.00217]
df = df.sort(&amp;#39;mean_difference&amp;#39;).reset_index().drop(&amp;#39;index&amp;#39;,axis=1)
df

/Library/Python/2.7/site-packages/IPython/kernel/__main__.py:1: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  if __name__ == &amp;#39;__main__&amp;#39;:
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;group1&lt;/th&gt;
      &lt;th&gt;group2&lt;/th&gt;
      &lt;th&gt;meanCTR1&lt;/th&gt;
      &lt;th&gt;meanCTR2&lt;/th&gt;
      &lt;th&gt;p_value&lt;/th&gt;
      &lt;th&gt;mean_difference&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;(18, 24]&lt;/td&gt;
      &lt;td&gt;(64, 1000]&lt;/td&gt;
      &lt;td&gt;0.009720&lt;/td&gt;
      &lt;td&gt;0.029803&lt;/td&gt;
      &lt;td&gt;2.458627e-272&lt;/td&gt;
      &lt;td&gt;-0.020082&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;(44, 54]&lt;/td&gt;
      &lt;td&gt;(64, 1000]&lt;/td&gt;
      &lt;td&gt;0.009958&lt;/td&gt;
      &lt;td&gt;0.029803&lt;/td&gt;
      &lt;td&gt;1.430923e-295&lt;/td&gt;
      &lt;td&gt;-0.019845&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;(24, 34]&lt;/td&gt;
      &lt;td&gt;(64, 1000]&lt;/td&gt;
      &lt;td&gt;0.010146&lt;/td&gt;
      &lt;td&gt;0.029803&lt;/td&gt;
      &lt;td&gt;7.860398e-285&lt;/td&gt;
      &lt;td&gt;-0.019656&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;(18, 24]&lt;/td&gt;
      &lt;td&gt;(7, 18]&lt;/td&gt;
      &lt;td&gt;0.009720&lt;/td&gt;
      &lt;td&gt;0.026585&lt;/td&gt;
      &lt;td&gt;6.900980e-144&lt;/td&gt;
      &lt;td&gt;-0.016865&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;(54, 64]&lt;/td&gt;
      &lt;td&gt;(64, 1000]&lt;/td&gt;
      &lt;td&gt;0.020307&lt;/td&gt;
      &lt;td&gt;0.029803&lt;/td&gt;
      &lt;td&gt;9.214903e-56&lt;/td&gt;
      &lt;td&gt;-0.009496&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;(54, 64]&lt;/td&gt;
      &lt;td&gt;(7, 18]&lt;/td&gt;
      &lt;td&gt;0.020307&lt;/td&gt;
      &lt;td&gt;0.026585&lt;/td&gt;
      &lt;td&gt;8.273993e-20&lt;/td&gt;
      &lt;td&gt;-0.006278&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;td&gt;(7, 18]&lt;/td&gt;
      &lt;td&gt;(64, 1000]&lt;/td&gt;
      &lt;td&gt;0.026585&lt;/td&gt;
      &lt;td&gt;0.029803&lt;/td&gt;
      &lt;td&gt;3.563408e-05&lt;/td&gt;
      &lt;td&gt;-0.003218&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;td&gt;(54, 64]&lt;/td&gt;
      &lt;td&gt;(34, 44]&lt;/td&gt;
      &lt;td&gt;0.020307&lt;/td&gt;
      &lt;td&gt;0.010286&lt;/td&gt;
      &lt;td&gt;7.523228e-144&lt;/td&gt;
      &lt;td&gt;0.010020&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;8&lt;/th&gt;
      &lt;td&gt;(54, 64]&lt;/td&gt;
      &lt;td&gt;(24, 34]&lt;/td&gt;
      &lt;td&gt;0.020307&lt;/td&gt;
      &lt;td&gt;0.010146&lt;/td&gt;
      &lt;td&gt;5.668132e-141&lt;/td&gt;
      &lt;td&gt;0.010160&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;9&lt;/th&gt;
      &lt;td&gt;(54, 64]&lt;/td&gt;
      &lt;td&gt;(44, 54]&lt;/td&gt;
      &lt;td&gt;0.020307&lt;/td&gt;
      &lt;td&gt;0.009958&lt;/td&gt;
      &lt;td&gt;2.525271e-151&lt;/td&gt;
      &lt;td&gt;0.010349&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10&lt;/th&gt;
      &lt;td&gt;(54, 64]&lt;/td&gt;
      &lt;td&gt;(18, 24]&lt;/td&gt;
      &lt;td&gt;0.020307&lt;/td&gt;
      &lt;td&gt;0.009720&lt;/td&gt;
      &lt;td&gt;1.007813e-130&lt;/td&gt;
      &lt;td&gt;0.010586&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;11&lt;/th&gt;
      &lt;td&gt;(7, 18]&lt;/td&gt;
      &lt;td&gt;(34, 44]&lt;/td&gt;
      &lt;td&gt;0.026585&lt;/td&gt;
      &lt;td&gt;0.010286&lt;/td&gt;
      &lt;td&gt;4.575147e-146&lt;/td&gt;
      &lt;td&gt;0.016299&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12&lt;/th&gt;
      &lt;td&gt;(7, 18]&lt;/td&gt;
      &lt;td&gt;(24, 34]&lt;/td&gt;
      &lt;td&gt;0.026585&lt;/td&gt;
      &lt;td&gt;0.010146&lt;/td&gt;
      &lt;td&gt;7.449266e-146&lt;/td&gt;
      &lt;td&gt;0.016439&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;13&lt;/th&gt;
      &lt;td&gt;(7, 18]&lt;/td&gt;
      &lt;td&gt;(44, 54]&lt;/td&gt;
      &lt;td&gt;0.026585&lt;/td&gt;
      &lt;td&gt;0.009958&lt;/td&gt;
      &lt;td&gt;4.014382e-151&lt;/td&gt;
      &lt;td&gt;0.016628&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;14&lt;/th&gt;
      &lt;td&gt;(64, 1000]&lt;/td&gt;
      &lt;td&gt;(34, 44]&lt;/td&gt;
      &lt;td&gt;0.029803&lt;/td&gt;
      &lt;td&gt;0.010286&lt;/td&gt;
      &lt;td&gt;5.245541e-288&lt;/td&gt;
      &lt;td&gt;0.019516&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;We itereated through all 21 groups and found 14 pairs who's mean CTR are different from each other with a signicance less than 0.00217.   These results can be summarized in the following way:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;People older than 64 have a statistically significant difference in mean CTR from all other age groups&lt;/li&gt;
&lt;li&gt;People between 54 adn 64 have a statistically significant difference in mean CTR from all other age groups&lt;/li&gt;
&lt;li&gt;People between 7 and 18 have a statistically significant difference in mean CTR from all other age groups&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The order of CTR seems to be older than 65, 7-18 year olds, and then 54-64 year olds.  &lt;/p&gt;
&lt;p&gt;Its interest that the high click through rate of non-signed-in users matches those of the older groups.   &lt;/p&gt;
&lt;h2&gt;Afternoon&lt;/h2&gt;
&lt;p&gt;In the afternoon we learned about AB testing, and our paired programming assignment had to do with analyzing the results of simulated data for &lt;a href="http://etsy.com"&gt;Etsy&lt;/a&gt;.  We were asked to analysis the data from a given Tuesday where an AB test was performed on a website between two pages.   The goal is to change the conversion rate from 10% to 10.1% with this new page, a lift of 1%.  We are told that the weekend users are different than weeday users, and most of Etsy's revenue is made on the weekend.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;df = pd.read_csv(&amp;#39;../ab-testing/data/experiment.csv&amp;#39;)
df.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;user_id&lt;/th&gt;
      &lt;th&gt;ts&lt;/th&gt;
      &lt;th&gt;ab&lt;/th&gt;
      &lt;th&gt;landing_page&lt;/th&gt;
      &lt;th&gt;converted&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;4040615247&lt;/td&gt;
      &lt;td&gt;1356998400&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;new_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;4365389205&lt;/td&gt;
      &lt;td&gt;1356998400&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;new_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;4256174578&lt;/td&gt;
      &lt;td&gt;1356998402&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;new_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;8122359922&lt;/td&gt;
      &lt;td&gt;1356998402&lt;/td&gt;
      &lt;td&gt;control&lt;/td&gt;
      &lt;td&gt;old_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;6077269891&lt;/td&gt;
      &lt;td&gt;1356998402&lt;/td&gt;
      &lt;td&gt;control&lt;/td&gt;
      &lt;td&gt;old_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;dfa = df[(df.ab==&amp;#39;treatment&amp;#39;)&amp;amp;(df.landing_page==&amp;#39;new_page&amp;#39;)]
dfb = df[(df.ab==&amp;#39;control&amp;#39;)&amp;amp;(df.landing_page==&amp;#39;old_page&amp;#39;)]
dfc = df[(df.ab==&amp;#39;control&amp;#39;)&amp;amp;(df.landing_page==&amp;#39;new_page&amp;#39;)]
dfd = df[(df.ab==&amp;#39;treatment&amp;#39;)&amp;amp;(df.landing_page==&amp;#39;old_page&amp;#39;)]
print dfa.user_id.nunique(),dfa.user_id.count()
print dfb.user_id.nunique(),dfb.user_id.count()
print dfc.user_id.nunique(),dfc.user_id.count()
print dfd.user_id.nunique(),dfd.user_id.count()

95574 95574
90814 90815
0 0
4759 4759
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Right away we have a problem in the data.  We have 4759 users that are in treatment group that have seen the new page and old page.  There is also one person in the control group that appear's twice.  &lt;/p&gt;
&lt;p&gt;In my minds, a good experiment outlines how to handle missing data, mistakes, and errors in the analysis before they a found.  This is not the case for this assignment, so we will have to decided what to do ourselves.  I am going to exam the 4759 users.  First I will get a datetime in the dataframe, and then I will try to figure out what is happening with this group.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;df[&amp;#39;dt&amp;#39;] = np.nan
df[&amp;#39;dt&amp;#39;] = pd.to_datetime(df.ts,unit=&amp;#39;s&amp;#39;)
dfa = df[(df.ab==&amp;#39;treatment&amp;#39;)&amp;amp;(df.landing_page==&amp;#39;new_page&amp;#39;)].sort(&amp;#39;user_id&amp;#39;)
dfb = df[(df.ab==&amp;#39;control&amp;#39;)&amp;amp;(df.landing_page==&amp;#39;old_page&amp;#39;)].sort(&amp;#39;user_id&amp;#39;)
dfc = df[(df.ab==&amp;#39;control&amp;#39;)&amp;amp;(df.landing_page==&amp;#39;new_page&amp;#39;)].sort(&amp;#39;user_id&amp;#39;)
dfd = df[(df.ab==&amp;#39;treatment&amp;#39;)&amp;amp;(df.landing_page==&amp;#39;old_page&amp;#39;)].sort(&amp;#39;user_id&amp;#39;)

dfd.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;user_id&lt;/th&gt;
      &lt;th&gt;ts&lt;/th&gt;
      &lt;th&gt;ab&lt;/th&gt;
      &lt;th&gt;landing_page&lt;/th&gt;
      &lt;th&gt;converted&lt;/th&gt;
      &lt;th&gt;dt&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;189992&lt;/th&gt;
      &lt;td&gt;1033628&lt;/td&gt;
      &lt;td&gt;1357084275&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;old_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2013-01-01 23:51:15&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;151793&lt;/th&gt;
      &lt;td&gt;1891740&lt;/td&gt;
      &lt;td&gt;1357066970&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;old_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2013-01-01 19:02:50&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;114751&lt;/th&gt;
      &lt;td&gt;4557110&lt;/td&gt;
      &lt;td&gt;1357050318&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;old_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2013-01-01 14:25:18&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;99066&lt;/th&gt;
      &lt;td&gt;5534964&lt;/td&gt;
      &lt;td&gt;1357043251&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;old_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2013-01-01 12:27:31&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;104055&lt;/th&gt;
      &lt;td&gt;6180378&lt;/td&gt;
      &lt;td&gt;1357045528&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;old_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2013-01-01 13:05:28&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;dfa[dfa.user_id.isin(dfd.user_id)].head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;user_id&lt;/th&gt;
      &lt;th&gt;ts&lt;/th&gt;
      &lt;th&gt;ab&lt;/th&gt;
      &lt;th&gt;landing_page&lt;/th&gt;
      &lt;th&gt;converted&lt;/th&gt;
      &lt;th&gt;dt&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;189991&lt;/th&gt;
      &lt;td&gt;1033628&lt;/td&gt;
      &lt;td&gt;1357084274&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;new_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2013-01-01 23:51:14&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;151790&lt;/th&gt;
      &lt;td&gt;1891740&lt;/td&gt;
      &lt;td&gt;1357066969&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;new_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2013-01-01 19:02:49&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;114746&lt;/th&gt;
      &lt;td&gt;4557110&lt;/td&gt;
      &lt;td&gt;1357050317&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;new_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2013-01-01 14:25:17&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;99064&lt;/th&gt;
      &lt;td&gt;5534964&lt;/td&gt;
      &lt;td&gt;1357043250&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;new_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2013-01-01 12:27:30&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;104052&lt;/th&gt;
      &lt;td&gt;6180378&lt;/td&gt;
      &lt;td&gt;1357045527&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;new_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2013-01-01 13:05:27&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;In these 5 cases we see that the users saw the new landing page, then one second later saw the old landing page.  None of these users displayed converted.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;print dfd[dfd.converted==1].user_id.count()
dfd[dfd.converted==1].head()

501
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;user_id&lt;/th&gt;
      &lt;th&gt;ts&lt;/th&gt;
      &lt;th&gt;ab&lt;/th&gt;
      &lt;th&gt;landing_page&lt;/th&gt;
      &lt;th&gt;converted&lt;/th&gt;
      &lt;th&gt;dt&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;100082&lt;/th&gt;
      &lt;td&gt;10792592&lt;/td&gt;
      &lt;td&gt;1357043708&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;old_page&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2013-01-01 12:35:08&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;67975&lt;/th&gt;
      &lt;td&gt;13223933&lt;/td&gt;
      &lt;td&gt;1357029144&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;old_page&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2013-01-01 08:32:24&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;42109&lt;/th&gt;
      &lt;td&gt;27727121&lt;/td&gt;
      &lt;td&gt;1357017491&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;old_page&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2013-01-01 05:18:11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;22040&lt;/th&gt;
      &lt;td&gt;34535851&lt;/td&gt;
      &lt;td&gt;1357008350&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;old_page&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2013-01-01 02:45:50&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;87355&lt;/th&gt;
      &lt;td&gt;85676035&lt;/td&gt;
      &lt;td&gt;1357037889&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;old_page&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2013-01-01 10:58:09&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;print dfa[dfa.user_id.isin(dfd[dfd.converted==1].user_id)].user_id.count()
dfa[dfa.user_id.isin(dfd[dfd.converted==1].user_id)].head()

501
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;user_id&lt;/th&gt;
      &lt;th&gt;ts&lt;/th&gt;
      &lt;th&gt;ab&lt;/th&gt;
      &lt;th&gt;landing_page&lt;/th&gt;
      &lt;th&gt;converted&lt;/th&gt;
      &lt;th&gt;dt&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;100079&lt;/th&gt;
      &lt;td&gt;10792592&lt;/td&gt;
      &lt;td&gt;1357043707&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;new_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2013-01-01 12:35:07&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;67973&lt;/th&gt;
      &lt;td&gt;13223933&lt;/td&gt;
      &lt;td&gt;1357029143&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;new_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2013-01-01 08:32:23&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;42108&lt;/th&gt;
      &lt;td&gt;27727121&lt;/td&gt;
      &lt;td&gt;1357017490&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;new_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2013-01-01 05:18:10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;22038&lt;/th&gt;
      &lt;td&gt;34535851&lt;/td&gt;
      &lt;td&gt;1357008349&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;new_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2013-01-01 02:45:49&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;87352&lt;/th&gt;
      &lt;td&gt;85676035&lt;/td&gt;
      &lt;td&gt;1357037888&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;new_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2013-01-01 10:58:08&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;We have 501 users that saw the new page, then 1 second later saw the old page and converted.  This does not make sense interms of our project/assignment, so I think the safest thing to do for this analysis is throw out these mistakes, and only do the analysis with the untainted results.  If this was a real experiment, I would definatley investigate the details of the test.&lt;/p&gt;
&lt;p&gt;The goal of the experiment is to have a new pages that has a conversion lift of 1 percent.   With that goal in mine we define the following test:&lt;/p&gt;
&lt;p&gt;H0:  The lift in conversions from the new page and old page is equal to 1%
HA:  the lift if conversions from the new page to the old page is less than 1%&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def z_test(old_conversion, new_conversion, old_nrow, new_nrow,
           effect_size=0., two_tailed=True, alpha=.05):
    &amp;quot;&amp;quot;&amp;quot;z-test&amp;quot;&amp;quot;&amp;quot;
    conversion = (old_conversion * old_nrow + new_conversion * new_nrow) / \
                 (old_nrow + new_nrow)

    se = np.sqrt(conversion * (1 - conversion) * (1 / old_nrow + 1 / new_nrow))

    z_score = (new_conversion - old_conversion - effect_size) / se

    if not two_tailed:
        p_val = 1 - sc.norm.cdf(abs(z_score))
    else:
        p_val = (1 - sc.norm.cdf(abs(z_score))) * 2

    reject_null = p_val &amp;lt; alpha
    #print &amp;#39;z-score: %s, p-value: %s, reject null: %s&amp;#39; % (z_score, p_val, reject_null)
    return z_score, p_val, reject_null



conA,cntA = dfa.converted.mean(),dfa.converted.count()
conB,cntB = dfb.converted.mean(),dfb.converted.count()
print conA,conB,cntA,cntB,0.01*conB
z_test(conA,conB,cntA,cntB,two_tailed=False,effect_size=0.01*conB)

0.0996819218616 0.0996421296041 95574 90815 0.000996421296041





(-0.74648172622270292, 0.22768823318094589, False)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In this frame there results are not significantly different from a 1% left that we can rule them out.  But we could have also tested if there is a difference between them.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;z_test(conA,conB,cntA,cntB,two_tailed=True,effect_size=0.0)




(-0.028666091979081442, 0.9771308999283459, False)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is also not signifcant difference between the groups either.  The results of our Tuesday experiment are really inconclusive.  Ultimately we are concerned with the effect on weekend users, because they are responsible for most of Etsy's revenue.   We were told this user base is different from the weekend users.  &lt;/p&gt;
&lt;p&gt;AirBNB had a talks (&lt;a href="http://nerds.airbnb.com/experiments-airbnb/"&gt;here&lt;/a&gt; and &lt;a href="http://nerds.airbnb.com/experiments-at-airbnb/"&gt;here&lt;/a&gt;) about looking at the hourly change in a p-vale, and examing if and when it level's off as the 'true' p-value for an experiment.   We are going to explore this method.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;p_values = []
effect = 0
last_effect=0
for i in range(23):

    # Grab the hour
    df_houra = dfa[dfa.dt.dt.hour&amp;lt;=i]
    df_hourb = dfb[dfb.dt.dt.hour&amp;lt;=i]

    conA,cntA = df_houra.converted.mean(),df_houra.converted.count()
    conB,cntB = df_hourb.converted.mean(),df_hourb.converted.count()

    p_values.append( z_test(conA,conB,cntA,cntB,two_tailed=False,effect_size=0.01*conB)[1] )

plt.figure()
plt.plot(range(23),p_values,color=&amp;#39;indianred&amp;#39;,alpha=0.8,lw=2)
plt.hlines(0.05,0,23,color=&amp;#39;red&amp;#39;,alpha=0.6,lw=2,linestyle=&amp;#39;--&amp;#39;)
plt.xlabel(&amp;quot;Hours&amp;quot;)
plt.ylabel(&amp;quot;P-values&amp;quot;)
plt.ylim([0,1])
plt.xlim([0,23])
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D3/output_38_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;From this method we see that the p-value is still changing, making me believe that our experiment could be under-powered.&lt;/p&gt;
&lt;p&gt;There is additional data about the country of each user.  It could be interesting to look that these results by country.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;countries = pd.read_csv(&amp;quot;../ab-testing/data/country.csv&amp;quot;)
countries.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;user_id&lt;/th&gt;
      &lt;th&gt;country&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;9160993935&lt;/td&gt;
      &lt;td&gt;UK&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;5879439034&lt;/td&gt;
      &lt;td&gt;UK&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;8915383273&lt;/td&gt;
      &lt;td&gt;UK&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;2917824565&lt;/td&gt;
      &lt;td&gt;US&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;3980216975&lt;/td&gt;
      &lt;td&gt;UK&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;dfac = dfa.merge(countries,on=&amp;#39;user_id&amp;#39;)
dfbc = dfb.merge(countries,on=&amp;#39;user_id&amp;#39;)
print dfac.user_id.count(),dfac.user_id.nunique()
print dfbc.user_id.count(),dfbc.user_id.nunique()
dfac.head()

97151 92554
87927 87924
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;user_id&lt;/th&gt;
      &lt;th&gt;ts&lt;/th&gt;
      &lt;th&gt;ab&lt;/th&gt;
      &lt;th&gt;landing_page&lt;/th&gt;
      &lt;th&gt;converted&lt;/th&gt;
      &lt;th&gt;dt&lt;/th&gt;
      &lt;th&gt;country&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;23267&lt;/td&gt;
      &lt;td&gt;1357066015&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;new_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2013-01-01 18:46:55&lt;/td&gt;
      &lt;td&gt;CA&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;79973&lt;/td&gt;
      &lt;td&gt;1357018111&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;new_page&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2013-01-01 05:28:31&lt;/td&gt;
      &lt;td&gt;US&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;338650&lt;/td&gt;
      &lt;td&gt;1357083484&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;new_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2013-01-01 23:38:04&lt;/td&gt;
      &lt;td&gt;UK&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;340147&lt;/td&gt;
      &lt;td&gt;1357083599&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;new_page&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2013-01-01 23:39:59&lt;/td&gt;
      &lt;td&gt;US&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;382429&lt;/td&gt;
      &lt;td&gt;1357002072&lt;/td&gt;
      &lt;td&gt;treatment&lt;/td&gt;
      &lt;td&gt;new_page&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2013-01-01 01:01:12&lt;/td&gt;
      &lt;td&gt;CA&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;dfac.groupby(&amp;#39;user_id&amp;#39;).country.count().max()




2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We see that some users have two countries listed.  Since the user country data is not time sensitive, we have to drop them.  We do not know which country they were in at the type of the experiment.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;dfac = dfa.merge(countries.drop_duplicates(&amp;#39;user_id&amp;#39;),on=&amp;#39;user_id&amp;#39;)
print dfac.user_id.count(),dfac.user_id.nunique()
dfbc = dfb.merge(countries.drop_duplicates(&amp;#39;user_id&amp;#39;),on=&amp;#39;user_id&amp;#39;)
print dfbc.user_id.count(),dfbc.user_id.nunique()

92554 92554
87925 87924




p_values = {&amp;#39;US&amp;#39;:[],&amp;#39;CA&amp;#39;:[],&amp;#39;UK&amp;#39;:[]}
effect = {&amp;#39;US&amp;#39;:0,&amp;#39;CA&amp;#39;:0,&amp;#39;UK&amp;#39;:0}
last_effect=0
for i in range(23):
    for country in dfac.country.unique():
    # Grab the hour
        df_houra = dfac[(dfac.dt.dt.hour&amp;lt;=i)&amp;amp;(dfac.country==country)]
        df_hourb = dfbc[(dfbc.dt.dt.hour&amp;lt;=i)&amp;amp;(dfbc.country==country)]

        conA,cntA = df_houra.converted.mean(),df_houra.converted.count()
        conB,cntB = df_hourb.converted.mean(),df_hourb.converted.count()

        p_values[country].append( z_test(conA,conB,cntA,cntB,two_tailed=False,effect_size=0.01*effect[country])[1] )
        effect[country] = conB

plt.figure()
plt.plot(range(23),p_values[&amp;#39;US&amp;#39;],color=&amp;#39;indianred&amp;#39;,alpha=0.8,lw=2,label=&amp;#39;US&amp;#39;)
plt.plot(range(23),p_values[&amp;#39;CA&amp;#39;],color=&amp;#39;blue&amp;#39;,alpha=0.8,lw=2,label=&amp;#39;CA&amp;#39;)
plt.plot(range(23),p_values[&amp;#39;UK&amp;#39;],color=&amp;#39;green&amp;#39;,alpha=0.8,lw=2,label=&amp;#39;UK&amp;#39;)
plt.hlines(0.05,0,23,color=&amp;#39;red&amp;#39;,alpha=0.6,lw=2,linestyle=&amp;#39;--&amp;#39;)
plt.xlabel(&amp;quot;Hours&amp;quot;)
plt.ylabel(&amp;quot;P-values&amp;quot;)
plt.ylim([0,1])
plt.xlim([0,23])
plt.legend()
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D3/output_45_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;If we constructed a hypthoesis at the end of day on Tuesday, the US would look like they were responsive to the new page, but the time plot shows that this could be a cherry-picked value.  If the experiment was allowed to run for more time, or we collect more data, the value would have changed.   It is clear from these plots that the sample sizes are not large enough that a additional data does not heavily influence the result.   I would be hesitant to make any strong conclusions about the new page based on these results.  &lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="ab testing"></category><category term="statistics"></category><category term="hypthesis testing"></category></entry><entry><title>Galvanize - Week 02 - Day 2</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-02-02/" rel="alternate"></link><updated>2015-06-09T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-09:galvanize/galvanize-data-science-02-02/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 2 - Day 2&lt;/h2&gt;
&lt;p&gt;Today we started with a mini-quiz, had a lecture on sampling methods, were given a talk about searching for a job, and finished the day with lecture on estimations/bootstraping and a reinforcement paired programming section.&lt;/p&gt;
&lt;h2&gt;Mini-Quiz&lt;/h2&gt;
&lt;p&gt;The mini-quiz is interesting because it involved using pandas, which I have found to be great and flexible, while also mysterious.&lt;/p&gt;
&lt;p&gt;We were given a salary dataset and asked to make some changes to it and answer some questions.  The first was to read in the data and convert the names to a human readiable text and transform variables to the correct type.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;

&lt;span class="n"&gt;salary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;../estimation-sampling/data/salary_data.csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;salary&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;info&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="nc"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;core&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;frame&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&amp;gt;&lt;/span&gt;
&lt;span class="n"&gt;Int64Index&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;32160&lt;/span&gt; &lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="mi"&gt;32159&lt;/span&gt;
&lt;span class="n"&gt;Data&lt;/span&gt; &lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="n"&gt;name&lt;/span&gt;          &lt;span class="mi"&gt;32160&lt;/span&gt; &lt;span class="n"&gt;non&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;null&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;
&lt;span class="n"&gt;job_title&lt;/span&gt;     &lt;span class="mi"&gt;32160&lt;/span&gt; &lt;span class="n"&gt;non&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;null&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;
&lt;span class="n"&gt;department&lt;/span&gt;    &lt;span class="mi"&gt;32160&lt;/span&gt; &lt;span class="n"&gt;non&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;null&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;
&lt;span class="n"&gt;salary&lt;/span&gt;        &lt;span class="mi"&gt;32160&lt;/span&gt; &lt;span class="n"&gt;non&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;null&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;
&lt;span class="n"&gt;Join&lt;/span&gt; &lt;span class="n"&gt;Date&lt;/span&gt;     &lt;span class="mi"&gt;32160&lt;/span&gt; &lt;span class="n"&gt;non&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;null&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;
&lt;span class="n"&gt;dtypes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;memory&lt;/span&gt; &lt;span class="n"&gt;usage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;1.5&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;MB&lt;/span&gt;



&lt;span class="n"&gt;salary&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;job_title&lt;/th&gt;
      &lt;th&gt;department&lt;/th&gt;
      &lt;th&gt;salary&lt;/th&gt;
      &lt;th&gt;Join Date&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;AARON,  ELVIA J&lt;/td&gt;
      &lt;td&gt;WATER RATE TAKER&lt;/td&gt;
      &lt;td&gt;WATER MGMNT&lt;/td&gt;
      &lt;td&gt;$87228.0&lt;/td&gt;
      &lt;td&gt;2000-09-27 00:00:00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;AARON,  JEFFERY M&lt;/td&gt;
      &lt;td&gt;POLICE OFFICER&lt;/td&gt;
      &lt;td&gt;POLICE&lt;/td&gt;
      &lt;td&gt;$75372.0&lt;/td&gt;
      &lt;td&gt;2000-08-04 00:00:00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;AARON,  KARINA&lt;/td&gt;
      &lt;td&gt;POLICE OFFICER&lt;/td&gt;
      &lt;td&gt;POLICE&lt;/td&gt;
      &lt;td&gt;$75372.0&lt;/td&gt;
      &lt;td&gt;2000-01-20 00:00:00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;AARON,  KIMBERLEI R&lt;/td&gt;
      &lt;td&gt;CHIEF CONTRACT EXPEDITER&lt;/td&gt;
      &lt;td&gt;GENERAL SERVICES&lt;/td&gt;
      &lt;td&gt;$80916.0&lt;/td&gt;
      &lt;td&gt;2000-04-27 00:00:00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;ABAD JR,  VICENTE M&lt;/td&gt;
      &lt;td&gt;CIVIL ENGINEER IV&lt;/td&gt;
      &lt;td&gt;WATER MGMNT&lt;/td&gt;
      &lt;td&gt;$99648.0&lt;/td&gt;
      &lt;td&gt;2000-02-11 00:00:00&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;salary.columns = [&amp;#39;Name&amp;#39;,&amp;#39;Position Title&amp;#39;,&amp;#39;Department&amp;#39;,&amp;#39;Employee Annual Salary&amp;#39;,&amp;#39;Join Date&amp;#39;]
salary.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th&gt;Position Title&lt;/th&gt;
      &lt;th&gt;Department&lt;/th&gt;
      &lt;th&gt;Employee Annual Salary&lt;/th&gt;
      &lt;th&gt;Join Date&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;AARON,  ELVIA J&lt;/td&gt;
      &lt;td&gt;WATER RATE TAKER&lt;/td&gt;
      &lt;td&gt;WATER MGMNT&lt;/td&gt;
      &lt;td&gt;$87228.0&lt;/td&gt;
      &lt;td&gt;2000-09-27 00:00:00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;AARON,  JEFFERY M&lt;/td&gt;
      &lt;td&gt;POLICE OFFICER&lt;/td&gt;
      &lt;td&gt;POLICE&lt;/td&gt;
      &lt;td&gt;$75372.0&lt;/td&gt;
      &lt;td&gt;2000-08-04 00:00:00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;AARON,  KARINA&lt;/td&gt;
      &lt;td&gt;POLICE OFFICER&lt;/td&gt;
      &lt;td&gt;POLICE&lt;/td&gt;
      &lt;td&gt;$75372.0&lt;/td&gt;
      &lt;td&gt;2000-01-20 00:00:00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;AARON,  KIMBERLEI R&lt;/td&gt;
      &lt;td&gt;CHIEF CONTRACT EXPEDITER&lt;/td&gt;
      &lt;td&gt;GENERAL SERVICES&lt;/td&gt;
      &lt;td&gt;$80916.0&lt;/td&gt;
      &lt;td&gt;2000-04-27 00:00:00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;ABAD JR,  VICENTE M&lt;/td&gt;
      &lt;td&gt;CIVIL ENGINEER IV&lt;/td&gt;
      &lt;td&gt;WATER MGMNT&lt;/td&gt;
      &lt;td&gt;$99648.0&lt;/td&gt;
      &lt;td&gt;2000-02-11 00:00:00&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;This is how I traditionally have renamed columns.   I learned a new way that involed using pandas' 'rename' function.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;salary = pd.read_csv(&amp;#39;../estimation-sampling/data/salary_data.csv&amp;#39;)
salary.rename(columns={&amp;#39;name&amp;#39;: &amp;#39;Name&amp;#39;,
                  &amp;#39;job_title&amp;#39;: &amp;#39;Position Title&amp;#39;,
                  &amp;#39;department&amp;#39;:&amp;#39;Department&amp;#39;,
                  &amp;#39;salary&amp;#39;:&amp;#39;Employee Annual Salary&amp;#39;,
                   &amp;#39;join_data&amp;#39;: &amp;#39;Join Date&amp;#39;},
                   inplace=True)
salary.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th&gt;Position Title&lt;/th&gt;
      &lt;th&gt;Department&lt;/th&gt;
      &lt;th&gt;Employee Annual Salary&lt;/th&gt;
      &lt;th&gt;Join Date&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;AARON,  ELVIA J&lt;/td&gt;
      &lt;td&gt;WATER RATE TAKER&lt;/td&gt;
      &lt;td&gt;WATER MGMNT&lt;/td&gt;
      &lt;td&gt;$87228.0&lt;/td&gt;
      &lt;td&gt;2000-09-27 00:00:00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;AARON,  JEFFERY M&lt;/td&gt;
      &lt;td&gt;POLICE OFFICER&lt;/td&gt;
      &lt;td&gt;POLICE&lt;/td&gt;
      &lt;td&gt;$75372.0&lt;/td&gt;
      &lt;td&gt;2000-08-04 00:00:00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;AARON,  KARINA&lt;/td&gt;
      &lt;td&gt;POLICE OFFICER&lt;/td&gt;
      &lt;td&gt;POLICE&lt;/td&gt;
      &lt;td&gt;$75372.0&lt;/td&gt;
      &lt;td&gt;2000-01-20 00:00:00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;AARON,  KIMBERLEI R&lt;/td&gt;
      &lt;td&gt;CHIEF CONTRACT EXPEDITER&lt;/td&gt;
      &lt;td&gt;GENERAL SERVICES&lt;/td&gt;
      &lt;td&gt;$80916.0&lt;/td&gt;
      &lt;td&gt;2000-04-27 00:00:00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;ABAD JR,  VICENTE M&lt;/td&gt;
      &lt;td&gt;CIVIL ENGINEER IV&lt;/td&gt;
      &lt;td&gt;WATER MGMNT&lt;/td&gt;
      &lt;td&gt;$99648.0&lt;/td&gt;
      &lt;td&gt;2000-02-11 00:00:00&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;I personally do not like these names for the columns because they involve spaces.   That removes the ability to us the pd.variable notation.   &lt;/p&gt;
&lt;p&gt;I have also found multiple ways to update a variable type.  I am still not sure if there is a better method.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;salary[&amp;#39;Employee Annual Salary&amp;#39;] = salary[&amp;#39;Employee Annual Salary&amp;#39;].str.replace(&amp;quot;$&amp;quot;,&amp;quot;&amp;quot;).astype(float)
salary[&amp;#39;Join Date&amp;#39;] = pd.to_datetime(salary[&amp;#39;Join Date&amp;#39;])
salary.info()

&amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;
Int64Index: 32160 entries, 0 to 32159
Data columns (total 5 columns):
Name                      32160 non-null object
Position Title            32160 non-null object
Department                32160 non-null object
Employee Annual Salary    32160 non-null float64
Join Date                 32160 non-null datetime64[ns]
dtypes: datetime64[ns](1), float64(1), object(3)
memory usage: 1.5+ MB
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now that we have the data in the correct format, we can now answer questions about the dataset.  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;What are the top 5 paying job titles?&lt;/li&gt;
&lt;li&gt;How many people have "Police" in their title?&lt;/li&gt;
&lt;li&gt;What fraction of the people in 2 are a 'Police Officer'&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How many people were hired from July 30, 2000 to Aug 08, 2000&lt;/p&gt;
&lt;p&gt;salary.groupby('Position Title')['Employee Annual Salary'].mean().order(ascending=False).head()&lt;/p&gt;
&lt;p&gt;Position Title
SUPERINTENDENT OF POLICE          260004
MAYOR                             216210
FIRE COMMISSIONER                 202728
FIRST DEPUTY SUPERINTENDENT       188316
FIRST DEPUTY FIRE COMMISSIONER    188316
Name: Employee Annual Salary, dtype: float64&lt;/p&gt;
&lt;p&gt;print "Contains 'POLICE': ", salary[salary['Position Title'].str.contains('POLICE')]['Position Title'].count()
salary[salary['Position Title'].str.contains('POLICE')]['Position Title'].value_counts(normalize=True)&lt;/p&gt;
&lt;p&gt;Contains 'POLICE':  11141&lt;/p&gt;
&lt;p&gt;POLICE OFFICER                                      0.847051
POLICE OFFICER (ASSIGNED AS DETECTIVE)              0.076025
POLICE COMMUNICATIONS OPERATOR II                   0.019747
POLICE COMMUNICATIONS OPERATOR I                    0.012925
POLICE OFFICER / FLD TRNG OFFICER                   0.010232
POLICE OFFICER (ASSIGNED AS EVIDENCE TECHNICIAN)    0.006463
POLICE OFFICER/EXPLSV DETECT K9 HNDLR               0.003590
POLICE OFFICER (ASGND AS MARINE OFFICER)            0.002783
POLICE CADET                                        0.002603
ELECTRICAL MECHANIC-AUTO-POLICE MTR MNT             0.002423
MACHINIST (AUTO) POLICE MOTOR MAINT                 0.002244
POLICE OFFICER (ASSIGNED AS CANINE HANDLER)         0.001885
POLICE OFFICER (ASSIGNED AS TRAFFIC SPECIALIST)     0.001795
SUPERVISING POLICE COMMUNICATIONS OPERATOR          0.001616
POLICE OFFICER (ASGND AS MOUNTED PATROL OFFICER)    0.001346
POLICE OFFICER (ASSIGNED AS SECURITY SPECIALIST)    0.001346
POLICE AGENT                                        0.001167
POLICE FORENSIC INVESTIGATOR I                      0.001077
POLICE OFFICER(ASGND AS LATENT PRINT EX)            0.000987
POLICE OFFICER (PER ARBITRATION AWARD)              0.000898
POLICE TECHNICIAN                                   0.000539
POLICE LEGAL OFFICER II                             0.000359
POLICE LEGAL OFFICER I                              0.000269
DIR OF POLICE RECORDS                               0.000090
MANAGER OF POLICE PAYROLLS                          0.000090
POLICE OFFICER(ASGND AS SUPVG LATENT PRINT EX)      0.000090
EXECUTIVE DIR - POLICE BOARD                        0.000090
SUPERINTENDENT OF POLICE                            0.000090
ASST SUPVSR OF POLICE RECORDS                       0.000090
MANAGER OF POLICE PERSONNEL                         0.000090
dtype: float64&lt;/p&gt;
&lt;p&gt;salary.set_index('Join Date',inplace=True)
salary.head()&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th&gt;Position Title&lt;/th&gt;
      &lt;th&gt;Department&lt;/th&gt;
      &lt;th&gt;Employee Annual Salary&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Join Date&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;2000-09-27&lt;/th&gt;
      &lt;td&gt;AARON,  ELVIA J&lt;/td&gt;
      &lt;td&gt;WATER RATE TAKER&lt;/td&gt;
      &lt;td&gt;WATER MGMNT&lt;/td&gt;
      &lt;td&gt;87228&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2000-08-04&lt;/th&gt;
      &lt;td&gt;AARON,  JEFFERY M&lt;/td&gt;
      &lt;td&gt;POLICE OFFICER&lt;/td&gt;
      &lt;td&gt;POLICE&lt;/td&gt;
      &lt;td&gt;75372&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2000-01-20&lt;/th&gt;
      &lt;td&gt;AARON,  KARINA&lt;/td&gt;
      &lt;td&gt;POLICE OFFICER&lt;/td&gt;
      &lt;td&gt;POLICE&lt;/td&gt;
      &lt;td&gt;75372&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2000-04-27&lt;/th&gt;
      &lt;td&gt;AARON,  KIMBERLEI R&lt;/td&gt;
      &lt;td&gt;CHIEF CONTRACT EXPEDITER&lt;/td&gt;
      &lt;td&gt;GENERAL SERVICES&lt;/td&gt;
      &lt;td&gt;80916&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2000-02-11&lt;/th&gt;
      &lt;td&gt;ABAD JR,  VICENTE M&lt;/td&gt;
      &lt;td&gt;CIVIL ENGINEER IV&lt;/td&gt;
      &lt;td&gt;WATER MGMNT&lt;/td&gt;
      &lt;td&gt;99648&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;salary.ix[&amp;#39;2000-07-13&amp;#39; : &amp;#39;2000-08-13&amp;#39;].count()




Name                      2866
Position Title            2866
Department                2866
Employee Annual Salary    2866
dtype: int64
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Morning Sprint&lt;/h2&gt;
&lt;p&gt;The individual morning sprint covered sampling and estimation.   We were given a dataset on rain fall and attempted to use &lt;a href="http://en.wikipedia.org/wiki/Method_of_moments_%28statistics%29"&gt;Method of Moments&lt;/a&gt; estimates on the data to approximate the distributions.  We then followed up by looking at &lt;a href="http://en.wikipedia.org/wiki/Maximum_likelihood"&gt;Maximum Likelihood Estimates&lt;/a&gt; of the parameters.  &lt;/p&gt;
&lt;p&gt;I first looked at the data for January rainfall over the course of several years.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;data = pd.read_csv(&amp;quot;../estimation-sampling/data/rainfall.csv&amp;quot;)
print data.info()

&amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;
Int64Index: 140 entries, 0 to 139
Data columns (total 13 columns):
Year    140 non-null int64
Jan     140 non-null float64
Feb     140 non-null float64
Mar     140 non-null float64
Apr     140 non-null float64
May     140 non-null float64
Jun     140 non-null float64
Jul     140 non-null float64
Aug     140 non-null float64
Sep     140 non-null float64
Oct     140 non-null float64
Nov     140 non-null float64
Dec     140 non-null float64
dtypes: float64(12), int64(1)
memory usage: 15.3 KB
None



data.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Year&lt;/th&gt;
      &lt;th&gt;Jan&lt;/th&gt;
      &lt;th&gt;Feb&lt;/th&gt;
      &lt;th&gt;Mar&lt;/th&gt;
      &lt;th&gt;Apr&lt;/th&gt;
      &lt;th&gt;May&lt;/th&gt;
      &lt;th&gt;Jun&lt;/th&gt;
      &lt;th&gt;Jul&lt;/th&gt;
      &lt;th&gt;Aug&lt;/th&gt;
      &lt;th&gt;Sep&lt;/th&gt;
      &lt;th&gt;Oct&lt;/th&gt;
      &lt;th&gt;Nov&lt;/th&gt;
      &lt;th&gt;Dec&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1871&lt;/td&gt;
      &lt;td&gt;2.76&lt;/td&gt;
      &lt;td&gt;4.58&lt;/td&gt;
      &lt;td&gt;5.01&lt;/td&gt;
      &lt;td&gt;4.13&lt;/td&gt;
      &lt;td&gt;3.30&lt;/td&gt;
      &lt;td&gt;2.98&lt;/td&gt;
      &lt;td&gt;1.58&lt;/td&gt;
      &lt;td&gt;2.36&lt;/td&gt;
      &lt;td&gt;0.95&lt;/td&gt;
      &lt;td&gt;1.31&lt;/td&gt;
      &lt;td&gt;2.13&lt;/td&gt;
      &lt;td&gt;1.65&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1872&lt;/td&gt;
      &lt;td&gt;2.32&lt;/td&gt;
      &lt;td&gt;2.11&lt;/td&gt;
      &lt;td&gt;3.14&lt;/td&gt;
      &lt;td&gt;5.91&lt;/td&gt;
      &lt;td&gt;3.09&lt;/td&gt;
      &lt;td&gt;5.17&lt;/td&gt;
      &lt;td&gt;6.10&lt;/td&gt;
      &lt;td&gt;1.65&lt;/td&gt;
      &lt;td&gt;4.50&lt;/td&gt;
      &lt;td&gt;1.58&lt;/td&gt;
      &lt;td&gt;2.25&lt;/td&gt;
      &lt;td&gt;2.38&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;1873&lt;/td&gt;
      &lt;td&gt;2.96&lt;/td&gt;
      &lt;td&gt;7.14&lt;/td&gt;
      &lt;td&gt;4.11&lt;/td&gt;
      &lt;td&gt;3.59&lt;/td&gt;
      &lt;td&gt;6.31&lt;/td&gt;
      &lt;td&gt;4.20&lt;/td&gt;
      &lt;td&gt;4.63&lt;/td&gt;
      &lt;td&gt;2.36&lt;/td&gt;
      &lt;td&gt;1.81&lt;/td&gt;
      &lt;td&gt;4.28&lt;/td&gt;
      &lt;td&gt;4.36&lt;/td&gt;
      &lt;td&gt;5.94&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;1874&lt;/td&gt;
      &lt;td&gt;5.22&lt;/td&gt;
      &lt;td&gt;9.23&lt;/td&gt;
      &lt;td&gt;5.36&lt;/td&gt;
      &lt;td&gt;11.84&lt;/td&gt;
      &lt;td&gt;1.49&lt;/td&gt;
      &lt;td&gt;2.87&lt;/td&gt;
      &lt;td&gt;2.65&lt;/td&gt;
      &lt;td&gt;3.52&lt;/td&gt;
      &lt;td&gt;3.12&lt;/td&gt;
      &lt;td&gt;2.63&lt;/td&gt;
      &lt;td&gt;6.12&lt;/td&gt;
      &lt;td&gt;4.19&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;1875&lt;/td&gt;
      &lt;td&gt;6.15&lt;/td&gt;
      &lt;td&gt;3.06&lt;/td&gt;
      &lt;td&gt;8.14&lt;/td&gt;
      &lt;td&gt;4.22&lt;/td&gt;
      &lt;td&gt;1.73&lt;/td&gt;
      &lt;td&gt;5.63&lt;/td&gt;
      &lt;td&gt;8.12&lt;/td&gt;
      &lt;td&gt;1.60&lt;/td&gt;
      &lt;td&gt;3.79&lt;/td&gt;
      &lt;td&gt;1.25&lt;/td&gt;
      &lt;td&gt;5.46&lt;/td&gt;
      &lt;td&gt;4.30&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure()
data.Jan.hist(bins=30,color=&amp;#39;red&amp;#39;,alpha=.2)
plt.title(&amp;quot;Rain Fall In Janary For All Years&amp;quot;)
plt.xlabel(&amp;quot;Rain Values&amp;quot;)
plt.ylabel(&amp;quot;Count&amp;quot;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_16_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;To me this looks like it could be well fitted by a &lt;a href="http://en.wikipedia.org/wiki/Poisson_distribution"&gt;Poisson distribution&lt;/a&gt; or a &lt;a href="http://en.wikipedia.org/wiki/Gamma_distribution"&gt;Gamma distribution&lt;/a&gt;.   A poisson distribution models random events occuring in a fixed time interval, and is a discreate distribution.  Gamma distributions are a continuous distribution that model how long one must way for N events to happen.   That seems like a better framework to think about rain fall.&lt;/p&gt;
&lt;p&gt;The mean and variance for a Poisson distribution is the lambda parameter:&lt;/p&gt;
&lt;p&gt;$$\mu = \lambda$$&lt;/p&gt;
&lt;p&gt;So we will use this to see the fit.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;scipy.stats&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sc&lt;/span&gt;

&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Jan&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;var&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Jan&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;var&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;var&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;poisson&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pmf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Jan&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bins&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;red&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=.&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;normed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Jan Rain&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;red&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Poisson Fit&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Rain Fall In Janary For All Years&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Rain Values&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Count&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="mf"&gt;4.54457142857&lt;/span&gt; &lt;span class="mf"&gt;6.91677463515&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_18_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;This gives a fair fit to the distribution for january.   I want to compare this with the gama distribution.&lt;/p&gt;
&lt;p&gt;The gamma function is given by:&lt;/p&gt;
&lt;p&gt;$$X = Gamma(\alpha \ ,\beta) = \frac{\beta^\alpha \ x^{\alpha-1} \ e^{-\beta x}}{\Gamma(\alpha)}$$&lt;/p&gt;
&lt;p&gt;The mean and variance of the gamma distribution is given by&lt;/p&gt;
&lt;p&gt;$$\mu = \frac{\alpha}{\beta}$$&lt;/p&gt;
&lt;p&gt;$$\sigma^2 = \frac{\alpha}{\beta^2}$$&lt;/p&gt;
&lt;p&gt;So the estimate of alpha and beta are given by:&lt;/p&gt;
&lt;p&gt;$$\beta = \frac{\mu}{\sigma^2}$$&lt;/p&gt;
&lt;p&gt;$$\alpha = \frac{\mu^2}{\sigma^2}$$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;beta = mean/var
alpha = mean**2/var
print alpha,beta
x1 = np.linspace(0,16,100)
y1 = sc.gamma.pdf(x1,alpha,scale=1/beta)
plt.figure()
data.Jan.hist(bins=30,color=&amp;#39;red&amp;#39;,alpha=.2,normed=True,label=&amp;#39;Jan Rain&amp;#39;)
plt.plot(x,y,color=&amp;#39;red&amp;#39;,linestyle=&amp;#39;--&amp;#39;,label=&amp;#39;Poisson Fit&amp;#39;)
plt.plot(x1,y1,color=&amp;#39;red&amp;#39;,label=&amp;#39;Gamma Fit&amp;#39;,linestyle=&amp;#39;-&amp;#39;)
plt.title(&amp;quot;Rain Fall In Janary For All Years&amp;quot;)
plt.xlabel(&amp;quot;Rain Values&amp;quot;)
plt.ylabel(&amp;quot;Count&amp;quot;)
plt.legend()
plt.show()

2.98594801173 0.65703621533
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_20_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;The Gamma distribution fit matches the distribution's peak and tail better than the Poisson distribution fit.  There are method's to test the relative fit but I saved that for another day.&lt;/p&gt;
&lt;p&gt;Now lets look at the Gamma fits for all months.  The reason we bin by months is that we have the prior that rain and weather is season.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;f, axarr = plt.subplots(3, 4,figsize=(14, 8))

x = np.linspace(0,16,100)
for i,month in enumerate(data.columns[1:]):
    mean = data[month].mean()
    var = data[month].var()
    alpha = mean**2/var
    beta = mean/var
    y = sc.gamma.pdf(x,alpha,scale=1/beta)
    axarr[i/4,i%4].hist(data[month],bins=20,color=&amp;#39;red&amp;#39;,alpha=0.25,normed=True)
    axarr[i/4,i%4].set_xlim([0,20])
    axarr[i/4,i%4].set_ylim([0,.35])
    axarr[i/4,i%4].set_xlabel(&amp;quot;Rain Fall&amp;quot;)
    axarr[i/4,i%4].set_ylabel(&amp;quot;Prob Density&amp;quot;)
    axarr[i/4,i%4].set_title(month)
    axarr[i/4,i%4].plot(x,y,label=&amp;quot;Gamma Fit&amp;quot;,color=&amp;#39;red&amp;#39;)
    label = &amp;#39;alpha = %.2f\nbeta = %.2f&amp;#39; % (alpha, beta)
    axarr[i/4,i%4].annotate(label, xy=(4, 0.25))

plt.tight_layout()
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_22_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We have a Method of Moments fit of the gamma distribution of rainfall for each month.   Now lets doo Maximum Likely Hood.  &lt;/p&gt;
&lt;p&gt;First we need to make a funciton.  In order to test the method I will try it on a poisson generated dataset.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def poisson_likelihood(x, lam):
    return sc.poisson.pmf(x,lam)

##produces the probabilty of of each lambda(lam) given a value of 6
plt.plot(range(1,20),[poisson_likelihood(6, lam) for lam in range(1,20)])
plt.xlabel(&amp;quot;Lambda Value&amp;quot;)
plt.ylabel(&amp;quot;Probability of Lambda Value Given x=6&amp;quot;)




&amp;lt;matplotlib.text.Text at 0x10c5d0290&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_24_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;This make sense because the maximum likelihood is 6, but there are still changes that the value is different.  Lets run this on the data now.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;p_data = pd.read_csv(&amp;#39;../estimation-sampling/data/poisson.txt&amp;#39;,header=None)
p_data.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;0&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;x_values = np.linspace(1,20,1000)
likelihoods = np.array([np.log(poisson_likelihood(p_data.values[:,0],i)).sum() for i in x_values])
plt.plot(x_values,likelihoods)
plt.ylabel(&amp;quot;Log Likelyhood For Lambda Fro Data&amp;quot;)
plt.xlabel(&amp;quot;Lambda Values&amp;quot;)




&amp;lt;matplotlib.text.Text at 0x10c67f090&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_27_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;We want to compare the maximum likelihood (argmax) of this distribution to the mean fo the data since the mean of Poisson distribution should be the lambda parameter.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x_values[likelihoods.argmax()],p_data.mean()




(5.0510510510510516, 0    5.0437
 dtype: float64)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The maximum likelihood estimate of the lambda parameter is very close to the sample mean, which also matches the value of lambda used to generated the data ($$\lambda = 5$$).&lt;/p&gt;
&lt;p&gt;Scipy Stats has a fit function for each of the distributions that uses the maximum likelihood method.   I want to compare the plots the difference between the fits of the Method of Moments and the Maximum Likelihood.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;mean = data.Jan.mean()
var = data.Jan.var()
beta = mean/var
alpha = mean**2/var

x1 = np.linspace(0,16,100)
y1 = sc.gamma.pdf(x1,alpha,scale=1./beta)
alpha_MLE,loc_MFL,one_over_beta_MLE = sc.gamma.fit(data.Jan,floc=0) #Loc = 0 - no rainfall minimum
y2 = sc.gamma.pdf(x1,alpha_MLE,scale=one_over_beta_MLE)
plt.figure()
data.Jan.hist(bins=30,color=&amp;#39;red&amp;#39;,alpha=.2,normed=True,label=&amp;#39;Jan Rain&amp;#39;)
plt.plot(x1,y1,color=&amp;#39;red&amp;#39;,label=&amp;#39;Gamma Fit (MoM)&amp;#39;,linestyle=&amp;#39;--&amp;#39;)
plt.plot(x1,y2,color=&amp;#39;red&amp;#39;,label=&amp;#39;Gamma Fit (MLE)&amp;#39;,linestyle=&amp;#39;-&amp;#39;)
plt.title(&amp;quot;Rain Fall In Janary For All Years&amp;quot;)
plt.xlabel(&amp;quot;Rain Values&amp;quot;)
plt.ylabel(&amp;quot;Count&amp;quot;)
plt.legend()
plt.show()
print alpha, alpha_MLE
print beta, beta_MLE

2.98594801173 0.65703621533
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_31_1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;2.98594801173 3.25219914651
0.65703621533 1.39738411574
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can see the two distributions are similar, but slightly different.   The MLE is more skewed right, and the MLE fits are larger then the method of moments.  I just want to finish this section with a plot of all the months.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure()
f, axarr = plt.subplots(3, 4,figsize=(14, 10))
x = np.linspace(0,16,100)
for i,month in enumerate(data.columns[1:]):
    mean = data[month].mean()
    var = data[month].var()
    alpha = mean**2/var
    beta = mean/var
    fits = sc.gamma.fit(data[month],floc=0)
    alpha_fit = fits[0]
    beta_fit = 1./fits[2]
    y = sc.gamma.pdf(x,alpha,scale=1./beta)
    y1 = sc.gamma.pdf(x,alpha_fit,scale=1./beta_fit)
    print month, alpha, alpha_fit, beta, beta_fit
    axarr[i/4,i%4].hist(data[month],bins=20,color=&amp;#39;red&amp;#39;,alpha=0.25,normed=True)
    axarr[i/4,i%4].set_xlim([0,20])
    axarr[i/4,i%4].set_ylim([0,.35])
    axarr[i/4,i%4].set_xlabel(&amp;quot;Rain Fall&amp;quot;)
    axarr[i/4,i%4].set_ylabel(&amp;quot;Prob Density&amp;quot;)
    axarr[i/4,i%4].set_title(month)
    axarr[i/4,i%4].plot(x,y,label=&amp;quot;MOD&amp;quot;,linestyle=&amp;#39;-&amp;#39;,color=&amp;#39;red&amp;#39;,lw=3,alpha=0.5)
    axarr[i/4,i%4].plot(x,y1,label=&amp;quot;MLE&amp;quot;,linestyle=&amp;#39;--&amp;#39;,color=&amp;#39;green&amp;#39;,lw=3,alpha=0.5)
    axarr[i/4,i%4].legend()

plt.tight_layout()
plt.show()

Jan 2.98594801173 3.25219914651 0.65703621533 0.715622847528
Feb 3.0418721755 3.0803224672 0.740681272732 0.750043734186
Mar 4.67867768543 4.64576013378 0.946813252137 0.94015180285
Apr 4.28032831959 4.25175417646 1.01660157558 1.00981505905
May 3.53902182175 3.82055049055 0.815644176548 0.880528551612
Jun 2.97083704473 2.89974494499 0.765862938963 0.747535846757
Jul 3.98358361758 3.6314371778 1.02531889482 0.934681309897
Aug 3.02948804114 3.20185713476 0.907886646459 0.959542766645
Sep 2.29238948802 2.14489278382 0.678766821038 0.635093671449
Oct 2.46786112353 1.96116795936 0.945359556993 0.751261428601
Nov 3.69539855825 3.30306402837 1.00014653216 0.893962581139
Dec 3.23590721109 3.52396472416 0.77216125712 0.840898349041



&amp;lt;matplotlib.figure.Figure at 0x10c387e10&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_33_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;For each moths the distributions are similar, but like january the alpha and beta values are different. &lt;/p&gt;
&lt;h2&gt;Kernal Density Estimates&lt;/h2&gt;
&lt;p&gt;The last topic we had was to use the non-parametric method for fitting a distributions using gaussian kernal density estimates.   The idea is that each data point is fit with a gausian for some unknown variance, and the variance is shared for each such gaussian.   The variance paramenter is adjusted until an 'optimal' fit is found.&lt;/p&gt;
&lt;p&gt;We can do this with an example by convoluting two gaussian data sets.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;data2 = [sc.norm.rvs(loc=0,scale=2) for x in range(500)]+[sc.norm.rvs(loc=4,scale=1) for x in range(400)]
plt.figure()
plt.hist(data,bins=30,color=&amp;#39;red&amp;#39;,alpha=0.2)
plt.xlabel(&amp;quot;Values&amp;quot;)
plt.ylabel(&amp;quot;Counts&amp;quot;)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_35_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;fit = sc.gaussian_kde(data2)
plt.figure()
plt.hist(data,bins=30,normed=True,alpha=0.2)
x=np.linspace(-6,8,100)
plt.plot(x,fit(x),color=&amp;#39;blue&amp;#39;,label=&amp;#39;KDE Fit&amp;#39;)
plt.xlabel(&amp;quot;Values&amp;quot;)
plt.ylabel(&amp;quot;Counts&amp;quot;)
plt.legend()
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_36_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;The fit function can be used for a density estimate when we do not wish to model the data with a particlar model.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plt.figure()
f, axarr = plt.subplots(3, 4,figsize=(14, 10))
x = np.linspace(0,16,100)
for i,month in enumerate(data.columns[1:]):
    mean = data[month].mean()
    var = data[month].var()
    alpha = mean**2/var
    beta = mean/var
    fits = sc.gamma.fit(data[month],floc=0)
    alpha_fit = fits[0]
    beta_fit = 1./fits[2]
    y = sc.gamma.pdf(x,alpha,scale=1./beta)
    y1 = sc.gamma.pdf(x,alpha_fit,scale=1./beta_fit)
    gfit = sc.gaussian_kde(data[month])
    yg = gfit(x)
    axarr[i/4,i%4].hist(data[month],bins=20,color=&amp;#39;red&amp;#39;,alpha=0.25,normed=True)
    axarr[i/4,i%4].set_xlim([0,20])
    axarr[i/4,i%4].set_ylim([0,.35])
    axarr[i/4,i%4].set_xlabel(&amp;quot;Rain Fall&amp;quot;)
    axarr[i/4,i%4].set_ylabel(&amp;quot;Prob Density&amp;quot;)
    axarr[i/4,i%4].set_title(month)
    axarr[i/4,i%4].plot(x,y,label=&amp;quot;MOD&amp;quot;,linestyle=&amp;#39;-&amp;#39;,color=&amp;#39;red&amp;#39;,lw=3,alpha=0.5)
    axarr[i/4,i%4].plot(x,y1,label=&amp;quot;MLE&amp;quot;,linestyle=&amp;#39;--&amp;#39;,color=&amp;#39;green&amp;#39;,lw=3,alpha=0.5)
    axarr[i/4,i%4].plot(x,y2,label=&amp;quot;KDE&amp;quot;,linestyle=&amp;#39;--&amp;#39;,color=&amp;#39;blue&amp;#39;,lw=3,alpha=0.5)
    axarr[i/4,i%4].legend()

plt.tight_layout()
plt.show()


&amp;lt;matplotlib.figure.Figure at 0x10c65e490&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_38_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;In each case the non-KDE function seem tot fit the data better, but it could be used to for other estimates if we did not have a model.&lt;/p&gt;
&lt;h2&gt;Paired Programming&lt;/h2&gt;
&lt;p&gt;In the afternoon session we had to investigate the centeral limit theorem, produce confidence intervals, and attempt some bootstrapping estimates&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def make_draws(distribution, parameters, size):
    &amp;#39;&amp;#39;&amp;#39;
        returns distribrution or None if valid distribution is not selected
    &amp;#39;&amp;#39;&amp;#39;    
    dist = None

    if distribution.lower() == &amp;#39;binomial&amp;#39;:
        n, p = parameters[&amp;#39;n&amp;#39;], parameters[&amp;#39;p&amp;#39;]
        dist = sc.binom(n, p).rvs(size)

    elif distribution.lower() == &amp;#39;exponential&amp;#39;:
        l = parameters[&amp;#39;lambda&amp;#39;]
        dist = sc.expon(scale = l).rvs(size)

    elif distribution.lower() == &amp;#39;poisson&amp;#39;:
        l = parameters[&amp;#39;lambda&amp;#39;]
        dist = sc.poisson(mu=l).rvs(size)

    elif distribution.lower() == &amp;#39;gamma&amp;#39;:
        a, b = parameters[&amp;#39;alpha&amp;#39;],parameters[&amp;#39;beta&amp;#39;]
        dist = sc.gamma(a=a,scale=1./b).rvs(size)

    elif distribution.lower() == &amp;#39;normal&amp;#39;:
        mean, var = parameters[&amp;#39;mean&amp;#39;], parameters[&amp;#39;var&amp;#39;]
        dist = sc.norm(loc=mean, scale=var).rvs(size)

    elif distribution.lower() == &amp;#39;uniform&amp;#39;:
        low, high = parameters[&amp;#39;low&amp;#39;], parameters[&amp;#39;high&amp;#39;]
        dist = sc.uniform(loc=low, scale=(high-low)).rvs(size)

    return dist

def plot_means(distribution, parameters, size, repeat):
    arr = []
    for r in range(repeat):
        arr.append(make_draws(distribution, parameters, size).mean())
    plt.figure()
    plt.title(&amp;quot;Centeral Limit Theorem: &amp;quot; + distribution + &amp;quot; for N = &amp;quot; + str(size))
    plt.hist(arr, normed=1,bins=100)
    plt.show()

plot_means(&amp;#39;poisson&amp;#39;, {&amp;#39;lambda&amp;#39;:10}, 10, 5000)
plot_means(&amp;#39;poisson&amp;#39;, {&amp;#39;lambda&amp;#39;:10}, 200, 5000)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_41_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_41_1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plot_means(&amp;#39;binomial&amp;#39;, {&amp;#39;n&amp;#39;:10,&amp;#39;p&amp;#39;:0.1}, 10, 5000)
plot_means(&amp;#39;binomial&amp;#39;, {&amp;#39;n&amp;#39;:10,&amp;#39;p&amp;#39;:0.1}, 200, 5000)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_42_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_42_1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plot_means(&amp;#39;exponential&amp;#39;, {&amp;#39;lambda&amp;#39;:10}, 10, 5000)
plot_means(&amp;#39;exponential&amp;#39;, {&amp;#39;lambda&amp;#39;:10}, 200, 5000)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_43_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_43_1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plot_means(&amp;#39;gamma&amp;#39;, {&amp;#39;alpha&amp;#39;:10,&amp;#39;beta&amp;#39;:0.1}, 10, 5000)
plot_means(&amp;#39;gamma&amp;#39;, {&amp;#39;alpha&amp;#39;:10,&amp;#39;beta&amp;#39;:0.1}, 200, 5000)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_44_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_44_1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plot_means(&amp;#39;normal&amp;#39;, {&amp;#39;mean&amp;#39;:10,&amp;#39;var&amp;#39;:0.1}, 10, 5000)
plot_means(&amp;#39;normal&amp;#39;, {&amp;#39;mean&amp;#39;:10,&amp;#39;var&amp;#39;:0.1}, 200, 5000)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_45_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_45_1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;plot_means(&amp;#39;uniform&amp;#39;, {&amp;#39;low&amp;#39;:10,&amp;#39;high&amp;#39;:20}, 10, 5000)
plot_means(&amp;#39;uniform&amp;#39;, {&amp;#39;low&amp;#39;:10,&amp;#39;high&amp;#39;:20}, 200, 5000)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_46_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_46_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;Looking at these distirubtions we see that for N = 10, espeicaly for the discrete distriubiton, that the sampling distirubiton of the mean is not normal.   If the underlying distribution is skewed, so is the sampling distribution.  If we look at means of samples of size 200, the central limit theorm holds and the sampling distribution is normal even if the underlying distribution is skewed or discrete.  &lt;/p&gt;
&lt;p&gt;The central limit theorm does not hold for all statistics.  We can look at the max, for instance.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def plot_max(distribution, parameters, size, repeat):
    arr = []
    for r in range(repeat):
        arr.append(make_draws(distribution, parameters, size).max())
    plt.figure()
    plt.hist(arr, normed=1,bins=100)
    plt.show()

plot_max(&amp;#39;poisson&amp;#39;, {&amp;#39;lambda&amp;#39;:10}, 200, 5000)
plot_max(&amp;#39;binomial&amp;#39;, {&amp;#39;n&amp;#39;:10,&amp;#39;p&amp;#39;:0.1}, 200, 5000)
plot_max(&amp;#39;exponential&amp;#39;, {&amp;#39;lambda&amp;#39;:10}, 200, 5000)
plot_max(&amp;#39;gamma&amp;#39;, {&amp;#39;alpha&amp;#39;:10,&amp;#39;beta&amp;#39;:0.1}, 200, 5000)
plot_max(&amp;#39;normal&amp;#39;, {&amp;#39;mean&amp;#39;:10,&amp;#39;var&amp;#39;:0.1}, 200, 5000)
plot_max(&amp;#39;uniform&amp;#39;, {&amp;#39;low&amp;#39;:5, &amp;#39;high&amp;#39;:10}, 200, 5000)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_48_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_48_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_48_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_48_3.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_48_4.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_48_5.png" /&gt;&lt;/p&gt;
&lt;p&gt;These distributions are clearly not normally distributed, and the discrete distribution results remain discrete.&lt;/p&gt;
&lt;h3&gt;Population Inference and Confidence Interval&lt;/h3&gt;
&lt;p&gt;Our next section had to do with constructing confidence intervals on means for different situations.   We were given some lunch data, and attempted to construct the confidence interval for the mean lunch break.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;lunch_hour = np.loadtxt(&amp;#39;../estimation-sampling/data/lunch_hour.txt&amp;#39;)
plt.figure()
plt.hist(lunch_hour)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_50_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;There are 25 data points in the data.   Even though this distrubtion is not normal, the sampling distribution of the mean should be approching a normal distribution.  &lt;/p&gt;
&lt;p&gt;The standard deviation of the sampling distirubiton is suppose to be well approximated by the standard error of the sample.&lt;/p&gt;
&lt;p&gt;$$s = \sqrt{ \frac{\Sigma_{i}(x_i \ - \ \bar{x})^2}{N-1} }$$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;se = lunch_hour.std(ddof=1) / np.sqrt( len(lunch_hour) )
se, sc.sem(lunch_hour) ##scipy standard error comparison




(0.040925827625524797, 0.040925827625524797)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Using this standard error we can attempt to construct the confidence interval on the population mean.  We choose Z=1.96 for a 95% confidence interval&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;lm = lunch_hour.mean()
(ci_95_low, ci_95_hi) = (lm-1.96*se,lm+1.96*se)
(ci_95_low, ci_95_hi)




(2.1042853778539716, 2.264714622146029)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The 95% confidence interval interpretation is that 95% of the confidence intervals constructed through this method will contrain the population mean lunch hour.   If the sample size was smaller, the both the standard error and normal approximation would change in a way that would not allow this method to work.   &lt;/p&gt;
&lt;p&gt;For smaller sample sizes we would want to try another method.  Bootstrapping could be effective.&lt;/p&gt;
&lt;p&gt;Bootstrapping does not assume normality, or more any assumptions about the underlying distribution.   It is a non-parametric method of constructiong an confidence interval.   If the distribution is well approximateldy by some common distribution, the bootstrapped CI will overestimate the boundaries compared to this distribution.  &lt;/p&gt;
&lt;p&gt;We will try this for another data set involving productivity.&lt;/p&gt;
&lt;h3&gt;Bootstraping&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;productivity = np.loadtxt(&amp;#39;../estimation-sampling/data/productivity.txt&amp;#39;)
productivity




array([-19.1, -15.2, -12.4, -15.4,  -8.7,  -6.7,  -5.9,  -3.5,  -3.1,
        -2.1,   4.2,   6.1,   7. ,   9.1,  10. ,  10.3,  13.2,  10.1,
        14.1,  14.4,  20.1,  26.3,  27.7,  22.2,  23.4])
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Because the sample size is large enough, we would expect the centeral limit to hold.  Lets see if the boot strapping gives similar values.  If we do not know the population variance, we should us the t-distribution.   We will also check that.  The two results should be close&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;se = sc.sem(productivity)
mean = productivity.mean()
ci95lo, ci95hi = mean-1.96*se, mean+1.96*se
print ci95lo, ci95hi

-0.330202770421 10.4182027704



ci95lo, ci95hi = mean+sc.t.ppf(0.025,24)*se, mean+sc.t.ppf(0.975,24)*se
print ci95lo, ci95hi

-0.615086412127 10.7030864121
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;These intervals are very close.   Bootstrapping should give a similar result.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;bootstrap&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;B&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt; &lt;span class="nx"&gt;sample&lt;/span&gt;&lt;span class="err"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;np.random.randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nx"&gt;i&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="nx"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;B&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;

&lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;bootstrap_ci&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;stat_function&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;iterations&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;ci&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;95&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;

    &lt;span class="nx"&gt;statistic&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;apply_along_axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;stat_function&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;bootstrap&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;productivity&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;B&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;iterations&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nx"&gt;e&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;g&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="nx"&gt;array&lt;/span&gt; &lt;span class="nx"&gt;of&lt;/span&gt; &lt;span class="nx"&gt;means&lt;/span&gt;
    &lt;span class="nx"&gt;low&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;percentile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;statistic&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;ci&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;.)&lt;/span&gt;
    &lt;span class="nx"&gt;high&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;percentile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;statistic&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;ci&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;.)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;low&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;high&lt;/span&gt;

&lt;span class="nx"&gt;bootstrap_ci&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;productivity&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;




&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.49619999999999997&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;10.265000000000001&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is in line with the previous estimates.   Lets look at the histogram of bootstrapped means.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def bootstrap_plot_means(sample, iterations=1000):
    samples = bootstrap(sample, iterations)
    means = np.apply_along_axis(np.mean, 1, samples)
    plt.figure()
    plt.hist(means,normed=True,color=&amp;#39;red&amp;#39;,alpha=0.1)
    plt.xlabel(&amp;#39;Mean Values&amp;#39;)
    plt.ylabel(&amp;#39;Probability Density&amp;#39;)
    plt.show()

bootstrap_plot_means(productivity)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_63_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;Even though the results are not a statistically significant difference from zero, the results suggest that the population value is likely to be different from zero.   The uncertainty from the sample does not allow us to know that it is not zero, but we do know that it does not significantly harm productivity.&lt;/p&gt;
&lt;h3&gt;Bootstraping Correlation&lt;/h3&gt;
&lt;p&gt;We can bootstrap other variables.   We will try it for the correlation between LSAT and GPA from law data.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;law_sample = np.loadtxt(&amp;#39;../estimation-sampling/data/law_sample.txt&amp;#39;)
plt.scatter(law_sample[:,0],law_sample[:,1])
plt.xlabel(&amp;quot;LSAT Score&amp;quot;)
plt.ylabel(&amp;quot;GPA&amp;quot;)
print sc.pearsonr(law_sample[:,0],law_sample[:,1])

(0.77637449128940705, 0.00066510201110281625)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_65_1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;data = bootstrap(law_sample,B=10000)
corrs = np.array([sc.pearsonr(mat[:,0],mat[:,1])[0] for mat in data])
plt.figure()
plt.hist(corrs)
plt.show()
np.percentile(corrs,2.5),np.percentile(corrs,97.5)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW02D2/output_66_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;(0.45069334540504685, 0.96239529249176581)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Bootstrapping the correlation between the variables from the sampple finds that a 95% confidence interval estimates the population correlation of LSAT with GPA should be between 0.45 and 0.96.   Thankfully we have the full dataset from which this sample was pulled.   Lets compare.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;all_law = np.loadtxt(&amp;#39;../estimation-sampling/data/law_all.txt&amp;#39;)
sc.pearsonr(all_law[:,0],all_law[:,1])[0]




0.75999785550389798
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is smack in the middle of the confidence interval.   Pretty cool.   &lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="bootstraping"></category><category term="statistics"></category><category term="confidence interval"></category></entry><entry><title>Galvanize - Week 02 - Day 1</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-02-01/" rel="alternate"></link><updated>2015-06-08T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-08:galvanize/galvanize-data-science-02-01/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 2 - Day 1&lt;/h2&gt;
&lt;p&gt;Since this is the first day of the week we started with an hour long assessment on what we did last week.  The assessment was straight forward, and very doable with a modest understanding of the previous material.   &lt;/p&gt;
&lt;p&gt;After the test, we started a lecture on probability, which we finished in the afternoon.  There was the individual sprint after the morning lecture, and a paired spring as the afternoon lecture&lt;/p&gt;
&lt;h2&gt;Conditional Probabilities&lt;/h2&gt;
&lt;p&gt;We started with some simple questions like the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Suppose two cards are drawn from a standard 52 card deck.  What's the probability that the first is a queen and the second is a king?&lt;/p&gt;
&lt;p&gt;$$P\left(Q\right) = \frac{4}{52}$$&lt;/p&gt;
&lt;p&gt;$$P\left(K,Q\right) = P\left(K|Q\right)*P\left(Q\right) = \frac{4}{51} * \frac{4}{52} = \frac{16}{2652}$$&lt;/p&gt;
&lt;p&gt;print "Answer: ", 16./2652&lt;/p&gt;
&lt;p&gt;Answer:  0.00603318250377&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;What's the probability that both cards are queens?&lt;/p&gt;
&lt;p&gt;$$P\left(Q\right) = \frac{4}{52}$$&lt;/p&gt;
&lt;p&gt;$$P\left(Q,Q\right) = P\left(Q|Q\right)*P\left(Q\right) = \frac{3}{51} * \frac{4}{52} = \frac{12}{2652}$$&lt;/p&gt;
&lt;p&gt;print "Answer: ", 12./2652&lt;/p&gt;
&lt;p&gt;Answer:  0.00452488687783&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Suppose that before the second card was drawn, the first was inserted back into the deck and the deck reshuffled. What's the probability that both cards are queens?&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$P\left(Q\right) = \frac{4}{52}$$&lt;/p&gt;
&lt;p&gt;$$P\left(Q,Q\right) = P\left(Q\right)*P\left(Q\right) = \frac{4}{52} * \frac{4}{52} = \frac{16}{2705}$$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;print &amp;quot;Answer: &amp;quot;, 16./2705

Answer:  0.00591497227357
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We had similar questions about tables of data:&lt;/p&gt;
&lt;p&gt;A Store Manager wants to understand how his customers use different payment methods, and suspects that the size of the purchase is a major deciding factor. He organizes the table below.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align="right"&gt;Cash&lt;/th&gt;
&lt;th align="right"&gt;Debit&lt;/th&gt;
&lt;th align="right"&gt;Credit&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Under 20&lt;/td&gt;
&lt;td align="right"&gt;400&lt;/td&gt;
&lt;td align="right"&gt;150&lt;/td&gt;
&lt;td align="right"&gt;150&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;20 - 50&lt;/td&gt;
&lt;td align="right"&gt;200&lt;/td&gt;
&lt;td align="right"&gt;1200&lt;/td&gt;
&lt;td align="right"&gt;800&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Over 50&lt;/td&gt;
&lt;td align="right"&gt;100&lt;/td&gt;
&lt;td align="right"&gt;600&lt;/td&gt;
&lt;td align="right"&gt;1400&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Given that a customer spent over $50, what's the probability that the customer used a credit card?&lt;/p&gt;
&lt;p&gt;$$P\left(C|S&amp;gt;$50\right) = \frac{1400}{100+600+1400}$$ &lt;/p&gt;
&lt;p&gt;print "Answer: ", 1400./(100+600+1400)&lt;/p&gt;
&lt;p&gt;Answer:  0.666666666667&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Given that a customer paid in cash, what's the probability that the customer spent less than $20?&lt;/p&gt;
&lt;p&gt;$$P\left(S&amp;lt;20|Cash\right) = \frac{400}{400+200+100}$$&lt;/p&gt;
&lt;p&gt;print "Answer: ", 400./(400+200+100)&lt;/p&gt;
&lt;p&gt;Answer:  0.571428571429&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;What's the probability that a customer spent under $20 using cash?&lt;/p&gt;
&lt;p&gt;$$P\left(S &amp;lt; $20,Cash\right) = \frac{400}{400+150+150+200+1200+800+100+600+1400}$$&lt;/p&gt;
&lt;p&gt;print "Answer: ", 400./(400+150+150+200+1200+800+100+600+1400)&lt;/p&gt;
&lt;p&gt;Answer:  0.08&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We also had a question about job offers - something near and dear to our hearts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A gSchool grad is looking for her first job!  Given that she is freaked out, her chances of not getting an offer are 70%.  Given that she isn't freaked out, her chances of not getting an offer are 30%.  Suppose that the probability that she's freaked out is 80%. What's the probability that she gets an offer?&lt;/p&gt;
&lt;p&gt;$$P\left(Offer|Freak Out\right) = 0.7$$  &lt;/p&gt;
&lt;p&gt;$$P\left(Offer|No Freak Oout\right) = 0.3$$&lt;/p&gt;
&lt;p&gt;$$P\left(Freak Out\right) = 0.8$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$ P\left(A\right) = \Sigma_{B} P\left(A|B\right) $$&lt;/p&gt;
&lt;p&gt;$$ P\left(Offer\right) = P\left(Offer|Freak Out\right) * P\left(Freak Out\right) + P\left(Offer|No Freak Out\right) * P\left(No Freak Out\right)$$&lt;/p&gt;
&lt;p&gt;$$P\left(Offer\right) = 0.7 * 0.8 + 0.3 * 0.2$$ &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;print &amp;quot;Answer: &amp;quot;, 0.7 * 0.8 + 0.3 * 0.2

Answer:  0.62
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We also tackled the deep issue go heroin use at Google: &lt;/p&gt;
&lt;p&gt;*. Google decides to do random drug tests for heroin on their employees.
   They know that 3% of their population uses heroin. The drug test has the
   following accuracy: The test correctly identifies 95% of the
   heroin users (sensitivity) and 90% of the non-users (specificity).&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Test Results&lt;/th&gt;
&lt;th&gt;Uses heroin&lt;/th&gt;
&lt;th&gt;Doesn't use heroin&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Tests positive&lt;/td&gt;
&lt;td&gt;0.95&lt;/td&gt;
&lt;td&gt;0.10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Tests negative&lt;/td&gt;
&lt;td&gt;0.05&lt;/td&gt;
&lt;td&gt;0.90&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Alice gets tested and the test comes back positive. What is the probability
   that she uses heroin?&lt;/p&gt;
&lt;p&gt;$$P(Heroin \ | \ Positive Test) = \frac{P(Positive Test|Heroin) P(Heroin)}{P(Positive Test)}$$&lt;/p&gt;
&lt;p&gt;$$P(Heroin \ | \ Positive Test) = \frac{P(Positive Test|Heroin) P(Heroin)}{P(Positive Test|Heroin) P(Heroin) + P(Positive Test|No Heroin) P(No Heroin)}$$ &lt;/p&gt;
&lt;p&gt;$$ = \frac{0.95 \ 0.03}{0.95 \ 0.03 + 0.1 \ 0.97}$$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;print &amp;quot;Answer: &amp;quot;, 0.95*0.03/(0.95*0.03 + 0.1*0.97)

Answer:  0.227091633466
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finally we had the manditory birthday problem:   &lt;/p&gt;
&lt;p&gt;*The Birthday Problem.  Suppose there are 23 people in a data science class, lined up in a single file line.&lt;br /&gt;
Let A_i be the probability that the i'th person doesn't have the same birthday as the j'th person for any j &amp;lt; i.&lt;br /&gt;
Use the chain rule from probability to calculate the probability that at least 2 people share the same birthday. &lt;/p&gt;
&lt;p&gt;$$P(1,2,3,...,23) = \mbox{Probability that 23 people do not have the same birthday}$$&lt;/p&gt;
&lt;p&gt;$$P( \ 1, \ 2, \ 3, \ ..., \ 23) = P(1) \ P(2|1) \ P(3 \ | \ 2 \ , \ 1) \ ... \ P(23|22 \ , \ ... \ , \ 2, \ 1)$$&lt;/p&gt;
&lt;p&gt;Given that 2 people don't have the same birthday, there are 363 days that are not taken that a new person could have:&lt;/p&gt;
&lt;p&gt;$$P(3|2,1) = \frac{363}{365}$$&lt;/p&gt;
&lt;p&gt;Similarly, given that 3 people don't have the same birthday, then there are 362 days not occupied:&lt;/p&gt;
&lt;p&gt;$$P(4|3,2,1) = \frac{362}{365}$$&lt;/p&gt;
&lt;p&gt;Extending this to the problem we have the probability of no matching birthdays being &lt;/p&gt;
&lt;p&gt;$$P( \ 1, \ 2,\ 3, \ ..., \ 23) = \frac{1 \ 364 \ 363 \ ... \ (365-23)}{365^{23}}$$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def bday(N=23):
    prob = 1
    for i in range(1,N+1):
        prob = prob*(365.0-i+1)/365.
    return prob

print bday()

0.492702765676
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The probability of having 2 or more matches is us the inverse of this&lt;/p&gt;
&lt;p&gt;$$P(Matches &amp;gt;= 2| \ 23) = 1 - P(No Maches|23)$$&lt;/p&gt;
&lt;p&gt;$$P(Matches &amp;gt;= 2| \ 23) = 1-0.4927$$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;print &amp;quot;Answer: &amp;quot;, round(100-100*bday(),1)

Answer:  50.7
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Distributions&lt;/h2&gt;
&lt;p&gt;The afternoon paired programming assignment involved developing an intuition for and using various distributions.&lt;/p&gt;
&lt;h3&gt;Discrete:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Bernoulli&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Model one instance of a success or failure trial (p)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Binomial&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Number of successes out of a number of trials (n), each with probability of success (p)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Poisson&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Model the number of events occurring in a fixed interval&lt;/li&gt;
&lt;li&gt;Events occur at an average rate (lambda) independently of the last event&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Geometric&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sequence of Bernoulli trials until first success (p)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Continuous:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Uniform&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Any of the values in the interval of a to b are equally likely&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Gaussian&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Commonly occurring distribution shaped like a bell curve&lt;/li&gt;
&lt;li&gt;Often comes up because of the Central Limit Theorem (to be discussed later)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Exponential&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Model time between Poisson events&lt;/li&gt;
&lt;li&gt;Events occur continuously and independently&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some of our questions involved being given examples and identify the distribution that describes it.&lt;/p&gt;
&lt;p&gt;Often we have to identify what distribution we should use to model a real-life
situation. This exercise is designed to equip you with the ability to do so.&lt;/p&gt;
&lt;p&gt;*. A typist makes on average 2 mistakes per page.  What is the probability of a particular page having no errors on it?&lt;/p&gt;
&lt;p&gt;$$X = Poisson(\lambda = 2 \frac{mistakes}{page})$$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;scipy.stats&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sc&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;


&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;poisson&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pmf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Number of Mistakes on a Page&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Probability&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Prob of No Mistakes: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;poisson&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pmf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;Prob&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;No&lt;/span&gt; &lt;span class="n"&gt;Mistakes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.135335283237&lt;/span&gt;
&lt;span class="mf"&gt;0.135335283237&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW2D1/output_24_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;*. Components are packed in boxes of 20. The probability of a component being
   defective is 0.1.  What is the probability of a box containing 2 defective components?&lt;/p&gt;
&lt;p&gt;$$ X = Binomial(p=0.1,k=2,n=20) $$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x = np.arange(20)
y = sc.binom.pmf(x,20,.1)
plt.bar(x,y,color=&amp;#39;red&amp;#39;,alpha=.2)
plt.xlabel(&amp;quot;Number of Defective Components&amp;quot;)
plt.ylabel(&amp;quot;Probability&amp;quot;)
print &amp;quot;Prob of 2 Defects: &amp;quot;, sc.binom.pmf(2,20,.1)

Prob of 2 Defects:  0.285179807064
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW2D1/output_26_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;*. Patrons arrive at a local bar at a mean rate of 30 per hour.  What is the probability that the bouncer has to wait more than 3 minutes to card the next patron?&lt;/p&gt;
&lt;p&gt;$$X = Exponential(\lambda = .5 \frac{cards}{minute})$$&lt;/p&gt;
&lt;p&gt;$$ P(t \ &amp;gt; \ 3min) = \int_{t=3}^{t=\infty} Exponential(\lambda = .5 \frac{cards}{minute}) $$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;print &amp;quot;Answer: &amp;quot;, sc.expon.cdf(1e10,scale=0.5)-sc.expon.cdf(3,scale=0.5)


 Anser:  0.00247875217667



x = np.linspace(0,5,1000)
y = sc.expon.pdf(x,scale = 0.5)
plt.figure()
plt.plot(x,y)
plt.xlabel(&amp;quot;Minutes&amp;quot;)
plt.ylabel(&amp;quot;Probability Density&amp;quot;)
plt.ylim([0,0.1])
d = np.zeros(len(y))
plt.fill_between(x, y, where=x&amp;gt;=3, interpolate=True, color=&amp;#39;blue&amp;#39;,alpha=0.4)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW2D1/output_29_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;*. A variable is normally distributed with a mean of 120 and a standard
   deviation of 5. One score is randomly sampled. What is the probability the score is above 127?&lt;/p&gt;
&lt;p&gt;$$Z = (127-120)/5 = 7/5 = 1.4$$&lt;/p&gt;
&lt;p&gt;$$P(Z&amp;gt;1.4) = 1 - .91924 \ \mbox{(area to left)}$$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x = np.linspace(100,140,1000)
y = sc.norm.pdf(x,loc=120,scale=5)
plt.figure()
plt.plot(x,y)
plt.xlabel(&amp;quot;Variable Value&amp;quot;)
plt.ylabel(&amp;quot;Probability Density&amp;quot;)
d = np.zeros(len(y))
plt.fill_between(x, y, where=x&amp;gt;=127, interpolate=True, color=&amp;#39;blue&amp;#39;,alpha=0.4)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW2D1/output_31_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;*. You need to find a tall person, at least 6 feet tall, to help you reach
   a cookie jar. 8% of the population is 6 feet or taller.  If you wait on the sidewalk, how many people would you expect to have passed you by before you'd have a candidate to reach the jar?&lt;/p&gt;
&lt;p&gt;$$X = Geometric(p=0.08)$$&lt;/p&gt;
&lt;p&gt;$$average = \frac{1}{p} = \frac{1}{0.08} = 12.5$$&lt;/p&gt;
&lt;p&gt;We round up - 13th person is expected to be it - 12 people pass.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x = np.arange(40)
y = sc.geom.pmf(x,.08)
plt.bar(x,y,color=&amp;#39;red&amp;#39;,alpha=.2)
plt.xlabel(&amp;quot;Number of People&amp;quot;)
plt.ylabel(&amp;quot;Probability Person is Above 6ft&amp;quot;)




&amp;lt;matplotlib.text.Text at 0x106020790&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW2D1/output_33_1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x = np.arange(40)
y = sc.geom.cdf(x,.08)
plt.bar(x,y,color=&amp;#39;red&amp;#39;,alpha=.2)
plt.xlabel(&amp;quot;Number of People&amp;quot;)
plt.ylabel(&amp;quot;Cumlative Probability Person is Above 6ft&amp;quot;)




&amp;lt;matplotlib.text.Text at 0x106451c50&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW2D1/output_34_1.png" /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A harried passenger will be several minutes late for a scheduled 10 A.M.
   flight to NYC. Nevertheless, he might still make the flight, since boarding
   is always allowed until 10:10 A.M., and boarding is sometimes
   permitted up to 10:30 AM.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Assuming the extended boarding time is &lt;strong&gt;uniformly distributed&lt;/strong&gt; over the above
   limits, find the probability that the passenger will make his flight,
   assuming he arrives at the boarding gate at 10:25.&lt;/p&gt;
&lt;p&gt;$$X = Uniform(0,30)$$&lt;/p&gt;
&lt;p&gt;$$P( x &amp;gt; 25 ) = \int_{25}^{30} \frac{dx}{30}$$&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;print &amp;quot;Answer: &amp;quot;, 5./30

Answer:  0.166666666667



x = np.linspace(0,30,1000)
y = sc.uniform.pdf(x,loc=0,scale=30)
plt.figure()
plt.plot(x,y)
plt.xlabel(&amp;quot;Minutes Late&amp;quot;)
plt.ylabel(&amp;quot;Probability Density&amp;quot;)
d = np.zeros(len(y))
plt.fill_between(x, y, where=x&amp;gt;=25, interpolate=True, color=&amp;#39;blue&amp;#39;,alpha=0.4)
plt.show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW2D1/output_37_0.png" /&gt;&lt;/p&gt;
&lt;h2&gt;Covariance and Joint Distribution&lt;/h2&gt;
&lt;p&gt;Suppose a university wants to look for factors that are correlated with the GPA of the students that they
are going to admit. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="n"&gt;admissions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;../probability/data/admissions.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;addmissions&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;family_income&lt;/th&gt;
      &lt;th&gt;gpa&lt;/th&gt;
      &lt;th&gt;parent_avg_age&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;31402&lt;/td&gt;
      &lt;td&gt;3.18&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;32247&lt;/td&gt;
      &lt;td&gt;2.98&lt;/td&gt;
      &lt;td&gt;48&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;34732&lt;/td&gt;
      &lt;td&gt;2.85&lt;/td&gt;
      &lt;td&gt;61&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;53759&lt;/td&gt;
      &lt;td&gt;3.39&lt;/td&gt;
      &lt;td&gt;62&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;50952&lt;/td&gt;
      &lt;td&gt;3.10&lt;/td&gt;
      &lt;td&gt;45&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Implement a &lt;code&gt;covariance&lt;/code&gt; function and compute the covariance matrix of the dataframe. Check your results 
   with &lt;code&gt;df.cov()&lt;/code&gt;. Make sure you understand what each of the numbers in the matrix represents&lt;/p&gt;
&lt;p&gt;def make_cov(df):
    N = len(df)
    cols = df.columns
    return [[(df[x]&lt;em&gt;df[y]).sum()/(N)-(df[x].sum()&lt;/em&gt;df[y].sum())/(N**2) for y in cols] for x in cols]&lt;/p&gt;
&lt;p&gt;from pprint import pprint
pprint (make_cov(addmissions))&lt;/p&gt;
&lt;p&gt;[[332910756.59847927, 4014.9337921708066, -1226.2147143883631],
 [4014.9337921708066, 0.087883196618951942, -0.028782641179958546],
 [-1226.2147143883631, -0.028782641179958546, 112]]&lt;/p&gt;
&lt;p&gt;addmissions.cov()&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;family_income&lt;/th&gt;
      &lt;th&gt;gpa&lt;/th&gt;
      &lt;th&gt;parent_avg_age&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;family_income&lt;/th&gt;
      &lt;td&gt;3.329410e+08&lt;/td&gt;
      &lt;td&gt;4015.299085&lt;/td&gt;
      &lt;td&gt;-1226.326280&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;gpa&lt;/th&gt;
      &lt;td&gt;4.015299e+03&lt;/td&gt;
      &lt;td&gt;0.087891&lt;/td&gt;
      &lt;td&gt;-0.028785&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;parent_avg_age&lt;/th&gt;
      &lt;td&gt;-1.226326e+03&lt;/td&gt;
      &lt;td&gt;-0.028785&lt;/td&gt;
      &lt;td&gt;112.977442&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Implement a &lt;code&gt;normalize&lt;/code&gt; function that would compute the correlation matrix from the covariance matrix.
   Check your results with &lt;code&gt;df.corr()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;def make_corr(df):
    N = len(df)
    cols = df.columns
    return [[((df[x]&lt;em&gt;df[y]).sum()/(N)-(df[x].sum()&lt;/em&gt;df[y].sum())/(N**2))/(df[x].std() * df[y].std()) for y in cols] for x in cols]&lt;/p&gt;
&lt;p&gt;pprint (make_corr(addmissions))&lt;/p&gt;
&lt;p&gt;[[0.99990902474526921, 0.74220186205662952, -0.0063224730309758576],
 [0.74220186205662952, 0.99990902474528243, -0.0091340229188836969],
 [-0.0063224730309758576, -0.0091340229188836969, 0.99134834685640671]]&lt;/p&gt;
&lt;p&gt;addmissions.corr()&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;family_income&lt;/th&gt;
      &lt;th&gt;gpa&lt;/th&gt;
      &lt;th&gt;parent_avg_age&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;family_income&lt;/th&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.742269&lt;/td&gt;
      &lt;td&gt;-0.006323&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;gpa&lt;/th&gt;
      &lt;td&gt;0.742269&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;-0.009135&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;parent_avg_age&lt;/th&gt;
      &lt;td&gt;-0.006323&lt;/td&gt;
      &lt;td&gt;-0.009135&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;You should identify &lt;code&gt;family_income&lt;/code&gt; as being the most correlated with GPA. The university wants to make
   an effort to make sure people of all family income are being fairly represented in the admissions process.
   In order to achieve that, different GPA thresholds will be set according to family income. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The low, medium and high family income groups are &lt;code&gt;0 to 26832&lt;/code&gt;, &lt;code&gt;26833 to 37510&lt;/code&gt; and &lt;code&gt;37511 to 51112&lt;/code&gt; respectively. 
   Implement a function that would plot the distribution of GPA scores for each family income category. These are the 
   conditional probability distributions of &lt;code&gt;gpa&lt;/code&gt; given certain levels of &lt;code&gt;family_income&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def make_hist(df):
    low = df[df.family_income &amp;lt;= 26832]
    med = df[(df.family_income &amp;gt; 26832) &amp;amp; (df.family_income &amp;lt;= 37519)]
    high = df[(df.family_income &amp;gt; 37519) &amp;amp; (df.family_income &amp;lt;= 51112)]
    low.gpa.plot(kind=&amp;quot;kde&amp;quot;, color=&amp;quot;blue&amp;quot;,label=&amp;#39;Low Income&amp;#39;)
    med.gpa.plot(kind=&amp;quot;kde&amp;quot;, color=&amp;quot;green&amp;quot;,label=&amp;#39;Medium Income&amp;#39;)
    high.gpa.plot(kind=&amp;quot;kde&amp;quot;, color=&amp;quot;red&amp;quot;,label=&amp;#39;High Income&amp;#39;)
    plt.xlim([2.0, 4.0])
    plt.legend()
    plt.show()

make_hist(addmissions)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW2D1/output_47_0.png" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If the university decides to accept students with GPA above the 90th percentile within the respective family 
   income categories, what are the GPA thresholds for each of the categories?&lt;/p&gt;
&lt;p&gt;low = addmissions[addmissions.family_income &amp;lt;= 26832]
med = addmissions[(addmissions.family_income &amp;gt; 26832) &amp;amp; (addmissions.family_income &amp;lt;= 37519)]
high = addmissions[(addmissions.family_income &amp;gt; 37519) &amp;amp; (addmissions.family_income &amp;lt;= 51112)]
print "Low 90th Percentile", low.gpa.quantile(.9)
print "Medium 90th Percentile", med.gpa.quantile(.9)
print "High 90th Percentile", high.gpa.quantile(.9)&lt;/p&gt;
&lt;p&gt;Low 90th Percentile 3.01
Medium 90th Percentile 3.26
High 90th Percentile 3.36&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Pearson Correlation vs Spearman Correlation&lt;/h2&gt;
&lt;p&gt;The Pearson correlation evaluates the linear relationship between two continuous 
variables. The Spearman correlation evaluates the monotonic relationship between two continuous or ordinal variables
without assuming linearity of the variables. Spearman correlation is often more robust in capturing non-linear relationship
between variables.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;In addition to the &lt;code&gt;family_income&lt;/code&gt; and &lt;code&gt;parent_avg_age&lt;/code&gt;, you are also given data about the number of hours the 
   students studied. Load the new data in from &lt;code&gt;data/admissions_with_study_hrs_and_sports.csv&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;studydf = pd.read_csv('../probability/data/admissions_with_study_hrs_and_sports.csv')
studydf.head()&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;family_income&lt;/th&gt;
      &lt;th&gt;gpa&lt;/th&gt;
      &lt;th&gt;family_income_cat&lt;/th&gt;
      &lt;th&gt;parent_avg_age&lt;/th&gt;
      &lt;th&gt;hrs_studied&lt;/th&gt;
      &lt;th&gt;sport_performance&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;31402&lt;/td&gt;
      &lt;td&gt;3.18&lt;/td&gt;
      &lt;td&gt;medium&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;49.463745&lt;/td&gt;
      &lt;td&gt;0.033196&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;32247&lt;/td&gt;
      &lt;td&gt;2.98&lt;/td&gt;
      &lt;td&gt;medium&lt;/td&gt;
      &lt;td&gt;48&lt;/td&gt;
      &lt;td&gt;16.414467&lt;/td&gt;
      &lt;td&gt;0.000317&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;34732&lt;/td&gt;
      &lt;td&gt;2.85&lt;/td&gt;
      &lt;td&gt;medium&lt;/td&gt;
      &lt;td&gt;61&lt;/td&gt;
      &lt;td&gt;4.937079&lt;/td&gt;
      &lt;td&gt;0.021845&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;53759&lt;/td&gt;
      &lt;td&gt;3.39&lt;/td&gt;
      &lt;td&gt;high&lt;/td&gt;
      &lt;td&gt;62&lt;/td&gt;
      &lt;td&gt;160.210286&lt;/td&gt;
      &lt;td&gt;0.153819&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;50952&lt;/td&gt;
      &lt;td&gt;3.10&lt;/td&gt;
      &lt;td&gt;medium&lt;/td&gt;
      &lt;td&gt;45&lt;/td&gt;
      &lt;td&gt;36.417860&lt;/td&gt;
      &lt;td&gt;0.010444&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Make a scatter plot of the &lt;code&gt;gpa&lt;/code&gt; against &lt;code&gt;hrs_studied&lt;/code&gt;. Make the points more transperant so you can see the density
   of the points. Use the following command get the slope and intercept of a straight line to fit the data.&lt;/p&gt;
&lt;p&gt;slope, intercept, r_value, p_value, std_err = sc.linregress(studydf.gpa,studydf.hrs_studied)
print slope, intercept, r_value, p_value
x = np.linspace(studydf.gpa.min(),studydf.gpa.max(),100)
y = slope*x+intercept&lt;/p&gt;
&lt;p&gt;studydf.plot(kind='scatter',x='gpa',y='hrs_studied',alpha=0.01)
plt.plot(x,y,color='red')
plt.xlabel("GPA")
plt.ylabel("Hours Studied")
plt.show()&lt;/p&gt;
&lt;p&gt;494.329335528 -1400.63719543 0.475940264662 0.0&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW2D1/output_53_1.png" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Use the functions &lt;code&gt;scipy.stats.pearsonr&lt;/code&gt; and &lt;code&gt;scipy.stats.spearmanr&lt;/code&gt; to compute the Pearson and Spearman correlation&lt;/p&gt;
&lt;p&gt;print sc.pearsonr(studydf.gpa,studydf.hrs_studied)
print sc.spearmanr(studydf.gpa,studydf.hrs_studied)&lt;/p&gt;
&lt;p&gt;(0.47594026466220946, 0.0)
(0.98495916559333341, 0.0)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Repeat step &lt;code&gt;2&lt;/code&gt; and &lt;code&gt;3&lt;/code&gt; for &lt;code&gt;gpa&lt;/code&gt; and &lt;code&gt;sport_performance&lt;/code&gt;. Is there a strong relationship between the two variables?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;slope, intercept, r_value, p_value, std_err = sc.linregress(studydf.gpa,studydf.sport_performance)
print slope, intercept, r_value, p_value
x = np.linspace(studydf.gpa.min(),studydf.gpa.max(),100)
y = slope*x+intercept

studydf.plot(kind=&amp;#39;scatter&amp;#39;,x=&amp;#39;gpa&amp;#39;,y=&amp;#39;sport_performance&amp;#39;,alpha=0.1)
plt.plot(x,y,color=&amp;#39;black&amp;#39;)
plt.show()

0.00979813693421 0.0585103217504 0.0238485969548 0.0124044928587
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW2D1/output_57_1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;print sc.pearsonr(studydf.gpa,studydf.sport_performance)
print sc.spearmanr(studydf.gpa,studydf.sport_performance)

(0.023848596954761905, 0.012404492858691094)
(0.0022881402736224248, 0.81043264616449484)



temp = studydf[studydf.gpa &amp;gt; 3.0]
slope, intercept, r_value, p_value, std_err = sc.linregress(temp.gpa,temp.sport_performance)
print slope, intercept, r_value, p_value
x = np.linspace(temp.gpa.min(),temp.gpa.max(),100)
y = slope*x+intercept

temp.plot(kind=&amp;#39;scatter&amp;#39;,x=&amp;#39;gpa&amp;#39;,y=&amp;#39;sport_performance&amp;#39;,alpha=0.1)
plt.plot(x,y,color=&amp;#39;black&amp;#39;)
plt.show()
print sc.pearsonr(temp.gpa,temp.sport_performance)
print sc.spearmanr(temp.gpa,temp.sport_performance)

0.65608660543 -2.03523616554 0.945140987506 0.0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW2D1/output_59_1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;(0.94514098750633013, 0.0)
(1.0, 0.0)
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Part 4: Distribution Simulation&lt;/h2&gt;
&lt;p&gt;Often times in real life applications, we can specify the values of a variable to be of a particular distribution,
for example the number of sales made in the next month can be modeled as a uniform distribution over the range of
5000 and 6000.&lt;/p&gt;
&lt;p&gt;In this scenario, we are modeling &lt;code&gt;profit&lt;/code&gt; as a product of &lt;code&gt;number of views&lt;/code&gt;, &lt;code&gt;conversion&lt;/code&gt; and &lt;code&gt;profit per sale&lt;/code&gt;,
where &lt;code&gt;number of views&lt;/code&gt;, &lt;code&gt;conversion&lt;/code&gt; and &lt;code&gt;profit per sale&lt;/code&gt; can be modeled as probabilistic distributions.
By randomly drawing values from these distributions, we are able to get a distribution of the range of &lt;code&gt;profit&lt;/code&gt; 
based on the uncertainties in the other variables.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Profit = Number of views * Conversion * Profit per sale&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Assumptions:
- &lt;code&gt;Number of views&lt;/code&gt; is a uniform distribution over the range of 5000 and 6000
- &lt;code&gt;Conversion is a binomial distribution where the probability of success is&lt;/code&gt;0.12&lt;code&gt;for each sale among the&lt;/code&gt;Number on views made 
- &lt;code&gt;Profit per sale&lt;/code&gt; has &lt;code&gt;0.2&lt;/code&gt; probability of taking the value &lt;code&gt;50&lt;/code&gt; (for wholesale) and &lt;code&gt;0.8&lt;/code&gt; of 
  taking the value &lt;code&gt;60&lt;/code&gt; (non-wholesale)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Given the distributions of each of variables, use scipy to write a function that would draw random values from each of the distributions to simulate a distribution for &lt;code&gt;profit&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;def get_profit():
    num_views = np.round(sc.uniform.rvs(loc=5000,scale=1000,size=1),0)
    conversions = sc.binom.rvs(num_views,0.12)
    wholesale = sc.binom.rvs(conversions,0.2)
    return wholesale&lt;em&gt;50+(conversions-wholesale)&lt;/em&gt;60&lt;/p&gt;
&lt;p&gt;profits = np.array([get_profit() for i in xrange(100000)])
plt.hist(profits)
plt.show()
print "Low: ",np.percentile(profits,2.5)
print "High: ",np.percentile(profits,97.5)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/GW2D1/output_61_0.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Low&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;33800.0&lt;/span&gt;
&lt;span class="n"&gt;High&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;42920.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="pandas"></category><category term="money ball"></category></entry><entry><title>Galvanize - Week 01 - Day 5</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-01-05/" rel="alternate"></link><updated>2015-06-05T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-05:galvanize/galvanize-data-science-01-05/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 1 - Day 5&lt;/h2&gt;
&lt;p&gt;This morning we started with a reflection about the week, and completed a survey about our progress and thoughts on the program.   I think it is a very strong, hands-on program so far.&lt;/p&gt;
&lt;p&gt;The morning lesson and sprint was on using (pandas)[http://pandas.pydata.org/].   We were given some hospital data in a CSV format, read in the data, and answered a number of questions about most common diseases, most expensive procedures, the post profitable hospitals, and various subsets of these question on different conditions.  It was a simple exercise that gave us practice making new variables, grouping, and subsetting to look massage the data into a form that allowed us to answer the questions.&lt;/p&gt;
&lt;p&gt;During our lunch we had a presentation on learning, and the approach and attitudes that facilitate the bests learning.  It was partly motivational and partly reflective.  If you are familiar with Carol Dweck's work and the research it created, then you have a feeling for the talk.&lt;/p&gt;
&lt;p&gt;After lunch we did a fun assignment that was to recreate the MoneyBall movie where we are trying to get a set of three players that in aggregate replace the 3 key players that were just lost.   &lt;/p&gt;
&lt;p&gt;The data we used is hosted (here)[http://www.seanlahman.com/baseball-archive/statistics/]&lt;/p&gt;
&lt;h2&gt;Money Ball&lt;/h2&gt;
&lt;p&gt;We first started by downloading the dataset and loading it into Pandas.  We started with the batting data:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;

&lt;span class="n"&gt;batting&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data/baseball-csvs/Batting.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;batting&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;playerID&lt;/th&gt;
      &lt;th&gt;yearID&lt;/th&gt;
      &lt;th&gt;stint&lt;/th&gt;
      &lt;th&gt;teamID&lt;/th&gt;
      &lt;th&gt;lgID&lt;/th&gt;
      &lt;th&gt;G&lt;/th&gt;
      &lt;th&gt;G_batting&lt;/th&gt;
      &lt;th&gt;AB&lt;/th&gt;
      &lt;th&gt;R&lt;/th&gt;
      &lt;th&gt;H&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;SB&lt;/th&gt;
      &lt;th&gt;CS&lt;/th&gt;
      &lt;th&gt;BB&lt;/th&gt;
      &lt;th&gt;SO&lt;/th&gt;
      &lt;th&gt;IBB&lt;/th&gt;
      &lt;th&gt;HBP&lt;/th&gt;
      &lt;th&gt;SH&lt;/th&gt;
      &lt;th&gt;SF&lt;/th&gt;
      &lt;th&gt;GIDP&lt;/th&gt;
      &lt;th&gt;G_old&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;aardsda01&lt;/td&gt;
      &lt;td&gt;2004&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;SFN&lt;/td&gt;
      &lt;td&gt;NL&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;aardsda01&lt;/td&gt;
      &lt;td&gt;2006&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;CHN&lt;/td&gt;
      &lt;td&gt;NL&lt;/td&gt;
      &lt;td&gt;45&lt;/td&gt;
      &lt;td&gt;43&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;45&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;aardsda01&lt;/td&gt;
      &lt;td&gt;2007&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;CHA&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;aardsda01&lt;/td&gt;
      &lt;td&gt;2008&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;BOS&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;47&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;aardsda01&lt;/td&gt;
      &lt;td&gt;2009&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;SEA&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 24 columns&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;We then loaded the salaryd data:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;salary = pd.read_csv(&amp;#39;data/baseball-csvs/Salaries.csv&amp;#39;)
salary.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;yearID&lt;/th&gt;
      &lt;th&gt;teamID&lt;/th&gt;
      &lt;th&gt;lgID&lt;/th&gt;
      &lt;th&gt;playerID&lt;/th&gt;
      &lt;th&gt;salary&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1985&lt;/td&gt;
      &lt;td&gt;BAL&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;murraed02&lt;/td&gt;
      &lt;td&gt;1472819&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1985&lt;/td&gt;
      &lt;td&gt;BAL&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;lynnfr01&lt;/td&gt;
      &lt;td&gt;1090000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;1985&lt;/td&gt;
      &lt;td&gt;BAL&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;ripkeca01&lt;/td&gt;
      &lt;td&gt;800000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;1985&lt;/td&gt;
      &lt;td&gt;BAL&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;lacyle01&lt;/td&gt;
      &lt;td&gt;725000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;1985&lt;/td&gt;
      &lt;td&gt;BAL&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;flanami01&lt;/td&gt;
      &lt;td&gt;641667&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;salary[salary.yearID==2001].salary.describe()




count         860.000000
mean      2279841.061628
std       2907710.250521
min        200000.000000
25%        269375.000000
50%        925000.000000
75%       3250000.000000
max      22000000.000000
Name: salary, dtype: float64
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In the year 2001, the year we are concerned with, the minimum salary was $200,000.&lt;/p&gt;
&lt;p&gt;The next thing we did was merged the two dataframes and limited the data to 2001.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;mergeddf = batting.merge(salary,on=[&amp;#39;playerID&amp;#39;,&amp;#39;yearID&amp;#39;],how=&amp;#39;left&amp;#39;)
mergeddf = mergeddf[mergeddf.yearID==2001]
mergeddf.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;playerID&lt;/th&gt;
      &lt;th&gt;yearID&lt;/th&gt;
      &lt;th&gt;stint&lt;/th&gt;
      &lt;th&gt;teamID_x&lt;/th&gt;
      &lt;th&gt;lgID_x&lt;/th&gt;
      &lt;th&gt;G&lt;/th&gt;
      &lt;th&gt;G_batting&lt;/th&gt;
      &lt;th&gt;AB&lt;/th&gt;
      &lt;th&gt;R&lt;/th&gt;
      &lt;th&gt;H&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;SO&lt;/th&gt;
      &lt;th&gt;IBB&lt;/th&gt;
      &lt;th&gt;HBP&lt;/th&gt;
      &lt;th&gt;SH&lt;/th&gt;
      &lt;th&gt;SF&lt;/th&gt;
      &lt;th&gt;GIDP&lt;/th&gt;
      &lt;th&gt;G_old&lt;/th&gt;
      &lt;th&gt;teamID_y&lt;/th&gt;
      &lt;th&gt;lgID_y&lt;/th&gt;
      &lt;th&gt;salary&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;13&lt;/th&gt;
      &lt;td&gt;abadan01&lt;/td&gt;
      &lt;td&gt;2001&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;OAK&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;23&lt;/th&gt;
      &lt;td&gt;abbotje01&lt;/td&gt;
      &lt;td&gt;2001&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;FLO&lt;/td&gt;
      &lt;td&gt;NL&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;FLO&lt;/td&gt;
      &lt;td&gt;NL&lt;/td&gt;
      &lt;td&gt;300000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;44&lt;/th&gt;
      &lt;td&gt;abbotku01&lt;/td&gt;
      &lt;td&gt;2001&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;ATL&lt;/td&gt;
      &lt;td&gt;NL&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;ATL&lt;/td&gt;
      &lt;td&gt;NL&lt;/td&gt;
      &lt;td&gt;600000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;56&lt;/th&gt;
      &lt;td&gt;abbotpa01&lt;/td&gt;
      &lt;td&gt;2001&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;SEA&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;SEA&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;1700000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;64&lt;/th&gt;
      &lt;td&gt;abernbr01&lt;/td&gt;
      &lt;td&gt;2001&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;TBA&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;79&lt;/td&gt;
      &lt;td&gt;79&lt;/td&gt;
      &lt;td&gt;304&lt;/td&gt;
      &lt;td&gt;43&lt;/td&gt;
      &lt;td&gt;82&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;35&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;79&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 27 columns&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;We can see some of the salaries are missing.  There are players that can be aquired, but are not on a payroll.   If we pick them up we have to pay them 200,000.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;mergeddf.salary = mergeddf.salary.fillna(200000)
mergeddf.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;playerID&lt;/th&gt;
      &lt;th&gt;yearID&lt;/th&gt;
      &lt;th&gt;stint&lt;/th&gt;
      &lt;th&gt;teamID_x&lt;/th&gt;
      &lt;th&gt;lgID_x&lt;/th&gt;
      &lt;th&gt;G&lt;/th&gt;
      &lt;th&gt;G_batting&lt;/th&gt;
      &lt;th&gt;AB&lt;/th&gt;
      &lt;th&gt;R&lt;/th&gt;
      &lt;th&gt;H&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;SO&lt;/th&gt;
      &lt;th&gt;IBB&lt;/th&gt;
      &lt;th&gt;HBP&lt;/th&gt;
      &lt;th&gt;SH&lt;/th&gt;
      &lt;th&gt;SF&lt;/th&gt;
      &lt;th&gt;GIDP&lt;/th&gt;
      &lt;th&gt;G_old&lt;/th&gt;
      &lt;th&gt;teamID_y&lt;/th&gt;
      &lt;th&gt;lgID_y&lt;/th&gt;
      &lt;th&gt;salary&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;13&lt;/th&gt;
      &lt;td&gt;abadan01&lt;/td&gt;
      &lt;td&gt;2001&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;OAK&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;200000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;23&lt;/th&gt;
      &lt;td&gt;abbotje01&lt;/td&gt;
      &lt;td&gt;2001&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;FLO&lt;/td&gt;
      &lt;td&gt;NL&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;FLO&lt;/td&gt;
      &lt;td&gt;NL&lt;/td&gt;
      &lt;td&gt;300000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;44&lt;/th&gt;
      &lt;td&gt;abbotku01&lt;/td&gt;
      &lt;td&gt;2001&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;ATL&lt;/td&gt;
      &lt;td&gt;NL&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;ATL&lt;/td&gt;
      &lt;td&gt;NL&lt;/td&gt;
      &lt;td&gt;600000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;56&lt;/th&gt;
      &lt;td&gt;abbotpa01&lt;/td&gt;
      &lt;td&gt;2001&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;SEA&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;SEA&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;1700000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;64&lt;/th&gt;
      &lt;td&gt;abernbr01&lt;/td&gt;
      &lt;td&gt;2001&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;TBA&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;79&lt;/td&gt;
      &lt;td&gt;79&lt;/td&gt;
      &lt;td&gt;304&lt;/td&gt;
      &lt;td&gt;43&lt;/td&gt;
      &lt;td&gt;82&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;35&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;79&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;200000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 27 columns&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Now we need to make some new variables.   The number of times they were on First Base,the Batting Average (BA), the On Base Percentage (OBP), and the Slugg (SLG)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;mergeddf[&amp;#39;BA&amp;#39;] = mergeddf[&amp;#39;H&amp;#39;]/mergeddf[&amp;#39;AB&amp;#39;]
mergeddf.BA.describe()




count    1044.000000
mean        0.202532
std         0.140697
min         0.000000
25%         0.117647
50%         0.235227
75%         0.274705
max         1.000000
Name: BA, dtype: float64




mergeddf[&amp;#39;1B&amp;#39;] = mergeddf[&amp;#39;H&amp;#39;]-mergeddf[&amp;#39;2B&amp;#39;]-mergeddf[&amp;#39;3B&amp;#39;]-mergeddf[&amp;#39;HR&amp;#39;]
mergeddf[&amp;#39;1B&amp;#39;].describe()




count    1237.000000
mean       23.185125
std        34.327716
min         0.000000
25%         0.000000
50%         4.000000
75%        33.000000
max       192.000000
Name: 1B, dtype: float64




mergeddf[&amp;#39;SLG&amp;#39;]=(mergeddf[&amp;#39;1B&amp;#39;]+2*mergeddf[&amp;#39;2B&amp;#39;]+3*mergeddf[&amp;#39;3B&amp;#39;] \
                 +4*mergeddf[&amp;#39;HR&amp;#39;])/mergeddf[&amp;#39;AB&amp;#39;]
mergeddf[&amp;#39;SLG&amp;#39;].describe()




count    1044.000000
mean        0.303628
std         0.214569
min         0.000000
25%         0.142857
50%         0.337722
75%         0.436874
max         2.000000
Name: SLG, dtype: float64




mergeddf[&amp;#39;OBP&amp;#39;]=(mergeddf[&amp;#39;H&amp;#39;]+mergeddf[&amp;#39;BB&amp;#39;]+mergeddf[&amp;#39;HBP&amp;#39;]) \
/(mergeddf[&amp;#39;AB&amp;#39;]+mergeddf[&amp;#39;BB&amp;#39;]+mergeddf[&amp;#39;HBP&amp;#39;]+mergeddf[&amp;#39;SF&amp;#39;])
mergeddf[&amp;#39;OBP&amp;#39;].describe()




count    1047.000000
mean        0.254084
std         0.159932
min         0.000000
25%         0.162162
50%         0.293103
75%         0.338235
max         1.000000
Name: OBP, dtype: float64
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The A's lost Jason Giambi (&lt;code&gt;giambja01&lt;/code&gt;), Johnny Damon (&lt;code&gt;damonjo01&lt;/code&gt;), Jason Isringhausen (&lt;code&gt;isrinja01&lt;/code&gt;), and Rainer Gustavo "Ray" Olmedo (&lt;code&gt;'saenzol01'&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;These player need to replaced with similar player that bat, in total, as much as these guys, get on base as often as these guys, and can be payed less than these guys.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;my_mask = mergeddf[&amp;#39;playerID&amp;#39;].isin([&amp;#39;giambja01&amp;#39;,&amp;#39;damonjo01&amp;#39;,&amp;#39;isrinja01&amp;#39;,&amp;#39;saenzol01&amp;#39;])
lostboysdf = mergeddf[my_mask]
imp_var = [&amp;#39;playerID&amp;#39;, &amp;#39;teamID_x&amp;#39;,&amp;#39;AB&amp;#39;,&amp;#39;HR&amp;#39;, &amp;#39;OBP&amp;#39;, &amp;#39;SLG&amp;#39;, &amp;#39;salary&amp;#39;]
lostboysdf[imp_var]
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;playerID&lt;/th&gt;
      &lt;th&gt;teamID_x&lt;/th&gt;
      &lt;th&gt;AB&lt;/th&gt;
      &lt;th&gt;HR&lt;/th&gt;
      &lt;th&gt;OBP&lt;/th&gt;
      &lt;th&gt;SLG&lt;/th&gt;
      &lt;th&gt;salary&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;7065&lt;/th&gt;
      &lt;td&gt;damonjo01&lt;/td&gt;
      &lt;td&gt;OAK&lt;/td&gt;
      &lt;td&gt;644&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;0.323529&lt;/td&gt;
      &lt;td&gt;0.363354&lt;/td&gt;
      &lt;td&gt;7100000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10836&lt;/th&gt;
      &lt;td&gt;giambja01&lt;/td&gt;
      &lt;td&gt;OAK&lt;/td&gt;
      &lt;td&gt;520&lt;/td&gt;
      &lt;td&gt;38&lt;/td&gt;
      &lt;td&gt;0.476900&lt;/td&gt;
      &lt;td&gt;0.659615&lt;/td&gt;
      &lt;td&gt;4103333&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;14911&lt;/th&gt;
      &lt;td&gt;isrinja01&lt;/td&gt;
      &lt;td&gt;OAK&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;3300000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;27408&lt;/th&gt;
      &lt;td&gt;saenzol01&lt;/td&gt;
      &lt;td&gt;OAK&lt;/td&gt;
      &lt;td&gt;305&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;0.291176&lt;/td&gt;
      &lt;td&gt;0.383607&lt;/td&gt;
      &lt;td&gt;290000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;print &amp;quot;Avg OBP Needed to be replaced:&amp;quot;, 3*lostboysdf[imp_var].OBP.mean()
print &amp;quot;Total Bats needed to be replaced:&amp;quot;, lostboysdf[imp_var].AB.sum()

Avg OBP Needed to be replaced: 1.09160603138
Total Bats needed to be replaced: 1469.0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We would ideally like to get every combination of 3 players that are available.  That would be:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;mergeddf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mergeddf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="n"&gt;mergeddf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;playerID&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isin&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;giambja01&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;damonjo01&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;isrinja01&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;saenzol01&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
&lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mergeddf&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;math&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;nCr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;factorial&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;nCr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="mi"&gt;1335&lt;/span&gt;
&lt;span class="mi"&gt;395654395&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That is almost 400,000,000 combinations to search through.   Less make some reasonable assumptions about about the minimum At Bats and On Base Percentages&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;mergeddf.plot(kind=&amp;#39;scatter&amp;#39;,x=&amp;#39;AB&amp;#39;,y=&amp;#39;OBP&amp;#39;)




&amp;lt;matplotlib.axes._subplots.AxesSubplot at 0x1063f3f10&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="http://www.bryantravissmith.com/img/gw1d5_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;It looks like the variance does not change much above 200 AB.  We probably want them to bat about 500 times a season, however.  We also want the average to be above 0.33 for the OPB, so that seems like a reasonable initial cutoff.  We also want there average salary to be less than 5000000.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;size = len(mergeddf[(mergeddf.AB &amp;gt; 400) &amp;amp; (mergeddf.OBP &amp;gt; 0.33)])
nCr(size,3)




246905L
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That gives us 11,480 combinations to search through.  Lets do it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;#mdf = mergeddf[(mergeddf.yearID==2001)&amp;amp;(mergeddf.AB&amp;gt;50)] #.salary.describe()&lt;/span&gt;
&lt;span class="c"&gt;#mdf.salary = mdf.salary.fillna(200000)&lt;/span&gt;
&lt;span class="c"&gt;#mdf[imp_var].head()&lt;/span&gt;
&lt;span class="n"&gt;mdf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mergeddf&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;mergeddf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;AB&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mergeddf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OBP&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mf"&gt;0.33&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;itertools&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;combinations&lt;/span&gt;
&lt;span class="n"&gt;good_combinations&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;mdf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;playerID&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;giambja01&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;damonjo01&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;isrinja01&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;saenzol01&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
&lt;span class="n"&gt;gc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;player1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;player2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;player3&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;total_AB&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;total_OBP&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;total_salary&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;combinations&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OBP&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mf"&gt;0.4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;playerID&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tolist&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="n"&gt;total_salary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;playerID&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;salary&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;total_salary&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;playerID&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;salary&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;total_salary&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;playerID&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;salary&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;total_AB&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;playerID&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;AB&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;total_AB&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;playerID&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;AB&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;total_AB&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;playerID&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;AB&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;total_obp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;playerID&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OBP&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;total_obp&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;playerID&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OBP&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;total_obp&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mdf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;playerID&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OBP&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;total_salary&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;15000000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;total_obp&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mf"&gt;1.0961&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;gc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;total_AB&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;total_obp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;total_salary&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="n"&gt;gc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sort&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;total_salary&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;gc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;player1&lt;/th&gt;
      &lt;th&gt;player2&lt;/th&gt;
      &lt;th&gt;player3&lt;/th&gt;
      &lt;th&gt;total_AB&lt;/th&gt;
      &lt;th&gt;total_OBP&lt;/th&gt;
      &lt;th&gt;total_salary&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;28&lt;/th&gt;
      &lt;td&gt;berkmla01&lt;/td&gt;
      &lt;td&gt;gonzalu01&lt;/td&gt;
      &lt;td&gt;pujolal01&lt;/td&gt;
      &lt;td&gt;1776&lt;/td&gt;
      &lt;td&gt;1.261767&lt;/td&gt;
      &lt;td&gt;5338333&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;32&lt;/th&gt;
      &lt;td&gt;berkmla01&lt;/td&gt;
      &lt;td&gt;heltoto01&lt;/td&gt;
      &lt;td&gt;pujolal01&lt;/td&gt;
      &lt;td&gt;1754&lt;/td&gt;
      &lt;td&gt;1.264850&lt;/td&gt;
      &lt;td&gt;5455000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;36&lt;/th&gt;
      &lt;td&gt;berkmla01&lt;/td&gt;
      &lt;td&gt;martied01&lt;/td&gt;
      &lt;td&gt;pujolal01&lt;/td&gt;
      &lt;td&gt;1637&lt;/td&gt;
      &lt;td&gt;1.256603&lt;/td&gt;
      &lt;td&gt;6005000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;18&lt;/th&gt;
      &lt;td&gt;berkmla01&lt;/td&gt;
      &lt;td&gt;edmonji01&lt;/td&gt;
      &lt;td&gt;pujolal01&lt;/td&gt;
      &lt;td&gt;1667&lt;/td&gt;
      &lt;td&gt;1.243410&lt;/td&gt;
      &lt;td&gt;6838333&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;38&lt;/th&gt;
      &lt;td&gt;berkmla01&lt;/td&gt;
      &lt;td&gt;olerujo01&lt;/td&gt;
      &lt;td&gt;pujolal01&lt;/td&gt;
      &lt;td&gt;1739&lt;/td&gt;
      &lt;td&gt;1.234375&lt;/td&gt;
      &lt;td&gt;7205000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;24&lt;/th&gt;
      &lt;td&gt;berkmla01&lt;/td&gt;
      &lt;td&gt;gilesbr02&lt;/td&gt;
      &lt;td&gt;pujolal01&lt;/td&gt;
      &lt;td&gt;1743&lt;/td&gt;
      &lt;td&gt;1.236756&lt;/td&gt;
      &lt;td&gt;7838333&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;alomaro01&lt;/td&gt;
      &lt;td&gt;berkmla01&lt;/td&gt;
      &lt;td&gt;pujolal01&lt;/td&gt;
      &lt;td&gt;1742&lt;/td&gt;
      &lt;td&gt;1.247866&lt;/td&gt;
      &lt;td&gt;8255000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;43&lt;/th&gt;
      &lt;td&gt;berkmla01&lt;/td&gt;
      &lt;td&gt;pujolal01&lt;/td&gt;
      &lt;td&gt;thomeji01&lt;/td&gt;
      &lt;td&gt;1693&lt;/td&gt;
      &lt;td&gt;1.249345&lt;/td&gt;
      &lt;td&gt;8380000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;55&lt;/th&gt;
      &lt;td&gt;gonzalu01&lt;/td&gt;
      &lt;td&gt;heltoto01&lt;/td&gt;
      &lt;td&gt;pujolal01&lt;/td&gt;
      &lt;td&gt;1786&lt;/td&gt;
      &lt;td&gt;1.263189&lt;/td&gt;
      &lt;td&gt;9983333&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;25&lt;/th&gt;
      &lt;td&gt;berkmla01&lt;/td&gt;
      &lt;td&gt;gonzalu01&lt;/td&gt;
      &lt;td&gt;heltoto01&lt;/td&gt;
      &lt;td&gt;1773&lt;/td&gt;
      &lt;td&gt;1.290459&lt;/td&gt;
      &lt;td&gt;10088333&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;print len(gc)

66
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This allowed us to find 66 combination of players that would, in aggregate, have better statistics that the players that were lost.  It also turns out to be cheaper to do that.   This is the story of money ball.  It was a fun project.  &lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="pandas"></category><category term="money ball"></category></entry><entry><title>Galvanize - Week 01 - Day 4</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-01-04/" rel="alternate"></link><updated>2015-06-04T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-04:galvanize/galvanize-data-science-01-04/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 1 - Day 4&lt;/h2&gt;
&lt;p&gt;The day started out with a mini-quiz on object-oriented programming, and that was followed by an introduction to git and sophisticated join queries.   Our instructor for the day used to work at Facebook, and she walked us through some the queries she would do on the job.  &lt;/p&gt;
&lt;p&gt;She then gave us a simulated data set that match the structure, but not the content, of Facebook tables and we had an individual sprint attempting to complete 10 queries in 2 hours.&lt;/p&gt;
&lt;p&gt;After lunch we had a lecture on pyscopg2, a python library to use to connect and interact with a PostgreSQL server.   We ran a server locally, loaded with the same data as the morning, and were given an assignment to construct a pipeline that we could run each day to give us an updated status of our users.   We were to check on results for today being set to Aug 14, 2014. &lt;/p&gt;
&lt;p&gt;Our resulting script is below:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;psycopg2&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;datetime&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;

&lt;span class="n"&gt;conn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;psycopg2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;connect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dbname&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;socialmedia&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;postgres&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;password&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;password&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;localhost&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;today&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;2014-08-14&amp;#39;&lt;/span&gt;

&lt;span class="n"&gt;timestamp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strptime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;today&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;%Y-%M-&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strftime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;CREATE TABLE logins_7d_%s AS&lt;/span&gt;
&lt;span class="sd"&gt;    WITH&lt;/span&gt;
&lt;span class="sd"&gt;    main AS (&lt;/span&gt;
&lt;span class="sd"&gt;    SELECT&lt;/span&gt;
&lt;span class="sd"&gt;        r.userid,&lt;/span&gt;
&lt;span class="sd"&gt;        tmstmp::date AS reg_date,&lt;/span&gt;
&lt;span class="sd"&gt;        CASE WHEN optout.userid IS NULL then 0 ELSE 1 END AS opt_out&lt;/span&gt;
&lt;span class="sd"&gt;    FROM registrations r&lt;/span&gt;
&lt;span class="sd"&gt;    LEFT OUTER JOIN optout&lt;/span&gt;
&lt;span class="sd"&gt;    ON r.userid = optout.userid&lt;/span&gt;
&lt;span class="sd"&gt;    ORDER BY r.userid),&lt;/span&gt;
&lt;span class="sd"&gt;    last AS (&lt;/span&gt;
&lt;span class="sd"&gt;    SELECT&lt;/span&gt;
&lt;span class="sd"&gt;        userid,&lt;/span&gt;
&lt;span class="sd"&gt;        MAX(tmstmp::date) AS last_login&lt;/span&gt;
&lt;span class="sd"&gt;    FROM logins&lt;/span&gt;
&lt;span class="sd"&gt;    GROUP BY userid&lt;/span&gt;
&lt;span class="sd"&gt;    ORDER BY userid),&lt;/span&gt;
&lt;span class="sd"&gt;    last7 AS (&lt;/span&gt;
&lt;span class="sd"&gt;    SELECT&lt;/span&gt;
&lt;span class="sd"&gt;        t.userid,&lt;/span&gt;
&lt;span class="sd"&gt;        COUNT(t.dt) AS logins_7d&lt;/span&gt;
&lt;span class="sd"&gt;    FROM (&lt;/span&gt;
&lt;span class="sd"&gt;        SELECT&lt;/span&gt;
&lt;span class="sd"&gt;            DISTINCT userid,&lt;/span&gt;
&lt;span class="sd"&gt;            tmstmp::date AS dt&lt;/span&gt;
&lt;span class="sd"&gt;        FROM logins&lt;/span&gt;
&lt;span class="sd"&gt;        WHERE logins.tmstmp &amp;gt; timestamp &amp;#39;2014-08-14&amp;#39; - interval &amp;#39;7 days&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        GROUP BY userid, tmstmp::date&lt;/span&gt;
&lt;span class="sd"&gt;        ORDER BY userid) t&lt;/span&gt;
&lt;span class="sd"&gt;    GROUP BY t.userid),&lt;/span&gt;
&lt;span class="sd"&gt;    last7m AS (&lt;/span&gt;
&lt;span class="sd"&gt;    SELECT t.userid, COUNT(t.dt) AS logins_7m&lt;/span&gt;
&lt;span class="sd"&gt;    FROM (&lt;/span&gt;
&lt;span class="sd"&gt;        SELECT&lt;/span&gt;
&lt;span class="sd"&gt;            DISTINCT userid,&lt;/span&gt;
&lt;span class="sd"&gt;            tmstmp::date AS dt&lt;/span&gt;
&lt;span class="sd"&gt;        FROM logins&lt;/span&gt;
&lt;span class="sd"&gt;        WHERE&lt;/span&gt;
&lt;span class="sd"&gt;            logins.tmstmp &amp;gt; timestamp &amp;#39;2014-08-14&amp;#39; - interval &amp;#39;7 days&amp;#39; AND&lt;/span&gt;
&lt;span class="sd"&gt;            logins.type = &amp;#39;mobile&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        GROUP BY userid, tmstmp::date&lt;/span&gt;
&lt;span class="sd"&gt;        ORDER BY userid) t&lt;/span&gt;
&lt;span class="sd"&gt;    GROUP BY t.userid),&lt;/span&gt;
&lt;span class="sd"&gt;    last7w AS (&lt;/span&gt;
&lt;span class="sd"&gt;    SELECT&lt;/span&gt;
&lt;span class="sd"&gt;        t.userid,&lt;/span&gt;
&lt;span class="sd"&gt;        COUNT(t.dt) AS logins_7w&lt;/span&gt;
&lt;span class="sd"&gt;    FROM (&lt;/span&gt;
&lt;span class="sd"&gt;        SELECT&lt;/span&gt;
&lt;span class="sd"&gt;            DISTINCT userid,&lt;/span&gt;
&lt;span class="sd"&gt;            tmstmp::date AS dt&lt;/span&gt;
&lt;span class="sd"&gt;        FROM logins&lt;/span&gt;
&lt;span class="sd"&gt;        WHERE&lt;/span&gt;
&lt;span class="sd"&gt;            logins.tmstmp &amp;gt; timestamp &amp;#39;2014-08-14&amp;#39; - interval &amp;#39;7 days&amp;#39; AND&lt;/span&gt;
&lt;span class="sd"&gt;            logins.type = &amp;#39;web&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        GROUP BY userid, tmstmp::date&lt;/span&gt;
&lt;span class="sd"&gt;        ORDER BY userid) t&lt;/span&gt;
&lt;span class="sd"&gt;    GROUP BY t.userid),&lt;/span&gt;
&lt;span class="sd"&gt;    uf1 AS (&lt;/span&gt;
&lt;span class="sd"&gt;    (SELECT * FROM friends)&lt;/span&gt;
&lt;span class="sd"&gt;    UNION ALL&lt;/span&gt;
&lt;span class="sd"&gt;    (SELECT userid2, userid1 FROM friends)),&lt;/span&gt;
&lt;span class="sd"&gt;    uf2 AS (&lt;/span&gt;
&lt;span class="sd"&gt;    SELECT DISTINCT *&lt;/span&gt;
&lt;span class="sd"&gt;    FROM uf1),&lt;/span&gt;
&lt;span class="sd"&gt;    friend_cnt AS (&lt;/span&gt;
&lt;span class="sd"&gt;    SELECT&lt;/span&gt;
&lt;span class="sd"&gt;        userid1 AS userid,&lt;/span&gt;
&lt;span class="sd"&gt;        COUNT(1) AS num_friends&lt;/span&gt;
&lt;span class="sd"&gt;    FROM uf2&lt;/span&gt;
&lt;span class="sd"&gt;    GROUP BY userid)&lt;/span&gt;
&lt;span class="sd"&gt;    SELECT&lt;/span&gt;
&lt;span class="sd"&gt;        main.userid,&lt;/span&gt;
&lt;span class="sd"&gt;        reg_date,&lt;/span&gt;
&lt;span class="sd"&gt;        last_login,&lt;/span&gt;
&lt;span class="sd"&gt;        coalesce(logins_7d,0) AS logins_7d,&lt;/span&gt;
&lt;span class="sd"&gt;        coalesce(logins_7m,0) AS logins_7d_mobile,&lt;/span&gt;
&lt;span class="sd"&gt;        coalesce(logins_7w,0) AS logins_7d_web,&lt;/span&gt;
&lt;span class="sd"&gt;        coalesce(num_friends,0) AS num_friends,&lt;/span&gt;
&lt;span class="sd"&gt;        opt_out&lt;/span&gt;
&lt;span class="sd"&gt;    FROM main&lt;/span&gt;
&lt;span class="sd"&gt;    LEFT OUTER JOIN last&lt;/span&gt;
&lt;span class="sd"&gt;    ON main.userid = last.userid&lt;/span&gt;
&lt;span class="sd"&gt;    LEFT OUTER JOIN last7&lt;/span&gt;
&lt;span class="sd"&gt;    ON main.userid = last7.userid&lt;/span&gt;
&lt;span class="sd"&gt;    LEFT OUTER JOIN last7m&lt;/span&gt;
&lt;span class="sd"&gt;    ON main.userid = last7m.userid&lt;/span&gt;
&lt;span class="sd"&gt;    LEFT OUTER JOIN last7w&lt;/span&gt;
&lt;span class="sd"&gt;    ON main.userid = last7w.userid&lt;/span&gt;
&lt;span class="sd"&gt;    LEFT OUTER JOIN friend_cnt&lt;/span&gt;
&lt;span class="sd"&gt;    ON main.userid = friend_cnt.userid;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;timestamp&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;commit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We also learned how pull data and load the data into a pandas dataframe.   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pandas.io&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;sql&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pandas.io.sql&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;read_sql&lt;/span&gt;

&lt;span class="n"&gt;conn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;psycopg2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;connect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dbname&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;socialmedia&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                        &lt;span class="n"&gt;user&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;postgres&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                        &lt;span class="n"&gt;password&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;password&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                        &lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;localhost&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;sql&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;SELECT * FROM logins_7d_1389686880 LIMIT 20;&amp;#39;&lt;/span&gt;

&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;read_sql&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index_col&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;userid&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;coerce_float&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;df&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="max-height:1000px;max-width:1500px;overflow:auto;"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;reg_date&lt;/th&gt;
      &lt;th&gt;last_login&lt;/th&gt;
      &lt;th&gt;logins_7d&lt;/th&gt;
      &lt;th&gt;logins_7d_mobile&lt;/th&gt;
      &lt;th&gt;logins_7d_web&lt;/th&gt;
      &lt;th&gt;num_friends&lt;/th&gt;
      &lt;th&gt;opt_out&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;userid&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;2014-06-23&lt;/td&gt;
      &lt;td&gt;2014-08-13&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2013-12-21&lt;/td&gt;
      &lt;td&gt;2014-08-12&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;2014-04-18&lt;/td&gt;
      &lt;td&gt;2014-08-14&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;38&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;2013-12-17&lt;/td&gt;
      &lt;td&gt;2014-08-13&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;2014-08-11&lt;/td&gt;
      &lt;td&gt;2014-08-09&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;2013-08-31&lt;/td&gt;
      &lt;td&gt;2014-08-10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;29&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;td&gt;2013-08-18&lt;/td&gt;
      &lt;td&gt;2014-08-12&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;td&gt;2014-03-21&lt;/td&gt;
      &lt;td&gt;2014-08-12&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;8&lt;/th&gt;
      &lt;td&gt;2014-05-03&lt;/td&gt;
      &lt;td&gt;2014-08-11&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;9&lt;/th&gt;
      &lt;td&gt;2014-06-06&lt;/td&gt;
      &lt;td&gt;2014-08-11&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10&lt;/th&gt;
      &lt;td&gt;2013-08-31&lt;/td&gt;
      &lt;td&gt;2014-08-10&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;11&lt;/th&gt;
      &lt;td&gt;2013-08-16&lt;/td&gt;
      &lt;td&gt;2014-08-10&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12&lt;/th&gt;
      &lt;td&gt;2013-09-12&lt;/td&gt;
      &lt;td&gt;2014-08-13&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;13&lt;/th&gt;
      &lt;td&gt;2014-07-29&lt;/td&gt;
      &lt;td&gt;2014-08-14&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;23&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;14&lt;/th&gt;
      &lt;td&gt;2013-11-03&lt;/td&gt;
      &lt;td&gt;2014-08-11&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;37&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;15&lt;/th&gt;
      &lt;td&gt;2013-10-09&lt;/td&gt;
      &lt;td&gt;2014-08-13&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;16&lt;/th&gt;
      &lt;td&gt;2014-02-16&lt;/td&gt;
      &lt;td&gt;2014-08-12&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;17&lt;/th&gt;
      &lt;td&gt;2014-04-20&lt;/td&gt;
      &lt;td&gt;2014-08-14&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;18&lt;/th&gt;
      &lt;td&gt;2014-07-02&lt;/td&gt;
      &lt;td&gt;2014-08-12&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;19&lt;/th&gt;
      &lt;td&gt;2014-08-14&lt;/td&gt;
      &lt;td&gt;2014-05-10&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Today was a very intense day.   But the programming is delivering on what it promised: Hands On Learning From Experience Professions!&lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="sql"></category><category term="postgresql"></category><category term="psycopg2"></category></entry><entry><title>Galvanize - Week 01 - Day 3</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-01-03/" rel="alternate"></link><updated>2015-06-03T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-03:galvanize/galvanize-data-science-01-03/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 1 - Day 3&lt;/h2&gt;
&lt;p&gt;Today was an 'introduction' to SQL and PostgreSQL.  I put introduction in quotes because it does not properly describe what we did.  The pre-reading was to complete all 9 (1-9) tutorials on &lt;a href="http://sqlzoo.net/"&gt;SQLZoo&lt;/a&gt;.  This took me about 5 hours.   During lecture we have a review of the order of operation of SQL queries, as well as a detailed explanation of joins.    &lt;/p&gt;
&lt;p&gt;The sprint for the day involved install &lt;a href="http://www.postgresql.org/"&gt;PostgreSQL&lt;/a&gt; locally, loading a database into it, then completing ~25 basic and 10 advance (extra credit) queries.   Our database had 3 tables with 300k, 500k, and 5k entries respectively.&lt;/p&gt;
&lt;p&gt;These were a great set of assignment because of how they 'leveled-up'.  Even the few among us that were sophisticated with SQL had difficulty with the advance problems.&lt;/p&gt;
&lt;p&gt;Now that I have completed ~10 hours of SQL queries today, I am going to end this post now.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;SELECT * 
FROM bryan JOIN bed 
ON bryan.location=bed.location 
AND bryan.state=&amp;#39;sleep&amp;#39; 
AND bed.state=&amp;#39;comfy&amp;#39;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="sql"></category><category term="postgresql"></category></entry><entry><title>Galvanize - Week 01 - Day 2</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-01-02/" rel="alternate"></link><updated>2015-06-02T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-02:galvanize/galvanize-data-science-01-02/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 1 - Day 2&lt;/h2&gt;
&lt;p&gt;Today was he first 'regular' day in the program.  I showed up about 90 minutes before the mini-quiz to review the readings for the day's lecture on Object Oriented Programming (OOP).   At 9:30 we started the mini-quiz on SQL statements and results.  I found it rather simple.  We were given 30 minutes to complete it, and I finished in about 10 minutes.  Most the topics involved analogs in pandas that I am familiar with, so I think that's why I finished rather quickly.&lt;/p&gt;
&lt;h2&gt;Lecture&lt;/h2&gt;
&lt;p&gt;We had two lectures today.  The first lecture was on object oriented structures, and how to implement them in python.  The afternoon lecture was on scoping in python, and a little bit of debugging.  We were introduced to pdb, but told that the use of debuggers is not well integrated in the data science community.&lt;/p&gt;
&lt;h3&gt;LEGB&lt;/h3&gt;
&lt;p&gt;We were told the variables are looked for in the order of local, enclosing function, global, and python build-in.   I made a set of functions to try to illustrate it for myself.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nx"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;printer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="nx"&gt;x&lt;/span&gt;  &lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="nx"&gt;globally&lt;/span&gt; &lt;span class="nx"&gt;finds&lt;/span&gt; &lt;span class="nx"&gt;x&lt;/span&gt;
&lt;span class="nx"&gt;printer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;printer1&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="nx"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="nx"&gt;x&lt;/span&gt;  &lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="nx"&gt;locally&lt;/span&gt; &lt;span class="nx"&gt;finds&lt;/span&gt; &lt;span class="nx"&gt;x&lt;/span&gt;
&lt;span class="nx"&gt;printer1&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;printer2&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;innerprinter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="nx"&gt;x&lt;/span&gt;  &lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="nx"&gt;globally&lt;/span&gt; &lt;span class="nx"&gt;finds&lt;/span&gt; &lt;span class="nx"&gt;x&lt;/span&gt;
    &lt;span class="nx"&gt;innerprinter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;printer2&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;printer3&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="nx"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;
    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;innerprinter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="nx"&gt;x&lt;/span&gt; &lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="nx"&gt;encapsulating&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;finds&lt;/span&gt; &lt;span class="nx"&gt;x&lt;/span&gt;
    &lt;span class="nx"&gt;innerprinter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;printer3&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;printer4&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;innerprinter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="kr"&gt;int&lt;/span&gt; &lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="nx"&gt;built&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;finds&lt;/span&gt; &lt;span class="kr"&gt;int&lt;/span&gt;
    &lt;span class="nx"&gt;innerprinter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;printer4&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;printer5&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="kr"&gt;int&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;innerprinter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="kr"&gt;int&lt;/span&gt; &lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="nx"&gt;encapsulating&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;finds&lt;/span&gt; &lt;span class="kr"&gt;int&lt;/span&gt;
    &lt;span class="nx"&gt;innerprinter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;printer5&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="kr"&gt;int&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;
&lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;printer6&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;innerprinter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="nx"&gt;print&lt;/span&gt; &lt;span class="kr"&gt;int&lt;/span&gt; &lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="nx"&gt;globally&lt;/span&gt; &lt;span class="nx"&gt;finds&lt;/span&gt; &lt;span class="kr"&gt;int&lt;/span&gt;
    &lt;span class="nx"&gt;innerprinter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;printer6&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nx"&gt;type&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;int&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="mi"&gt;6&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Paired Programming Sprint&lt;/h2&gt;
&lt;p&gt;Today's project involved programming a text based game of black jack with a dealer and 1 number of players.  We also had the extra credit options adding n-players, AI/Bot players, double down, and split.  I am happy to report that we that my partner and I were able to complete the first three, but ran out of time before implementing split.&lt;/p&gt;
&lt;p&gt;We started off with pencil and paper using the noun,verb method of abstraction.   We settled on making a Deck, a Player, and Hand, and Game, and an AI.    Its clear at the end that we should have abstracted the game more, and given the Hand class more responsibilities to best implement the split method.&lt;/p&gt;
&lt;p&gt;After we finished we had our dealer hit until 17 or above, while our AI bot hit until soft 17 below.   We also had it implement a doubling bettering strategy.   In our sample, the AI agent one more often then not came out ahead from this setup.   It added a little credence to the ways dealer's seem to play in Las Vegas.&lt;/p&gt;
&lt;p&gt;The repo is currently private, because it could be a project for future cohorts.   I do not want to make a copy public, but will if they give permission.&lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="python"></category></entry><entry><title>Galvanize - Week 01 - Day 1</title><link href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-01-01/" rel="alternate"></link><updated>2015-06-01T10:30:00-07:00</updated><author><name>Bryan Smith</name></author><id>tag:www.bryantravissmith.com,2015-06-01:galvanize/galvanize-data-science-01-01/</id><summary type="html">&lt;h1&gt;Galvanize Immersive Data Science&lt;/h1&gt;
&lt;h2&gt;Week 1 - Day 1&lt;/h2&gt;
&lt;p&gt;Today is my first day attending Galvanize's Immersive Data Science Program in San Francisco, CA.   The program is a 12 week program that is approximately 10 hours a day of learning and activities to reinforce and refine the learning.   I am very excited to be a part of this program.&lt;/p&gt;
&lt;h2&gt;My Background&lt;/h2&gt;
&lt;p&gt;I have a Ph.d in Theoretical High Energy Particle Physics and Cosmology, earned a Data Analysis Nano-degree from Udacity.com, and also am current working on a M.S. in Computer Science from GA Tech.    I have also spent the last 8 years teaching high school physics and robotics.   &lt;/p&gt;
&lt;p&gt;I will likely have some strength with math and theory, but I have no doubt that my programming will significantly improve over the next 12 weeks.   Everyone in the program is well educated and intelligent, and each one of them have strengths in some areas and room for improvements in others.  It seems to be a strength for this program.   No matter your weakness, there are students that have that as a strength.&lt;/p&gt;
&lt;h2&gt;Summary of the Day&lt;/h2&gt;
&lt;p&gt;The first half of the day is getting to know our instructors, hour cohort, and the amazingly nice galvanize complex.  It is a 5 story building filled with startup companies, work spaces, galvanize students, and other tech visitors.   I found this to be an impressive building.&lt;/p&gt;
&lt;p&gt;After about an hour of getting to know everyone, we were given a presentation.  That was followed by a tour of the galvanize building.  We were then given an assessment on the pre-course material that was given to us before we showed up.&lt;/p&gt;
&lt;p&gt;After lunch, we had an 90 minute lecture, then worked on a paired sprint assignment for about 3 hours.   This assignment involved...&lt;/p&gt;
&lt;p&gt;After we finished the sprint, we were invited to a Galvanize happy hour to socialize over beer and wine.   I feel very lucky to be apart of this program, and have been impressed with my cohort, the instructors, and Galvanize.  &lt;/p&gt;
&lt;h2&gt;The Test&lt;/h2&gt;
&lt;p&gt;The pre-course material required us to complete material on the following topics:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Python&lt;/li&gt;
&lt;li&gt;Linear Algebra&lt;/li&gt;
&lt;li&gt;SQL&lt;/li&gt;
&lt;li&gt;Numpy/Pandas&lt;/li&gt;
&lt;li&gt;Probability&lt;/li&gt;
&lt;li&gt;Statistics&lt;/li&gt;
&lt;li&gt;Hypothesis Testing&lt;/li&gt;
&lt;li&gt;Web Awareness&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The initial assessment we were given was a 120 minute test on the first 5 topics.  It was an 'open book' test, but that does not mean it was easy.  A majority of my peers did not finish within the allotted time.   &lt;/p&gt;
&lt;p&gt;I am not going to post details on the test because I would hate to ruin the thrill of discovery for potential future students.&lt;/p&gt;
&lt;h2&gt;LUNCH!!!!&lt;/h2&gt;
&lt;p&gt;They provide us a lunch on the first day, but most days we have an 75 minute break for lunch.  There are kitchen, fridges, storage for us to use if we wish.   The lunch was nice, from a local Thai place.   &lt;/p&gt;
&lt;h2&gt;Lecture&lt;/h2&gt;
&lt;p&gt;The lecture, in my opinion, was a little redundant with the course material.  It seemed structure under the assumption that you didn't read or review the python pre-course materials.  I understand its important that everyone is on the same starting point, but I wish we got to jump in a little deeper.&lt;/p&gt;
&lt;p&gt;I did learn and see the importance of using generators when possible.   It save both memory and time.   &lt;/p&gt;
&lt;h2&gt;Paired programming&lt;/h2&gt;
&lt;p&gt;After the lecture we grouped up for a paired programming assignment.   We trade off roles of being the driver and the navigator in 20 to 30 minute rotations for a 3 hour block of programming.  We start of by forking the day's assignment from a Github repo and cloning it locally.  Today we then worked two projects.  The first project was completing a list of functions based on a description of the function, including inputs and outputs.  The second project was fixing inefficiently running code.&lt;/p&gt;
&lt;p&gt;A simple example is checking if a key is in a dictionary.   Before today I might have checked to see if it was in the keys() results, but we can see that for medium size dictionaries that it is almost 40x slower than just using in in the dictionary.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;collections&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;randint&lt;/span&gt;

&lt;span class="n"&gt;cnt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10000&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;cnt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;cnt&lt;/span&gt;

&lt;span class="mi"&gt;100000&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;4.17&lt;/span&gt; &lt;span class="err"&gt;µ&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;
&lt;span class="mi"&gt;10000000&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;111&lt;/span&gt; &lt;span class="n"&gt;ns&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We saw similar results for iter compared to iteritems, range to xrange, and izip to zip.   It was a useful assignment for the content and the practice of collaborating with someone else.&lt;/p&gt;
&lt;h2&gt;After reception&lt;/h2&gt;
&lt;p&gt;Galvanize SF now runs two cohorts 6 weeks apart.  We had a mixer with previous cohort, enjoying beer, wine, and conversation on the roof of the building.  &lt;/p&gt;
&lt;p&gt;After 11 hours at Galvanize, I decided it was time to head home.   Definitely looking forward to day 2. &lt;/p&gt;</summary><category term="data-science"></category><category term="galvanize"></category><category term="python"></category></entry></feed>