<!DOCTYPE html>
<html lang="en">

<head>
      <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="canonical" href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-06-03/index.html" />

    <title>  Bryan Travis Smith, Ph.D &mdash; Galvanize - Week 06 - Day 3
</title>




    <link rel="stylesheet" href="http://www.bryantravissmith.com/theme/css/style.css">

    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-24340005-3', 'auto');
    ga('send', 'pageview');

  </script>

    <meta name="author" content="Bryan Smith">
    <meta name="description" content="Today we covered clustering recommendation engines, focusing on collaboritive filtering.">
  <meta name="tags" contents="data-science, galvanize, nlp, collaboritive filtering, recommendation engines, ">
</head>

<body>
<header class="header">
  <div class="container">
      <div class="header-image pull-left">
        <a class="nodec" href="http://www.bryantravissmith.com"><img src=http://www.bryantravissmith.com/img/bryan.jpeg></a>
      </div>
    <div class="header-inner">
      <h1 class="header-name">
        <a class="nodec" href="http://www.bryantravissmith.com">Bryan Travis Smith, Ph.D</a>
      </h1>
      <h3 class="header-text">Physicist, Data Scientist, Martial Artist, & Life Enthusiast</h3>
      <ul class="header-menu list-inline">
              <li class="muted">|</li>
            <li><a class="nodec" href="http://www.bryantravissmith.com/about/">About</a></li>
              <li class="muted">|</li>
          <li><a class="nodec icon-mail-alt" href="mailto:bryantravissmith@gmail.com"></a></li>
          <li><a class="nodec icon-github" href="https://github.com/bryantravissmith"></a></li>
      </ul>
    </div>
  </div>
</header> <!-- /.header -->  <div class="container">
  <div class="post full-post">
    <h1 class="post-title">
      <a href="/galvanize/galvanize-data-science-06-03/" title="Permalink to Galvanize - Week 06 - Day 3">Galvanize - Week 06 - Day 3</a>
    </h1>
    <ul class="list-inline">
      <li class="post-date">
        <a class="text-muted" href="/galvanize/galvanize-data-science-06-03/" title="2015-07-08T10:20:00-07:00">Wed 08 July 2015</a>
      </li>
      <li class="muted">&middot;</li>
      <li class="post-category">
        <a href="http://www.bryantravissmith.com/category/galvanize.html">Galvanize</a>
      </li>
        <li class="muted">&middot;</li>
        <li>
          <address class="post-author">
            By <a href="http://www.bryantravissmith.com/author/bryan-smith.html">Bryan Smith</a>
          </address>
        </li>
    </ul>
    <div class="post-content">
      <h1>Galvanize Immersive Data Science</h1>
<h2>Week 6 - Day 3</h2>
<p>I liked our quiz today.  It was more SQL, but we had to load data into a local PostgreSQL database and test the queries.  We were give two table discriptions:</p>
<div class="highlight"><pre>log
    userid
    tmstmp
    itemid
    event

items
    itemid
    name
    category
</pre></div>


<p>Where the possible events are:
<em> <code>view</code>: Viewing the details of an item
</em> <code>add</code>: Adding the item to shopping cart
* <code>buy</code>: Buying an item</p>
<p>We had to write two queries.  One that would select all the user, item pairs where a user has added an item to the cart but has not bought it.  If they bought that item, then added it to their cart again, that add should be counted.  </p>
<div class="highlight"><pre>    SELECT a.userid, a.itemid FROM log a 
    JOIN (SELECT userid, 
                    itemid, 
                    MAX(tmstmp) as last_tmstmp 
        FROM log
        GROUP BY userid, itemid) b 
    ON a.userid = b.userid
    AND a.itemid = b.itemid
    AND a.event = &#39;add&#39;
    AND a.tmstmp = b.last_tmstamp
</pre></div>


<p>The next query we had to write was to fetch the ratio of views to purchases for each category.   I decided to get the count for views and joins for each item, then group by category for the ratio.  </p>
<div class="highlight"><pre>    SELECT i.category,
        SUM( a.buy_count ) / SUM( a.view_count ) 
            as ration
    FROM items i JOIN (
        SELECT itemid,
        SUM( CASE(event = &#39;buy&#39; THEN 1 ELSE 0) )
            as buy_count,
        SUM( CASE(event = &#39;view&#39; THEN 1 ELSE 0) )
            as view_count 
        FROM log 
        GROUP BY itemid) a
    ON i.itemid = a.itemid
    GROUP BY i.category
</pre></div>


<h2>Collaborative Filtering</h2>
<p>Collaborative Filtering is a way to make recommendations based on using related data to make predictions.  There are item-item collaborative filtering techniques that take interest in one item to be a signal that you might be interested in a similar item.  User-user collaborative filtering takes users that are similar to you and recommends things these users have liked that you have not tried/bought/experienced.   </p>
<p>Our morning sprint is making an item-item collaborative filtering enging for moviews in the data from 
You will be using the <a href="http://grouplens.org/datasets/movielens/">MovieLens</a></p>
<p>Our process for making recommendations will involved the following: </p>
<ol>
<li>Calculated how similarly movies are related using cosine similarity  </li>
<li>Construct a neighborhood for each movie of the N most similar movies  </li>
<li>Take the weighted average of each user's previous ratings for each movie's neighborhood</li>
<li>Return prediction</li>
</ol>
<p>Our ItemItemRecommender Class is below.  This class does not take advantage of scipy's sparse matrixes.  The reason is I found that for this dataset that it ran measurably slower compared to using numpy matrixes.   I am not sure if I am just unfarmiliar with the best practices of sparse matrixes, or if there is something characteristic of sparse matrixes.  </p>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="k">class</span> <span class="nc">ItemItemRecommender</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">neighborhood_size</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initializes the parameters of the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighborhood_size</span> <span class="o">=</span> <span class="n">neighborhood_size</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="kp">matrix</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Implements the model and fits it to the data passed as an</span>
<span class="sd">        argument.</span>

<span class="sd">        Stores objects for describing model fit as class attributes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="kp">matrix</span> <span class="o">=</span> <span class="kp">matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_neighborhoods</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_set_neighborhoods</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Gets the items most similar to each other item.</span>

<span class="sd">        Should set a class attribute with a matrix that is has</span>
<span class="sd">        number of rows equal to number of items and number of </span>
<span class="sd">        columns equal to neighborhood size. Entries of this matrix</span>
<span class="sd">        will be indexes of other items.</span>

<span class="sd">        You will call this in your fit method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sim</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="kp">matrix</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighborhoods</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">argsort</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="p">[:,:],</span><span class="mi">1</span><span class="p">)[:,</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">neighborhood_size</span><span class="p">:]</span>

    <span class="k">def</span> <span class="nf">pred_one_user</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Accept user id as arg. Return the predictions for a single user.</span>

<span class="sd">        Optional argument to specify whether or not timing should be provided</span>
<span class="sd">        on this operation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="kp">matrix</span><span class="p">[</span><span class="n">index</span><span class="p">,:]</span><span class="o">.</span><span class="kp">nonzero</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="kp">matrix</span><span class="o">.</span><span class="kp">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="kp">matrix</span><span class="o">.</span><span class="kp">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">relevant_items</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">intersect1d</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">neighborhoods</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">assume_unique</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="c">#if i in scores:</span>
            <span class="c">#    result = self.matrix[mask,:][0,i]</span>
            <span class="c">#else:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="kp">matrix</span><span class="p">[</span><span class="n">index</span><span class="p">,</span><span class="n">relevant_items</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">relevant_items</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">result</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="kp">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">relevant_items</span><span class="p">])</span>
            <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span>
        <span class="k">return</span> <span class="n">predictions</span>

    <span class="k">def</span> <span class="nf">pred_all_users</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Repeated calls of pred_one_user, are combined into a single matrix.</span>
<span class="sd">        Return value is matrix of users (rows) items (columns) and predicted</span>
<span class="sd">        ratings (values).</span>

<span class="sd">        Optional argument to specify whether or not timing should be provided</span>
<span class="sd">        on this operation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="kp">matrix</span><span class="o">.</span><span class="kp">shape</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="kp">matrix</span><span class="o">.</span><span class="kp">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_one_user</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">predictions</span>


    <span class="k">def</span> <span class="nf">top_n_recs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">index</span><span class="p">,</span><span class="n">n</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Takes user_id argument and number argument.</span>

<span class="sd">        Returns that number of items with the highest predicted ratings,</span>
<span class="sd">        after removing items that user has already rated.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="kp">matrix</span><span class="p">[</span><span class="n">index</span><span class="p">,:]</span><span class="o">.</span><span class="kp">nonzero</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_one_user</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">predictions</span><span class="p">[</span><span class="n">scores</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="kp">argsort</span><span class="p">(</span><span class="n">predictions</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="n">n</span><span class="p">]</span>
</pre></div>


<p>We are ready to import our data</p>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">ItemRecommender</span> <span class="kn">import</span> <span class="n">ItemItemRecommender</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">ratings_contents</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="s">&quot;../data/u.data&quot;</span><span class="p">,</span>
                                     <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s">&quot;user&quot;</span><span class="p">,</span> <span class="s">&quot;movie&quot;</span><span class="p">,</span> <span class="s">&quot;rating&quot;</span><span class="p">,</span> <span class="s">&quot;timestamp&quot;</span><span class="p">])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">ratings_contents</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s">&#39;timestamp&#39;</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s">&#39;user&#39;</span><span class="p">,</span><span class="s">&#39;movie&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">unstack</span><span class="p">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">droplevel</span><span class="p">()</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>


<div style="max-height:1000px;max-width:1500px;overflow:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>movie</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>...</th>
      <th>1673</th>
      <th>1674</th>
      <th>1675</th>
      <th>1676</th>
      <th>1677</th>
      <th>1678</th>
      <th>1679</th>
      <th>1680</th>
      <th>1681</th>
      <th>1682</th>
    </tr>
    <tr>
      <th>user</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>5</td>
      <td>3</td>
      <td>4</td>
      <td>3</td>
      <td>3</td>
      <td>5</td>
      <td>4</td>
      <td>1</td>
      <td>5</td>
      <td>3</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>4</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1682 columns</p>
</div>

<div class="highlight"><pre><span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>
<span class="n">IIR</span> <span class="o">=</span> <span class="n">ItemItemRecommender</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">IIR</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="k">print</span> <span class="s">&quot;Time to Fit: &quot;</span><span class="p">,</span> <span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">t1</span>

<span class="n">Time</span> <span class="n">to</span> <span class="n">Fit</span><span class="p">:</span>  <span class="mf">0.853658914566</span>
</pre></div>


<p>The item-item recommender is finding a cosine similarity matrix, which is relatively quick.  Predictions, however, will not that quick.</p>
<div class="highlight"><pre>t1=time()
print &quot;Prediction: &quot;, np.round(IIR.pred_one_user(0)[:10],0)
print &quot;Actual:     &quot;, df.values[0,:10]
print &quot;Time to Predict 1 User: &quot;, time()-t1

Prediction:  [ 4.  3.  4.  4.  3.  5.  4.  4.  4.  4.]
Actual:      [ 5.  3.  4.  3.  3.  5.  4.  1.  5.  3.]
Time to Predict 1 User:  0.0642509460449
</pre></div>


<p>If we want to predict for all users.</p>
<div class="highlight"><pre>t1 = time()
predictions = IIR.pred_all_users()
print &quot;Time to predict 943 Users:&quot;, time()-t1

Time to predict 943 Users: 23.9097139835
</pre></div>


<p>We can also increase the size of the neighborhoods for similar movies.  We just did 20, lets change it to 75.</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>
<span class="n">IIR</span> <span class="o">=</span> <span class="n">ItemItemRecommender</span><span class="p">(</span><span class="mi">75</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">IIR</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="k">print</span> <span class="s">&quot;Time to Fit: &quot;</span><span class="p">,</span> <span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">t1</span>
<span class="n">t1</span><span class="o">=</span><span class="n">time</span><span class="p">()</span>
<span class="k">print</span> <span class="s">&quot;Prediction: &quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">IIR</span><span class="o">.</span><span class="n">pred_one_user</span><span class="p">(</span><span class="mi">0</span><span class="p">)[:</span><span class="mi">10</span><span class="p">],</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span> <span class="s">&quot;Actual:     &quot;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">,:</span><span class="mi">10</span><span class="p">]</span>
<span class="k">print</span> <span class="s">&quot;Time to Predict 1 User: &quot;</span><span class="p">,</span> <span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">t1</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">IIR</span><span class="o">.</span><span class="n">pred_all_users</span><span class="p">()</span>
<span class="k">print</span> <span class="s">&quot;Time to predict 943 Users:&quot;</span><span class="p">,</span> <span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">t1</span>

<span class="n">Time</span> <span class="n">to</span> <span class="n">Fit</span><span class="p">:</span>  <span class="mf">0.224536895752</span>
<span class="n">Prediction</span><span class="p">:</span>  <span class="p">[</span> <span class="mf">4.</span>  <span class="mf">4.</span>  <span class="mf">4.</span>  <span class="mf">4.</span>  <span class="mf">4.</span>  <span class="mf">5.</span>  <span class="mf">4.</span>  <span class="mf">4.</span>  <span class="mf">4.</span>  <span class="mf">4.</span><span class="p">]</span>
<span class="n">Actual</span><span class="p">:</span>      <span class="p">[</span> <span class="mf">5.</span>  <span class="mf">3.</span>  <span class="mf">4.</span>  <span class="mf">3.</span>  <span class="mf">3.</span>  <span class="mf">5.</span>  <span class="mf">4.</span>  <span class="mf">1.</span>  <span class="mf">5.</span>  <span class="mf">3.</span><span class="p">]</span>
<span class="n">Time</span> <span class="n">to</span> <span class="n">Predict</span> <span class="mi">1</span> <span class="n">User</span><span class="p">:</span>  <span class="mf">0.0480990409851</span>
<span class="n">Time</span> <span class="n">to</span> <span class="n">predict</span> <span class="mi">943</span> <span class="n">Users</span><span class="p">:</span> <span class="mf">32.1997280121</span>
</pre></div>


<p>We can see that the neighborhood size is going to change the results.  One thing I know is that there are many more action moviews then documentaries in the dataset.   This does not allow us to filter based on the different number of each.   </p>
<p>The larger neighborhood also increases the computation size.  Papers have published results that it does reduce the mean square error.  For a production item-item recommender like the one we built, we would have to update our predictions at a regualar basis.  This would have to be off line because of how long it takes to fit.</p>
<h2>Top Movies</h2>
<p>We also have movie details for the data in our recommender.  I am going to import that data and see what movies are being recommended.</p>
<div class="highlight"><pre>idf = pd.read_table(&quot;../data/u.item&quot;,sep=&quot;|&quot;,header=None)
idf = idf.iloc[:,[1,2]]
idf.columns = [&#39;Title&#39;,&#39;Date&#39;]
idf.head()
</pre></div>


<div style="max-height:1000px;max-width:1500px;overflow:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Title</th>
      <th>Date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Toy Story (1995)</td>
      <td>01-Jan-1995</td>
    </tr>
    <tr>
      <th>1</th>
      <td>GoldenEye (1995)</td>
      <td>01-Jan-1995</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Four Rooms (1995)</td>
      <td>01-Jan-1995</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Get Shorty (1995)</td>
      <td>01-Jan-1995</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Copycat (1995)</td>
      <td>01-Jan-1995</td>
    </tr>
  </tbody>
</table>
</div>

<p>The first user rated the following movies:</p>
<div class="highlight"><pre>user1_rating_indexes = df.values[0,:].nonzero()[0]
user1 = idf.loc[user1_rating_indexes,:]
user1[&#39;Ratings&#39;] = df.values[0,user1_rating_indexes]
user1[user1.Ratings==5]
</pre></div>


<div style="max-height:1000px;max-width:1500px;overflow:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Title</th>
      <th>Date</th>
      <th>Ratings</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Toy Story (1995)</td>
      <td>01-Jan-1995</td>
      <td>5</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Shanghai Triad (Yao a yao yao dao waipo qiao) ...</td>
      <td>01-Jan-1995</td>
      <td>5</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Dead Man Walking (1995)</td>
      <td>01-Jan-1995</td>
      <td>5</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Usual Suspects, The (1995)</td>
      <td>14-Aug-1995</td>
      <td>5</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Mighty Aphrodite (1995)</td>
      <td>30-Oct-1995</td>
      <td>5</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Postino, Il (1994)</td>
      <td>01-Jan-1994</td>
      <td>5</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Mr. Holland's Opus (1995)</td>
      <td>29-Jan-1996</td>
      <td>5</td>
    </tr>
    <tr>
      <th>15</th>
      <td>French Twist (Gazon maudit) (1995)</td>
      <td>01-Jan-1995</td>
      <td>5</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Antonia's Line (1995)</td>
      <td>01-Jan-1995</td>
      <td>5</td>
    </tr>
    <tr>
      <th>31</th>
      <td>Crumb (1994)</td>
      <td>01-Jan-1994</td>
      <td>5</td>
    </tr>
    <tr>
      <th>41</th>
      <td>Clerks (1994)</td>
      <td>01-Jan-1994</td>
      <td>5</td>
    </tr>
    <tr>
      <th>43</th>
      <td>Dolores Claiborne (1994)</td>
      <td>01-Jan-1994</td>
      <td>5</td>
    </tr>
    <tr>
      <th>44</th>
      <td>Eat Drink Man Woman (1994)</td>
      <td>01-Jan-1994</td>
      <td>5</td>
    </tr>
    <tr>
      <th>47</th>
      <td>Hoop Dreams (1994)</td>
      <td>01-Jan-1994</td>
      <td>5</td>
    </tr>
    <tr>
      <th>49</th>
      <td>Star Wars (1977)</td>
      <td>01-Jan-1977</td>
      <td>5</td>
    </tr>
    <tr>
      <th>54</th>
      <td>Professional, The (1994)</td>
      <td>01-Jan-1994</td>
      <td>5</td>
    </tr>
    <tr>
      <th>56</th>
      <td>Priest (1994)</td>
      <td>01-Jan-1994</td>
      <td>5</td>
    </tr>
    <tr>
      <th>58</th>
      <td>Three Colors: Red (1994)</td>
      <td>01-Jan-1994</td>
      <td>5</td>
    </tr>
    <tr>
      <th>59</th>
      <td>Three Colors: Blue (1993)</td>
      <td>01-Jan-1993</td>
      <td>5</td>
    </tr>
    <tr>
      <th>63</th>
      <td>Shawshank Redemption, The (1994)</td>
      <td>01-Jan-1994</td>
      <td>5</td>
    </tr>
    <tr>
      <th>80</th>
      <td>Hudsucker Proxy, The (1994)</td>
      <td>01-Jan-1994</td>
      <td>5</td>
    </tr>
    <tr>
      <th>81</th>
      <td>Jurassic Park (1993)</td>
      <td>01-Jan-1993</td>
      <td>5</td>
    </tr>
    <tr>
      <th>85</th>
      <td>Remains of the Day, The (1993)</td>
      <td>01-Jan-1993</td>
      <td>5</td>
    </tr>
    <tr>
      <th>86</th>
      <td>Searching for Bobby Fischer (1993)</td>
      <td>01-Jan-1993</td>
      <td>5</td>
    </tr>
    <tr>
      <th>88</th>
      <td>Blade Runner (1982)</td>
      <td>01-Jan-1982</td>
      <td>5</td>
    </tr>
    <tr>
      <th>90</th>
      <td>Nightmare Before Christmas, The (1993)</td>
      <td>01-Jan-1993</td>
      <td>5</td>
    </tr>
    <tr>
      <th>92</th>
      <td>Welcome to the Dollhouse (1995)</td>
      <td>24-May-1996</td>
      <td>5</td>
    </tr>
    <tr>
      <th>95</th>
      <td>Terminator 2: Judgment Day (1991)</td>
      <td>01-Jan-1991</td>
      <td>5</td>
    </tr>
    <tr>
      <th>99</th>
      <td>Fargo (1996)</td>
      <td>14-Feb-1997</td>
      <td>5</td>
    </tr>
    <tr>
      <th>107</th>
      <td>Kids in the Hall: Brain Candy (1996)</td>
      <td>12-Apr-1996</td>
      <td>5</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>173</th>
      <td>Raiders of the Lost Ark (1981)</td>
      <td>01-Jan-1981</td>
      <td>5</td>
    </tr>
    <tr>
      <th>174</th>
      <td>Brazil (1985)</td>
      <td>01-Jan-1985</td>
      <td>5</td>
    </tr>
    <tr>
      <th>175</th>
      <td>Aliens (1986)</td>
      <td>01-Jan-1986</td>
      <td>5</td>
    </tr>
    <tr>
      <th>176</th>
      <td>Good, The Bad and The Ugly, The (1966)</td>
      <td>01-Jan-1966</td>
      <td>5</td>
    </tr>
    <tr>
      <th>177</th>
      <td>12 Angry Men (1957)</td>
      <td>01-Jan-1957</td>
      <td>5</td>
    </tr>
    <tr>
      <th>180</th>
      <td>Return of the Jedi (1983)</td>
      <td>14-Mar-1997</td>
      <td>5</td>
    </tr>
    <tr>
      <th>182</th>
      <td>Alien (1979)</td>
      <td>01-Jan-1979</td>
      <td>5</td>
    </tr>
    <tr>
      <th>189</th>
      <td>Henry V (1989)</td>
      <td>01-Jan-1989</td>
      <td>5</td>
    </tr>
    <tr>
      <th>190</th>
      <td>Amadeus (1984)</td>
      <td>01-Jan-1984</td>
      <td>5</td>
    </tr>
    <tr>
      <th>194</th>
      <td>Terminator, The (1984)</td>
      <td>01-Jan-1984</td>
      <td>5</td>
    </tr>
    <tr>
      <th>195</th>
      <td>Dead Poets Society (1989)</td>
      <td>01-Jan-1989</td>
      <td>5</td>
    </tr>
    <tr>
      <th>196</th>
      <td>Graduate, The (1967)</td>
      <td>01-Jan-1967</td>
      <td>5</td>
    </tr>
    <tr>
      <th>197</th>
      <td>Nikita (La Femme Nikita) (1990)</td>
      <td>01-Jan-1990</td>
      <td>5</td>
    </tr>
    <tr>
      <th>201</th>
      <td>Groundhog Day (1993)</td>
      <td>01-Jan-1993</td>
      <td>5</td>
    </tr>
    <tr>
      <th>203</th>
      <td>Back to the Future (1985)</td>
      <td>01-Jan-1985</td>
      <td>5</td>
    </tr>
    <tr>
      <th>206</th>
      <td>Cyrano de Bergerac (1990)</td>
      <td>01-Jan-1990</td>
      <td>5</td>
    </tr>
    <tr>
      <th>207</th>
      <td>Young Frankenstein (1974)</td>
      <td>01-Jan-1974</td>
      <td>5</td>
    </tr>
    <tr>
      <th>215</th>
      <td>When Harry Met Sally... (1989)</td>
      <td>01-Jan-1989</td>
      <td>5</td>
    </tr>
    <tr>
      <th>220</th>
      <td>Breaking the Waves (1996)</td>
      <td>15-Nov-1996</td>
      <td>5</td>
    </tr>
    <tr>
      <th>222</th>
      <td>Sling Blade (1996)</td>
      <td>22-Nov-1996</td>
      <td>5</td>
    </tr>
    <tr>
      <th>223</th>
      <td>Ridicule (1996)</td>
      <td>27-Nov-1996</td>
      <td>5</td>
    </tr>
    <tr>
      <th>227</th>
      <td>Star Trek: The Wrath of Khan (1982)</td>
      <td>01-Jan-1982</td>
      <td>5</td>
    </tr>
    <tr>
      <th>234</th>
      <td>Mars Attacks! (1996)</td>
      <td>13-Dec-1996</td>
      <td>5</td>
    </tr>
    <tr>
      <th>241</th>
      <td>Kolya (1996)</td>
      <td>24-Jan-1997</td>
      <td>5</td>
    </tr>
    <tr>
      <th>245</th>
      <td>Chasing Amy (1997)</td>
      <td>01-Jan-1997</td>
      <td>5</td>
    </tr>
    <tr>
      <th>252</th>
      <td>Pillow Book, The (1995)</td>
      <td>13-Jun-1997</td>
      <td>5</td>
    </tr>
    <tr>
      <th>257</th>
      <td>Contact (1997)</td>
      <td>11-Jul-1997</td>
      <td>5</td>
    </tr>
    <tr>
      <th>267</th>
      <td>Chasing Amy (1997)</td>
      <td>01-Jan-1997</td>
      <td>5</td>
    </tr>
    <tr>
      <th>268</th>
      <td>Full Monty, The (1997)</td>
      <td>01-Jan-1997</td>
      <td>5</td>
    </tr>
    <tr>
      <th>269</th>
      <td>Gattaca (1997)</td>
      <td>01-Jan-1997</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
<p>81 rows × 3 columns</p>
</div>

<p>Based on this list, our recommener is making recommendations for movies that user has not watched.  The Top 10 Movies recommended to this user are:</p>
<div class="highlight"><pre>idf.loc[IIR.top_n_recs(0,10),:]
</pre></div>


<div style="max-height:1000px;max-width:1500px;overflow:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Title</th>
      <th>Date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>810</th>
      <td>Thirty-Two Short Films About Glenn Gould (1993)</td>
      <td>01-Jan-1993</td>
    </tr>
    <tr>
      <th>1572</th>
      <td>Spirits of the Dead (Tre passi nel delirio) (1...</td>
      <td>01-Jan-1968</td>
    </tr>
    <tr>
      <th>1526</th>
      <td>Senseless (1998)</td>
      <td>09-Jan-1998</td>
    </tr>
    <tr>
      <th>1462</th>
      <td>Boys, Les (1997)</td>
      <td>01-Jan-1997</td>
    </tr>
    <tr>
      <th>792</th>
      <td>Crooklyn (1994)</td>
      <td>01-Jan-1994</td>
    </tr>
    <tr>
      <th>1544</th>
      <td>Frankie Starlight (1995)</td>
      <td>01-Jan-1995</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>Mrs. Dalloway (1997)</td>
      <td>01-Jan-1997</td>
    </tr>
    <tr>
      <th>781</th>
      <td>Little Odessa (1994)</td>
      <td>01-Jan-1994</td>
    </tr>
    <tr>
      <th>1369</th>
      <td>I Can't Sleep (J'ai pas sommeil) (1994)</td>
      <td>01-Jan-1994</td>
    </tr>
    <tr>
      <th>1360</th>
      <td>Search for One-eye Jimmy, The (1996)</td>
      <td>01-Jan-1996</td>
    </tr>
  </tbody>
</table>
</div>

<p>Unfortunately we do not have a measure for how successful these recommnedations are.  We can not have the user watch them, and if we did we would need the user to follow up with a rating.  These are all predicted to be 5 star movies for this user.</p>
<p>One of the shortcomings I see from looking up some of these titles on IMDB is the measure of similarity is only user ratings.   This metric does not deal with the property of the movies.  I, personally, like Kevin Spacey.   He has been in a wide variety of movies, and I have enjoyed movies that are out of my traditional preferences in part of his performances.   That is not weighted into our similarity.  Including it, however, will also increase the computational time for updates.  </p>
<h2>Matrix Factorization Based Recommenders</h2>
<p>Our afternoon paired sprint was implementing matrix factorization based recommenders.   These involved constructing two matrixes that multiply together to produce the rating matrix.  The idea is that through the user of latent variables, the matrix product will make predictions for movies that are not yet reviewed.  </p>
<p>We were introduced to the <a href="http://sifter.org/~simon/journal/20061211.html">Simon Funk</a> matrix factorization using stocastic gradient decent.   There is a good <a href="http://www2.research.att.com/~volinsky/papers/ieeecomputer.pdf">ATT Research Paper</a> on this topics.  Our implmentation was to be contained in a class that match the 'API' from the morning sprint.   </p>
<p>The idea is that we have a ratings matrix $R$, and are trying to break it into a users matrix $U$ and a movie matrix $M$ such that:</p>
<p>$$R = U \ M$$</p>
<p>Since we do not know $U$ and $M$, we must find it by finding the error, then iteratively changing the matrixes until we have the least error possible.</p>
<p>$$ \mbox{squared error} =  \sum_{i,j} (r_{ij} - u_{ia} \ m_{aj})^2 $$</p>
<p>The SGD method is to go through all the ratings and use the following update rules:</p>
<p>$$ u_i \ = u_i + \ \gamma ( e_{ij} m_i - \lambda u_i ) $$</p>
<p>$$ m_i  \ = m_i + \ \gamma ( e_{ij} u_j - \lambda m_i ) $$</p>
<p>You can see our class below</p>
<div class="highlight"><pre><span class="s-Atom">class</span> <span class="nv">MatrixFactorizationRecommender</span><span class="p">(</span><span class="s-Atom">object</span><span class="p">)</span><span class="s-Atom">:</span>

    <span class="s-Atom">def</span> <span class="k">__</span><span class="nf">init__</span><span class="p">(</span><span class="s-Atom">self</span><span class="p">,</span><span class="s-Atom">n_features</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span><span class="s-Atom">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span> 
                 <span class="s-Atom">regularization</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span><span class="s-Atom">optimizer_pct_improvement_criterion</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                 <span class="s-Atom">verbose</span><span class="o">=</span><span class="nv">False</span><span class="p">)</span><span class="s-Atom">:</span>

        <span class="s2">&quot;&quot;&quot;Initializes the parameters of the model.</span>
<span class="s2">        &quot;&quot;&quot;</span>
        <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">n_features</span> <span class="o">=</span> <span class="s-Atom">n_features</span>
        <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">learning_rate</span> <span class="o">=</span> <span class="s-Atom">learning_rate</span>
        <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">regularization</span> <span class="o">=</span> <span class="s-Atom">regularization</span>
        <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">optimizer_pct_improvement_criterion</span> <span class="o">=</span> <span class="s-Atom">optimizer_pct_improvement_criterion</span>
        <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">verbose</span> <span class="o">=</span> <span class="s-Atom">verbose</span>

    <span class="s-Atom">def</span> <span class="nf">fit</span><span class="p">(</span><span class="s-Atom">self</span><span class="p">,</span><span class="s-Atom">matrix</span><span class="p">)</span><span class="s-Atom">:</span>
        <span class="s2">&quot;&quot;&quot;Like the scikit learn fit methods, this method </span>
<span class="s2">        should take the ratings data as an input and should</span>
<span class="s2">        compute and store the matrix factorization. It should assign</span>
<span class="s2">        some class variables like n_users, which depend on the</span>
<span class="s2">        ratings_mat data.</span>

<span class="s2">        It can return nothing</span>
<span class="s2">        &quot;&quot;&quot;</span>
        <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">matrix</span> <span class="o">=</span> <span class="s-Atom">matrix</span>

        <span class="s-Atom">n_users</span> <span class="o">=</span> <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">matrix</span><span class="p">.</span><span class="s-Atom">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="s-Atom">n_movies</span> <span class="o">=</span> <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">matrix</span><span class="p">.</span><span class="s-Atom">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="s-Atom">n_already_rated</span> <span class="o">=</span> <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">matrix</span><span class="p">.</span><span class="nf">nonzero</span><span class="p">()[</span><span class="mi">0</span><span class="p">].</span><span class="s-Atom">size</span>
        <span class="s-Atom">user_mat</span> <span class="o">=</span> <span class="s-Atom">np</span><span class="p">.</span><span class="s-Atom">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span>
            <span class="s-Atom">n_users</span><span class="o">*</span><span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">n_features</span><span class="p">).</span><span class="nf">reshape</span><span class="p">([</span><span class="s-Atom">n_users</span><span class="p">,</span> <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">n_features</span><span class="p">])</span>
        <span class="s-Atom">movie_mat</span> <span class="o">=</span> <span class="s-Atom">np</span><span class="p">.</span><span class="s-Atom">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span>
            <span class="s-Atom">n_movies</span><span class="o">*</span><span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">n_features</span><span class="p">).</span><span class="nf">reshape</span><span class="p">([</span><span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">n_features</span><span class="p">,</span> <span class="s-Atom">n_movies</span><span class="p">])</span>


        <span class="s-Atom">optimizer_iteration_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="s-Atom">sse_accum</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="s-Atom">if</span> <span class="s-Atom">self</span><span class="p">.</span><span class="nn">verbose</span><span class="p">:</span>
            <span class="nf">print</span><span class="p">(</span><span class="s2">&quot;Optimizaiton Statistics&quot;</span><span class="p">)</span>
            <span class="nf">print</span><span class="p">(</span><span class="s2">&quot;Iterations | Mean Squared Error  |  Percent Improvement&quot;</span><span class="p">)</span>
        <span class="nf">while</span> <span class="p">(</span><span class="s-Atom">optimizer_iteration_count</span> <span class="o">&lt;</span> <span class="mi">2</span> <span class="nf">or</span> <span class="p">(</span><span class="s-Atom">pct_improvement</span> <span class="o">&gt;</span> <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">optimizer_pct_improvement_criterion</span><span class="p">))</span><span class="s-Atom">:</span>
            <span class="s-Atom">old_sse</span> <span class="o">=</span> <span class="s-Atom">sse_accum</span>
            <span class="s-Atom">sse_accum</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="s-Atom">for</span> <span class="s-Atom">i</span> <span class="s-Atom">in</span> <span class="nf">range</span><span class="p">(</span><span class="s-Atom">n_users</span><span class="p">)</span><span class="s-Atom">:</span>
                <span class="s-Atom">for</span> <span class="s-Atom">j</span> <span class="s-Atom">in</span> <span class="nf">range</span><span class="p">(</span><span class="s-Atom">n_movies</span><span class="p">)</span><span class="s-Atom">:</span>
                    <span class="s-Atom">if</span> <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">matrix</span><span class="p">[</span><span class="s-Atom">i</span><span class="p">,</span> <span class="s-Atom">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="s-Atom">:</span>
                        <span class="s-Atom">error</span> <span class="o">=</span> <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">matrix</span><span class="p">[</span><span class="s-Atom">i</span><span class="p">,</span> <span class="s-Atom">j</span><span class="p">]</span> <span class="o">-</span> <span class="s-Atom">\</span>
                            <span class="s-Atom">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="s-Atom">user_mat</span><span class="p">[</span><span class="s-Atom">i</span><span class="p">,</span> <span class="s-Atom">:</span><span class="p">],</span> <span class="s-Atom">movie_mat</span><span class="p">[</span><span class="s-Atom">:</span><span class="p">,</span> <span class="s-Atom">j</span><span class="p">])</span>
                        <span class="s-Atom">sse_accum</span> <span class="s-Atom">+=</span> <span class="s-Atom">error**</span><span class="mi">2</span>
                        <span class="s-Atom">for</span> <span class="s-Atom">k</span> <span class="s-Atom">in</span> <span class="nf">range</span><span class="p">(</span><span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">n_features</span><span class="p">)</span><span class="s-Atom">:</span>
                            <span class="s-Atom">user_mat</span><span class="p">[</span><span class="s-Atom">i</span><span class="p">,</span> <span class="s-Atom">k</span><span class="p">]</span> <span class="o">=</span> <span class="s-Atom">user_mat</span><span class="p">[</span>
                                <span class="s-Atom">i</span><span class="p">,</span> <span class="s-Atom">k</span><span class="p">]</span> <span class="o">+</span> <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">learning_rate</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="s-Atom">error</span> <span class="o">*</span> <span class="s-Atom">movie_mat</span><span class="p">[</span><span class="s-Atom">k</span><span class="p">,</span> <span class="s-Atom">j</span><span class="p">]</span> <span class="o">-</span> <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">regularization</span> <span class="o">*</span> <span class="s-Atom">user_mat</span><span class="p">[</span><span class="s-Atom">i</span><span class="p">,</span> <span class="s-Atom">k</span><span class="p">])</span>
                            <span class="s-Atom">movie_mat</span><span class="p">[</span><span class="s-Atom">k</span><span class="p">,</span> <span class="s-Atom">j</span><span class="p">]</span> <span class="o">=</span> <span class="s-Atom">movie_mat</span><span class="p">[</span>
                                <span class="s-Atom">k</span><span class="p">,</span> <span class="s-Atom">j</span><span class="p">]</span> <span class="o">+</span> <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">learning_rate</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="s-Atom">error</span> <span class="o">*</span> <span class="s-Atom">user_mat</span><span class="p">[</span><span class="s-Atom">i</span><span class="p">,</span> <span class="s-Atom">k</span><span class="p">]</span> <span class="o">-</span> <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">regularization</span> <span class="o">*</span> <span class="s-Atom">movie_mat</span><span class="p">[</span><span class="s-Atom">k</span><span class="p">,</span> <span class="s-Atom">j</span><span class="p">])</span>
            <span class="s-Atom">pct_improvement</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="p">(</span><span class="s-Atom">old_sse</span> <span class="o">-</span> <span class="s-Atom">sse_accum</span><span class="p">)</span> <span class="o">/</span> <span class="s-Atom">old_sse</span>
            <span class="s-Atom">if</span> <span class="s-Atom">self</span><span class="p">.</span><span class="nn">verbose</span><span class="p">:</span>
                    <span class="nf">print</span><span class="p">(</span><span class="s2">&quot;%d \t\t %f \t\t %f&quot;</span> <span class="c1">% (</span>
                        <span class="s-Atom">optimizer_iteration_count</span><span class="p">,</span> <span class="s-Atom">sse_accum</span> <span class="o">/</span> <span class="s-Atom">n_already_rated</span><span class="p">,</span> <span class="s-Atom">pct_improvement</span><span class="p">))</span>
            <span class="s-Atom">old_sse</span> <span class="o">=</span> <span class="s-Atom">sse_accum</span>
            <span class="s-Atom">optimizer_iteration_count</span> <span class="s-Atom">+=</span> <span class="mi">1</span>

        <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">user_mat</span> <span class="o">=</span> <span class="s-Atom">user_mat</span>
        <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">movie_mat</span> <span class="o">=</span> <span class="s-Atom">movie_mat</span>
        <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">recommendations</span> <span class="o">=</span> <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">user_mat</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">movie_mat</span><span class="p">)</span>

    <span class="s-Atom">def</span> <span class="nf">pred_one_user</span><span class="p">(</span><span class="s-Atom">self</span><span class="p">,</span><span class="s-Atom">index</span><span class="p">)</span><span class="s-Atom">:</span>
        <span class="s2">&quot;&quot;&quot;Returns the predicted rating for a single</span>
<span class="s2">        user.</span>
<span class="s2">        &quot;&quot;&quot;</span>
        <span class="s-Atom">return</span> <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">recommendations</span><span class="p">[</span><span class="s-Atom">index</span><span class="p">]</span>

    <span class="s-Atom">def</span> <span class="nf">pred_all_users</span><span class="p">(</span><span class="s-Atom">self</span><span class="p">)</span><span class="s-Atom">:</span>
        <span class="s2">&quot;&quot;&quot;Returns the predicted rating for all users/items.</span>
<span class="s2">        &quot;&quot;&quot;</span>
        <span class="s-Atom">return</span> <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">recommendations</span>

    <span class="s-Atom">def</span> <span class="nf">top_n_recs</span><span class="p">(</span><span class="s-Atom">self</span><span class="p">,</span><span class="s-Atom">index</span><span class="p">,</span><span class="s-Atom">n</span><span class="p">)</span><span class="s-Atom">:</span>
        <span class="s2">&quot;&quot;&quot;Takes user_id argument and number argument.</span>

<span class="s2">        Returns that number of items with the highest predicted ratings,</span>
<span class="s2">        after removing items that user has already rated.</span>
<span class="s2">        &quot;&quot;&quot;</span>
        <span class="s-Atom">scores</span> <span class="o">=</span> <span class="s-Atom">self</span><span class="p">.</span><span class="s-Atom">matrix</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="s-Atom">:</span><span class="p">].</span><span class="nf">nonzero</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="s-Atom">predictions</span> <span class="o">=</span> <span class="s-Atom">self</span><span class="p">.</span><span class="nf">pred_one_user</span><span class="p">(</span><span class="s-Atom">index</span><span class="p">)</span>
        <span class="s-Atom">predictions</span><span class="p">[</span><span class="s-Atom">scores</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="s-Atom">return</span> <span class="s-Atom">np</span><span class="p">.</span><span class="nf">argsort</span><span class="p">(</span><span class="s-Atom">predictions</span><span class="p">)[</span><span class="s-Atom">::-</span><span class="mi">1</span><span class="p">][</span><span class="s-Atom">:n</span><span class="p">]</span>
</pre></div>


<p>Now we can look at the relative performance and predictions from this morning!</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">SVD</span> <span class="kn">import</span> <span class="n">MatrixFactorizationRecommender</span>
<span class="n">NMF</span> <span class="o">=</span> <span class="n">MatrixFactorizationRecommender</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">NMF</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="k">print</span> <span class="s">&quot;Time to Fit: &quot;</span><span class="p">,</span> <span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">t1</span>

<span class="n">Time</span> <span class="n">to</span> <span class="n">Fit</span><span class="p">:</span>  <span class="mf">51.0261509418</span>
</pre></div>


<p>The fit time is signficantly longer than the Item-Item recommender.  What about predictions.</p>
<div class="highlight"><pre>t1=time()
print &quot;Prediction: &quot;, np.round(NMF.pred_one_user(0)[:10],0)
print &quot;Actual:     &quot;, df.values[0,:10]
print &quot;Time to Predict 1 User: &quot;, time()-t1
t1 = time()
predictions = NMF.pred_all_users()
print &quot;Time to predict 943 Users:&quot;, time()-t1

Prediction:  [ 4.  3.  3.  3.  3.  4.  4.  4.  4.  4.]
Actual:      [ 5.  3.  4.  3.  3.  5.  4.  1.  5.  3.]
Time to Predict 1 User:  0.00182199478149
Time to predict 943 Users: 0.00263500213623
</pre></div>


<p>So in this case the predictions is just the matrix multiplication found in the fit.  It is significantly faster to make predictions.   In fact I cheated by saving the predictions in the class.  This is really just a lookup.</p>
<p>It does seem the predictions are not as good as the Item-Item recommendor.   Lets look at the movie predictions.</p>
<div class="highlight"><pre>idf.loc[NMF.top_n_recs(0,10),:]
</pre></div>


<div style="max-height:1000px;max-width:1500px;overflow:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Title</th>
      <th>Date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1632</th>
      <td>� k�ldum klaka (Cold Fever) (1994)</td>
      <td>08-Mar-1996</td>
    </tr>
    <tr>
      <th>1405</th>
      <td>When Night Is Falling (1995)</td>
      <td>01-Jan-1995</td>
    </tr>
    <tr>
      <th>1458</th>
      <td>Madame Butterfly (1995)</td>
      <td>20-Sep-1996</td>
    </tr>
    <tr>
      <th>1616</th>
      <td>Hugo Pool (1997)</td>
      <td>01-Jan-1997</td>
    </tr>
    <tr>
      <th>1463</th>
      <td>Stars Fell on Henrietta, The (1995)</td>
      <td>01-Jan-1995</td>
    </tr>
    <tr>
      <th>1648</th>
      <td>Big One, The (1997)</td>
      <td>27-Mar-1998</td>
    </tr>
    <tr>
      <th>1583</th>
      <td>Symphonie pastorale, La (1946)</td>
      <td>01-Jan-1946</td>
    </tr>
    <tr>
      <th>1340</th>
      <td>Hedd Wyn (1992)</td>
      <td>01-Jan-1992</td>
    </tr>
    <tr>
      <th>1481</th>
      <td>Gate of Heavenly Peace, The (1995)</td>
      <td>10-May-1996</td>
    </tr>
    <tr>
      <th>1599</th>
      <td>Guantanamera (1994)</td>
      <td>16-May-1997</td>
    </tr>
  </tbody>
</table>
</div>

<p>These are wildly different predictions than this morning.  In order to get a feel for which better we need to come up with a way to validate our strategy. </p>
<h2>Validations</h2>
<p>If this was a uppervised problem, we would make a training and testing set, cross validate on the training set, then measure the error on the test set.  We can do that here by removing rating from the matrix, and checking if which recommendor is making a better predictions on the test set.</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">validation_score</span><span class="p">(</span><span class="n">REC</span><span class="p">,</span><span class="n">frac_row</span><span class="p">,</span> <span class="n">frac_col</span><span class="p">,</span><span class="kp">matrix</span><span class="p">,</span><span class="n">scoring_func</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
    <span class="n">row_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="kp">matrix</span><span class="o">.</span><span class="kp">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="nb">int</span><span class="p">(</span><span class="kp">matrix</span><span class="o">.</span><span class="kp">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">frac_row</span><span class="p">),</span><span class="n">replace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">col_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="kp">matrix</span><span class="o">.</span><span class="kp">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="nb">int</span><span class="p">(</span><span class="kp">matrix</span><span class="o">.</span><span class="kp">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">frac_col</span><span class="p">),</span><span class="n">replace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">matrix_copy</span> <span class="o">=</span> <span class="kp">matrix</span><span class="o">.</span><span class="kp">copy</span><span class="p">()</span>
    <span class="n">matrix_copy</span><span class="p">[</span><span class="n">row_test</span><span class="p">,:][:,</span><span class="n">col_test</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="n">REC</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">matrix_copy</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">REC</span><span class="o">.</span><span class="n">pred_all_users</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">scoring_func</span><span class="p">(</span><span class="kp">matrix</span><span class="p">[</span><span class="n">row_test</span><span class="p">,:][:,</span><span class="n">col_test</span><span class="p">],</span><span class="n">pred</span><span class="p">[</span><span class="n">row_test</span><span class="p">,:][:,</span><span class="n">col_test</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">mse_recommendor</span><span class="p">(</span><span class="n">truth_mat</span><span class="p">,</span> <span class="n">pred_mat</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes mean-squared-error between a sparse and a dense matrix.  Does not include the 0&#39;s from</span>
<span class="sd">        the sparse matrix in computation (treats them as missing)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c">#get mask of non-zero, mean-square of those, divide by count of those</span>
        <span class="n">nonzero_idx</span> <span class="o">=</span> <span class="n">truth_mat</span><span class="o">.</span><span class="kp">nonzero</span><span class="p">()</span>
        <span class="n">mse</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="kp">array</span><span class="p">(</span><span class="n">truth_mat</span><span class="p">[</span><span class="n">nonzero_idx</span><span class="p">]</span> <span class="o">-</span> <span class="n">pred_mat</span><span class="p">[</span><span class="n">nonzero_idx</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="kp">mean</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">mse</span>


<span class="n">IIR</span> <span class="o">=</span> <span class="n">ItemItemRecommender</span><span class="p">(</span><span class="n">neighborhood_size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">validation_score</span><span class="p">(</span><span class="n">IIR</span><span class="p">,</span><span class="mf">0.3</span><span class="p">,</span><span class="mf">0.3</span><span class="p">,</span><span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="p">,</span><span class="n">mse_recommendor</span><span class="p">)</span>




<span class="mf">0.57135223474377161</span>




<span class="n">NMF</span> <span class="o">=</span> <span class="n">MatrixFactorizationRecommender</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">validation_score</span><span class="p">(</span><span class="n">NMF</span><span class="p">,</span><span class="mf">0.3</span><span class="p">,</span><span class="mf">0.3</span><span class="p">,</span><span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="p">,</span><span class="n">mse_recommendor</span><span class="p">)</span>




<span class="mf">0.88865196231368859</span>
</pre></div>


<p>Our mean error on the Item-Item is about half a rating, while the error on the Matrix-Factorization is almost a full rating.   In this case, I will probably go with the Item-Item</p>
<p>The NMF, on the other hand, has a number of turning parameters.  I performed a gridsearch offline, and found parameters that improved the fit.   The way Item-Item is done, this is not possible.   Below is a fit that is much better.</p>
<div class="highlight"><pre>NMF = MatrixFactorizationRecommender(n_features=20,learning_rate=0.01,regularization=0.01)
validation_score(NMF,0.3,0.3,df.values,mse_recommendor)




0.47107202771056506




NMF = MatrixFactorizationRecommender(n_features=20,learning_rate=0.01,regularization=0.01)
NMF.fit(df.values)
idf.loc[NMF.top_n_recs(0,10),:]
</pre></div>


<div style="max-height:1000px;max-width:1500px;overflow:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Title</th>
      <th>Date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>407</th>
      <td>Close Shave, A (1995)</td>
      <td>28-Apr-1996</td>
    </tr>
    <tr>
      <th>1367</th>
      <td>Mina Tannenbaum (1994)</td>
      <td>01-Jan-1994</td>
    </tr>
    <tr>
      <th>510</th>
      <td>Lawrence of Arabia (1962)</td>
      <td>01-Jan-1962</td>
    </tr>
    <tr>
      <th>660</th>
      <td>High Noon (1952)</td>
      <td>01-Jan-1952</td>
    </tr>
    <tr>
      <th>646</th>
      <td>Ran (1985)</td>
      <td>01-Jan-1985</td>
    </tr>
    <tr>
      <th>284</th>
      <td>Secrets &amp; Lies (1996)</td>
      <td>04-Oct-1996</td>
    </tr>
    <tr>
      <th>918</th>
      <td>City of Lost Children, The (1995)</td>
      <td>01-Jan-1995</td>
    </tr>
    <tr>
      <th>477</th>
      <td>Philadelphia Story, The (1940)</td>
      <td>01-Jan-1940</td>
    </tr>
    <tr>
      <th>428</th>
      <td>Day the Earth Stood Still, The (1951)</td>
      <td>01-Jan-1951</td>
    </tr>
    <tr>
      <th>1141</th>
      <td>When We Were Kings (1996)</td>
      <td>14-Feb-1997</td>
    </tr>
  </tbody>
</table>
</div>

<p>We can see the movies recommended by the tuned recommendor are different from before.  They are also, at a glance, much more related to the moviews this user rated.  This improves the recommendor, but the search took over an hour to run, and I have no idea how much better we can make it.</p>
<p>One final note is that we noticed with Matrix-Factorization based recomendors is that when the number of features are low, the highest rated and most rated movies dominate the suggestions.   You haven't seen 'Titatic'?  Watch it!  'Casablanca'?  Watch it!   It defaults to a popularity recommendor instead of a personalized recommendor.   </p>
    </div>
  </div>
  <hr class="separator">
  <div class="col-md-8 col-md-offset-2">
  <div id="disqus_thread">
    <script>
      var disqus_shortname = 'bryansmithphd';
      (function() {
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] ||
         document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
    </script>
    <noscript>
      Please enable JavaScript to view the
      <a href="https://disqus.com/?ref_noscript=bryansmithphd">
        comments powered by Disqus.
      </a>
    </noscript>
    <a href="https://disqus.com" class="dsq-brlink">
      blog comments powered by <span class="logo-disqus">Disqus</span>
    </a>
  </div>
  </div>
  </div>
<footer class="footer">
  <div class="container">
    <p class="text-center">
      Bryan Smith, <a href="" target="_blank"></a> unless otherwise noted.
    </p>
    <div class="text-center">
      Generated by <a href="http://getpelican.com" target="_blank">Pelican</a> with the <a href="http://github.com/nairobilug/pelican-alchemy">alchemy</a> theme.
    </div>
  </div>
</footer> <!-- /.footer -->
  <script src="http://www.bryantravissmith.com/theme/js/jquery.min.js"></script>
  <script src="http://www.bryantravissmith.com/theme/js/bootstrap.min.js"></script>
</body> <!-- 42 -->
<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$$','$$'], ['\\(','\\)']]}
});
</script>
</html>