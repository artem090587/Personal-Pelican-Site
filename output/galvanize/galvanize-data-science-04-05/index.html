<!DOCTYPE html>
<html lang="en">

<head>
      <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="canonical" href="http://www.bryantravissmith.com/galvanize/galvanize-data-science-04-05/index.html" />

    <title>  Bryan Travis Smith, Ph.D &mdash; Galvanize - Week 04 - Day 5
</title>




    <link rel="stylesheet" href="http://www.bryantravissmith.com/theme/css/style.css">

    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-24340005-3', 'auto');
    ga('send', 'pageview');

  </script>

    <meta name="author" content="Bryan Smith">
    <meta name="description" content="Today we covered Profit curves.">
  <meta name="tags" contents="data-science, galvanize, Profit Curves, ">
</head>

<body>
<header class="header">
  <div class="container">
      <div class="header-image pull-left">
        <a class="nodec" href="http://www.bryantravissmith.com"><img src=http://www.bryantravissmith.com/img/bryan.jpeg></a>
      </div>
    <div class="header-inner">
      <h1 class="header-name">
        <a class="nodec" href="http://www.bryantravissmith.com">Bryan Travis Smith, Ph.D</a>
      </h1>
      <h3 class="header-text">Physicist, Data Scientist, Martial Artist, & Life Enthusiast</h3>
      <ul class="header-menu list-inline">
              <li class="muted">|</li>
            <li><a class="nodec" href="http://www.bryantravissmith.com/about/">About</a></li>
              <li class="muted">|</li>
          <li><a class="nodec icon-mail-alt" href="mailto:bryantravissmith@gmail.com"></a></li>
          <li><a class="nodec icon-github" href="https://github.com/bryantravissmith"></a></li>
      </ul>
    </div>
  </div>
</header> <!-- /.header -->  <div class="container">
  <div class="post full-post">
    <h1 class="post-title">
      <a href="/galvanize/galvanize-data-science-04-05/" title="Permalink to Galvanize - Week 04 - Day 5">Galvanize - Week 04 - Day 5</a>
    </h1>
    <ul class="list-inline">
      <li class="post-date">
        <a class="text-muted" href="/galvanize/galvanize-data-science-04-05/" title="2015-06-26T10:20:00-07:00">Fri 26 June 2015</a>
      </li>
      <li class="muted">&middot;</li>
      <li class="post-category">
        <a href="http://www.bryantravissmith.com/category/galvanize.html">Galvanize</a>
      </li>
        <li class="muted">&middot;</li>
        <li>
          <address class="post-author">
            By <a href="http://www.bryantravissmith.com/author/bryan-smith.html">Bryan Smith</a>
          </address>
        </li>
    </ul>
    <div class="post-content">
      <h1>Galvanize Immersive Data Science</h1>
<h2>Week 4 - Day 5</h2>
<p>Today we had an accessment on regression and classification methods we have covered the prevous two weeks.  It was a conceptional test, making sure we understood the underlying models and their applications.  </p>
<p>We then had a lecture on blogging.  Personally, I did not appreciate it.   I am obviously already blogging about what I am doing at Galvanize, but I also did not appreciate the frame given to the presentation: "I know you don't want to do this, but..."  It reminds me that we can all take issues based on attributes of an interaction that are not content based.  Good to be reminded of this going forward.</p>
<h2>Profit Curves</h2>
<p>The afternoon sprint was on a profit curves.  You and read about them from chapter 8 of <a href="http://www.amazon.com/Data-Science-Business-data-analytic-thinking/dp/1449361323">Data Science For Business</a>.   </p>
<p>The goal of the assignment is to define a cost-benefit matrix for a business problem.  An example from the book involves calculating Lift, the increase in conversions.</p>
<p>$$ \left( \begin{array}{cc}  TP &amp; FP \ FN &amp; TN \end{array} \right) =&gt; \left( \begin{array}{cc}  4 &amp; -5 \ 0 &amp; 0 \end{array} \right) $$</p>
<p>In this case if we correct identify someone who will convert, we can spend mondy to convert them and make 5 dollars.   On the other hand, if we have a false positive and invest in someone who will not convert, we lose the 5 dollars of cost.   </p>
<p>If we do not predict someone to churn, we do not assume any cost.  But we also do not make any profit.   </p>
<p>In this case the best model will maximize True Positive and Minimize False Positives.   It needs high precisions, but not necessarily hight accuracy or recall.</p>
<p>The data set we are working with today is a cell phone dataset of users that churned.  We will start with the obligitory cleaning.   Since we have worked with this dataset before I will not be exploring it.  </p>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>

<span class="n">churn</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">&#39;data/churn.csv&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">&#39;State&#39;</span><span class="p">,</span><span class="s">&#39;Area Code&#39;</span><span class="p">,</span><span class="s">&#39;Phone&#39;</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">churn</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s">&#39;yes&#39;</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">churn</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s">&#39;no&#39;</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">churn</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s">&#39;False.&#39;</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">churn</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s">&#39;True.&#39;</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">churn</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>


<div style="max-height:1000px;max-width:1500px;overflow:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Account Length</th>
      <th>Int'l Plan</th>
      <th>VMail Plan</th>
      <th>VMail Message</th>
      <th>Day Mins</th>
      <th>Day Calls</th>
      <th>Day Charge</th>
      <th>Eve Mins</th>
      <th>Eve Calls</th>
      <th>Eve Charge</th>
      <th>Night Mins</th>
      <th>Night Calls</th>
      <th>Night Charge</th>
      <th>Intl Mins</th>
      <th>Intl Calls</th>
      <th>Intl Charge</th>
      <th>CustServ Calls</th>
      <th>Churn?</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>128</td>
      <td>1</td>
      <td>1</td>
      <td>25</td>
      <td>265.1</td>
      <td>110</td>
      <td>45.07</td>
      <td>197.4</td>
      <td>99</td>
      <td>16.78</td>
      <td>244.7</td>
      <td>91</td>
      <td>11.01</td>
      <td>10.0</td>
      <td>3</td>
      <td>2.70</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>107</td>
      <td>1</td>
      <td>1</td>
      <td>26</td>
      <td>161.6</td>
      <td>123</td>
      <td>27.47</td>
      <td>195.5</td>
      <td>103</td>
      <td>16.62</td>
      <td>254.4</td>
      <td>103</td>
      <td>11.45</td>
      <td>13.7</td>
      <td>3</td>
      <td>3.70</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>137</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>243.4</td>
      <td>114</td>
      <td>41.38</td>
      <td>121.2</td>
      <td>110</td>
      <td>10.30</td>
      <td>162.6</td>
      <td>104</td>
      <td>7.32</td>
      <td>12.2</td>
      <td>5</td>
      <td>3.29</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>84</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>299.4</td>
      <td>71</td>
      <td>50.90</td>
      <td>61.9</td>
      <td>88</td>
      <td>5.26</td>
      <td>196.9</td>
      <td>89</td>
      <td>8.86</td>
      <td>6.6</td>
      <td>7</td>
      <td>1.78</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>75</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>166.7</td>
      <td>113</td>
      <td>28.34</td>
      <td>148.3</td>
      <td>122</td>
      <td>12.61</td>
      <td>186.9</td>
      <td>121</td>
      <td>8.41</td>
      <td>10.1</td>
      <td>3</td>
      <td>2.73</td>
      <td>3</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

<div class="highlight"><pre>y = churn.pop(&quot;Churn?&quot;).values
x = churn.values
</pre></div>


<p>Because we are dealing with a cell phone companies, the model is different.   I wil fillow suit with the Data Science For Buisness example and not worry about the fixed cost of the business.  Instead we will make a simple model that if we correcy identify someone who will churn then we will invest and make a profit.  If we incorrectly predict someone is going to churn and invest in keeping them, we lose the investment of cost.  </p>
<p>$$ \mbox{Profit Matrix} = \left( \begin{array}{cc}  80 &amp; -20 \ 0 &amp; 0 \end{array} \right)$$</p>
<div class="highlight"><pre>profit_matrix = np.array([[80,-20],[0,0]])
</pre></div>


<p>The profit for a sample of uses will change if the total number of users changes.  For this reason we need make a rate to estimate the average profit per user.   We will have some model with a confusion matrix, and we will want to convert it a rate:</p>
<p>$$ \left( \begin{array}{cc}  TP &amp; FP \ FN &amp; TN \end{array} \right) =&gt; \left( \begin{array}{cc}  \frac{TP}{TP+FP} &amp; \frac{FN}{FN+TN} \ \frac{FP}{TP+FP} &amp; \frac{TN}{FN+TN} \end{array} \right) $$</p>
<p>This will allow us to get a feel for the acutal rate of misclassification and correct classification in the populations we are concerned with if we know the population proportions $P_+$ and $P_-$.</p>
<p>$$ \left( \begin{array}{cc}  \frac{TP}{TP+FP} \ P_+ &amp; \frac{FN}{FN+TN} \ P_- \ \frac{FP}{TP+FP} \ P_+ &amp; \frac{TN}{FN+TN} \ P_- \end{array} \right)$$</p>
<p>In our dataset we have approximately 14% churn rate.  We can check that in the two extreams what will happen.   </p>
<p>If our model predicts that everyone will churn, our confusion matrix and rate look like:</p>
<p>$$ \left( \begin{array}{cc}  N_+ &amp; N_- \ 0 &amp; 0 \end{array} \right) =&gt; \left( \begin{array}{cc}  1 &amp; 1 \ 0 &amp; 0 \end{array} \right) $$</p>
<p>Since our $P_+ = .14$ and our $P_- = 0.86$, we have the error rate that looks like:</p>
<p>$$\left( \begin{array}{cc}  .14 &amp; .86 \ 0 &amp; 0 \end{array} \right) $$</p>
<p>The element wise multipication with our cost matrix gives:</p>
<p>$$\left( \begin{array}{cc}  11.2 &amp; -17.2 \ 0 &amp; 0 \end{array} \right) $$</p>
<p>We sum all the elements of this matrix together to get the expected profit:</p>
<p>$$E[\mbox{Profit}] = 11.2 - 17.2 + 0 + 0 = -6$$</p>
<p>This is obviously a bad strategy.  If we look at the other extreme and guess no one will churn we get the following results</p>
<p>$$ \left( \begin{array}{cc}  0 &amp; 0 \ N+ &amp; N- \end{array} \right) =&gt; \left( \begin{array}{cc}  0 &amp; 0 \ 1 &amp; 1 \end{array} \right) $$</p>
<p>$$\left( \begin{array}{cc}  0 &amp; 0 \  .14 &amp; .86  \end{array} \right) $$</p>
<p>The element wise multipication with our cost matrix gives:</p>
<p>$$\left( \begin{array}{cc}  0 &amp; 0 \ 0 &amp; 0 \end{array} \right) $$</p>
<p>$$E[\mbox{Profit}] = 0 + 0 + 0 + 0 = 0$$ </p>
<p>So we have two extreme predictions.  One where we lose money, and one where we do not make a profit.   The idea is that if we can make smart prediction about who will churn and who will not churn, we can target our spending in the right places.   That will allow us to maximize our profit.   The smarter the predictions in terms of this problem and population, the better the results.  </p>
<h2>Smart Classifiers</h2>
<p>We are going to make somem smart predictors.  By smart I mean genertic, untuned, machine learning algorithms.   We will try a Logistic Regression, Support Vector Machine, Random Forest, Gradient Boosting, and AdaBoost methods and compare their results.</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span><span class="p">,</span> <span class="n">AdaBoostClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">smart_classifiers</span> <span class="o">=</span> <span class="p">[</span><span class="n">LogisticRegression</span><span class="p">(),</span><span class="n">SVC</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span><span class="n">GradientBoostingClassifier</span><span class="p">(),</span> <span class="n">RandomForestClassifier</span><span class="p">(),</span> <span class="n">AdaBoostClassifier</span><span class="p">()]</span>
</pre></div>


<p>Because sklearn's confusion matrix calculation is in a different format that I was expecting, we built a helper function to calculate the rate and format it into the form we were expencting</p>
<div class="highlight"><pre>def confusion_rates(matrix):
    new = np.zeros(matrix.shape)
    new[0,0] = matrix[1,1]
    new[1,1] = matrix[0,0]
    new[1,0] = matrix[1,0]
    new[0,1] = matrix[0,1]
    return new.astype(float)/np.sum(new,axis=0)

confusion_rates(np.array([[94,6],[96,4]]))




array([[ 0.04,  0.06],
       [ 0.96,  0.94]])
</pre></div>


<h2>Profit Curves Theory</h2>
<p>The idea behind the profit curves we are producing is that each classifier is fitted to training data.   Then test data is given to the classifier, the classifier predicts if it is a positive example or negative example.   The classifieres we are testing also estimate how strongly the algorithm believes each instance is a positive example (or negative example).    </p>
<p>We can now take the strength of these believes and asked the question:  If we only take the test example with the strongest belief as a positive example, and guess that all other test examples as negative example, how profitable is this. We should get something close to zero in our churn example.</p>
<p>We can then ask the question for the two strongest predictions, then the three strongest predictions, and so on.  We do this until we just guess everything is a positive example.   That would lead us back to the -6 dollar profits in our churn model.  </p>
<h3>Example</h3>
<p>$$truth = [1, \ 1, \ 0, \ 0, \ 1]$$
$$ \mbox{model 1} = [0.9, \ 0.4, \ 0.2, \ 0.8, \ 0.7] $$
$$\mbox{model 2} = [0.8, \ 0.7, \ 0.2, \ 0.3, \ 0.6] $$</p>
<p>Model 1 and Model 2 have the same strongest predictor, so we would precict the following for our first question:</p>
<p>$$ \mbox{model 1} = [1, \ 0, \ 0, \ 0, \ 0]$$
$$ \mbox{model 2} = [1, \ 0, \ 0, \ 0, \ 0]$$</p>
<p>Leading to the confusion matrix:</p>
<p>$$ \left( \begin{array}{cc}  1 &amp; 0 \ 2 &amp; 1 \end{array} \right) =&gt; \left( \begin{array}{cc}  0.33 &amp; 0 \ 0.67 &amp; 1 \end{array} \right) $$</p>
<p>We have the proportion of positive examples $P_+ = 0.6$ and $P_- = 0.4$.  That leads to the classification rates of:</p>
<p>$$\left( \begin{array}{cc}  0.2 &amp; 0 \ 0.4 &amp; 0.4 \end{array} \right) $$</p>
<p>Using the cost matrix from the Data Science for Business School of 4 dollars profit for true positives and -5 dollars profit for false positives we get a profit matrix of:</p>
<p>$$\left( \begin{array}{cc}  0.8 &amp; 0 \ 0 &amp; 0 \end{array} \right) $$</p>
<p>For if we only take the strongest predictor we expect an average profit of 0.8 per costomer for both models.</p>
<p>$$E(\mbox{Profit}) = 0.8 + 0 + 0 + 0 = 0.8$$</p>
<p>We can now ask the second question of what is the expected profit if we take two two strongest predictors.  In this case we have the following predecitions:</p>
<p>$$ \mbox{model 1} = [1, \ 0, \ 0, \ 1, \ 0]$$
$$ \mbox{model 2} = [1, \ 1, \ 0, \ 0, \ 0]$$</p>
<p>Now the two models make different predictions!</p>
<p>The confusion matrix for model 1 (left) and model 2 (right) right are next. </p>
<p>$$ \left( \begin{array}{cc}  1 &amp; 1 \ 2 &amp; 1 \end{array} \right) \ ,  \ \left( \begin{array}{cc}  2 &amp; 0 \ 1 &amp; 2 \end{array} \right) $$</p>
<p>The rate matrixes become:</p>
<p>$$ \left( \begin{array}{cc}  0.33 &amp; .5 \ .67 &amp; .5 \end{array} \right) \ , \ \left( \begin{array}{cc}  0.67 &amp; 0 \ 0.33 &amp; 1 \end{array} \right) $$</p>
<p>The population proportions have not changed. The proportion of positive examples $P_+ = 0.6$ and $P_- = 0.4$. </p>
<p>$$\left( \begin{array}{cc}  0.2 &amp; 0.2 \ 0.4 &amp; 0.2 \end{array} \right) \ , \ \left( \begin{array}{cc}  0.4 &amp; 0 \ 0.2 &amp; 0.4 \end{array} \right) $$</p>
<p>That then makes the final profit matrix look like:</p>
<p>$$\left( \begin{array}{cc}  0.8 &amp; -1 \ 0 &amp; 0 \end{array} \right) \ , \ \left( \begin{array}{cc}  1.6 &amp; 0 \ 0 &amp; 0 \end{array} \right)  $$</p>
<p>Now there is a clear difference in the models if we take the two strongest predictors.</p>
<p>$$E(\mbox{Profit Model 1}) = 0.8 + -1 + 0 + 0 = -0.2$$</p>
<p>$$E(\mbox{Profit Model 2}) = 1.6 + 0 + 0 + 0 = 1.6$$</p>
<p>Model 2 is much better model if we limit ourselves to the two strongest predictions.  To find the most profitable model, we should conditinue to do these calcuations.  Becausse they are so repetative, its time for some automation</p>
<h2>Plotting Profit Curves</h2>
<div class="highlight"><pre><span class="s-Atom">def</span> <span class="nf">profit_curve</span><span class="p">(</span><span class="s-Atom">classifiers</span><span class="p">,</span> <span class="s-Atom">cb</span><span class="p">,</span> <span class="s-Atom">x</span><span class="p">,</span> <span class="s-Atom">y</span><span class="p">)</span><span class="s-Atom">:</span>
    <span class="s-Atom">#split</span> <span class="s-Atom">data</span> <span class="s-Atom">into</span> <span class="s-Atom">a</span> <span class="s-Atom">training</span> <span class="s-Atom">and</span> <span class="s-Atom">test</span> <span class="s-Atom">set</span>
    <span class="s-Atom">x_train</span><span class="p">,</span><span class="s-Atom">x_test</span><span class="p">,</span><span class="s-Atom">y_train</span><span class="p">,</span><span class="s-Atom">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="s-Atom">x</span><span class="p">,</span><span class="s-Atom">y</span><span class="p">,</span><span class="s-Atom">test_size</span><span class="o">=</span><span class="mf">0.35</span><span class="p">)</span>

    <span class="s-Atom">#get</span> <span class="s-Atom">the</span> <span class="s-Atom">true</span> <span class="s-Atom">proportions</span> <span class="s-Atom">in</span> <span class="s-Atom">the</span> <span class="s-Atom">test</span> <span class="s-Atom">set</span>
    <span class="s-Atom">p_pos</span> <span class="o">=</span> <span class="s-Atom">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="s-Atom">y_test</span><span class="o">==</span><span class="mi">1</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="s-Atom">float</span><span class="p">)</span><span class="o">/</span><span class="nf">len</span><span class="p">(</span><span class="s-Atom">y_test</span><span class="p">)</span>
    <span class="s-Atom">p_neg</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="s-Atom">p_pos</span>

    <span class="s-Atom">#scale</span> <span class="s-Atom">the</span> <span class="s-Atom">training</span> <span class="s-Atom">data</span> <span class="o">-</span> <span class="s-Atom">important</span> <span class="s-Atom">for</span> <span class="s-Atom">some</span> <span class="s-Atom">classifiers</span> <span class="s-Atom">and</span> <span class="s-Atom">to</span> <span class="s-Atom">get</span> <span class="s-Atom">consistent</span> <span class="s-Atom">results</span>
    <span class="s-Atom">s</span> <span class="o">=</span> <span class="nv">StandardScaler</span><span class="p">()</span>
    <span class="s-Atom">xtrn</span> <span class="o">=</span> <span class="s-Atom">s</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="s-Atom">x_train</span><span class="p">)</span>
    <span class="s-Atom">xtst</span> <span class="o">=</span> <span class="s-Atom">s</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="s-Atom">x_test</span><span class="p">)</span>

    <span class="s-Atom">for</span> <span class="s-Atom">c</span> <span class="s-Atom">in</span> <span class="nn">classifiers</span><span class="p">:</span>
        <span class="s-Atom">prob</span> <span class="o">=</span> <span class="s-Atom">c</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="s-Atom">xtrn</span><span class="p">,</span><span class="s-Atom">y_train</span><span class="p">).</span><span class="nf">predict_proba</span><span class="p">(</span><span class="s-Atom">xtst</span><span class="p">)[</span><span class="s-Atom">:</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>

        <span class="s-Atom">#</span><span class="nv">Get</span> <span class="s-Atom">the</span> <span class="s-Atom">indexes</span> <span class="s-Atom">of</span> <span class="s-Atom">the</span> <span class="s-Atom">data</span> <span class="s-Atom">most</span> <span class="s-Atom">likely</span> <span class="s-Atom">to</span> <span class="s-Atom">be</span> <span class="s-Atom">positive</span>
        <span class="s-Atom">indicies</span> <span class="o">=</span> <span class="s-Atom">np</span><span class="p">.</span><span class="nf">argsort</span><span class="p">(</span><span class="s-Atom">prob</span><span class="p">)[</span><span class="s-Atom">::-</span><span class="mi">1</span><span class="p">]</span>
        <span class="s-Atom">costs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="s-Atom">x_axis</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="s-Atom">#</span><span class="nv">For</span> <span class="s-Atom">each</span> <span class="s-Atom">data</span> <span class="s-Atom">point</span>
        <span class="s-Atom">for</span> <span class="s-Atom">i</span> <span class="s-Atom">in</span> <span class="nn">indicies</span><span class="p">:</span>

            <span class="s-Atom">#predict</span> <span class="s-Atom">the</span> <span class="s-Atom">all</span> <span class="s-Atom">probabilities</span> <span class="s-Atom">above</span> <span class="s-Atom">the</span> <span class="s-Atom">ith</span> <span class="s-Atom">strongest</span> <span class="s-Atom">predicters</span> <span class="o">is</span> <span class="s-Atom">positive</span><span class="p">,</span> <span class="s-Atom">else</span> <span class="s-Atom">negative</span>
            <span class="s-Atom">y_pred</span> <span class="o">=</span> <span class="p">(</span><span class="s-Atom">prob</span> <span class="o">&gt;</span> <span class="s-Atom">prob</span><span class="p">[</span><span class="s-Atom">i</span><span class="p">]).</span><span class="nf">astype</span><span class="p">(</span><span class="s-Atom">int</span><span class="p">)</span>

            <span class="s-Atom">#calculate</span> <span class="s-Atom">the</span> <span class="s-Atom">confusion</span> <span class="s-Atom">matrix</span> <span class="s-Atom">for</span> <span class="s-Atom">the</span> <span class="s-Atom">predictions</span>
            <span class="s-Atom">matrix</span> <span class="o">=</span> <span class="nf">confusion_rates</span><span class="p">(</span><span class="nf">confusion_matrix</span><span class="p">(</span><span class="s-Atom">y_test</span><span class="p">,</span><span class="s-Atom">y_pred</span><span class="p">))</span>
            <span class="s-Atom">#matrix</span> <span class="o">=</span> <span class="s-Atom">np</span><span class="p">.</span><span class="nf">nan_to_num</span><span class="p">(</span><span class="s-Atom">matrix</span><span class="p">)</span>

            <span class="s-Atom">#calculate</span> <span class="s-Atom">the</span> <span class="s-Atom">cost</span> <span class="s-Atom">matrix</span> <span class="s-Atom">through</span> <span class="s-Atom">element</span> <span class="s-Atom">wise</span> <span class="s-Atom">product</span> <span class="s-Atom">and</span> <span class="s-Atom">sum</span>
            <span class="s-Atom">cost</span> <span class="o">=</span> <span class="s-Atom">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">((</span><span class="s-Atom">matrix</span><span class="o">*</span><span class="s-Atom">cb</span><span class="p">).</span><span class="nf">dot</span><span class="p">(</span><span class="s-Atom">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="s-Atom">p_pos</span><span class="p">],[</span><span class="s-Atom">p_neg</span><span class="p">]])))</span>

            <span class="s-Atom">#append</span> <span class="s-Atom">the</span> <span class="s-Atom">cost</span> <span class="s-Atom">and</span> <span class="s-Atom">proportion</span> <span class="s-Atom">of</span> <span class="s-Atom">test</span> <span class="s-Atom">predictions</span> <span class="s-Atom">we</span> <span class="s-Atom">set</span> <span class="s-Atom">positive</span>
            <span class="s-Atom">x_axis</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="s-Atom">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="s-Atom">y_pred</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="s-Atom">float</span><span class="p">)</span><span class="o">/</span><span class="nf">len</span><span class="p">(</span><span class="s-Atom">y_pred</span><span class="p">))</span>
            <span class="s-Atom">costs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="s-Atom">cost</span><span class="p">)</span>

        <span class="s-Atom">p</span> <span class="o">=</span> <span class="s-Atom">prob</span><span class="p">[</span><span class="s-Atom">indicies</span><span class="p">[</span><span class="s-Atom">np</span><span class="p">.</span><span class="nf">argsort</span><span class="p">(</span><span class="s-Atom">costs</span><span class="p">)[</span><span class="s-Atom">::-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]]]</span>

        <span class="s-Atom">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="s-Atom">x_axis</span><span class="p">,</span> <span class="s-Atom">costs</span><span class="p">,</span> <span class="s-Atom">label</span><span class="o">=</span><span class="s-Atom">c</span><span class="p">.</span><span class="k">__</span><span class="s-Atom">class__</span><span class="p">.</span><span class="k">__</span><span class="s-Atom">name__</span><span class="p">)</span>



<span class="s-Atom">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="s-Atom">figsize=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">14</span><span class="p">))</span>
<span class="nf">profit_curve</span><span class="p">(</span><span class="s-Atom">smart_classifiers</span><span class="p">,</span><span class="s-Atom">profit_matrix</span><span class="p">,</span><span class="s-Atom">x</span><span class="p">,</span> <span class="s-Atom">y</span><span class="p">)</span>
<span class="s-Atom">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="s-Atom">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="s-Atom">&#39;Expected Profit Rate&#39;</span><span class="p">)</span>
<span class="s-Atom">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="s-Atom">&#39;% Test Predictions Set Positive&#39;</span><span class="p">)</span>
<span class="s-Atom">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="http://www.bryantravissmith.com/img/GW04D5/output_14_0.png" /></p>
<h2>Analysis</h2>
<p>The plots we have generated match our intuition we developed.  If we do not guess anyone churns (left), then we expect the profit to be zero.   If we guess everyone churns (right), we expect the profit to be -6.  The acutal value is different be the actual proportion in the test set is different from 14%.  Inbetween we are using smart classifier to predict who will churn and who will not churn.  Even the worst model leads to some profitability, which is promising for our cell phone company.   </p>
<p>The best model, in this trial, is the GradientBoostingClassifier, followed closely by the Support Vector Machine and Randome Forest.  The peak profitability for all the models seem to be taking the 18% of strongest predictors in the models.  </p>
<div class="highlight"><pre>x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.35)

#Prediction Probabilities on the test set
probs = GradientBoostingClassifier().fit(x_train,y_train).predict_proba(x_test)[:,1]

#class probabilities ~ [.14,.86]
class_prob = np.array([sum(y_test).astype(float)/len(y_test), sum(y_test==0).astype(float)/len(y_test) ])

#get the cutoff for the tope 18%, 100-18 - 82
percentile = np.percentile(probs,82)
print &quot;If probabibility is larger than this predict Churn:&quot;, percentile
y_pred = (probs &gt;= percentile).astype(int)
rates = confusion_rates(confusion_matrix(y_test,y_pred))

print &quot;Predicted Profit Rate:&quot;, np.sum(rates*class_prob*profit_matrix)

print &quot;% Costomers Affected/Targed, %of Correct Costomers:&quot;, np.sum((rates*class_prob)[0]),(rates*class_prob)[0,0]

If probabibility is larger than this predict Churn: 0.184275129582
Predicted Profit Rate: 6.51242502142
% Costomers Affected/Targed, %of Correct Costomers: 0.179948586118 0.101113967438
</pre></div>


<p>For our gradient model we will predict a costomer to be likely churn if their prediciton probability is above 0.18, and we have expected profit rate of $6.5/prediction.   We estimate that we will target approximately 18% of our costomers using this model, with 10% of them being the group we want to target.</p>
<p>If we have an unlimited budget, or a budget larger than the cost of targeting every costomer, then we would choose this model.  </p>
<p>If we have a limited budget that want to be profitable (near term) but are willing to not persue maximal profit to reach the largest number of customers and reduce churn, then we will want a differnet strategy.  Because the cost of targeting a customer is fixed, we will want to optimize precision by moving to the left of the graph.  In our case of the cell phone churn, the the top models move in lock-step.   </p>
<p>We would just increase the threshold for our GradientBoostedClassifier.  If we increase the threshold to be the top 10% of predictions instead of the top 18%, we get reduce profitability but increase targeting rate.</p>
<div class="highlight"><pre>#Prediction Probabilities on the test set
probs = GradientBoostingClassifier().fit(x_train,y_train).predict_proba(x_test)[:,1]

#class probabilities ~ [.14,.86]
class_prob = np.array([sum(y_test).astype(float)/len(y_test), sum(y_test==0).astype(float)/len(y_test) ])

#get the cutoff for the tope 18%, 100-18 - 82
percentile = np.percentile(probs,92)
print &quot;If probabibility is larger than this predict Churn:&quot;, percentile
y_pred = (probs &gt;= percentile).astype(int)
rates = confusion_rates(confusion_matrix(y_test,y_pred))

print &quot;Predicted Profit Rate:&quot;, np.sum(rates*class_prob*profit_matrix)

print &quot;% Costomers Affected/Targed, %of Correct Costomers:&quot;, np.sum((rates*class_prob)[0]),(rates*class_prob)[0,0]

If probabibility is larger than this predict Churn: 0.5623562992
Predicted Profit Rate: 5.8440445587
% Costomers Affected/Targed, %of Correct Costomers: 0.0805484147386 0.0745501285347
</pre></div>


<p>Here, our expected profit drops to 5.8 from 6.5, and our threshold is increased to 0.56.   What we like to see is now we are only targeting 8% of our customers, but 7.5% of them are the ones we want to target.  That takes our precision to approximately 93% from 56%.  We are not getting the most profit, but we are spending our money in the most targeted way in this campaign.  If we know what percentage of our customers we can target with our budget, we can move down the curve and clacluate our expected results.  </p>
<div class="highlight"><pre>10.1/17.99, 0.07455/0.08055




(0.5614230127848805, 0.9255121042830541)
</pre></div>
    </div>
  </div>
  <hr class="separator">
  <div class="col-md-8 col-md-offset-2">
  <div id="disqus_thread">
    <script>
      var disqus_shortname = 'bryansmithphd';
      (function() {
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] ||
         document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
    </script>
    <noscript>
      Please enable JavaScript to view the
      <a href="https://disqus.com/?ref_noscript=bryansmithphd">
        comments powered by Disqus.
      </a>
    </noscript>
    <a href="https://disqus.com" class="dsq-brlink">
      blog comments powered by <span class="logo-disqus">Disqus</span>
    </a>
  </div>
  </div>
  </div>
<footer class="footer">
  <div class="container">
    <p class="text-center">
      Bryan Smith, <a href="" target="_blank"></a> unless otherwise noted.
    </p>
    <div class="text-center">
      Generated by <a href="http://getpelican.com" target="_blank">Pelican</a> with the <a href="http://github.com/nairobilug/pelican-alchemy">alchemy</a> theme.
    </div>
  </div>
</footer> <!-- /.footer -->
  <script src="http://www.bryantravissmith.com/theme/js/jquery.min.js"></script>
  <script src="http://www.bryantravissmith.com/theme/js/bootstrap.min.js"></script>
</body> <!-- 42 -->
<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$$','$$'], ['\\(','\\)']]}
});
</script>
</html>